demos: (120, 50, 8)
demo_rewards: (120,)
[-50.0022206  -48.82373914 -47.15605336 -46.19619105 -45.59422709
 -45.36842966 -45.19068756 -44.1649084  -44.07830313 -43.99355529
 -43.86306534 -43.84874807 -43.84199129 -43.80638567 -43.80581986
 -42.75947674 -42.66316469 -42.33177225 -41.77496339 -41.41006807
 -41.17786296 -40.72352042 -40.52718976 -40.49595848 -40.42938988
 -40.05653451 -39.59232358 -39.54162101 -39.19523747 -39.17238958
 -38.51095963 -38.44726577 -38.39210704 -38.0074535  -37.46482489
 -37.10988161 -34.27116724 -34.14139118 -33.26307273 -33.13344797
 -33.07825234 -33.03213148 -32.44934973 -32.40079781 -32.40063926
 -30.73440379 -30.57151372 -30.1312365  -29.99326723 -29.66908259
 -29.29723351 -29.28889042 -29.14587835 -28.49601894 -28.49202366
 -28.31596147 -27.12111057 -26.0645326  -25.52052428 -25.27101421
 -25.06664428 -24.92584938 -24.18810567 -23.48479966 -23.15394356
 -22.9547303  -22.74124885 -22.73927354 -22.26494505 -22.15569724
 -21.05592093 -20.54335656 -20.33499634 -20.18157658 -19.5814441
 -19.37722575 -19.24313562 -19.06062023 -18.96412452 -18.44896231
 -17.74072202 -16.8588937  -16.33811941 -14.53589256 -14.44367057
 -14.20041301 -13.93697618 -13.86225304 -13.48309853 -13.45589275
 -13.35586828 -12.27851524 -12.22738746 -12.02071783 -11.9100948
 -11.40028402 -11.13461816 -10.85916692  -9.59513796  -9.28992161
  -8.23087707  -7.88236324  -7.64789842  -7.45962324  -7.12435731
  -7.05379066  -6.8530911   -6.62113845  -6.49455522  -6.11735418
  -6.0870551   -5.43500832  -5.10529174  -4.62864941  -4.47103119
  -4.45550478  -4.28054982  -3.79447357  -2.95124385  -2.54161816]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=8, out_features=1, bias=False)
)
Total number of parameters: 8
Number of trainable paramters: 8
device: cuda:0
end of epoch 0: val_loss 0.01616788294543781, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-4.8628e-05, -9.9745e-05, -4.4518e-04,  2.7749e-04, -7.3105e-02,
          8.4035e-05,  8.3685e-05, -1.3369e+00]], device='cuda:0'))])
end of epoch 1: val_loss 0.014169608594732175, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.1696e-02,  8.4322e-03,  6.2542e-03,  2.6699e-02, -2.1580e-02,
         -1.4499e-03, -1.5445e-03, -1.5656e+00]], device='cuda:0'))])
end of epoch 2: val_loss 0.01607517595159063, val_acc 0.99
trigger times: 1
end of epoch 3: val_loss 0.03443729676819327, val_acc 0.99
trigger times: 2
end of epoch 4: val_loss 0.23119619003403166, val_acc 0.935
trigger times: 3
end of epoch 5: val_loss 0.4284356134374639, val_acc 0.88
trigger times: 4
end of epoch 6: val_loss 0.3753457349944438, val_acc 0.91
trigger times: 5
end of epoch 7: val_loss 0.01628979124854528, val_acc 1.0
trigger times: 6
end of epoch 8: val_loss 0.0881519101139208, val_acc 0.955
trigger times: 7
end of epoch 9: val_loss 0.02922228698144302, val_acc 0.98
trigger times: 8
end of epoch 10: val_loss 0.016997773181837914, val_acc 0.985
trigger times: 9
end of epoch 11: val_loss 0.009832434623365992, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-5.3142e-03, -1.7481e-02,  2.6648e-03,  1.7088e-02, -1.1679e-01,
          1.1339e-05, -1.0118e-03, -1.8545e+00]], device='cuda:0'))])
end of epoch 12: val_loss 0.020360729404014677, val_acc 0.99
trigger times: 1
end of epoch 13: val_loss 0.5572138248393208, val_acc 0.91
trigger times: 2
end of epoch 14: val_loss 0.010680629625357128, val_acc 1.0
trigger times: 3
end of epoch 15: val_loss 3.137050309163068, val_acc 0.695
trigger times: 4
end of epoch 16: val_loss 0.031347613381771854, val_acc 0.99
trigger times: 5
end of epoch 17: val_loss 0.0222674166727948, val_acc 0.98
trigger times: 6
end of epoch 18: val_loss 0.11704247817182584, val_acc 0.98
trigger times: 7
end of epoch 19: val_loss 0.04929657407675908, val_acc 0.985
trigger times: 8
end of epoch 20: val_loss 0.35012685478743255, val_acc 0.875
trigger times: 9
end of epoch 21: val_loss 0.01193736664073768, val_acc 0.99
trigger times: 10
Early stopping.
0 -31.284745641052723 -50.00222059884506
1 -23.48141337931156 -48.823739140882175
2 -22.95987492054701 -47.15605336419176
3 -22.832209944725037 -46.19619104961985
4 -30.85935813188553 -45.594227093057754
5 -27.088304549455643 -45.36842966452394
6 -33.0484639108181 -45.19068756322445
7 -23.942141458392143 -44.16490839583478
8 -17.77630315721035 -44.078303125872196
9 -27.04754677787423 -43.993555290419714
10 -17.46178250387311 -43.86306534422809
11 -27.66941182129085 -43.84874807044028
12 -25.415930062532425 -43.84199129025074
13 -16.69036029279232 -43.806385671938365
14 -15.691166371107101 -43.80581985978556
15 -19.664412066340446 -42.7594767358323
16 -15.760311022400856 -42.66316468983175
17 -24.803153604269028 -42.33177224591743
18 -23.539515793323517 -41.774963389485094
19 -23.50744530558586 -41.410068073767725
20 -24.29369656741619 -41.17786296442943
21 -20.028679572045803 -40.723520424948155
22 -25.010321617126465 -40.527189756101116
23 -23.620165824890137 -40.49595848244517
24 -25.563071832060814 -40.429389880911344
25 -24.085732370615005 -40.05653450521898
26 -22.98732826858759 -39.59232357792555
27 -31.65010079741478 -39.54162101198148
28 -24.74034982174635 -39.195237471709476
29 -25.410518988966942 -39.172389579378766
30 -21.627844654023647 -38.51095963496708
31 -19.81791179254651 -38.447265769744824
32 -26.508628115057945 -38.392107037026264
33 -16.358780533075333 -38.00745349944469
34 -15.667984038591385 -37.46482488602393
35 -24.73646254837513 -37.10988160586883
36 -21.72675159573555 -34.27116723637227
37 -14.933882508426905 -34.14139118114101
38 -15.090937033295631 -33.263072731706835
39 -18.995316352695227 -33.13344797200536
40 -16.06224298477173 -33.07825234291984
41 -21.057709366083145 -33.0321314765637
42 -28.637640617787838 -32.44934973065406
43 -13.636486873030663 -32.4007978120153
44 -19.91839462518692 -32.40063925734975
45 -10.083772249519825 -30.734403792103194
46 -11.231784254312515 -30.57151371770873
47 -17.799396686255932 -30.131236504472803
48 -16.66472901403904 -29.99326722619033
49 -15.05861410498619 -29.66908258985071
50 -23.95585411041975 -29.297233511513635
51 -14.274949975311756 -29.288890423975797
52 -11.375138133764267 -29.145878352769948
53 -13.74020326603204 -28.49601894351319
54 -16.089793652296066 -28.492023661124072
55 -19.755714066326618 -28.315961465855167
56 -11.989894140511751 -27.121110566589827
57 -9.590070068836212 -26.064532595535336
58 -13.887509234249592 -25.520524278341334
59 -14.32866333425045 -25.27101421179229
60 -12.89111927896738 -25.066644278800943
61 -15.000733360648155 -24.925849381327673
62 -14.768600799143314 -24.188105669766596
63 -13.42683570832014 -23.48479966198816
64 -7.369874553754926 -23.153943559703283
65 -12.225594878196716 -22.954730295117237
66 -10.352852365002036 -22.74124885266394
67 -10.991976888850331 -22.739273544503753
68 -7.374988850206137 -22.264945050603636
69 -14.795878676697612 -22.15569724300287
70 -10.362322464585304 -21.055920928583344
71 -8.659090775996447 -20.543356562348553
72 -10.239174727350473 -20.33499633836848
73 -10.1838144287467 -20.18157658281111
74 -11.839912287890911 -19.58144410477429
75 -11.628338171169162 -19.377225745334304
76 -10.026143185794353 -19.243135617403095
77 -8.899114664644003 -19.060620225371707
78 -12.805073499679565 -18.964124524696246
79 -12.391289560124278 -18.448962308005108
80 -12.86580553278327 -17.740722019993825
81 -6.137612057849765 -16.85889369985028
82 -8.391274702735245 -16.3381194095591
83 -8.369718227535486 -14.535892564189266
84 -8.671611532568932 -14.443670567499144
85 -8.428131017833948 -14.200413010108107
86 -11.007203094661236 -13.936976181618805
87 -9.141067199409008 -13.862253042167257
88 -9.064362933859229 -13.483098530680483
89 -9.067167479544878 -13.455892754889845
90 -7.111619895324111 -13.355868275096913
91 -8.217032846063375 -12.278515244993585
92 -4.8611221220344305 -12.227387460046547
93 -6.129860434681177 -12.020717825467683
94 -9.539072632789612 -11.910094799877324
95 -7.639762621372938 -11.400284019256157
96 -7.32503123767674 -11.134618158086587
97 -6.687164880335331 -10.859166921158222
98 -5.270502746105194 -9.595137958067907
99 -8.41818131878972 -9.289921608799773
100 -10.614677825011313 -8.230877068641124
101 -9.64105623960495 -7.882363241796725
102 -9.970781464129686 -7.6478984168416355
103 -9.27558210119605 -7.459623237418707
104 -9.11727187409997 -7.124357312750265
105 -11.367408320307732 -7.05379065585803
106 -7.650273742154241 -6.853091098326624
107 -7.650000877678394 -6.6211384471641495
108 -11.853998012840748 -6.494555224953677
109 -6.906082630157471 -6.117354180737655
110 -9.55572596937418 -6.087055095509873
111 -7.003282411023974 -5.43500831968483
112 -6.059557582251728 -5.105291741614599
113 -6.99237796664238 -4.628649413275992
114 -5.533122966066003 -4.471031187897325
115 -4.789611361920834 -4.455504779070034
116 -6.584975980222225 -4.2805498188182405
117 -6.508119970560074 -3.7944735717969627
118 -3.529583763331175 -2.9512438456190186
119 -3.3879606686532497 -2.541618164765197
train accuracy: 0.9983333333333333
validation accuracy: 0.99
