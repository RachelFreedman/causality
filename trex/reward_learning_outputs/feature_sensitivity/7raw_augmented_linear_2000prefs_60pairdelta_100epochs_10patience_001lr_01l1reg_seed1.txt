demos: (120, 50, 8)
demo_rewards: (120,)
[-50.0022206  -48.82373914 -47.15605336 -46.19619105 -45.59422709
 -45.36842966 -45.19068756 -44.1649084  -44.07830313 -43.99355529
 -43.86306534 -43.84874807 -43.84199129 -43.80638567 -43.80581986
 -42.75947674 -42.66316469 -42.33177225 -41.77496339 -41.41006807
 -41.17786296 -40.72352042 -40.52718976 -40.49595848 -40.42938988
 -40.05653451 -39.59232358 -39.54162101 -39.19523747 -39.17238958
 -38.51095963 -38.44726577 -38.39210704 -38.0074535  -37.46482489
 -37.10988161 -34.27116724 -34.14139118 -33.26307273 -33.13344797
 -33.07825234 -33.03213148 -32.44934973 -32.40079781 -32.40063926
 -30.73440379 -30.57151372 -30.1312365  -29.99326723 -29.66908259
 -29.29723351 -29.28889042 -29.14587835 -28.49601894 -28.49202366
 -28.31596147 -27.12111057 -26.0645326  -25.52052428 -25.27101421
 -25.06664428 -24.92584938 -24.18810567 -23.48479966 -23.15394356
 -22.9547303  -22.74124885 -22.73927354 -22.26494505 -22.15569724
 -21.05592093 -20.54335656 -20.33499634 -20.18157658 -19.5814441
 -19.37722575 -19.24313562 -19.06062023 -18.96412452 -18.44896231
 -17.74072202 -16.8588937  -16.33811941 -14.53589256 -14.44367057
 -14.20041301 -13.93697618 -13.86225304 -13.48309853 -13.45589275
 -13.35586828 -12.27851524 -12.22738746 -12.02071783 -11.9100948
 -11.40028402 -11.13461816 -10.85916692  -9.59513796  -9.28992161
  -8.23087707  -7.88236324  -7.64789842  -7.45962324  -7.12435731
  -7.05379066  -6.8530911   -6.62113845  -6.49455522  -6.11735418
  -6.0870551   -5.43500832  -5.10529174  -4.62864941  -4.47103119
  -4.45550478  -4.28054982  -3.79447357  -2.95124385  -2.54161816]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=8, out_features=1, bias=False)
)
Total number of parameters: 8
Number of trainable paramters: 8
device: cuda:0
end of epoch 0: val_loss 0.024535432832411174, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.1237e-03,  2.1638e-03,  7.8490e-03,  2.5883e-04, -6.0954e-03,
          1.4030e-02, -2.7013e-03, -1.0822e+00]], device='cuda:0'))])
end of epoch 1: val_loss 0.0030625777950686484, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.9195e-03, -7.2370e-03,  5.4585e-03,  3.0548e-03,  2.1549e-04,
         -9.1730e-05,  1.3317e-03, -1.9154e+00]], device='cuda:0'))])
end of epoch 2: val_loss 0.5084567790250974, val_acc 0.905
trigger times: 1
end of epoch 3: val_loss 1.0205439403017311, val_acc 0.87
trigger times: 2
end of epoch 4: val_loss 0.16784397465812348, val_acc 0.925
trigger times: 3
end of epoch 5: val_loss 0.006614425950571068, val_acc 0.995
trigger times: 4
end of epoch 6: val_loss 0.002351390875213184, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-8.0256e-03,  2.6850e-05,  2.0157e-02,  2.9669e-05, -7.7428e-02,
          1.3506e-04, -1.3929e-03, -1.7157e+00]], device='cuda:0'))])
end of epoch 7: val_loss 0.2933043357350646, val_acc 0.925
trigger times: 1
end of epoch 8: val_loss 0.1906619984785786, val_acc 0.93
trigger times: 2
end of epoch 9: val_loss 0.0035491502247451834, val_acc 1.0
trigger times: 3
end of epoch 10: val_loss 3.3886338209974416, val_acc 0.74
trigger times: 4
end of epoch 11: val_loss 0.0027537152477108504, val_acc 1.0
trigger times: 5
end of epoch 12: val_loss 0.0012307886736722296, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 5.7584e-05, -2.7444e-02, -7.9217e-05, -4.2411e-05, -8.7129e-02,
         -1.6762e-04,  1.0933e-04, -2.5810e+00]], device='cuda:0'))])
end of epoch 13: val_loss 0.3476807293772698, val_acc 0.91
trigger times: 1
end of epoch 14: val_loss 0.332248550408201, val_acc 0.92
trigger times: 2
end of epoch 15: val_loss 0.006351876801991452, val_acc 1.0
trigger times: 3
end of epoch 16: val_loss 0.020604313207334676, val_acc 0.995
trigger times: 4
end of epoch 17: val_loss 0.0011502028125995522, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 5.2609e-05, -3.3648e-05,  5.5645e-02, -2.2867e-02, -8.2697e-05,
          2.7648e-04, -6.8854e-07, -2.4212e+00]], device='cuda:0'))])
end of epoch 18: val_loss 0.0141866722293641, val_acc 0.995
trigger times: 1
end of epoch 19: val_loss 3.3143493785288083, val_acc 0.77
trigger times: 2
end of epoch 20: val_loss 0.0014795169928636298, val_acc 1.0
trigger times: 3
end of epoch 21: val_loss 0.20150322247932043, val_acc 0.96
trigger times: 4
end of epoch 22: val_loss 0.007269937167310836, val_acc 0.995
trigger times: 5
end of epoch 23: val_loss 0.012278713686986542, val_acc 1.0
trigger times: 6
end of epoch 24: val_loss 0.002999685670664363, val_acc 1.0
trigger times: 7
end of epoch 25: val_loss 0.007678605276128927, val_acc 0.995
trigger times: 8
end of epoch 26: val_loss 0.013205496616774006, val_acc 0.995
trigger times: 9
end of epoch 27: val_loss 0.005171967456655189, val_acc 1.0
trigger times: 10
Early stopping.
0 -19.083242245018482 -50.00222059884506
1 -19.357187554240227 -48.823739140882175
2 -19.938045285642147 -47.15605336419176
3 -19.309786453843117 -46.19619104961985
4 -21.927357137203217 -45.594227093057754
5 -22.191848635673523 -45.36842966452394
6 -24.132603734731674 -45.19068756322445
7 -17.87706397473812 -44.16490839583478
8 -17.762913674116135 -44.078303125872196
9 -25.199839875102043 -43.993555290419714
10 -12.839528366923332 -43.86306534422809
11 -19.670025094412267 -43.84874807044028
12 -15.114486014470458 -43.84199129025074
13 -11.39467166364193 -43.806385671938365
14 -11.937294257804751 -43.80581985978556
15 -10.27293582353741 -42.7594767358323
16 -15.804865390062332 -42.66316468983175
17 -13.318505596369505 -42.33177224591743
18 -17.377142280340195 -41.774963389485094
19 -15.409158147871494 -41.410068073767725
20 -10.663424633909017 -41.17786296442943
21 -12.666638752445579 -40.723520424948155
22 -21.202842980623245 -40.527189756101116
23 -19.666782423853874 -40.49595848244517
24 -20.76619589328766 -40.429389880911344
25 -14.281799015589058 -40.05653450521898
26 -15.38721935171634 -39.59232357792555
27 -25.32863387465477 -39.54162101198148
28 -20.69866479933262 -39.195237471709476
29 -17.411797404289246 -39.172389579378766
30 -16.105518989264965 -38.51095963496708
31 -15.405793003737926 -38.447265769744824
32 -19.867952298372984 -38.392107037026264
33 -9.383550107479095 -38.00745349944469
34 -11.529484055936337 -37.46482488602393
35 -16.436622876673937 -37.10988160586883
36 -16.79110597074032 -34.27116723637227
37 -7.504902340937406 -34.14139118114101
38 -9.395792319439352 -33.263072731706835
39 -12.85877793468535 -33.13344797200536
40 -13.068822056055069 -33.07825234291984
41 -14.17801782488823 -33.0321314765637
42 -18.380966562777758 -32.44934973065406
43 -11.808330208063126 -32.4007978120153
44 -13.83977396786213 -32.40063925734975
45 -6.407974597066641 -30.734403792103194
46 -9.38776220753789 -30.57151371770873
47 -11.895226828753948 -30.131236504472803
48 -11.795090638101101 -29.99326722619033
49 -9.233684784267098 -29.66908258985071
50 -16.116035163402557 -29.297233511513635
51 -8.00421135686338 -29.288890423975797
52 -8.989405015483499 -29.145878352769948
53 -10.050386525690556 -28.49601894351319
54 -10.583957068622112 -28.492023661124072
55 -15.476063095033169 -28.315961465855167
56 -9.770729281008244 -27.121110566589827
57 -6.528210639022291 -26.064532595535336
58 -8.225539417937398 -25.520524278341334
59 -10.432591535151005 -25.27101421179229
60 -10.496292352676392 -25.066644278800943
61 -12.493973158299923 -24.925849381327673
62 -12.00407937914133 -24.188105669766596
63 -10.22178215533495 -23.48479966198816
64 -3.0012949761003256 -23.153943559703283
65 -9.69122070632875 -22.954730295117237
66 -7.551329215988517 -22.74124885266394
67 -7.061694016680121 -22.739273544503753
68 -5.697793550789356 -22.264945050603636
69 -8.50396502763033 -22.15569724300287
70 -8.25230224430561 -21.055920928583344
71 -6.430870659649372 -20.543356562348553
72 -8.19789457321167 -20.33499633836848
73 -5.392885327339172 -20.18157658281111
74 -5.946749199181795 -19.58144410477429
75 -5.90522637963295 -19.377225745334304
76 -7.867991540580988 -19.243135617403095
77 -6.110146313440055 -19.060620225371707
78 -9.484677329659462 -18.964124524696246
79 -7.740621171426028 -18.448962308005108
80 -8.500746129080653 -17.740722019993825
81 -5.539299476891756 -16.85889369985028
82 -6.450875628739595 -16.3381194095591
83 -3.899530226364732 -14.535892564189266
84 -6.4363358821719885 -14.443670567499144
85 -4.7269824789837 -14.200413010108107
86 -6.619354821043089 -13.936976181618805
87 -7.558740317821503 -13.862253042167257
88 -5.695247633382678 -13.483098530680483
89 -6.165274812374264 -13.455892754889845
90 -6.190733378753066 -13.355868275096913
91 -4.575388751924038 -12.278515244993585
92 -3.8244517715647817 -12.227387460046547
93 -4.799858972430229 -12.020717825467683
94 -7.987357042729855 -11.910094799877324
95 -7.512998014688492 -11.400284019256157
96 -3.307898549363017 -11.134618158086587
97 -6.142795354127884 -10.859166921158222
98 -5.0016516000032425 -9.595137958067907
99 -5.989252135157585 -9.289921608799773
100 -7.281010495498776 -8.230877068641124
101 -4.494439072906971 -7.882363241796725
102 -5.726120604202151 -7.6478984168416355
103 -4.146525979042053 -7.459623237418707
104 -5.293391145765781 -7.124357312750265
105 -9.349499925971031 -7.05379065585803
106 -3.444511679932475 -6.853091098326624
107 -4.353749083355069 -6.6211384471641495
108 -9.988273032009602 -6.494555224953677
109 -2.7386494651436806 -6.117354180737655
110 -8.804344788193703 -6.087055095509873
111 -5.346503682434559 -5.43500831968483
112 -4.546171757392585 -5.105291741614599
113 -4.552676647901535 -4.628649413275992
114 -3.312419388908893 -4.471031187897325
115 -2.6859170123934746 -4.455504779070034
116 -6.412118531763554 -4.2805498188182405
117 -6.135663218796253 -3.7944735717969627
118 -2.256964972242713 -2.9512438456190186
119 -2.440832338295877 -2.541618164765197
train accuracy: 0.9977777777777778
validation accuracy: 1.0
