demos: (120, 50, 11)
demo_rewards: (120,)
[-50.0022206  -48.82373914 -47.15605336 -46.19619105 -45.59422709
 -45.36842966 -45.19068756 -44.1649084  -44.07830313 -43.99355529
 -43.86306534 -43.84874807 -43.84199129 -43.80638567 -43.80581986
 -42.75947674 -42.66316469 -42.33177225 -41.77496339 -41.41006807
 -41.17786296 -40.72352042 -40.52718976 -40.49595848 -40.42938988
 -40.05653451 -39.59232358 -39.54162101 -39.19523747 -39.17238958
 -38.51095963 -38.44726577 -38.39210704 -38.0074535  -37.46482489
 -37.10988161 -34.27116724 -34.14139118 -33.26307273 -33.13344797
 -33.07825234 -33.03213148 -32.44934973 -32.40079781 -32.40063926
 -30.73440379 -30.57151372 -30.1312365  -29.99326723 -29.66908259
 -29.29723351 -29.28889042 -29.14587835 -28.49601894 -28.49202366
 -28.31596147 -27.12111057 -26.0645326  -25.52052428 -25.27101421
 -25.06664428 -24.92584938 -24.18810567 -23.48479966 -23.15394356
 -22.9547303  -22.74124885 -22.73927354 -22.26494505 -22.15569724
 -21.05592093 -20.54335656 -20.33499634 -20.18157658 -19.5814441
 -19.37722575 -19.24313562 -19.06062023 -18.96412452 -18.44896231
 -17.74072202 -16.8588937  -16.33811941 -14.53589256 -14.44367057
 -14.20041301 -13.93697618 -13.86225304 -13.48309853 -13.45589275
 -13.35586828 -12.27851524 -12.22738746 -12.02071783 -11.9100948
 -11.40028402 -11.13461816 -10.85916692  -9.59513796  -9.28992161
  -8.23087707  -7.88236324  -7.64789842  -7.45962324  -7.12435731
  -7.05379066  -6.8530911   -6.62113845  -6.49455522  -6.11735418
  -6.0870551   -5.43500832  -5.10529174  -4.62864941  -4.47103119
  -4.45550478  -4.28054982  -3.79447357  -2.95124385  -2.54161816]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=11, out_features=1, bias=False)
)
Total number of parameters: 11
Number of trainable paramters: 11
device: cuda:0
end of epoch 0: val_loss 2.8218440277681536, val_acc 0.74
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.0642, -0.1055,  0.1027,  0.1020, -0.2799, -0.0430,  0.0444,  0.0549,
          0.1145,  0.0221, -1.5418]], device='cuda:0'))])
end of epoch 1: val_loss 0.009480208880414622, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-5.4626e-03, -1.5292e-02,  1.1124e-02,  9.5936e-03,  1.4518e-04,
          2.7086e-03, -4.0303e-03,  1.4484e-03, -2.9220e-04, -7.6905e-05,
         -1.5797e+00]], device='cuda:0'))])
end of epoch 2: val_loss 0.0625936707911982, val_acc 0.99
trigger times: 1
end of epoch 3: val_loss 0.001380737294460026, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-3.4797e-02, -7.4259e-03, -2.7013e-03,  7.1376e-03,  1.4897e-04,
         -1.1427e-04,  3.4818e-04,  3.5971e-03,  7.9103e-04,  3.6761e-05,
         -2.6366e+00]], device='cuda:0'))])
end of epoch 4: val_loss 0.0038933194565613505, val_acc 1.0
trigger times: 1
end of epoch 5: val_loss 0.0297163903317956, val_acc 0.99
trigger times: 2
end of epoch 6: val_loss 0.005498760728381314, val_acc 1.0
trigger times: 3
end of epoch 7: val_loss 1.5453084105255817, val_acc 0.84
trigger times: 4
end of epoch 8: val_loss 0.0028358053746724466, val_acc 1.0
trigger times: 5
end of epoch 9: val_loss 0.2830256975693554, val_acc 0.945
trigger times: 6
end of epoch 10: val_loss 0.002246011766482674, val_acc 1.0
trigger times: 7
end of epoch 11: val_loss 0.0005264274780767764, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.9635e-03,  8.5905e-04,  7.6822e-02, -4.0695e-02, -2.0236e-02,
         -9.9036e-05, -4.0234e-03,  1.4959e-02, -6.3603e-04, -2.4748e-03,
         -3.5631e+00]], device='cuda:0'))])
end of epoch 12: val_loss 0.0048834588459890325, val_acc 0.995
trigger times: 1
end of epoch 13: val_loss 0.001718965539307078, val_acc 1.0
trigger times: 2
end of epoch 14: val_loss 0.03722740766953791, val_acc 0.995
trigger times: 3
end of epoch 15: val_loss 0.04498139785958394, val_acc 0.99
trigger times: 4
end of epoch 16: val_loss 0.0017982271016332163, val_acc 1.0
trigger times: 5
end of epoch 17: val_loss 0.001573017366797984, val_acc 1.0
trigger times: 6
end of epoch 18: val_loss 0.15574107013775296, val_acc 0.975
trigger times: 7
end of epoch 19: val_loss 0.0033784144699341213, val_acc 1.0
trigger times: 8
end of epoch 20: val_loss 0.0028475732327902037, val_acc 1.0
trigger times: 9
end of epoch 21: val_loss 0.08138950354950993, val_acc 0.985
trigger times: 10
Early stopping.
0 -37.91100799292326 -50.00222059884506
1 -39.01396697759628 -48.823739140882175
2 -32.047459699213505 -47.15605336419176
3 -34.90722131729126 -46.19619104961985
4 -43.451458275318146 -45.594227093057754
5 -39.141223430633545 -45.36842966452394
6 -44.497443199157715 -45.19068756322445
7 -27.184011429548264 -44.16490839583478
8 -32.93688282370567 -44.078303125872196
9 -36.244850650429726 -43.993555290419714
10 -18.73483733832836 -43.86306534422809
11 -38.18096874281764 -43.84874807044028
12 -29.71343097090721 -43.84199129025074
13 -14.869375757873058 -43.806385671938365
14 -16.425388649106026 -43.80581985978556
15 -19.872985407710075 -42.7594767358323
16 -25.254850439727306 -42.66316468983175
17 -29.222747169435024 -42.33177224591743
18 -29.86549174785614 -41.774963389485094
19 -31.839460790157318 -41.410068073767725
20 -27.796891264617443 -41.17786296442943
21 -20.29623406007886 -40.723520424948155
22 -35.12541729211807 -40.527189756101116
23 -35.27771185338497 -40.49595848244517
24 -37.61326774954796 -40.429389880911344
25 -32.51369044184685 -40.05653450521898
26 -29.04647423326969 -39.59232357792555
27 -44.002430498600006 -39.54162101198148
28 -36.745020031929016 -39.195237471709476
29 -25.877560660243034 -39.172389579378766
30 -31.279535353183746 -38.51095963496708
31 -23.71820691972971 -38.447265769744824
32 -33.66770273447037 -38.392107037026264
33 -22.52290028333664 -38.00745349944469
34 -16.567502692341805 -37.46482488602393
35 -27.911059826612473 -37.10988160586883
36 -31.80260357260704 -34.27116723637227
37 -16.93469114974141 -34.14139118114101
38 -15.988037042319775 -33.263072731706835
39 -25.39067697431892 -33.13344797200536
40 -27.348195612430573 -33.07825234291984
41 -21.279511719942093 -33.0321314765637
42 -34.68557254970074 -32.44934973065406
43 -22.798870533704758 -32.4007978120153
44 -27.128055453300476 -32.40063925734975
45 -8.412282928824425 -30.734403792103194
46 -18.959850639104843 -30.57151371770873
47 -22.736619792878628 -30.131236504472803
48 -20.534920305013657 -29.99326722619033
49 -20.47281150519848 -29.66908258985071
50 -26.364126816391945 -29.297233511513635
51 -15.74430736899376 -29.288890423975797
52 -14.006248958408833 -29.145878352769948
53 -17.68319170922041 -28.49601894351319
54 -19.565989270806313 -28.492023661124072
55 -29.055532723665237 -28.315961465855167
56 -15.907471790909767 -27.121110566589827
57 -9.303509153425694 -26.064532595535336
58 -17.12603084743023 -25.520524278341334
59 -17.64996065199375 -25.27101421179229
60 -17.245024658739567 -25.066644278800943
61 -21.277944020926952 -24.925849381327673
62 -23.154083400964737 -24.188105669766596
63 -15.417081356048584 -23.48479966198816
64 -2.7606394588947296 -23.153943559703283
65 -16.10734076052904 -22.954730295117237
66 -10.456103034317493 -22.74124885266394
67 -8.526717238128185 -22.739273544503753
68 -8.104545935988426 -22.264945050603636
69 -13.321881577372551 -22.15569724300287
70 -14.537456035614014 -21.055920928583344
71 -11.722051486372948 -20.543356562348553
72 -13.86550872027874 -20.33499633836848
73 -5.399513848125935 -20.18157658281111
74 -9.400732442736626 -19.58144410477429
75 -9.5917217284441 -19.377225745334304
76 -11.317274304106832 -19.243135617403095
77 -10.280232787132263 -19.060620225371707
78 -14.864966616034508 -18.964124524696246
79 -17.31506807357073 -18.448962308005108
80 -13.490388333797455 -17.740722019993825
81 -9.099086873233318 -16.85889369985028
82 -10.900618286803365 -16.3381194095591
83 -2.677099719643593 -14.535892564189266
84 -9.736034035682678 -14.443670567499144
85 -9.429121192544699 -14.200413010108107
86 -16.14542678743601 -13.936976181618805
87 -15.921033069491386 -13.862253042167257
88 -5.737925015389919 -13.483098530680483
89 -12.567523248493671 -13.455892754889845
90 -10.761088225990534 -13.355868275096913
91 -4.6148839220404625 -12.278515244993585
92 -4.931419592350721 -12.227387460046547
93 -6.425491191446781 -12.020717825467683
94 -13.12173394113779 -11.910094799877324
95 -16.40227870643139 -11.400284019256157
96 -1.3856047987937927 -11.134618158086587
97 -12.369493409991264 -10.859166921158222
98 -8.609947979450226 -9.595137958067907
99 -11.832756243646145 -9.289921608799773
100 -11.145836856216192 -8.230877068641124
101 -5.2449366599321365 -7.882363241796725
102 -7.856679297983646 -7.6478984168416355
103 -4.439484640955925 -7.459623237418707
104 -7.3627426996827126 -7.124357312750265
105 -22.462623924016953 -7.05379065585803
106 -1.9339943528175354 -6.853091098326624
107 -4.5851955935359 -6.6211384471641495
108 -22.97913831472397 -6.494555224953677
109 -0.37656304240226746 -6.117354180737655
110 -18.891831785440445 -6.087055095509873
111 -6.813605517148972 -5.43500831968483
112 -8.473533686250448 -5.105291741614599
113 -6.723313268274069 -4.628649413275992
114 -5.888707919046283 -4.471031187897325
115 1.1501073017716408 -4.455504779070034
116 -13.046954944729805 -4.2805498188182405
117 -11.919416531920433 -3.7944735717969627
118 -0.4480127841234207 -2.9512438456190186
119 -0.9063936658203602 -2.541618164765197
train accuracy: 0.9755555555555555
validation accuracy: 0.985
