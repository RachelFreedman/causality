demos: (480, 1000, 23)
demo_rewards: (480,)
sorted_train_rewards: [-524.69363357 -519.9080064  -428.04712667 -426.07186886 -400.69209088
 -391.95882373 -391.95857823 -388.59399582 -382.64759058 -376.76557862
 -373.51420524 -360.72317391 -359.81019509 -357.01902541 -354.47400187
 -346.3907683  -340.93368667 -338.24427931 -336.02543195 -331.62260389
 -329.80209332 -323.40639163 -319.2332748  -317.83524537 -316.10403797
 -315.72296788 -311.34859504 -308.66558365 -303.90832615 -301.55233277
 -300.05811195 -297.00598958 -290.06408949 -286.79145896 -285.62255496
 -280.86172479 -280.79509685 -278.93507563 -274.17047796 -273.93576074
 -273.83226615 -271.80602473 -268.17088379 -264.55923119 -261.40264183
 -257.70030889 -257.03338564 -256.49969365 -248.79063039 -248.56818267
 -247.59340728 -244.37737256 -239.39040955 -238.0865228  -233.67489674
 -226.4021581  -215.62618485 -211.88658718 -211.36661726 -208.03522829
 -207.41638882 -207.28517741 -205.96911148 -203.9046547  -190.14098957
 -184.9841793  -184.73594166 -180.59042632 -175.50125481 -171.6271578
 -153.5033803  -152.60167504 -144.91600187 -138.2312438  -133.30170121
 -130.30804227 -123.62457903 -120.40905315  -93.1000472   -71.26903173
  -68.60132228  -60.59147508  -57.33491011  -38.29932913  -36.36051483
  -28.46460989  -26.64860697  -25.89971503  -25.24730779  -22.69834944
   18.14094557   18.534251     36.03771571   36.66670793   46.41665444
   52.56239787   57.08738085   61.62771572   64.26879367   72.77987258
   76.22063096   84.71704946   94.00125843   94.19740352   99.27272471
  106.18413986  106.61888653  112.63324094  114.60067786  116.47086787
  116.51098     117.95497782  124.34187604  128.90443776  134.3205758
  144.4467766   147.06057442  154.08827534  156.24618581  156.42911943
  158.51798413  166.92992889  168.12910327  168.32790079  169.99590647
  170.97708371  179.83810426  184.08731548  184.42954181  189.88700793
  190.01224314  191.95774675  195.01398454  196.33453198  201.05317488
  201.78522879  205.26303142  207.61010756  210.43454315  212.15813467
  213.58916802  213.68066085  214.28737943  215.76903125  218.87296056
  219.8938352   221.55427931  221.88051933  223.25804144  229.06331402
  229.89034361  230.83614278  246.00283085  256.83932945  272.70119861
  276.10991136  283.22855048  285.96659066  290.72864991  302.97557119
  314.70262512  320.18594509  323.2057931   344.96494304  366.6351554
  384.68362826  401.19893609  404.85545829  406.27949347  422.31704774
  436.83002729  437.06821619  446.71216718  450.64332733  469.63473588
  475.78724129  482.5534186   497.3271866   502.51838567  508.23621599
  527.7648076   537.05928655  553.32533334  553.48426895  560.46506436
  572.11974327  581.50409261  583.00550482  585.6694137   597.52795318
  600.85493229  605.95370052  606.89618343  624.70681015  630.23736491
  631.5518751   635.90294353  658.72608238  662.37365481  666.1488369
  668.77079518  671.3080771   680.56533067  683.13000451  685.21886664
  688.58993175  710.31589512  716.22536939  722.3609598   726.11333231
  726.16233976  726.47925137  734.56779392  736.63583003  744.30138878
  767.70105489  768.73209782  774.75191394  774.91311809  779.47144797
  788.53688263  793.82716573  799.17615147  799.74418213  803.53481759
  809.76264369  810.97531053  818.76684211  827.03676572  833.27242674
  837.12768435  837.18291032  852.97506692  855.23698313  856.06693798
  867.72120341  868.1633077   870.96953141  871.39424881  877.52097954
  877.78695006  886.97441062  905.39040983  909.9186257   911.49951501
  912.66890385  918.67761934  923.04099951  927.21378749  928.17981275
  937.01547782  952.96707777  958.0699434   962.84124522  967.21586262
  972.47460426  996.85650278 1025.00347782 1039.16402885 1039.78397173
 1069.35602053 1069.96912738 1079.52750826 1081.27763751 1084.26627495
 1122.50176508 1145.64247268 1156.74610959 1165.94831239 1172.65408898
 1191.35557305 1231.31773398 1281.40819681 1291.63482155 1298.98143007
 1313.68336221 1332.76858676 1370.8854603  1373.68641894 1389.96137052
 1408.32927479 1415.37100158 1415.95662921 1418.79397866 1425.64201846
 1436.7703022  1444.8742987  1455.10103315 1460.30079394 1464.81151459
 1480.27876503 1480.73126013 1491.97755394 1501.39430535 1512.23108748
 1525.58827426 1525.82648228 1538.38225196 1539.56531557 1553.18718808
 1553.40060648 1553.67248127 1554.2785549  1573.13710957 1578.57170849
 1583.32001802 1587.18145893 1587.78856335 1600.05548118 1637.33115926
 1648.38966521 1662.66715374 1670.14070122 1670.87137062 1671.74729172
 1679.99597469 1683.90874741 1700.93624107 1702.52424931 1705.57520837
 1729.56297887 1735.16955392 1756.39335374 1757.82710459 1790.32408447
 1806.9001545  1814.74908046 1817.87221105 1874.99064848 1897.44938647
 1903.37414384 1940.04647372 1955.52695868 1989.8060044  1990.4471889
 1999.71073314 2002.79461683 2030.25906501 2059.6721564  2067.38126332
 2073.84052963 2081.41663239 2098.26393327 2163.9281288  2169.4214639
 2188.24289228 2213.59247392 2214.79038033 2236.76410259 2240.25649811
 2259.29310248 2316.13575875 2350.74327548 2528.06277524 2529.57128632
 2558.45425896 2610.04155006 2615.28414462 2618.61361065 2645.18727726
 2646.06899759 2646.2884004  2655.46915359 2713.48495737 2745.16246933
 2746.14021096 2751.45964996 2805.70013928 2823.98410982 2832.18301075
 2865.68703628 2866.65517781 2868.3962322  2873.7900389  2908.17840563
 2911.74741678 2919.89904375 2939.98546055 2989.07503168 3000.82229205
 3026.52472405 3126.80889538 3188.6198344  3218.69401887 3230.75246286
 3266.16351614 3600.19661451 3617.23374779 3812.28142926 3813.16447538
 4015.87846288 4031.94536718 4071.18016174 4079.05565608 4079.96795983
 4089.53158236 4116.6937375  4117.41090968 4127.2547502  4167.1747594
 4184.17992205 4207.38529871 4210.25253259 4212.52885125 4215.11172055
 4222.00212054 4223.81264398 4226.98787167 4227.76468527 4234.10144303
 4243.33767626 4249.4217244  4261.11475591 4265.40573288 4283.31217151
 4290.96762481 4305.60777891 4328.6025185  4330.38249264 4340.43328662
 4343.30329165 4350.83517393 4357.79194471 4391.63916041 4408.45567702
 4418.19675027 4474.0948897  4526.63478974 4531.20723922 4542.61529274
 4584.4027012  4771.14676225]
sorted_val_rewards: [-417.85007471 -395.02788639 -393.33566725 -377.7472339  -356.52299073
 -293.61621306 -264.37152489 -229.04306351 -121.70501653  -84.51907957
   18.69225769   25.17834962   31.89666741   32.4050049    54.25957428
   79.97704618   95.07232442  105.91989234  116.59548472  154.46689919
  182.16470192  242.86029354  293.14863056  473.79372057  481.47003396
  555.5199792   578.16420374  620.51299525  701.81295875  819.72967372
  932.93634177 1172.88001302 1223.34001438 1483.93039685 1521.56198243
 1596.85943303 1776.35494333 1777.61207979 1844.10564114 2081.17454623
 3078.96260724 4108.47914019 4187.95937903 4200.0771443  4302.28859443
 4318.0498578  4362.47487658 4647.53502786]
maximum traj length 1000
maximum traj length 1000
num train_obs 52326
num train_labels 52326
num val_obs 1128
num val_labels 1128
ModuleList(
  (0): Linear(in_features=23, out_features=128, bias=True)
  (1): Linear(in_features=128, out_features=64, bias=True)
  (2): Linear(in_features=64, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 11392
Number of trainable paramters: 11392
device: cuda:0
end of epoch 0: val_loss 0.14585328945673523, val_acc 0.9831560283687943
trigger times: 0
saving model weights...
end of epoch 1: val_loss 0.016492035452009886, val_acc 0.9902482269503546
trigger times: 0
saving model weights...
end of epoch 2: val_loss 0.01716437835992045, val_acc 0.9937943262411347
trigger times: 1
end of epoch 3: val_loss 0.007029587270921958, val_acc 0.99822695035461
trigger times: 0
saving model weights...
end of epoch 4: val_loss 0.03768322526323884, val_acc 0.9902482269503546
trigger times: 1
end of epoch 5: val_loss 0.01568540276649476, val_acc 0.9964539007092199
trigger times: 2
end of epoch 6: val_loss 0.030720641596249088, val_acc 0.9911347517730497
trigger times: 3
end of epoch 7: val_loss 0.009717561850307204, val_acc 0.9955673758865248
trigger times: 4
end of epoch 8: val_loss 0.018904364338182513, val_acc 0.9937943262411347
trigger times: 5
end of epoch 9: val_loss 0.022365593726753175, val_acc 0.9929078014184397
trigger times: 6
end of epoch 10: val_loss 0.008886507322634527, val_acc 0.9973404255319149
trigger times: 7
end of epoch 11: val_loss 0.03652127690346529, val_acc 0.9902482269503546
trigger times: 8
end of epoch 12: val_loss 0.010324568401027067, val_acc 0.9955673758865248
trigger times: 9
end of epoch 13: val_loss 0.013084874280578822, val_acc 0.9946808510638298
trigger times: 10
Early stopping.
0 -20.81790321970766 -417.8500747112217
1 -18.709660722714034 -395.0278863934491
2 -18.12542930150812 -393.33566724796447
3 -13.27523407008266 -377.74723390148745
4 -7.432810030717519 -356.52299073299355
5 4.670964875833306 -293.61621306390157
6 9.7902880413003 -264.37152488512595
7 18.60061175145529 -229.04306350923414
8 47.48820703232195 -121.70501653144265
9 57.250085251551354 -84.51907956755302
10 82.35538660509701 18.692257691900576
11 81.14930402825121 25.178349617410355
12 84.19540564739145 31.896667411820435
13 82.52034294788609 32.40500490386286
14 89.54235366586363 54.25957427857534
15 94.17803492976236 79.97704618322362
16 99.66913503487012 95.07232442353506
17 100.86677438978222 105.9198923418008
18 102.85821668195422 116.59548471755453
19 116.93560822866311 154.46689919193952
20 119.09786431991961 182.1647019201146
21 135.54135036017396 242.860293539308
22 145.9526317913842 293.1486305602138
23 191.9657795286912 473.7937205693257
24 191.48838462079038 481.47003395927266
25 208.40927429968724 555.5199792011284
26 218.07118015561718 578.1642037415102
27 225.5926641675178 620.5129952457143
28 243.70317737502046 701.8129587451294
29 270.8810749283293 819.7296737154431
30 298.8833133641165 932.9363417650754
31 354.02958676355775 1172.8800130151055
32 370.19234364792646 1223.340014376065
33 440.9258598568849 1483.9303968479487
34 436.74761828634655 1521.5619824319874
35 460.12950470363285 1596.8594330279877
36 500.68323698686436 1776.3549433333546
37 497.8323257283773 1777.612079786244
38 521.3638142885175 1844.1056411379384
39 577.9650602811016 2081.1745462322774
40 817.1230257777497 3078.9626072426972
41 1069.9398278640583 4108.479140186715
42 1093.2658334448934 4187.95937902959
43 1092.7118897978216 4200.077144304393
44 1115.9983651386574 4302.2885944270065
45 1125.255386274308 4318.049857801658
46 1127.2010302692652 4362.47487658048
47 1192.5838705450296 4647.535027861095
train accuracy: 0.9982417918434431
validation accuracy: 0.9946808510638298
