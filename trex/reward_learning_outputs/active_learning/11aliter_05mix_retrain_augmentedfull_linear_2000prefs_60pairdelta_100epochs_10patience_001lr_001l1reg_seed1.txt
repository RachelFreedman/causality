[-54.98547503 -50.4922686  -50.03933802 -49.75347185 -49.72654641
 -46.98011874 -45.73515428 -45.67057988 -44.99030608 -44.14602409
 -43.81326882 -43.18878399 -42.29180715 -42.00401746 -41.69100444
 -41.68588229 -41.2817771  -40.44278203 -40.34838366 -39.59970115
 -39.57586365 -39.31972693 -39.02461056 -38.45534494 -38.4127039
 -38.35634328 -37.79713617 -37.74152899 -37.66475324 -37.51313938
 -37.1809993  -37.10070314 -37.00630589 -36.82191677 -36.48799015
 -36.2096527  -36.19207562 -36.11445903 -35.78149902 -35.39450387
 -35.262825   -35.24303541 -35.20970524 -35.06544085 -34.80241748
 -34.64469045 -33.84284986 -32.70706485 -31.9690994  -31.7109134
 -31.64414356 -31.39238276 -31.22319602 -31.12953085 -29.3915714
 -29.34012561 -29.10618999 -27.4110235  -27.34372236 -27.19668163
 -27.07399029 -26.70472176 -26.2447949  -25.54836509 -25.45878529
 -24.879107   -24.82869536 -24.59274514 -23.97874558 -23.57262108
 -23.44970808 -22.74530916 -22.60679894 -22.19891032 -20.65686376
 -20.44447256 -20.1969901  -20.13839115 -19.63760344 -19.51559872
 -18.9283881  -17.99477406 -17.5574237  -16.82307393 -14.8550828
 -14.5314246  -14.44242009 -13.59601285 -12.68135973 -12.66418206
 -12.30017947 -12.15190477 -11.78885214 -10.8699891  -10.3276815
  -9.85721598  -8.330117    -8.13319584  -8.10819769  -7.57539849
  -7.36244313  -7.10832736  -6.95906356  -6.77694649  -6.72206384
  -6.71997062  -6.53544734  -6.51820418  -5.61579673  -5.3472021
  -5.07848501  -5.02795798  -4.82757292  -4.63049542  -4.230832
  -4.03104862  -3.38446715  -3.3322555   -2.64166233  -1.91361965]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:3
end of epoch 0: val_loss 4.053112508728418e-08, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-4.5801e-06,  9.4920e-02,  7.2793e-02, -6.0650e-02, -2.6848e-02,
         -1.0409e-05,  8.3804e-04, -1.2667e-02, -4.2668e-05, -1.0290e-05,
         -1.4320e-03, -7.3769e-01, -9.0043e-01]], device='cuda:3'))])
end of epoch 1: val_loss 3.838529057276219e-07, val_acc 1.0
trigger times: 1
end of epoch 2: val_loss 0.00016264474358830937, val_acc 1.0
trigger times: 2
end of epoch 3: val_loss 1.8035395769118167e-05, val_acc 1.0
trigger times: 3
end of epoch 4: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 6.5565e-06,  2.2388e-01,  3.4402e-01, -7.6654e-02, -2.9708e-05,
         -7.7138e-06,  3.8098e-03,  3.6863e-02,  2.1129e-07,  1.0585e-04,
         -1.4320e-03, -1.3970e+00, -2.7137e+00]], device='cuda:3'))])
end of epoch 5: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.2145e-05, -4.0056e-05,  1.1318e-01,  1.8308e-05, -9.1442e-05,
          1.5299e-04, -8.2469e-08, -7.5541e-07,  3.1226e-05,  2.4508e-04,
         -1.4320e-03, -1.1824e-02, -2.3710e+00]], device='cuda:3'))])
end of epoch 6: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 6.0366e-05,  4.5927e-06, -5.3862e-05, -4.9570e-05, -2.3551e-04,
          2.0369e-04, -6.2716e-07, -7.9942e-06,  1.0450e-04,  5.5306e-04,
         -1.4320e-03,  1.7238e-04, -1.5287e+00]], device='cuda:3'))])
end of epoch 7: val_loss 1.4606965123675764e-06, val_acc 1.0
trigger times: 1
end of epoch 8: val_loss 7.1525522571391775e-09, val_acc 1.0
trigger times: 2
end of epoch 9: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.8080e-05,  8.8906e-06,  4.5368e-06,  1.1575e-06,  2.8995e-04,
         -1.8347e-04, -1.9212e-06,  3.7206e-03,  1.8520e-04,  2.3085e-04,
         -1.4320e-03, -1.4036e-04, -1.7760e+00]], device='cuda:3'))])
end of epoch 10: val_loss 3.5881901435885763e-07, val_acc 1.0
trigger times: 1
end of epoch 11: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.1400e-02,  2.8609e-01,  2.5474e-01, -5.8271e-02,  1.6340e-02,
         -4.8073e-02, -5.5286e-03,  5.0340e-02,  7.7394e-03, -1.4174e-01,
         -1.4321e-03, -1.4848e+00, -2.0466e+00]], device='cuda:3'))])
end of epoch 12: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.0067e-06,  1.0765e-01,  8.9646e-02, -1.1154e-05,  9.2487e-05,
         -5.0512e-05, -4.3598e-03,  2.0032e-02, -7.9242e-05, -9.0028e-05,
         -1.4321e-03, -6.4833e-01, -1.8538e+00]], device='cuda:3'))])
end of epoch 13: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.3402e-05,  1.1012e-05, -5.8717e-05, -2.9423e-05,  2.3592e-04,
         -1.0515e-04,  1.9438e-06, -2.3738e-05, -1.8150e-04,  7.1593e-05,
         -1.4321e-03,  2.1256e-05, -1.3593e+00]], device='cuda:3'))])
end of epoch 14: val_loss 0.0006836509758267084, val_acc 1.0
trigger times: 1
end of epoch 15: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-4.3912e-02,  6.8169e-02,  1.2184e-01, -3.8944e-01,  1.1433e-01,
         -1.0284e-04, -2.4843e-02,  6.0486e-02, -6.8748e-05, -3.2085e-01,
         -1.4322e-03, -1.7116e+00, -2.2419e+00]], device='cuda:3'))])
end of epoch 16: val_loss 1.7881390590446245e-09, val_acc 1.0
trigger times: 1
end of epoch 17: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.8414e-07, -1.7842e-07, -1.8821e-05,  9.0247e-05, -7.4974e-04,
         -2.1191e-04,  4.4214e-06,  1.8580e-05, -3.0419e-04,  3.9810e-05,
         -1.4323e-03,  1.0411e-04, -1.2927e+00]], device='cuda:3'))])
end of epoch 18: val_loss 0.49726098471740754, val_acc 0.96
trigger times: 1
end of epoch 19: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.5931e-01,  3.4352e-01,  1.8829e-01, -1.5250e-01,  3.6424e-05,
          7.3807e-06, -1.3168e-02,  3.7084e-06,  2.9506e-05, -2.5865e-05,
         -1.4324e-03, -1.1007e+00, -2.1206e+00]], device='cuda:3'))])
end of epoch 20: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-3.8530e-05,  8.9500e-02, -2.5434e-05, -3.8661e-05,  9.3193e-05,
          3.1384e-05,  1.2753e-06, -1.3043e-06,  5.5025e-05, -9.1654e-05,
         -1.4324e-03,  2.0812e-05, -1.7880e+00]], device='cuda:3'))])
end of epoch 21: val_loss 5.006787656469669e-08, val_acc 1.0
trigger times: 1
end of epoch 22: val_loss 7.771172677131233e-06, val_acc 1.0
trigger times: 2
end of epoch 23: val_loss 1.0430703696329147e-07, val_acc 1.0
trigger times: 3
end of epoch 24: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 8.2647e-05, -1.4222e-04, -3.6271e-05,  3.8789e-06,  1.9733e-05,
         -5.1191e-05,  2.2971e-07,  2.8580e-06, -2.1168e-04, -2.7316e-05,
         -1.4325e-03, -4.8022e-04, -1.2745e+00]], device='cuda:3'))])
end of epoch 25: val_loss 1.7285317426285475e-08, val_acc 1.0
trigger times: 1
end of epoch 26: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.2265e-02,  2.1364e-01,  2.9596e-02, -1.3877e-01, -4.2882e-05,
         -1.6177e-01,  7.1622e-03,  5.9526e-02, -5.0000e-06, -1.2444e-04,
         -1.4326e-03, -1.0949e+00, -2.1556e+00]], device='cuda:3'))])
end of epoch 27: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.3745e-06,  7.0691e-03, -5.7034e-05, -4.5002e-05, -1.2856e-04,
         -1.2610e-04,  8.2993e-07,  5.0398e-03, -1.2363e-04,  1.9289e-04,
         -1.4326e-03, -9.9899e-05, -1.8995e+00]], device='cuda:3'))])
end of epoch 28: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.9096e-05, -2.3190e-05, -2.8449e-05, -1.0701e-04, -3.3480e-04,
         -2.9499e-04,  1.8181e-06,  2.1135e-10, -1.6765e-04,  2.3641e-04,
         -1.4327e-03, -3.3648e-04, -1.2695e+00]], device='cuda:3'))])
end of epoch 29: val_loss 2.980231634808206e-09, val_acc 1.0
trigger times: 1
end of epoch 30: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-6.2836e-02,  1.0304e-01,  1.3509e-05, -1.7878e-01, -7.9239e-05,
         -6.3953e-05, -1.3711e-02,  9.5043e-03, -3.3652e-05,  6.0248e-05,
         -1.4327e-03, -1.1802e+00, -1.9767e+00]], device='cuda:3'))])
end of epoch 31: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.0542e-05, -1.9440e-05,  3.1664e-05, -1.3711e-02, -9.3251e-05,
         -3.9377e-05, -6.5765e-06, -4.6808e-06, -8.5144e-05,  1.4736e-04,
         -1.4328e-03,  2.2702e-04, -1.5999e+00]], device='cuda:3'))])
end of epoch 32: val_loss 4.544746226997632e-06, val_acc 1.0
trigger times: 1
end of epoch 33: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.7090e-02,  3.0850e-01,  4.5649e-01, -1.0405e-01,  3.0948e-02,
         -2.8513e-05,  8.8977e-03, -1.7080e-03,  1.8066e-05, -4.7127e-05,
         -1.4328e-03, -1.2988e+00, -2.2118e+00]], device='cuda:3'))])
end of epoch 34: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-6.0645e-06,  1.4928e-01,  3.0299e-01, -6.4652e-07,  4.2810e-05,
          6.0300e-05, -1.2163e-07, -3.5515e-06,  1.2443e-04, -1.0037e-04,
         -1.4329e-03, -5.0354e-01, -2.0172e+00]], device='cuda:3'))])
end of epoch 35: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.7162e-05, -1.0861e-06, -3.6111e-05, -8.3349e-06, -1.6393e-04,
          1.7649e-04,  2.7205e-06, -1.8765e-06, -1.2665e-04,  2.8498e-04,
         -1.4329e-03, -4.2096e-04, -1.5354e+00]], device='cuda:3'))])
end of epoch 36: val_loss 0.00032896459931137657, val_acc 1.0
trigger times: 1
end of epoch 37: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-4.1539e-02,  3.3396e-01,  2.2217e-01, -3.0362e-01, -2.3351e-05,
         -5.3524e-02, -2.5871e-02,  2.9489e-02,  8.7485e-05, -3.8211e-05,
         -1.4330e-03, -1.9144e+00, -2.5046e+00]], device='cuda:3'))])
end of epoch 38: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-7.2746e-05,  1.6992e-01,  1.8630e-02, -1.5649e-01, -5.1335e-05,
         -4.3636e-05, -1.6785e-02,  3.5824e-04, -2.3382e-05, -7.4996e-05,
         -1.4330e-03, -9.9398e-01, -2.2505e+00]], device='cuda:3'))])
end of epoch 39: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.7152e-04, -5.1600e-05,  1.0078e-04,  5.0593e-05, -1.1949e-04,
         -1.1652e-04,  3.3353e-07,  5.4034e-06, -1.0856e-04,  2.3932e-04,
         -1.4331e-03,  5.3904e-06, -1.6254e+00]], device='cuda:3'))])
end of epoch 40: val_loss 0.07365145653295706, val_acc 0.995
trigger times: 1
end of epoch 41: val_loss 6.393285467417797e-05, val_acc 1.0
trigger times: 2
end of epoch 42: val_loss 7.521540101151913e-07, val_acc 1.0
trigger times: 3
end of epoch 43: val_loss 1.9073481958287174e-08, val_acc 1.0
trigger times: 4
end of epoch 44: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.3938e-01,  2.5728e-01,  3.5163e-01, -3.1890e-01, -3.5800e-05,
          1.4606e-01, -1.9788e-02,  3.8017e-02,  1.1147e-02, -8.0716e-02,
         -1.4332e-03, -1.2993e+00, -2.0231e+00]], device='cuda:3'))])
end of epoch 45: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-5.3598e-02,  1.3930e-01,  2.5604e-01, -2.1270e-01, -8.8564e-05,
          2.0294e-05, -1.2937e-02,  1.5709e-02, -1.1187e-04, -3.7579e-05,
         -1.4333e-03, -6.3251e-01, -1.8685e+00]], device='cuda:3'))])
end of epoch 46: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.9348e-05, -7.7402e-06,  2.4817e-02,  4.3175e-07, -2.2679e-04,
          6.1645e-05, -2.3691e-06, -8.4516e-06, -2.6367e-04, -1.0176e-04,
         -1.4333e-03,  1.2174e-04, -1.4842e+00]], device='cuda:3'))])
end of epoch 47: val_loss 3.689655158030547e-05, val_acc 1.0
trigger times: 1
end of epoch 48: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-3.1035e-02,  4.9813e-01,  2.0386e-01, -2.6632e-01,  6.1758e-06,
         -1.4514e-05, -2.3101e-03,  1.5745e-02,  1.6843e-05,  1.2618e-05,
         -1.4334e-03, -1.3526e+00, -2.1889e+00]], device='cuda:3'))])
end of epoch 49: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.5048e-05,  2.8340e-01,  2.3073e-05, -8.9792e-02,  2.9466e-04,
         -1.1304e-04, -1.9849e-03, -8.9670e-07, -1.4206e-05, -9.5472e-05,
         -1.4334e-03, -2.3873e-01, -1.9588e+00]], device='cuda:3'))])
end of epoch 50: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-3.6950e-05,  3.0078e-06,  9.5919e-06, -1.0391e-04,  7.1934e-04,
         -2.5542e-04, -4.7538e-07, -2.9282e-06, -4.4002e-05, -5.5052e-04,
         -1.4334e-03, -3.8077e-04, -1.3599e+00]], device='cuda:3'))])
end of epoch 51: val_loss 2.384185471271394e-09, val_acc 1.0
trigger times: 1
end of epoch 52: val_loss 1.548361542376142e-06, val_acc 1.0
trigger times: 2
end of epoch 53: val_loss 1.561639731306741e-07, val_acc 1.0
trigger times: 3
end of epoch 54: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.8199e-01,  1.7399e-01,  2.5757e-01, -2.6256e-01,  2.6801e-01,
         -6.4251e-01, -7.5742e-03, -4.2701e-02, -8.0336e-02,  5.2578e-02,
         -1.4336e-03, -1.8690e+00, -2.4172e+00]], device='cuda:3'))])
end of epoch 55: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.5894e-01,  8.0488e-02,  1.6093e-01, -1.8530e-01, -9.7292e-06,
         -1.5876e-01, -9.2929e-04, -2.6520e-02,  6.0912e-05,  2.4869e-04,
         -1.4336e-03, -1.2342e+00, -2.2638e+00]], device='cuda:3'))])
end of epoch 56: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.7024e-05, -1.1522e-05,  3.9390e-06,  9.8241e-05,  8.9124e-05,
          2.1954e-04, -2.2030e-06, -2.7832e-06,  1.4454e-04,  5.9986e-04,
         -1.4336e-03, -6.1948e-04, -1.8865e+00]], device='cuda:3'))])
end of epoch 57: val_loss 5.9008564861073864e-08, val_acc 1.0
trigger times: 1
end of epoch 58: val_loss 2.5033921353667664e-08, val_acc 1.0
trigger times: 2
end of epoch 59: val_loss 2.831144199433311e-07, val_acc 1.0
trigger times: 3
end of epoch 60: val_loss 2.363888235201728e-06, val_acc 1.0
trigger times: 4
end of epoch 61: val_loss 2.3841852225814363e-09, val_acc 1.0
trigger times: 5
end of epoch 62: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.1480e-05,  2.6086e-01,  9.6198e-03,  4.9869e-06,  2.6166e-05,
         -9.7221e-05,  4.3192e-07,  2.0517e-02,  1.4320e-05, -2.2582e-05,
         -1.4339e-03, -4.6818e-01, -1.9854e+00]], device='cuda:3'))])
end of epoch 63: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 8.7769e-05,  3.0809e-06,  1.3944e-06, -8.6515e-06,  1.8218e-04,
         -2.2520e-04,  9.8939e-08, -2.6551e-07,  3.7794e-05,  5.9493e-04,
         -1.4339e-03, -2.9733e-04, -1.5193e+00]], device='cuda:3'))])
end of epoch 64: val_loss 0.00032936008205410874, val_acc 1.0
trigger times: 1
end of epoch 65: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.7969e-03,  4.6130e-01,  2.8035e-01, -2.9906e-01,  5.3278e-02,
         -3.7432e-01, -1.8583e-02,  7.2380e-02, -3.4266e-04, -1.9705e-01,
         -1.4340e-03, -2.1419e+00, -2.7945e+00]], device='cuda:3'))])
end of epoch 66: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.8650e-05,  3.5948e-01,  1.7779e-01, -2.1563e-01,  6.7821e-05,
          1.3097e-06, -1.0960e-02,  4.5924e-02, -1.8195e-05, -1.4946e-04,
         -1.4340e-03, -1.3739e+00, -2.6187e+00]], device='cuda:3'))])
end of epoch 67: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.2163e-05,  1.0896e-01,  9.2439e-06, -1.0337e-02,  1.4405e-04,
         -4.9796e-05,  4.9438e-06, -3.0275e-06, -4.8139e-05, -3.7293e-04,
         -1.4340e-03,  3.0687e-05, -2.1863e+00]], device='cuda:3'))])
end of epoch 68: val_loss 4.172324743478839e-09, val_acc 1.0
trigger times: 1
end of epoch 69: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.4803e-01,  4.0441e-01,  1.8457e-01, -1.4619e-01,  1.0131e-01,
         -1.0881e-01,  9.8982e-03,  5.5408e-02,  1.9777e-01, -1.2912e-04,
         -1.4341e-03, -1.3765e+00, -2.1642e+00]], device='cuda:3'))])
end of epoch 70: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.6490e-05,  2.6589e-01,  5.5647e-02, -4.8286e-02, -2.8870e-05,
         -1.0552e-04,  2.7494e-03,  1.9818e-02, -5.9052e-05,  1.4393e-04,
         -1.4341e-03, -5.5176e-01, -1.9737e+00]], device='cuda:3'))])
end of epoch 71: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-4.4620e-05,  3.7808e-05, -4.5370e-05, -7.5069e-06, -8.4128e-05,
         -2.6546e-04, -1.7058e-07, -2.9866e-05,  1.1396e-04,  3.6688e-04,
         -1.4342e-03,  5.3724e-05, -1.5052e+00]], device='cuda:3'))])
end of epoch 72: val_loss 0.00050413337897119, val_acc 1.0
trigger times: 1
end of epoch 73: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.0006e-01,  1.9999e-01,  2.8887e-01, -1.1147e-01,  8.2863e-02,
         -6.8345e-03, -4.1355e-07,  9.5543e-02, -3.2700e-05,  3.8828e-05,
         -1.4342e-03, -1.1594e+00, -2.2756e+00]], device='cuda:3'))])
end of epoch 74: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.1716e-05,  2.6172e-02,  1.2917e-01,  2.6561e-04, -1.1153e-04,
         -2.4259e-05,  1.7726e-06,  6.0174e-02,  5.1473e-05,  3.0325e-05,
         -1.4343e-03, -2.2096e-01, -2.0498e+00]], device='cuda:3'))])
end of epoch 75: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-5.4521e-05,  5.4561e-05, -1.3454e-05,  5.4254e-05, -2.0259e-04,
         -2.1270e-04,  4.9566e-06,  1.5278e-05, -1.0854e-04,  1.5403e-04,
         -1.4343e-03, -6.0593e-04, -1.4945e+00]], device='cuda:3'))])
end of epoch 76: val_loss 0.032420473069250874, val_acc 0.995
trigger times: 1
end of epoch 77: val_loss 6.630608811946104e-05, val_acc 1.0
trigger times: 2
end of epoch 78: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-8.7203e-06,  4.3280e-05,  4.1784e-05, -9.7756e-03,  2.4602e-04,
         -5.0775e-05,  3.1525e-05,  1.9645e-02, -2.5025e-04,  1.9567e-04,
         -1.4344e-03,  1.2373e-04, -1.4002e+00]], device='cuda:3'))])
end of epoch 79: val_loss 6.522920104039542e-06, val_acc 1.0
trigger times: 1
end of epoch 80: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 5.1718e-02,  6.7489e-02,  1.4998e-01, -7.6611e-02,  1.9899e-01,
         -1.6571e-01,  1.2026e-02,  3.5109e-02, -1.1660e-01, -9.9606e-08,
         -1.4345e-03, -9.7740e-01, -1.7130e+00]], device='cuda:3'))])
end of epoch 81: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-4.5480e-05, -2.1731e-05, -3.4623e-05,  4.9152e-06,  1.2906e-04,
          3.4057e-05,  2.8313e-03,  1.5330e-07,  4.9765e-05,  5.0450e-05,
         -1.4345e-03, -1.1820e-01, -1.4378e+00]], device='cuda:3'))])
end of epoch 82: val_loss 1.2010245332305657e-06, val_acc 1.0
trigger times: 1
end of epoch 83: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-9.9632e-02,  1.2662e-01,  2.2426e-01, -2.3476e-01,  8.5744e-02,
         -1.5402e-01,  9.1014e-03,  3.1723e-03,  4.6811e-06,  3.4187e-05,
         -1.4346e-03, -1.3882e+00, -2.1839e+00]], device='cuda:3'))])
end of epoch 84: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.9800e-05,  1.0532e-05,  7.5463e-02, -1.4149e-01, -1.1508e-05,
          3.2477e-05,  1.0152e-04, -3.3367e-06,  1.0130e-04,  8.0207e-05,
         -1.4346e-03, -6.4188e-01, -1.9847e+00]], device='cuda:3'))])
end of epoch 85: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 7.5655e-05,  2.8629e-05,  3.4414e-05, -3.1834e-05,  9.9583e-05,
          7.8979e-05, -2.2489e-06, -9.6358e-06,  2.6179e-04,  1.9395e-04,
         -1.4347e-03, -6.6099e-05, -1.4947e+00]], device='cuda:3'))])
end of epoch 86: val_loss 0.0006775853641363483, val_acc 1.0
trigger times: 1
end of epoch 87: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 6.0376e-02,  2.7486e-01,  1.0643e-01, -1.4974e-01, -2.1571e-05,
         -1.7724e-01, -4.8055e-03,  7.9571e-02,  4.1172e-05,  1.4130e-04,
         -1.4347e-03, -1.5777e+00, -2.1340e+00]], device='cuda:3'))])
end of epoch 88: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.7754e-05,  6.1754e-02, -2.9975e-06, -9.8338e-03,  3.4275e-05,
          6.8307e-05, -2.1534e-06,  4.5403e-02,  9.3265e-05,  3.6145e-04,
         -1.4348e-03, -5.0467e-01, -1.8441e+00]], device='cuda:3'))])
end of epoch 89: val_loss 3.5762784023063432e-09, val_acc 1.0
trigger times: 1
end of epoch 90: val_loss 3.711991594137487e-06, val_acc 1.0
trigger times: 2
end of epoch 91: val_loss 2.6562486307284417e-05, val_acc 1.0
trigger times: 3
end of epoch 92: val_loss 4.768370303054325e-09, val_acc 1.0
trigger times: 4
end of epoch 93: val_loss 1.575780175357977e-05, val_acc 1.0
trigger times: 5
end of epoch 94: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 6
end of epoch 95: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-5.3655e-05,  9.7043e-02,  4.6078e-02, -2.0339e-02, -3.5205e-05,
         -4.0750e-05, -2.3307e-07,  6.0981e-02,  9.3476e-05, -9.8908e-05,
         -1.4350e-03, -2.8057e-01, -1.7574e+00]], device='cuda:3'))])
end of epoch 96: val_loss 1.7881392366803084e-09, val_acc 1.0
trigger times: 1
end of epoch 97: val_loss 4.351124729851108e-08, val_acc 1.0
trigger times: 2
end of epoch 98: val_loss 8.582995178585406e-08, val_acc 1.0
trigger times: 3
end of epoch 99: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.7432e-06,  5.6407e-06,  1.3824e-05,  1.8354e-05, -4.8661e-05,
         -1.9633e-06, -3.3422e-06, -6.6003e-06,  1.8492e-04, -2.4217e-04,
         -1.4351e-03,  3.4545e-04, -1.2505e+00]], device='cuda:3'))])
Finished training.
0 -53.0764636695385 -54.98547503240923
1 -55.15623424947262 -50.492268601198035
2 -49.40962718427181 -50.03933801517046
3 -50.83596816658974 -49.75347184620696
4 -50.32339112460613 -49.72654640753777
5 -53.43691544234753 -46.98011874490918
6 -50.61932960152626 -45.7351542845057
7 -48.61457930132747 -45.670579884154705
8 -50.054469257593155 -44.99030608142343
9 -47.04277493059635 -44.14602409201361
10 -47.566616639494896 -43.81326882122305
11 -48.18287896737456 -43.18878399086166
12 -49.21919985115528 -42.29180714825394
13 -46.568613685667515 -42.00401746161006
14 -51.44096298515797 -41.6910044370425
15 -47.475565776228905 -41.68588229294918
16 -47.96501851081848 -41.281777102712205
17 -45.9403415620327 -40.44278203413966
18 -47.4214356392622 -40.34838365523108
19 -45.440143436193466 -39.599701153458774
20 -45.48545905947685 -39.57586365327889
21 -43.31669524312019 -39.31972693233231
22 -41.30452474951744 -39.024610555047154
23 -43.412224635481834 -38.45534493538269
24 -43.36334829777479 -38.41270390343083
25 -44.71854904294014 -38.35634328077039
26 -41.98456993326545 -37.79713616772368
27 -39.781483232975006 -37.741528994987384
28 -47.23952320218086 -37.66475323879293
29 -42.82094247639179 -37.513139380385574
30 -47.66283555328846 -37.1809993033689
31 -43.548558700829744 -37.100703136010694
32 -42.61035184562206 -37.00630588930485
33 -44.41511704027653 -36.821916772458344
34 -43.85357716679573 -36.48799015296732
35 -41.121094450354576 -36.20965269874363
36 -42.346282351762056 -36.19207561676116
37 -44.64912089705467 -36.114459029559086
38 -41.77223029732704 -35.78149902167743
39 -39.40145745128393 -35.394503873250635
40 -43.45932997763157 -35.26282499693737
41 -42.12348861992359 -35.24303541418371
42 -43.96486892551184 -35.209705244501436
43 -42.48581272363663 -35.0654408505187
44 -40.91974923759699 -34.80241747531743
45 -40.89705228805542 -34.64469044638467
46 -38.718960631638765 -33.84284985953318
47 -36.728313349187374 -32.70706485357069
48 -36.39448665082455 -31.969099402548657
49 -37.324812300503254 -31.7109134007892
50 -39.07830125838518 -31.64414355845032
51 -38.31266334652901 -31.392382758954444
52 -40.60338542610407 -31.223196019713853
53 -36.15236508846283 -31.12953085092458
54 -37.615687005221844 -29.39157139549552
55 -38.5397290289402 -29.340125609942326
56 -31.354052551090717 -29.106189988903285
57 -34.791595965623856 -27.41102349748205
58 -35.43122408539057 -27.343722362182305
59 -35.92849563807249 -27.196681629483837
60 -34.57581349462271 -27.07399028854534
61 -31.48311585187912 -26.7047217556024
62 -33.7406240105629 -26.244794902859052
63 -34.1134619936347 -25.548365085275513
64 -30.937451407313347 -25.45878528601009
65 -32.9078309237957 -24.879106999799365
66 -32.15972247347236 -24.828695359328833
67 -33.248647194355726 -24.592745144504722
68 -32.060850985348225 -23.978745577896312
69 -30.874953225255013 -23.57262108435893
70 -29.230673849582672 -23.44970807952351
71 -30.751762442290783 -22.745309160183492
72 -29.447848290205002 -22.60679894414887
73 -29.605728082358837 -22.19891031871716
74 -29.267777900211513 -20.656863763892378
75 -26.75248546153307 -20.444472560731253
76 -26.71227177232504 -20.19699010077007
77 -29.54901783540845 -20.13839114930498
78 -28.149599883705378 -19.63760343800059
79 -28.507568314671516 -19.515598718228343
80 -26.883009258657694 -18.92838809611677
81 -26.700492464005947 -17.994774057192853
82 -24.601127810776234 -17.55742370467821
83 -23.644560545682907 -16.823073927842348
84 -22.667003633454442 -14.855082803515382
85 -21.92830721847713 -14.531424598833084
86 -20.82232605665922 -14.442420089224363
87 -22.5599177852273 -13.596012850960644
88 -16.644553756341338 -12.68135972540495
89 -21.581074092537165 -12.66418205637357
90 -20.457154095638543 -12.30017947419658
91 -19.185343235731125 -12.151904772081672
92 -19.03657670877874 -11.788852141676486
93 -18.311843384057283 -10.869989101210326
94 -18.707994488067925 -10.327681503524177
95 -15.65916977263987 -9.8572159761571
96 -15.193261126521975 -8.330116995310416
97 -15.58238185569644 -8.133195842510668
98 -16.578657306730747 -8.108197691178031
99 -11.402796793729067 -7.57539849177145
100 -10.93649660423398 -7.362443126623615
101 -10.559857035055757 -7.108327355338034
102 -11.224894083105028 -6.959063561385431
103 -10.970202509313822 -6.776946485018116
104 -10.143446602392942 -6.7220638398623045
105 -11.247436236590147 -6.719970621583102
106 -15.641832765191793 -6.535447341844848
107 -12.922688653692603 -6.51820418055673
108 -12.579009180888534 -5.615796733870542
109 -10.717267822474241 -5.34720210027791
110 -10.42802393808961 -5.078485007852753
111 -10.74513372965157 -5.027957977402961
112 -9.782270665280521 -4.827572916892203
113 -10.205954233184457 -4.63049541560991
114 -9.88847067207098 -4.230832004686763
115 -10.152458502911031 -4.031048624093466
116 -9.342764401808381 -3.3844671463622564
117 -9.55371271353215 -3.3322555012187633
118 -9.909202240407467 -2.6416623314910934
119 -8.060785536654294 -1.9136196540088464
train accuracy: 1.0
validation accuracy: 1.0
[-50.4922686  -50.03933802 -49.75347185 -49.72654641 -46.98011874
 -45.67057988 -44.14602409 -43.81326882 -41.68588229 -40.34838366
 -39.31972693 -39.02461056 -38.4127039  -38.35634328 -37.79713617
 -37.51313938 -37.00630589 -36.82191677 -35.78149902 -35.262825
 -34.80241748 -34.64469045 -33.84284986 -31.9690994  -31.7109134
 -31.39238276 -31.12953085 -29.34012561 -27.4110235  -26.70472176
 -24.879107   -24.59274514 -23.57262108 -20.65686376 -20.44447256
 -20.1969901  -20.13839115 -19.63760344 -19.63436396 -19.03868419
 -19.01366146 -18.40219305 -18.13112681 -18.12524762 -17.5574237
 -16.46524529 -16.44056833 -15.69844216 -15.12252306 -15.08728073
 -15.04626953 -14.98912762 -14.8550828  -14.78622576 -14.5314246
 -14.51735397 -14.44242009 -14.41583474 -14.37972793 -14.13660346
 -13.68634927 -13.59601285 -13.53453212 -13.46738201 -13.28824842
 -12.94042091 -12.88077847 -12.87408383 -12.85344495 -12.68135973
 -12.66418206 -12.64627127 -12.63040428 -12.5024721  -12.24407241
 -12.15190477 -11.98108374 -11.97027503 -11.9042515  -11.58584831
 -11.53480251 -11.4436213  -11.20813099 -10.92999647 -10.56227461
 -10.31685999 -10.05616271  -9.89169983  -9.73501692  -9.22561711
  -9.14765635  -9.0098247   -9.00032931  -8.96382669  -8.45579764
  -8.44036508  -8.26243204  -8.13319584  -8.02716962  -7.94379606
  -7.63951035  -7.57539849  -7.53264209  -7.36278501  -7.36244313
  -7.10832736  -6.95906356  -6.85677384  -6.77694649  -6.72206384
  -6.66003536  -6.53544734  -6.38767366  -5.69407869  -5.61579673
  -5.07848501  -5.02795798  -4.230832    -3.3322555   -2.64166233]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:3
end of epoch 0: val_loss 0.0013653383274447961, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.5946e-04,  1.7098e-03,  1.4810e-02, -1.8438e-04, -7.7458e-05,
          1.9474e-04, -5.1814e-04, -5.8338e-04, -6.1764e-05, -2.5468e-02,
         -1.4320e-03, -5.0470e-01, -3.8731e-01]], device='cuda:3'))])
end of epoch 1: val_loss 0.0023077428518176292, val_acc 1.0
trigger times: 1
end of epoch 2: val_loss 8.450407328368214e-05, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.1632e-02,  1.5674e-01,  8.7872e-02, -3.3405e-01,  3.7460e-01,
          3.3333e-01,  2.0204e-02,  9.8033e-02, -4.2256e-01, -9.6871e-01,
         -1.4320e-03, -1.9876e+00, -1.7202e+00]], device='cuda:3'))])
end of epoch 3: val_loss 5.590703926117158e-07, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 5.7164e-06,  3.2903e-02,  3.0654e-05, -2.0834e-01,  8.0709e-05,
         -3.9116e-05,  6.0880e-03,  7.1396e-02,  7.5611e-05, -4.9547e-01,
         -1.4320e-03, -1.5458e+00, -1.4568e+00]], device='cuda:3'))])
end of epoch 4: val_loss 1.1423041148559065, val_acc 0.94
trigger times: 1
end of epoch 5: val_loss 2.470597974024713e-06, val_acc 1.0
trigger times: 2
end of epoch 6: val_loss 4.827963365983123e-08, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-4.8883e-07,  5.4853e-06,  1.2848e-06,  1.5082e-05, -2.7516e-05,
         -2.5695e-05, -1.6476e-06, -4.4896e-03,  2.2086e-05,  3.7844e-04,
         -1.4320e-03, -1.8747e+00, -1.7795e+00]], device='cuda:3'))])
end of epoch 7: val_loss 0.44715650577875704, val_acc 0.97
trigger times: 1
end of epoch 8: val_loss 1.7819147661413127e-06, val_acc 1.0
trigger times: 2
end of epoch 9: val_loss 3.36303146401562e-05, val_acc 1.0
trigger times: 3
end of epoch 10: val_loss 5.278190317081766e-05, val_acc 1.0
trigger times: 4
end of epoch 11: val_loss 2.192111711373457e-05, val_acc 1.0
trigger times: 5
end of epoch 12: val_loss 0.0001900725339851306, val_acc 1.0
trigger times: 6
end of epoch 13: val_loss 5.382586342257411e-06, val_acc 1.0
trigger times: 7
end of epoch 14: val_loss 3.1531101914161755e-05, val_acc 1.0
trigger times: 8
end of epoch 15: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.7920e-01,  2.0976e-01,  2.2434e-01, -4.9485e-02,  7.2682e-07,
          2.7812e-01, -6.4294e-02, -1.9811e-02, -8.3636e-02, -6.7463e-01,
         -1.4322e-03, -2.0092e+00, -2.2882e+00]], device='cuda:3'))])
end of epoch 16: val_loss 5.072619160131353e-06, val_acc 1.0
trigger times: 1
end of epoch 17: val_loss 1.1465593411479346e-05, val_acc 1.0
trigger times: 2
end of epoch 18: val_loss 2.187710836629719e-06, val_acc 1.0
trigger times: 3
end of epoch 19: val_loss 3.544283924199476e-06, val_acc 1.0
trigger times: 4
end of epoch 20: val_loss 5.735436182177978e-05, val_acc 1.0
trigger times: 5
end of epoch 21: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.0909e-02, -8.3797e-03,  6.9019e-02, -1.6526e-01,  1.0488e-01,
         -1.4502e-01, -2.2887e-02,  1.8048e-03, -1.3619e-01, -6.5642e-01,
         -1.4324e-03, -1.9042e+00, -2.3912e+00]], device='cuda:3'))])
end of epoch 22: val_loss 2.3960804613665233e-05, val_acc 1.0
trigger times: 1
end of epoch 23: val_loss 0.15858632755810614, val_acc 0.965
trigger times: 2
end of epoch 24: val_loss 2.1457658405665826e-08, val_acc 1.0
trigger times: 3
end of epoch 25: val_loss 1.1198263656204688e-05, val_acc 1.0
trigger times: 4
end of epoch 26: val_loss 0.00033112432633782164, val_acc 1.0
trigger times: 5
end of epoch 27: val_loss 3.5404127494587103e-07, val_acc 1.0
trigger times: 6
end of epoch 28: val_loss 0.0004510035452901917, val_acc 1.0
trigger times: 7
end of epoch 29: val_loss 0.0002188084831282211, val_acc 1.0
trigger times: 8
end of epoch 30: val_loss 5.36441721266101e-09, val_acc 1.0
trigger times: 9
end of epoch 31: val_loss 6.835824548392821e-05, val_acc 1.0
trigger times: 10
Early stopping.
0 -79.18420940637589 -50.492268601198035
1 -77.89497974514961 -50.03933801517046
2 -64.30259583890438 -49.75347184620696
3 -73.8588093817234 -49.72654640753777
4 -47.73719096183777 -46.98011874490918
5 -69.36855384707451 -45.670579884154705
6 -83.81032741069794 -44.14602409201361
7 -63.010767072439194 -43.81326882122305
8 -65.99911817908287 -41.68588229294918
9 -70.35444352030754 -40.34838365523108
10 -72.6025624871254 -39.31972693233231
11 -64.32025098800659 -39.024610555047154
12 -60.60807555913925 -38.41270390343083
13 -57.26097875833511 -38.35634328077039
14 -63.748810559511185 -37.79713616772368
15 -54.222621731460094 -37.513139380385574
16 -63.09142845869064 -37.00630588930485
17 -60.97433726489544 -36.821916772458344
18 -63.713727205991745 -35.78149902167743
19 -63.723600536584854 -35.26282499693737
20 -54.082304671406746 -34.80241747531743
21 -54.1087676435709 -34.64469044638467
22 -60.42536023259163 -33.84284985953318
23 -47.12897369265556 -31.969099402548657
24 -54.47271053493023 -31.7109134007892
25 -51.32965110242367 -31.392382758954444
26 -50.98098039627075 -31.12953085092458
27 -55.16759291291237 -29.340125609942326
28 -53.22178499400616 -27.41102349748205
29 -50.37347716093063 -26.7047217556024
30 -50.56483969092369 -24.879106999799365
31 -45.88050536811352 -24.592745144504722
32 -47.02826648950577 -23.57262108435893
33 -38.32642249017954 -20.656863763892378
34 -37.70339136943221 -20.444472560731253
35 -40.821728229522705 -20.19699010077007
36 -37.456523314118385 -20.13839114930498
37 -40.219344317913055 -19.63760343800059
38 -28.586685597896576 -19.634363962764166
39 -29.057773292064667 -19.038684194721387
40 -27.98331046104431 -19.013661458547123
41 -28.31673899292946 -18.40219305308781
42 -28.212363868951797 -18.131126814449324
43 -26.793593913316727 -18.12524762224982
44 -33.70934899151325 -17.55742370467821
45 -26.216339141130447 -16.465245286323213
46 -25.128383338451385 -16.440568326848314
47 -24.919495701789856 -15.698442160753391
48 -25.427176386117935 -15.12252306211355
49 -25.007611006498337 -15.087280726906778
50 -26.642453715205193 -15.046269525186256
51 -24.7045736014843 -14.98912761511048
52 -29.331706253811717 -14.855082803515382
53 -23.682663291692734 -14.786225758580233
54 -26.942465726286173 -14.531424598833084
55 -24.39014232158661 -14.517353968866582
56 -28.208967242389917 -14.442420089224363
57 -23.075939387083054 -14.415834737533931
58 -24.054342061281204 -14.379727929402803
59 -24.730569571256638 -14.136603456622273
60 -22.638271540403366 -13.686349266389305
61 -29.11527732014656 -13.596012850960644
62 -23.130373746156693 -13.534532124095186
63 -22.597568333148956 -13.46738201284224
64 -22.596113443374634 -13.288248424996306
65 -23.017298758029938 -12.940420913193535
66 -21.14658972620964 -12.880778469177017
67 -23.747171342372894 -12.87408382585279
68 -21.797271221876144 -12.853444948014234
69 -28.728034622967243 -12.68135972540495
70 -26.156226634979248 -12.66418205637357
71 -23.18064123392105 -12.646271270327462
72 -21.13791248202324 -12.630404284954777
73 -22.471176832914352 -12.502472096276058
74 -22.034524470567703 -12.244072413557515
75 -30.663430750370026 -12.151904772081672
76 -23.267768040299416 -11.98108374419155
77 -22.19169083237648 -11.970275029169322
78 -22.964203238487244 -11.904251499707616
79 -22.037068486213684 -11.585848306718171
80 -21.811925932765007 -11.534802514798704
81 -21.770724400877953 -11.443621302181096
82 -21.02426165342331 -11.20813098648127
83 -21.297628194093704 -10.92999647335951
84 -19.3793553262949 -10.56227460567635
85 -21.16102509200573 -10.31685998918951
86 -18.853168964385986 -10.056162705994502
87 -20.89710883796215 -9.891699828961956
88 -20.470836728811264 -9.735016921371221
89 -19.01256436109543 -9.22561711361344
90 -20.392374873161316 -9.147656351662803
91 -17.941585421562195 -9.00982469640954
92 -19.78441160917282 -9.000329314155312
93 -18.10828810930252 -8.963826694643434
94 -18.516951099038124 -8.455797636261352
95 -19.157031171023846 -8.440365078847586
96 -18.61487767100334 -8.262432035415433
97 -19.9304816480726 -8.133195842510668
98 -18.152382373809814 -8.027169616483599
99 -19.11624503135681 -7.943796064843775
100 -16.723022773861885 -7.639510351200451
101 -22.78778673708439 -7.57539849177145
102 -18.07451568543911 -7.532642088692973
103 -17.466019973158836 -7.36278501235848
104 -21.772364672273397 -7.362443126623615
105 -21.880085678771138 -7.108327355338034
106 -19.72470421716571 -6.959063561385431
107 -16.321539133787155 -6.85677384072701
108 -16.42762214690447 -6.776946485018116
109 -20.469132837839425 -6.7220638398623045
110 -15.33083974570036 -6.660035363747956
111 -20.275134570896626 -6.535447341844848
112 -16.20105868577957 -6.387673664752574
113 -15.513500735163689 -5.694078692466705
114 -15.850945265963674 -5.615796733870542
115 -15.330830428749323 -5.078485007852753
116 -16.794878048822284 -5.027957977402961
117 -12.840485956519842 -4.230832004686763
118 -11.973407588899136 -3.3322555012187633
119 -12.176969293504953 -2.6416623314910934
train accuracy: 1.0
validation accuracy: 1.0
[-50.4922686  -50.03933802 -46.98011874 -45.67057988 -44.14602409
 -38.4127039  -38.35634328 -36.82191677 -35.262825   -34.64469045
 -33.84284986 -31.9690994  -27.4110235  -26.70472176 -24.879107
 -24.59274514 -20.65686376 -20.13839115 -19.63436396 -18.12524762
 -17.5574237  -16.46524529 -15.69844216 -15.12252306 -15.08728073
 -15.04626953 -14.98912762 -14.8550828  -14.78622576 -14.57221323
 -14.57033715 -14.5314246  -14.47587183 -14.44242009 -14.13660346
 -13.69449913 -13.67333424 -13.53453212 -13.45393374 -13.11188782
 -12.94042091 -12.88077847 -12.85344495 -12.76848398 -12.68135973
 -12.66418206 -12.64857754 -12.63040428 -12.59783018 -12.5024721
 -12.15190477 -11.98108374 -11.97027503 -11.94729849 -11.58584831
 -11.5758374  -11.55694013 -11.43682694 -11.27302227 -11.20813099
 -11.09938699 -11.0351834  -11.01670111 -10.92999647 -10.65726784
 -10.46949731  -9.89169983  -9.87627927  -9.70369163  -9.66454975
  -9.6226534   -9.58850138  -9.25841285  -9.23303736  -9.22561711
  -9.22090272  -9.00032931  -8.96382669  -8.83869305  -8.45579764
  -8.26322821  -8.13319584  -8.02716962  -7.94379606  -7.57539849
  -7.53264209  -7.27678003  -7.25409082  -7.11739632  -6.96798766
  -6.96052528  -6.77694649  -6.74928003  -6.72206384  -6.43916901
  -6.39792348  -5.69407869  -5.69159461  -5.39987634  -5.30791743
  -5.1859748   -5.02795798  -4.93752492  -4.91803844  -4.85701611
  -4.62621557  -4.42077513  -4.33633383  -4.24422823  -3.78400371
  -3.58367476  -3.51212977  -3.5013679   -3.239227    -3.22533509
  -3.17327799  -3.11077157  -2.32250773  -2.25832126  -2.01605322]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:3
end of epoch 0: val_loss 0.0005188368874269856, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.1402e-01,  9.1488e-02,  2.5188e-02,  2.1993e-02, -1.2061e-02,
          2.3815e-04, -7.5730e-03,  7.0479e-03, -1.1350e-07, -6.2783e-02,
         -1.4320e-03, -8.9028e-01, -6.3155e-01]], device='cuda:3'))])
end of epoch 1: val_loss 0.0010396558502761266, val_acc 1.0
trigger times: 1
end of epoch 2: val_loss 0.8089517764873588, val_acc 0.955
trigger times: 2
end of epoch 3: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.8357e-01,  3.0339e-01,  7.7403e-02,  5.2589e-02,  2.7821e-02,
         -6.0082e-05, -1.8731e-02, -2.1627e-02, -8.3264e-05, -3.6382e-01,
         -1.4320e-03, -2.6913e+00, -2.1531e+00]], device='cuda:3'))])
end of epoch 4: val_loss 9.6196953865757e-07, val_acc 1.0
trigger times: 1
end of epoch 5: val_loss 0.7049063547013074, val_acc 0.94
trigger times: 2
end of epoch 6: val_loss 7.372570623687125e-07, val_acc 1.0
trigger times: 3
end of epoch 7: val_loss 2.6953944276186803e-06, val_acc 1.0
trigger times: 4
end of epoch 8: val_loss 0.0353073824528121, val_acc 0.99
trigger times: 5
end of epoch 9: val_loss 3.130702052551726e-06, val_acc 1.0
trigger times: 6
end of epoch 10: val_loss 0.05122513153400455, val_acc 0.995
trigger times: 7
end of epoch 11: val_loss 9.357904286133589e-08, val_acc 1.0
trigger times: 8
end of epoch 12: val_loss 3.8049841075924464e-05, val_acc 1.0
trigger times: 9
end of epoch 13: val_loss 0.04287767914805965, val_acc 0.98
trigger times: 10
Early stopping.
0 -90.30667638778687 -50.492268601198035
1 -88.8934930562973 -50.03933801517046
2 -58.005512207746506 -46.98011874490918
3 -65.0480495467782 -45.670579884154705
4 -78.96685844659805 -44.14602409201361
5 -72.63054019212723 -38.41270390343083
6 -61.25145509839058 -38.35634328077039
7 -59.32594533264637 -36.821916772458344
8 -61.64209036529064 -35.26282499693737
9 -54.41087916493416 -34.64469044638467
10 -69.71741232275963 -33.84284985953318
11 -49.71246778964996 -31.969099402548657
12 -58.2901217341423 -27.41102349748205
13 -53.60040110349655 -26.7047217556024
14 -42.98661855608225 -24.879106999799365
15 -54.789314806461334 -24.592745144504722
16 -31.601623009890318 -20.656863763892378
17 -41.93514546751976 -20.13839114930498
18 -34.35834130644798 -19.634363962764166
19 -31.692896872758865 -18.12524762224982
20 -43.61354258656502 -17.55742370467821
21 -31.927515745162964 -16.465245286323213
22 -29.77593085169792 -15.698442160753391
23 -32.29963609576225 -15.12252306211355
24 -31.910753786563873 -15.087280726906778
25 -26.697267651557922 -15.046269525186256
26 -29.573068112134933 -14.98912761511048
27 -40.69004397839308 -14.855082803515382
28 -29.897580593824387 -14.786225758580233
29 -17.500069377943873 -14.572213227275022
30 -17.338461650535464 -14.570337152831858
31 -32.18468090891838 -14.531424598833084
32 -17.730157621204853 -14.475871833196331
33 -26.073142655193806 -14.442420089224363
34 -28.966623544692993 -14.136603456622273
35 -18.06925353780389 -13.69449912514163
36 -19.68816214799881 -13.673334243070974
37 -28.88054832816124 -13.534532124095186
38 -18.012284446507692 -13.45393374182641
39 -18.01615597307682 -13.111887824448589
40 -29.59769582748413 -12.940420913193535
41 -31.08293643593788 -12.880778469177017
42 -30.04936710000038 -12.853444948014234
43 -16.389068003743887 -12.768483977935247
44 -24.343598172068596 -12.68135972540495
45 -29.781666599214077 -12.66418205637357
46 -16.21787778288126 -12.648577538962167
47 -27.020640194416046 -12.630404284954777
48 -16.68805504590273 -12.59783018134444
49 -26.7331320643425 -12.502472096276058
50 -28.70498736947775 -12.151904772081672
51 -26.509480878710747 -11.98108374419155
52 -28.8704991042614 -11.970275029169322
53 -16.390501134097576 -11.947298492726024
54 -26.156983196735382 -11.585848306718171
55 -15.589612539857626 -11.575837399288574
56 -15.986966915428638 -11.556940133484384
57 -14.631449164822698 -11.436826942600685
58 -15.261164365336299 -11.273022269768491
59 -27.65564939379692 -11.20813098648127
60 -15.65520103648305 -11.099386988340152
61 -16.37885763309896 -11.035183400130354
62 -14.888079855591059 -11.016701105226776
63 -27.62208181619644 -10.92999647335951
64 -14.166063010692596 -10.657267844670686
65 -14.42917487770319 -10.469497313817401
66 -26.452620774507523 -9.891699828961956
67 -14.157758295536041 -9.876279268337267
68 -13.326539795845747 -9.703691629947691
69 -12.243394592776895 -9.664549752371789
70 -14.312556743621826 -9.622653402800573
71 -13.237022273242474 -9.58850138466281
72 -13.489279232919216 -9.258412849977516
73 -14.011548835784197 -9.233037362027023
74 -24.273932218551636 -9.22561711361344
75 -13.000062882900238 -9.220902716215974
76 -25.53958621621132 -9.000329314155312
77 -25.38804993033409 -8.963826694643434
78 -14.834526114165783 -8.838693045735472
79 -24.238889187574387 -8.455797636261352
80 -11.450996646657586 -8.263228211358884
81 -25.084346517920494 -8.133195842510668
82 -21.771784156560898 -8.027169616483599
83 -25.238121926784515 -7.943796064843775
84 -22.303829230368137 -7.57539849177145
85 -23.517595142126083 -7.532642088692973
86 -16.081233210861683 -7.276780028486416
87 -15.885442480444908 -7.25409081600413
88 -13.848800614476204 -7.117396317348786
89 -15.77707440406084 -6.96798766029557
90 -15.270574256777763 -6.96052527538595
91 -12.632279425859451 -6.776946485018116
92 -17.505498372018337 -6.749280028409141
93 -19.2135049700737 -6.7220638398623045
94 -15.368437893688679 -6.439169012550623
95 -14.857339844107628 -6.397923481373852
96 -19.683636039495468 -5.694078692466705
97 -13.672140330076218 -5.691594605252225
98 -16.157763339579105 -5.39987633971003
99 -14.938449941575527 -5.307917431579535
100 -16.331629745662212 -5.185974797400482
101 -25.415254205465317 -5.027957977402961
102 -12.43601468577981 -4.937524915784605
103 -12.432482209056616 -4.918038444677467
104 -17.655899189412594 -4.8570161087009
105 -19.466632649302483 -4.626215572986378
106 -15.759343802928925 -4.420775126448759
107 -20.350093752145767 -4.336333831576879
108 -14.205945394933224 -4.244228234441251
109 -18.528703801333904 -3.7840037059190053
110 -12.13934475928545 -3.5836747649943446
111 -14.33062169700861 -3.5121297730673273
112 -12.377280313521624 -3.501367901480982
113 -18.9476560652256 -3.239226996013279
114 -16.074697002768517 -3.2253350862909245
115 -11.648207653313875 -3.173277990384719
116 -12.4855350330472 -3.110771566155352
117 -13.561923265457153 -2.3225077264016667
118 -13.722420185804367 -2.2583212592167494
119 -12.358828477561474 -2.01605321743914
train accuracy: 0.9711111111111111
validation accuracy: 0.98
[-50.4922686  -50.03933802 -45.67057988 -44.14602409 -38.4127039
 -31.9690994  -26.70472176 -24.879107   -20.13839115 -19.63436396
 -17.5574237  -15.12252306 -15.08728073 -15.04626953 -14.98912762
 -14.78622576 -14.57033715 -14.5314246  -14.44242009 -13.69449913
 -13.67333424 -13.53453212 -13.28160787 -13.11188782 -13.03601419
 -12.88077847 -12.76848398 -12.68135973 -12.64857754 -12.5024721
 -12.15190477 -11.97027503 -11.60444738 -11.41547111 -11.13929168
 -11.07666478 -11.0351834  -10.65726784 -10.62682405 -10.46949731
 -10.41586558 -10.26144616 -10.1758726   -9.89169983  -9.87627927
  -9.87347445  -9.85614181  -9.73577313  -9.70369163  -9.68597007
  -9.68231081  -9.6226534   -9.6214955   -9.60561306  -9.56895461
  -9.45768955  -9.45159317  -9.30262803  -9.23303736  -9.00032931
  -8.96450231  -8.96382669  -8.86513138  -8.76138579  -8.45579764
  -8.13319584  -7.92292238  -7.80438892  -7.67020091  -7.52444913
  -7.48226106  -7.37565708  -7.36885039  -7.33884548  -7.27678003
  -7.11739632  -6.99889967  -6.97882045  -6.96052528  -6.89242471
  -6.76806474  -6.74928003  -6.65949173  -6.62305499  -6.49282775
  -6.40090862  -6.17013604  -6.081789    -6.07315464  -5.98586002
  -5.97289767  -5.78248127  -5.5702836   -5.53652009  -5.51810096
  -5.30791743  -5.29984414  -5.14335273  -5.12070651  -5.02795798
  -4.93752492  -4.92720871  -4.91803844  -4.85701611  -4.66782013
  -4.50844382  -4.33633383  -4.2559573   -4.24422823  -3.85370224
  -3.78400371  -3.58367476  -3.55178087  -3.51212977  -3.5013679
  -3.17327799  -3.11077157  -2.40837219  -2.15923928  -2.01605322]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:2
end of epoch 0: val_loss 2.1280520160331663e-05, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 8.1957e-02,  2.2805e-02, -9.3142e-07,  4.4579e-03, -1.1461e-02,
          1.5210e-01,  1.4766e-02, -1.1617e-02, -2.3225e-01, -2.4530e-01,
         -1.4320e-03, -1.5328e+00, -8.0550e-01]], device='cuda:2'))])
end of epoch 1: val_loss 0.0002019034250527696, val_acc 1.0
trigger times: 1
end of epoch 2: val_loss 0.03271119753919574, val_acc 0.995
trigger times: 2
end of epoch 3: val_loss 5.137709082703168e-07, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 7.6032e-02,  1.8240e-01,  1.9451e-02,  3.9094e-02,  7.4196e-06,
          1.9444e-05,  3.3231e-03, -7.8959e-02, -8.8694e-02, -6.3570e-02,
         -1.4320e-03, -2.4537e+00, -1.5753e+00]], device='cuda:2'))])
end of epoch 4: val_loss 3.169028292592913e-05, val_acc 1.0
trigger times: 1
end of epoch 5: val_loss 0.027057614813395112, val_acc 0.99
trigger times: 2
end of epoch 6: val_loss 0.016928233295490928, val_acc 0.995
trigger times: 3
end of epoch 7: val_loss 5.4560834333088335e-05, val_acc 1.0
trigger times: 4
end of epoch 8: val_loss 5.636827757268037e-05, val_acc 1.0
trigger times: 5
end of epoch 9: val_loss 7.748550967079382e-08, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.2651e-01,  2.3867e-01,  2.2807e-02,  9.3503e-02, -2.0705e-02,
          9.8501e-02, -3.9844e-07, -1.1607e-01,  3.2461e-05, -3.8491e-01,
         -1.4320e-03, -3.2316e+00, -1.6847e+00]], device='cuda:2'))])
end of epoch 10: val_loss 1.3113020287391919e-08, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-6.5876e-03,  1.4054e-01,  1.4399e-02,  2.5264e-02, -5.8596e-03,
          1.1961e-02,  4.1993e-03, -6.6063e-02,  1.1582e-04,  2.8299e-04,
         -1.4320e-03, -2.6193e+00, -1.3815e+00]], device='cuda:2'))])
end of epoch 11: val_loss 0.00026904469856241063, val_acc 1.0
trigger times: 1
end of epoch 12: val_loss 4.351130336033293e-08, val_acc 1.0
trigger times: 2
end of epoch 13: val_loss 4.581958449243473e-06, val_acc 1.0
trigger times: 3
end of epoch 14: val_loss 4.501025028562189, val_acc 0.745
trigger times: 4
end of epoch 15: val_loss 0.0005576367457524611, val_acc 1.0
trigger times: 5
end of epoch 16: val_loss 0.0002523731818738284, val_acc 1.0
trigger times: 6
end of epoch 17: val_loss 1.5190941452836171e-05, val_acc 1.0
trigger times: 7
end of epoch 18: val_loss 2.0182248830238336e-05, val_acc 1.0
trigger times: 8
end of epoch 19: val_loss 1.3505513287839221e-05, val_acc 1.0
trigger times: 9
end of epoch 20: val_loss 0.029420088912265784, val_acc 0.99
trigger times: 10
Early stopping.
0 -101.9104662835598 -50.492268601198035
1 -121.0479507446289 -50.03933801517046
2 -98.09969791769981 -45.670579884154705
3 -104.2314003109932 -44.14602409201361
4 -93.46491795778275 -38.41270390343083
5 -90.15275603532791 -31.969099402548657
6 -82.65268290042877 -26.7047217556024
7 -39.209987848997116 -24.879106999799365
8 -26.158310502767563 -20.13839114930498
9 -59.82209986448288 -19.634363962764166
10 -66.80243289470673 -17.55742370467821
11 -44.22064405679703 -15.12252306211355
12 -40.38204437494278 -15.087280726906778
13 -42.50788193941116 -15.046269525186256
14 -33.05425103008747 -14.98912761511048
15 -34.58531588315964 -14.786225758580233
16 -48.80813154578209 -14.570337152831858
17 -27.1585031747818 -14.531424598833084
18 -57.45675632357597 -14.442420089224363
19 -53.86166474223137 -13.69449912514163
20 -55.79644149541855 -13.673334243070974
21 -30.39554649591446 -13.534532124095186
22 -18.23973013460636 -13.281607874517208
23 -57.79913729429245 -13.111887824448589
24 -20.323532164096832 -13.036014189531059
25 -47.205616891384125 -12.880778469177017
26 -51.69906669855118 -12.768483977935247
27 -46.31673573702574 -12.68135972540495
28 -40.11340841650963 -12.648577538962167
29 -29.515533417463303 -12.502472096276058
30 -39.7472442984581 -12.151904772081672
31 -31.8969454318285 -11.970275029169322
32 -32.08568027615547 -11.604447375583595
33 -21.505913253873587 -11.415471107721174
34 -22.070713341236115 -11.13929168040905
35 -7.924604546278715 -11.076664781518856
36 -39.06225185096264 -11.035183400130354
37 -37.970113545656204 -10.657267844670686
38 -28.869495898485184 -10.626824047074711
39 -45.39992368221283 -10.469497313817401
40 -28.51367588341236 -10.415865583824841
41 -12.426182938739657 -10.26144616292633
42 -31.644300520420074 -10.175872602504679
43 -16.33862517774105 -9.891699828961956
44 -42.66871017217636 -9.876279268337267
45 -17.30013421177864 -9.873474453082016
46 -25.37230859696865 -9.856141809726932
47 -32.77397997677326 -9.735773134141377
48 -36.48273104429245 -9.703691629947691
49 -34.10189610719681 -9.68597007263648
50 -23.56532545387745 -9.682310808453053
51 -43.819740280508995 -9.622653402800573
52 -33.30633395910263 -9.621495495376212
53 -5.818415131419897 -9.6056130561516
54 -34.44490268826485 -9.568954612422717
55 -37.86543595790863 -9.457689553120304
56 -32.60218349099159 -9.451593171456562
57 -33.243863970041275 -9.302628028417763
58 -45.58985494822264 -9.233037362027023
59 -26.202689960598946 -9.000329314155312
60 -2.2082418985664845 -8.964502312121855
61 -18.78289596736431 -8.963826694643434
62 -17.256148245185614 -8.865131384937952
63 -34.37295886874199 -8.761385789107377
64 -18.958144914358854 -8.455797636261352
65 2.3593183159828186 -8.133195842510668
66 -8.809422425925732 -7.9229223800732616
67 -23.96052412688732 -7.804388922007324
68 -11.241261087357998 -7.670200907249529
69 4.940126709640026 -7.524449126839224
70 -23.619719609618187 -7.482261060960065
71 -1.1094706356525421 -7.375657083130067
72 0.935768187046051 -7.368850394719649
73 6.154376953840256 -7.3388454760053525
74 -19.183730706572533 -7.276780028486416
75 -35.52702669799328 -7.117396317348786
76 -18.354108810424805 -6.99889967022435
77 -4.022080931812525 -6.978820452384221
78 -14.604664914309978 -6.96052527538595
79 -26.13961850106716 -6.89242471336658
80 -7.792848125100136 -6.7680647406367775
81 -12.021812587976456 -6.749280028409141
82 -13.865866515785456 -6.659491729217256
83 -7.988637149333954 -6.6230549900267075
84 10.143936984241009 -6.4928277503270895
85 7.385352447628975 -6.400908620500933
86 -1.7412329316139221 -6.170136036545298
87 -1.4803304821252823 -6.081788997211991
88 8.891693383455276 -6.073154642590908
89 0.3036128729581833 -5.985860022175071
90 7.006029784679413 -5.972897666427064
91 -7.610725311562419 -5.7824812723338335
92 -5.507089912891388 -5.570283603991597
93 -7.832003977149725 -5.536520093697909
94 12.266105890274048 -5.5181009563867125
95 -1.933858260512352 -5.307917431579535
96 11.47508816421032 -5.299844141339399
97 11.008528344333172 -5.143352729931229
98 15.227252170443535 -5.120706508505464
99 -12.519565060734749 -5.027957977402961
100 0.2616613581776619 -4.937524915784605
101 12.608520582318306 -4.927208709933311
102 4.650961644947529 -4.918038444677467
103 2.0992394015192986 -4.8570161087009
104 12.779590263962746 -4.66782012531225
105 16.577517822384834 -4.508443817413801
106 2.073034457862377 -4.336333831576879
107 12.006995975971222 -4.255957297172166
108 5.187006089836359 -4.244228234441251
109 7.867312490940094 -3.8537022364093745
110 5.717263922095299 -3.7840037059190053
111 10.853898011147976 -3.5836747649943446
112 19.857097566127777 -3.5517808684047165
113 9.681248225271702 -3.5121297730673273
114 11.79794193059206 -3.501367901480982
115 12.693946331739426 -3.173277990384719
116 12.640370897948742 -3.110771566155352
117 25.05109179019928 -2.408372191989257
118 26.14483407139778 -2.159239284403902
119 23.878398910164833 -2.01605321743914
train accuracy: 0.9966666666666667
validation accuracy: 0.99
[-50.4922686  -38.4127039  -31.9690994  -24.879107   -20.13839115
 -19.63436396 -17.5574237  -15.04626953 -14.98912762 -14.44242009
 -13.69449913 -13.53453212 -13.28160787 -13.11188782 -12.76848398
 -12.68135973 -12.5024721  -11.60444738 -11.41547111 -10.41586558
 -10.1758726  -10.13347022 -10.08824034  -9.91790582  -9.70369163
  -9.68231081  -9.67771531  -9.63724212  -9.6214955   -9.60561306
  -9.50467187  -9.45768955  -9.39208974  -9.23303736  -9.21850509
  -9.0640288   -8.98444854  -8.96450231  -8.96382669  -8.86513138
  -8.45579764  -8.13319584  -8.11058275  -7.97852454  -7.95353682
  -7.95180335  -7.92741233  -7.92292238  -7.69917784  -7.65397502
  -7.5643256   -7.38123906  -7.37565708  -7.36885039  -7.16014928
  -7.11739632  -7.08605794  -7.02526907  -7.00487228  -6.99889967
  -6.98862886  -6.97807786  -6.96052528  -6.89242471  -6.65949173
  -6.61123741  -6.5785526   -6.49282775  -6.40090862  -6.38991227
  -6.26170959  -6.22025727  -6.19383224  -6.081789    -6.07751441
  -5.98586002  -5.91463763  -5.80897696  -5.80712858  -5.78248127
  -5.77223419  -5.71557978  -5.69252566  -5.51810096  -5.40816736
  -5.29984414  -5.2260907   -5.21113244  -5.14335273  -5.12070651
  -5.06061172  -5.04431912  -4.96878574  -4.92720871  -4.92037143
  -4.91803844  -4.85701611  -4.76155945  -4.66782013  -4.38922138
  -4.28812488  -4.28426594  -4.24422823  -4.21724256  -4.15083079
  -4.09697995  -4.01476681  -4.00644327  -3.92554966  -3.91686522
  -3.90145674  -3.85370224  -3.78400371  -3.55786454  -3.51212977
  -3.5013679   -3.17327799  -2.3915218   -2.15923928  -1.92071472]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:1
end of epoch 0: val_loss 0.00506977214075615, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0599,  0.0201,  0.0181,  0.0222,  0.0154,  0.0736,  0.0062, -0.0048,
         -0.0234, -0.0077, -0.0014, -0.8073, -0.4249]], device='cuda:1'))])
end of epoch 1: val_loss 0.00045062142595647003, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.3170e-01,  1.1552e-01, -5.7678e-03,  5.6717e-02,  8.9014e-02,
         -7.7848e-02,  5.1042e-02, -6.3345e-02, -2.1005e-01, -7.2096e-05,
         -1.4320e-03, -1.7760e+00, -9.7061e-01]], device='cuda:1'))])
end of epoch 2: val_loss 0.0005281639302431174, val_acc 1.0
trigger times: 1
end of epoch 3: val_loss 2.06496203594142e-05, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.8093e-01,  1.9596e-01, -1.5172e-02,  1.1885e-01, -8.3666e-06,
         -1.6922e-02,  1.4350e-02, -7.7221e-02,  5.2505e-05, -2.4639e-01,
         -1.4320e-03, -2.9660e+00, -1.9070e+00]], device='cuda:1'))])
end of epoch 4: val_loss 2.668218095180919e-06, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.8241e-01,  8.9824e-02, -4.7516e-06, -3.9878e-06, -4.0821e-05,
         -2.7879e-06,  1.5568e-03, -4.6259e-02,  1.6597e-05,  8.0284e-05,
         -1.4320e-03, -2.4303e+00, -1.6949e+00]], device='cuda:1'))])
end of epoch 5: val_loss 0.00040203354563495, val_acc 1.0
trigger times: 1
end of epoch 6: val_loss 2.1454864229539795e-05, val_acc 1.0
trigger times: 2
end of epoch 7: val_loss 0.00012114097398217893, val_acc 1.0
trigger times: 3
end of epoch 8: val_loss 0.00018388557688002295, val_acc 1.0
trigger times: 4
end of epoch 9: val_loss 1.6092648243315466e-06, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.3709e-01,  1.0279e-01, -4.2343e-06, -3.1944e-06,  1.1010e-01,
         -5.8197e-05,  3.0588e-02, -8.1814e-02, -4.3731e-02, -3.1838e-05,
         -1.4320e-03, -2.1710e+00, -1.4690e+00]], device='cuda:1'))])
end of epoch 10: val_loss 0.0008140625910561284, val_acc 1.0
trigger times: 1
end of epoch 11: val_loss 0.0002536567045571303, val_acc 1.0
trigger times: 2
end of epoch 12: val_loss 7.837381345474626e-05, val_acc 1.0
trigger times: 3
end of epoch 13: val_loss 0.00012938500012285914, val_acc 1.0
trigger times: 4
end of epoch 14: val_loss 1.6492249618842436e-05, val_acc 1.0
trigger times: 5
end of epoch 15: val_loss 0.00019481363350131175, val_acc 1.0
trigger times: 6
end of epoch 16: val_loss 0.00019457506964311476, val_acc 1.0
trigger times: 7
end of epoch 17: val_loss 2.054004979495261e-05, val_acc 1.0
trigger times: 8
end of epoch 18: val_loss 5.689772570985241e-05, val_acc 1.0
trigger times: 9
end of epoch 19: val_loss 0.0015913446880923842, val_acc 1.0
trigger times: 10
Early stopping.
0 -75.86061039566994 -50.492268601198035
1 -63.05873146653175 -38.41270390343083
2 -69.9134002327919 -31.969099402548657
3 -70.6772580370307 -24.879106999799365
4 -32.752806305885315 -20.13839114930498
5 -55.37174654006958 -19.634363962764166
6 -45.182017505168915 -17.55742370467821
7 -46.70896118879318 -15.046269525186256
8 -43.97175416350365 -14.98912761511048
9 -50.48407506942749 -14.442420089224363
10 -34.78027103841305 -13.69449912514163
11 -36.27606496959925 -13.534532124095186
12 -16.087900385260582 -13.281607874517208
13 -41.1463328152895 -13.111887824448589
14 -33.39143782109022 -12.768483977935247
15 -49.65746983885765 -12.68135972540495
16 -30.621000230312347 -12.502472096276058
17 -24.210147947072983 -11.604447375583595
18 -20.446736127138138 -11.415471107721174
19 -22.703197941184044 -10.415865583824841
20 -28.25510135293007 -10.175872602504679
21 -27.86224415898323 -10.133470217246236
22 -27.86063039302826 -10.088240337894025
23 -28.341067999601364 -9.917905820382517
24 -29.635772675275803 -9.703691629947691
25 -19.888459905982018 -9.682310808453053
26 -29.56345236301422 -9.677715307879632
27 -28.680935978889465 -9.637242117755827
28 -28.92109641432762 -9.621495495376212
29 -7.005791733041406 -9.6056130561516
30 -23.854377761483192 -9.504671869086302
31 -26.151273868978024 -9.457689553120304
32 -23.148727037012577 -9.392089735112547
33 -28.327333979308605 -9.233037362027023
34 -25.664963960647583 -9.218505093463154
35 -25.287303738296032 -9.064028803362252
36 -18.218396559357643 -8.984448544640724
37 -7.5453408025205135 -8.964502312121855
38 -23.767681419849396 -8.963826694643434
39 -13.057693436741829 -8.865131384937952
40 -11.714635886251926 -8.455797636261352
41 -10.410704899579287 -8.133195842510668
42 -21.820120468735695 -8.110582754212167
43 -22.327295184135437 -7.978524542872976
44 -16.62152025103569 -7.953536820215964
45 -13.517224300652742 -7.951803348570104
46 -25.657464489340782 -7.927412329137731
47 -7.002211153507233 -7.9229223800732616
48 -11.039864391088486 -7.699177836325561
49 -24.402801506221294 -7.653975016396113
50 -24.471068292856216 -7.56432559594825
51 -11.98422272503376 -7.3812390582480125
52 -10.359516240656376 -7.375657083130067
53 -9.387392301112413 -7.368850394719649
54 -21.78508471697569 -7.160149280595334
55 -23.238147050142288 -7.117396317348786
56 -20.5520196557045 -7.086057940132588
57 -6.178870730102062 -7.0252690703179725
58 -11.399472326040268 -7.004872281212194
59 -8.324739843606949 -6.99889967022435
60 -14.540155358612537 -6.988628858123189
61 -20.109579905867577 -6.97807785651095
62 -18.844153463840485 -6.96052527538595
63 -12.853526812046766 -6.89242471336658
64 -16.45534924790263 -6.659491729217256
65 -16.495335586369038 -6.611237412607874
66 -15.05959309078753 -6.578552596151092
67 -0.15675681084394455 -6.4928277503270895
68 -5.346870865672827 -6.400908620500933
69 -14.751260727643967 -6.3899122666733605
70 -16.014241121709347 -6.261709590920128
71 -17.668249847367406 -6.220257269860126
72 -2.1248898580670357 -6.193832235016001
73 -9.372777629643679 -6.081788997211991
74 -15.283160086721182 -6.077514406020126
75 0.7082792520523071 -5.985860022175071
76 -9.63666282221675 -5.914637632847621
77 -2.9647353067994118 -5.808976959711392
78 -9.864134281873703 -5.807128584503187
79 0.15059305727481842 -5.7824812723338335
80 -10.18211516737938 -5.772234193249779
81 -1.5427315458655357 -5.715579781991958
82 -0.6668833643198013 -5.692525659799091
83 1.8610290102660656 -5.5181009563867125
84 -9.743025325238705 -5.408167364577382
85 -2.798853725194931 -5.299844141339399
86 -1.4882332608103752 -5.226090701056524
87 -2.928997129201889 -5.2111324399751355
88 -1.6817675232887268 -5.143352729931229
89 2.9262383729219437 -5.120706508505464
90 -5.493651360273361 -5.060611718283424
91 -6.602368324995041 -5.044319115012904
92 -8.583969611674547 -4.9687857425891035
93 -2.8559681326150894 -4.927208709933311
94 -2.214903824031353 -4.920371428871764
95 -7.420664634555578 -4.918038444677467
96 -4.4413615465164185 -4.8570161087009
97 3.6269803792238235 -4.76155944913195
98 5.2135012820363045 -4.66782012531225
99 5.550161696970463 -4.389221379432903
100 -2.698328457772732 -4.288124884141435
101 -2.020657865330577 -4.284265937452978
102 -4.517526514828205 -4.244228234441251
103 3.929733755066991 -4.21724256189977
104 -4.904806725680828 -4.150830791850557
105 6.8053537011146545 -4.096979945036695
106 6.305922947824001 -4.014766810338475
107 -5.384183749556541 -4.0064432693349215
108 -5.610120892524719 -3.925549655249319
109 4.5700255781412125 -3.916865221951316
110 -1.2092226296663284 -3.901456744340776
111 8.247675903141499 -3.8537022364093745
112 -1.276629500091076 -3.7840037059190053
113 8.241168171167374 -3.557864539653316
114 0.5509016811847687 -3.5121297730673273
115 -2.0534205585718155 -3.501367901480982
116 -1.9837718307971954 -3.173277990384719
117 12.024673357605934 -2.391521796332274
118 9.410474434494972 -2.159239284403902
119 10.351768493652344 -1.920714718803529
train accuracy: 0.9994444444444445
validation accuracy: 1.0
[-65.319612   -64.0396142  -63.40305399 -63.1967682  -63.09304393
 -62.87316648 -62.87231006 -62.36174757 -62.22804657 -61.96596139
 -61.74945372 -61.6564126  -61.56234396 -61.43159517 -61.14251884
 -61.08141396 -60.88783773 -60.86613251 -60.82642093 -60.72338817
 -60.54515494 -60.53416652 -60.50297289 -60.46748713 -60.42536388
 -60.37812138 -60.29633618 -60.21230976 -59.94658058 -59.865226
 -59.85593595 -59.66863702 -59.64165366 -59.59787072 -59.51999685
 -59.2555052  -59.24646433 -59.12019451 -59.02147115 -58.91650393
 -58.72630495 -58.67385354 -58.64159112 -58.55553268 -58.425395
 -58.08132835 -57.68520634 -57.56226576 -57.56028278 -57.52739998
 -57.49701831 -57.32180563 -57.30201045 -57.26759583 -56.90952285
 -56.6300878  -56.39385796 -56.10407856 -55.15987527 -54.20521174
 -38.4127039  -20.13839115 -19.63436396 -17.5574237  -15.04626953
 -13.53453212 -13.28160787 -12.76848398 -12.68135973 -11.41547111
  -9.70369163  -9.67771531  -9.6214955   -9.60561306  -9.39208974
  -9.0640288   -8.45579764  -8.13319584  -8.11058275  -7.97852454
  -7.95180335  -7.69917784  -7.65397502  -7.37565708  -7.08605794
  -6.99889967  -6.97807786  -6.96052528  -6.89242471  -6.65949173
  -6.61123741  -6.49282775  -6.40090862  -6.38991227  -6.22025727
  -6.19383224  -5.91463763  -5.77223419  -5.69252566  -5.51810096
  -5.29984414  -5.2260907   -5.21113244  -5.06061172  -5.04431912
  -4.96878574  -4.92720871  -4.92037143  -4.91803844  -4.85701611
  -4.76155945  -4.66782013  -4.38922138  -4.28812488  -4.09697995
  -3.92554966  -3.91686522  -3.51212977  -3.5013679   -1.92071472]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:1
end of epoch 0: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.7572e-05, -2.0374e-05, -5.6447e-05, -3.0606e-05,  3.4673e-05,
          1.7810e-04, -4.6155e-02, -2.2590e-06,  7.9005e-04,  9.3842e-05,
         -1.4320e-03, -1.9120e-04, -4.6073e-05]], device='cuda:1'))])
end of epoch 1: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.9560e-05, -5.1488e-05, -3.2017e-05, -9.2872e-05,  7.1670e-05,
          4.3626e-04, -3.9710e-02, -1.3064e-05, -2.0039e-03,  2.2889e-04,
         -1.4320e-03, -4.7263e-04, -8.5883e-06]], device='cuda:1'))])
end of epoch 2: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.6126e-07, -1.2446e-04, -1.9776e-04, -2.3815e-04,  1.0720e-04,
          8.1912e-06, -2.3381e-02, -2.9662e-06,  1.3825e-03,  7.3189e-04,
         -1.4320e-03, -3.1362e-04, -1.2094e-05]], device='cuda:1'))])
end of epoch 3: val_loss 2.892608788158668e-06, val_acc 1.0
trigger times: 1
end of epoch 4: val_loss 1.6784652069645745e-06, val_acc 1.0
trigger times: 2
end of epoch 5: val_loss 2.865786762527023e-06, val_acc 1.0
trigger times: 3
end of epoch 6: val_loss 2.417561138372548e-06, val_acc 1.0
trigger times: 4
end of epoch 7: val_loss 7.045266256611172e-07, val_acc 1.0
trigger times: 5
end of epoch 8: val_loss 4.89591226767061e-06, val_acc 1.0
trigger times: 6
end of epoch 9: val_loss 3.908864168806759e-06, val_acc 1.0
trigger times: 7
end of epoch 10: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.0246e-03,  8.7676e-04, -1.0992e-03, -2.6346e-03,  2.1407e-04,
         -2.0454e-04, -2.9531e-01, -3.6624e-03,  1.7462e-03,  1.6166e-03,
         -1.4320e-03,  6.9544e-04, -2.4414e-03]], device='cuda:1'))])
end of epoch 11: val_loss 1.830456739355668e-06, val_acc 1.0
trigger times: 1
end of epoch 12: val_loss 2.1302674025491796e-06, val_acc 1.0
trigger times: 2
end of epoch 13: val_loss 7.355210031434467e-07, val_acc 1.0
trigger times: 3
end of epoch 14: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.0008,  0.0032,  0.0037,  0.0018,  0.0002,  0.0029, -0.1730,  0.0221,
         -0.0005,  0.0015, -0.0014,  0.0006,  0.0030]], device='cuda:1'))])
end of epoch 15: val_loss 3.576278473360617e-09, val_acc 1.0
trigger times: 1
end of epoch 16: val_loss 6.407448961908812e-05, val_acc 1.0
trigger times: 2
end of epoch 17: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.0009,  0.0022,  0.0002, -0.0008,  0.0012,  0.0009, -0.0062,  0.0015,
         -0.0003, -0.0010, -0.0014, -0.0019, -0.0011]], device='cuda:1'))])
end of epoch 18: val_loss 1.5258787666283525e-07, val_acc 1.0
trigger times: 1
end of epoch 19: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0002,  0.0017, -0.0009,  0.0011,  0.0019,  0.0024, -0.0376,  0.0002,
          0.0003,  0.0012, -0.0014, -0.0007, -0.0003]], device='cuda:1'))])
end of epoch 20: val_loss 1.4752026389714956e-05, val_acc 1.0
trigger times: 1
end of epoch 21: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.0141e-03, -2.8970e-03,  4.0598e-04,  4.3882e-04, -9.3303e-04,
         -2.0830e-03, -4.5322e-02,  7.4241e-03, -1.8743e-03, -6.3858e-05,
         -1.4324e-03,  8.1824e-06, -1.2372e-03]], device='cuda:1'))])
end of epoch 22: val_loss 4.87147416663447e-06, val_acc 1.0
trigger times: 1
end of epoch 23: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.0037, -0.0018, -0.0018, -0.0008,  0.0006, -0.0004, -0.0919,  0.0027,
          0.0008,  0.0007, -0.0014, -0.0007,  0.0007]], device='cuda:1'))])
end of epoch 24: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0005, -0.0014,  0.0025,  0.0003,  0.0018, -0.0006, -0.1822,  0.0027,
          0.0008,  0.0005, -0.0014, -0.0011, -0.0018]], device='cuda:1'))])
end of epoch 25: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.7932e-03,  7.2634e-04, -1.7372e-03, -6.9649e-04, -5.5316e-05,
          3.9618e-04, -1.3010e-01, -2.5077e-03,  1.4585e-03, -7.3281e-04,
         -1.4326e-03, -2.5164e-03,  2.1006e-04]], device='cuda:1'))])
end of epoch 26: val_loss 6.747243274318748e-07, val_acc 1.0
trigger times: 1
end of epoch 27: val_loss 2.6112755423923773e-06, val_acc 1.0
trigger times: 2
end of epoch 28: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.0007,  0.0009, -0.0032,  0.0038, -0.0025, -0.0018, -0.1032, -0.0007,
          0.0029, -0.0006, -0.0014, -0.0021, -0.0007]], device='cuda:1'))])
end of epoch 29: val_loss 5.7285842609644535e-06, val_acc 1.0
trigger times: 1
end of epoch 30: val_loss 4.889355909654114e-06, val_acc 1.0
trigger times: 2
end of epoch 31: val_loss 3.31997807307971e-07, val_acc 1.0
trigger times: 3
end of epoch 32: val_loss 6.133296141115352e-06, val_acc 1.0
trigger times: 4
end of epoch 33: val_loss 4.082917240211259e-07, val_acc 1.0
trigger times: 5
end of epoch 34: val_loss 4.267691532788831e-07, val_acc 1.0
trigger times: 6
end of epoch 35: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0004,  0.0045,  0.0017,  0.0018, -0.0007,  0.0026, -0.0529,  0.0126,
          0.0011, -0.0029, -0.0014,  0.0008, -0.0004]], device='cuda:1'))])
end of epoch 36: val_loss 2.0331121467620504e-06, val_acc 1.0
trigger times: 1
end of epoch 37: val_loss 2.8288319973057694e-06, val_acc 1.0
trigger times: 2
end of epoch 38: val_loss 6.939144241187023e-06, val_acc 1.0
trigger times: 3
end of epoch 39: val_loss 5.401356664833657e-06, val_acc 1.0
trigger times: 4
end of epoch 40: val_loss 7.641878576123417e-06, val_acc 1.0
trigger times: 5
end of epoch 41: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.4932e-05, -8.8570e-04,  2.8392e-03, -4.3573e-05,  1.7437e-03,
          9.8877e-04, -1.4230e-02,  1.9564e-03, -7.6551e-04,  1.7888e-03,
         -1.4331e-03, -2.0418e-03, -1.0364e-03]], device='cuda:1'))])
end of epoch 42: val_loss 9.14334768253866e-07, val_acc 1.0
trigger times: 1
end of epoch 43: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0006,  0.0012,  0.0008,  0.0004,  0.0004, -0.0027, -0.0923, -0.0006,
         -0.0004,  0.0027, -0.0014, -0.0012, -0.0039]], device='cuda:1'))])
end of epoch 44: val_loss 9.149308021605406e-07, val_acc 1.0
trigger times: 1
end of epoch 45: val_loss 2.4215861362790747e-05, val_acc 1.0
trigger times: 2
end of epoch 46: val_loss 7.77244240417474e-07, val_acc 1.0
trigger times: 3
end of epoch 47: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.8856e-03, -5.8261e-04, -9.2523e-04,  1.7227e-03, -6.9521e-04,
         -7.7006e-04, -2.4910e-01, -1.1109e-04,  1.6469e-04, -1.1036e-04,
         -1.4333e-03, -1.1601e-03, -1.8967e-03]], device='cuda:1'))])
end of epoch 48: val_loss 2.0921205205581826e-06, val_acc 1.0
trigger times: 1
end of epoch 49: val_loss 6.101706859453771e-06, val_acc 1.0
trigger times: 2
end of epoch 50: val_loss 1.8972137510786523e-06, val_acc 1.0
trigger times: 3
end of epoch 51: val_loss 2.0635103791732943e-06, val_acc 1.0
trigger times: 4
end of epoch 52: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-6.6107e-06,  1.8471e-03, -2.1168e-04,  1.6752e-04,  8.2015e-04,
          5.0385e-04, -4.0104e-02,  1.1598e-04, -1.6895e-03, -4.0499e-04,
         -1.4335e-03,  1.5083e-03, -1.8065e-03]], device='cuda:1'))])
end of epoch 53: val_loss 1.3275645271733082e-05, val_acc 1.0
trigger times: 1
end of epoch 54: val_loss 2.561804028005099e-06, val_acc 1.0
trigger times: 2
end of epoch 55: val_loss 3.029102765310654e-06, val_acc 1.0
trigger times: 3
end of epoch 56: val_loss 3.262156418770701e-06, val_acc 1.0
trigger times: 4
end of epoch 57: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.2948e-03,  5.4926e-05,  7.6091e-04, -4.5691e-04,  1.8825e-03,
          7.0936e-04, -1.2898e-01, -1.1304e-03,  8.8681e-04, -2.7983e-05,
         -1.4337e-03,  2.9832e-04, -1.6431e-03]], device='cuda:1'))])
end of epoch 58: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-7.6350e-04, -1.7162e-03,  1.6752e-03, -2.2482e-04,  2.1278e-03,
          2.7064e-04, -2.3656e-01, -2.9070e-04, -7.0998e-04,  1.3328e-03,
         -1.4337e-03, -1.8430e-03, -2.7220e-03]], device='cuda:1'))])
end of epoch 59: val_loss 9.983772255495183e-07, val_acc 1.0
trigger times: 1
end of epoch 60: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0004,  0.0012,  0.0002,  0.0014, -0.0012, -0.0011, -0.0263,  0.0019,
          0.0001, -0.0007, -0.0014,  0.0006,  0.0002]], device='cuda:1'))])
end of epoch 61: val_loss 1.103281293950431e-06, val_acc 1.0
trigger times: 1
end of epoch 62: val_loss 2.3853747097746236e-06, val_acc 1.0
trigger times: 2
end of epoch 63: val_loss 4.692661371450413e-06, val_acc 1.0
trigger times: 3
end of epoch 64: val_loss 3.3915036155462987e-07, val_acc 1.0
trigger times: 4
end of epoch 65: val_loss 5.195125942805134e-06, val_acc 1.0
trigger times: 5
end of epoch 66: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-3.5874e-03,  4.1537e-03,  1.1761e-03, -3.0455e-03, -4.7842e-05,
          8.4957e-04, -1.0032e-01,  7.0211e-03,  1.4985e-03,  2.0591e-04,
         -1.4340e-03,  1.3516e-03,  1.1787e-03]], device='cuda:1'))])
end of epoch 67: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.4455e-03,  9.9789e-04,  1.9603e-03,  5.5758e-04,  9.0594e-04,
          3.6894e-05, -2.1694e-01,  2.6991e-04, -2.8220e-04, -2.2981e-03,
         -1.4340e-03, -1.0227e-05,  1.0021e-03]], device='cuda:1'))])
end of epoch 68: val_loss 2.868766899837283e-06, val_acc 1.0
trigger times: 1
end of epoch 69: val_loss 3.40997525796638e-06, val_acc 1.0
trigger times: 2
end of epoch 70: val_loss 1.2874602283829973e-07, val_acc 1.0
trigger times: 3
end of epoch 71: val_loss 6.022433165071562e-06, val_acc 1.0
trigger times: 4
end of epoch 72: val_loss 5.8430248668628335e-06, val_acc 1.0
trigger times: 5
end of epoch 73: val_loss 3.1894389229591977e-06, val_acc 1.0
trigger times: 6
end of epoch 74: val_loss 6.616113122603906e-07, val_acc 1.0
trigger times: 7
end of epoch 75: val_loss 7.720555888681702e-06, val_acc 1.0
trigger times: 8
end of epoch 76: val_loss 9.47713787269322e-08, val_acc 1.0
trigger times: 9
end of epoch 77: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-3.6446e-04,  3.1864e-03,  2.6023e-03,  1.7216e-03,  6.8031e-04,
          3.5256e-04, -6.6812e-03,  9.0821e-04, -1.5754e-03,  2.2481e-04,
         -1.4344e-03, -1.3495e-05, -4.2556e-04]], device='cuda:1'))])
end of epoch 78: val_loss 1.6581996729314596e-06, val_acc 1.0
trigger times: 1
end of epoch 79: val_loss 2.0307279478970487e-06, val_acc 1.0
trigger times: 2
end of epoch 80: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.0346e-03, -1.2394e-03, -2.6238e-03,  5.8889e-04, -1.9642e-03,
         -3.8324e-06, -1.6934e-01,  1.7814e-03,  1.8258e-03,  1.2552e-03,
         -1.4345e-03, -1.5814e-03,  1.4956e-03]], device='cuda:1'))])
end of epoch 81: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0015, -0.0012, -0.0004,  0.0012,  0.0012,  0.0014, -0.2665,  0.0021,
          0.0008, -0.0012, -0.0014,  0.0007, -0.0015]], device='cuda:1'))])
end of epoch 82: val_loss 1.77204418505994e-06, val_acc 1.0
trigger times: 1
end of epoch 83: val_loss 1.5836939508062642e-06, val_acc 1.0
trigger times: 2
end of epoch 84: val_loss 5.817411473785228e-07, val_acc 1.0
trigger times: 3
end of epoch 85: val_loss 3.234738311732599e-06, val_acc 1.0
trigger times: 4
end of epoch 86: val_loss 2.4628604595022808e-06, val_acc 1.0
trigger times: 5
end of epoch 87: val_loss 2.914066191692655e-06, val_acc 1.0
trigger times: 6
end of epoch 88: val_loss 1.3250102547601728e-06, val_acc 1.0
trigger times: 7
end of epoch 89: val_loss 5.206451053254568e-06, val_acc 1.0
trigger times: 8
end of epoch 90: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.5959e-04, -2.8922e-04,  3.0451e-05,  4.6966e-03,  1.8672e-03,
         -1.2772e-03, -1.9645e-01, -5.6584e-04,  2.2770e-03,  2.1865e-03,
         -1.4348e-03, -8.6888e-04,  1.4265e-03]], device='cuda:1'))])
end of epoch 91: val_loss 2.6774367023563175e-06, val_acc 1.0
trigger times: 1
end of epoch 92: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.0013,  0.0019,  0.0002,  0.0010, -0.0015,  0.0003, -0.0741,  0.0018,
         -0.0006, -0.0019, -0.0014, -0.0020,  0.0010]], device='cuda:1'))])
end of epoch 93: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.0006,  0.0009,  0.0007,  0.0016,  0.0003, -0.0017, -0.0055,  0.0018,
         -0.0007, -0.0006, -0.0014,  0.0017, -0.0005]], device='cuda:1'))])
end of epoch 94: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0010,  0.0016,  0.0006,  0.0004, -0.0009, -0.0004, -0.0658,  0.0048,
          0.0012,  0.0025, -0.0014,  0.0010, -0.0016]], device='cuda:1'))])
end of epoch 95: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-6.7191e-04, -2.5673e-03,  1.2430e-03, -2.5176e-03, -2.3057e-03,
          7.9883e-06, -5.0262e-02,  4.1334e-03,  1.9489e-04,  1.8317e-04,
         -1.4350e-03,  1.1070e-03, -1.8639e-03]], device='cuda:1'))])
end of epoch 96: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0010,  0.0032, -0.0004, -0.0003, -0.0014,  0.0011, -0.0336, -0.0015,
          0.0009,  0.0014, -0.0014,  0.0019, -0.0013]], device='cuda:1'))])
end of epoch 97: val_loss 4.064827144702576e-05, val_acc 1.0
trigger times: 1
end of epoch 98: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.3740e-04,  1.2454e-03,  4.7793e-04, -1.6343e-03,  2.8475e-03,
          3.8383e-04, -3.3321e-02,  4.9183e-04, -6.8547e-04,  6.9906e-04,
         -1.4351e-03,  1.3865e-03,  6.8494e-05]], device='cuda:1'))])
end of epoch 99: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0043,  0.0007,  0.0029,  0.0013, -0.0002,  0.0009, -0.0537,  0.0019,
         -0.0017,  0.0021, -0.0014, -0.0003,  0.0001]], device='cuda:1'))])
Finished training.
0 -184.92034178087488 -65.31961199865464
1 -186.03666195832193 -64.03961420391967
2 -183.42701021768153 -63.40305399375934
3 -181.9856922593899 -63.19676819597365
4 -184.256765388418 -63.0930439253028
5 -184.4772641849704 -62.87316647592391
6 -184.60809870203957 -62.87231006153974
7 -182.3882731362246 -62.3617475655687
8 -182.97369456849992 -62.228046573671705
9 -185.14740755874664 -61.965961387876746
10 -182.10059090005234 -61.74945371844752
11 -185.17267158767208 -61.65641260048595
12 -182.29104882199317 -61.562343957764405
13 -185.9571119491011 -61.43159516774143
14 -186.3422884522006 -61.14251883888298
15 -183.41656529903412 -61.08141395797017
16 -180.98587936209515 -60.8878377268014
17 -186.58038528682664 -60.86613250598757
18 -182.53467423003167 -60.826420926933366
19 -185.25442495336756 -60.72338817308264
20 -184.33201549155638 -60.54515493863752
21 -186.01132159819826 -60.53416651569491
22 -184.39475651225075 -60.502972892279764
23 -181.8454066226259 -60.4674871268045
24 -184.54799632448703 -60.425363883821696
25 -183.69947273517027 -60.37812138002903
26 -185.34654689347371 -60.296336176761976
27 -184.5043802158907 -60.21230975593699
28 -186.38375961733982 -59.9465805812333
29 -180.6370153897442 -59.86522600456503
30 -185.53958221524954 -59.855935946610316
31 -182.4402670059353 -59.6686370215618
32 -179.12694869143888 -59.64165366117192
33 -180.96262715244666 -59.59787071674172
34 -184.35430193482898 -59.5199968494475
35 -183.97941514477134 -59.2555052010615
36 -182.59528391063213 -59.246464332054536
37 -183.02529268385842 -59.120194511305954
38 -177.9309496548958 -59.02147115487134
39 -184.0951638072729 -58.916503934525736
40 -184.6110599176027 -58.72630494807572
41 -181.234959338326 -58.67385353944724
42 -185.48664471507072 -58.6415911232248
43 -186.9599637268111 -58.555532684860786
44 -181.82839926937595 -58.42539499724231
45 -183.1025442602113 -58.08132834569192
46 -183.25578217674047 -57.685206343682104
47 -185.20938448328525 -57.56226575834924
48 -184.9005358889699 -57.56028277892836
49 -184.36298336368054 -57.52739998432471
50 -182.45802835887298 -57.49701831187017
51 -185.9511010441929 -57.32180563137693
52 -184.02797523420304 -57.302010448870234
53 -183.94376015337184 -57.26759583085017
54 -185.7982215178199 -56.90952284500719
55 -184.08755305036902 -56.63008780137557
56 -182.4818729897961 -56.39385795668819
57 -186.22307863924652 -56.10407856183112
58 -182.01903300220147 -55.15987526757128
59 -183.7761582112871 -54.205211741403204
60 -7.606316678225994 -38.41270390343083
61 1.0577099395450205 -20.13839114930498
62 -5.610473164124414 -19.634363962764166
63 -7.362166734994389 -17.55742370467821
64 -8.090445109643042 -15.046269525186256
65 -6.133524083998054 -13.534532124095186
66 0.596053065120941 -13.281607874517208
67 25.392064328771085 -12.768483977935247
68 -1.58626146055758 -12.68135972540495
69 4.062407500416157 -11.415471107721174
70 20.97156645776704 -9.703691629947691
71 8.066050421213731 -9.677715307879632
72 10.397807934408775 -9.621495495376212
73 0.4154766414430924 -9.6056130561516
74 -7.616925743728643 -9.392089735112547
75 8.261149446305353 -9.064028803362252
76 -6.008017474610824 -8.455797636261352
77 -0.9096573246497428 -8.133195842510668
78 5.676736018795054 -8.110582754212167
79 -11.647799759171903 -7.978524542872976
80 -7.024749890319072 -7.951803348570104
81 -6.092989951139316 -7.699177836325561
82 4.692797088937368 -7.653975016396113
83 2.4271776828099973 -7.375657083130067
84 3.834247578633949 -7.086057940132588
85 -3.5577176860533655 -6.99889967022435
86 4.207867166027427 -6.97807785651095
87 2.8968983904633205 -6.96052527538595
88 -4.715277446521213 -6.89242471336658
89 4.237053083372302 -6.659491729217256
90 -9.531647364608943 -6.611237412607874
91 0.017128521692939103 -6.4928277503270895
92 1.0169152214657515 -6.400908620500933
93 -8.442522481578635 -6.3899122666733605
94 5.022696679923683 -6.220257269860126
95 -3.544114265299868 -6.193832235016001
96 3.4524721511188545 -5.914637632847621
97 3.427726392634213 -5.772234193249779
98 -4.994871571499971 -5.692525659799091
99 0.43491858162451535 -5.5181009563867125
100 1.543444026785437 -5.299844141339399
101 2.325894276611507 -5.226090701056524
102 1.9510173250891967 -5.2111324399751355
103 -3.5440481468103826 -5.060611718283424
104 -2.192378809762886 -5.044319115012904
105 -0.926290687173605 -4.9687857425891035
106 1.5571864561643451 -4.927208709933311
107 2.0817863660340663 -4.920371428871764
108 1.638336030067876 -4.918038444677467
109 -1.8016730605158955 -4.8570161087009
110 -1.7957215971546248 -4.76155944913195
111 -0.8017933251685463 -4.66782012531225
112 -1.0353613402694464 -4.389221379432903
113 -0.6070775894331746 -4.288124884141435
114 -3.1219753761834 -4.096979945036695
115 -2.9327641484269407 -3.925549655249319
116 -1.5559573778882623 -3.916865221951316
117 -1.0875857075443491 -3.5121297730673273
118 0.4106644297717139 -3.501367901480982
119 0.3440493685338879 -1.920714718803529
train accuracy: 1.0
validation accuracy: 1.0
[-76.49560211 -76.4325429  -76.39400052 -76.39288656 -75.51175559
 -75.45491472 -75.37590377 -75.23051263 -75.12844559 -74.94647424
 -74.79011195 -74.77244137 -74.6748125  -73.72336318 -73.56431969
 -73.49099128 -73.40639184 -73.24050385 -73.20947906 -73.04035109
 -73.02698226 -73.0164561  -72.87357241 -72.82662623 -72.75980645
 -72.68194171 -72.40058497 -72.01711228 -71.9471454  -71.92263145
 -71.70235835 -71.38296357 -71.30478131 -70.31193013 -70.25790213
 -70.2186336  -70.17159015 -70.16337967 -70.000609   -69.55155652
 -69.45887648 -69.34168125 -69.31877251 -69.21666769 -69.01198925
 -68.9602219  -68.91236469 -68.89798973 -68.27776123 -68.17059013
 -68.07523886 -67.81491337 -67.72610323 -67.62984987 -67.43287859
 -67.05456977 -65.62268808 -65.20606877 -65.15619695 -64.82009049
 -63.09304393 -62.87231006 -62.22804657 -61.96596139 -61.74945372
 -61.6564126  -61.43159517 -61.08141396 -60.88783773 -60.86613251
 -60.72338817 -60.53416652 -60.46748713 -60.37812138 -60.29633618
 -59.94658058 -59.865226   -59.85593595 -59.66863702 -59.59787072
 -59.12019451 -58.67385354 -58.64159112 -57.68520634 -57.56226576
 -57.56028278 -57.52739998 -57.26759583 -56.90952285 -56.6300878
 -38.4127039  -20.13839115 -19.63436396 -13.28160787 -12.76848398
 -12.68135973  -9.39208974  -8.45579764  -7.95180335  -7.69917784
  -7.37565708  -7.08605794  -6.99889967  -6.97807786  -6.96052528
  -6.65949173  -6.49282775  -6.22025727  -5.91463763  -5.51810096
  -5.29984414  -5.21113244  -5.06061172  -4.92037143  -4.91803844
  -4.76155945  -4.28812488  -3.92554966  -3.91686522  -3.51212977]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:1
end of epoch 0: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.7293e-01, -1.0356e-05, -4.3412e-02, -1.2264e-06, -2.2927e-05,
          4.4662e-05,  1.0158e-01, -1.4108e-03, -8.1122e-05, -5.2621e-05,
         -1.4320e-03, -1.3543e-06, -2.8101e-06]], device='cuda:1'))])
end of epoch 1: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 5.3500e-06, -2.5241e-05, -4.5117e-05,  3.1394e-05,  1.6966e-04,
         -5.9265e-05,  9.9544e-02,  7.0867e-07, -2.2699e-04, -1.3726e-04,
         -1.4320e-03,  8.7152e-05, -5.9331e-06]], device='cuda:1'))])
end of epoch 2: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 8.4455e-05, -6.0775e-05, -9.5556e-05,  7.7016e-05,  3.3366e-04,
          1.1242e-05,  9.4374e-02,  2.1983e-06, -5.5333e-04, -3.2705e-04,
         -1.4320e-03,  2.2402e-04, -5.3646e-05]], device='cuda:1'))])
end of epoch 3: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-8.2627e-06, -1.4749e-04, -2.1706e-04,  1.8780e-04,  6.6988e-04,
         -6.1002e-04,  8.1593e-02,  5.6041e-05, -1.1297e-03, -6.6545e-04,
         -1.4320e-03, -5.6329e-04, -3.9909e-05]], device='cuda:1'))])
end of epoch 4: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.0004, -0.0004, -0.0005,  0.0004,  0.0011, -0.0002,  0.0501,  0.0001,
         -0.0016, -0.0010, -0.0014, -0.0012, -0.0001]], device='cuda:1'))])
end of epoch 5: val_loss 2.5826614512425296e-06, val_acc 1.0
trigger times: 1
end of epoch 6: val_loss 3.2168516770525457e-06, val_acc 1.0
trigger times: 2
end of epoch 7: val_loss 1.6868110702006334e-07, val_acc 1.0
trigger times: 3
end of epoch 8: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0033,  0.0018, -0.0007,  0.0016,  0.0023,  0.0006,  0.1837, -0.0006,
         -0.0015,  0.0006, -0.0014,  0.0014, -0.0005]], device='cuda:1'))])
end of epoch 9: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.1936e-03,  7.5910e-05,  2.5321e-03, -1.4993e-03, -2.7076e-03,
          2.5010e-04,  1.4112e-01,  4.5468e-04,  2.2829e-03, -6.7538e-04,
         -1.4320e-03, -2.2424e-06, -1.6367e-04]], device='cuda:1'))])
end of epoch 10: val_loss 2.3841856489070778e-09, val_acc 1.0
trigger times: 1
end of epoch 11: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.0015, -0.0038,  0.0008,  0.0004,  0.0004,  0.0039,  0.0113,  0.0007,
          0.0007, -0.0006, -0.0014, -0.0005,  0.0046]], device='cuda:1'))])
end of epoch 12: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0003,  0.0003,  0.0011,  0.0018, -0.0039,  0.0009,  0.0352, -0.0296,
          0.0022,  0.0012, -0.0014, -0.0011,  0.0006]], device='cuda:1'))])
end of epoch 13: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.6514e-04, -1.0542e-03, -2.3721e-03,  1.4577e-03, -6.0362e-05,
          1.6680e-03,  1.0132e-01,  3.1224e-05, -1.3329e-04,  3.1862e-04,
         -1.4321e-03,  7.7377e-04,  2.4345e-03]], device='cuda:1'))])
end of epoch 14: val_loss 0.0045856314148113595, val_acc 1.0
trigger times: 1
end of epoch 15: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 9.5703e-04, -1.2542e-04,  2.3048e-03,  7.9261e-04,  2.9444e-03,
         -3.6938e-04,  1.6235e-01,  8.4368e-04, -1.7237e-03, -5.7157e-04,
         -1.4322e-03, -5.9017e-04, -2.6107e-05]], device='cuda:1'))])
end of epoch 16: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 5.8175e-04, -1.1228e-04, -6.1656e-04,  6.4750e-03,  9.7468e-05,
         -7.9119e-04,  1.1357e-01, -4.1602e-02, -7.7250e-04, -2.2190e-03,
         -1.4323e-03, -7.3031e-05, -1.4945e-03]], device='cuda:1'))])
end of epoch 17: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.0033,  0.0005,  0.0006,  0.0008, -0.0012, -0.0023,  0.1604,  0.0007,
          0.0019,  0.0007, -0.0014, -0.0007,  0.0008]], device='cuda:1'))])
end of epoch 18: val_loss 2.137417694711985e-06, val_acc 1.0
trigger times: 1
end of epoch 19: val_loss 1.8256862307453047e-06, val_acc 1.0
trigger times: 2
end of epoch 20: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 9.1810e-05, -1.2078e-03, -9.2929e-04, -1.0696e-03, -3.4003e-03,
         -9.7346e-04,  1.6639e-02,  1.9805e-03, -1.4288e-03,  1.3988e-03,
         -1.4324e-03, -4.2689e-05,  1.3517e-04]], device='cuda:1'))])
end of epoch 21: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-8.9892e-05,  4.7440e-04, -1.8506e-03, -7.9574e-04,  9.4905e-04,
          1.2159e-03,  2.0366e-01, -2.2159e-03, -8.6451e-04,  1.2551e-04,
         -1.4324e-03, -8.2942e-04, -1.1355e-03]], device='cuda:1'))])
end of epoch 22: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.9889e-05,  1.7422e-03, -6.5299e-04, -1.5953e-03,  2.7824e-03,
          3.4180e-04,  6.8864e-03,  1.9297e-03,  2.2813e-04,  5.7241e-04,
         -1.4325e-03,  5.0388e-04, -1.6049e-03]], device='cuda:1'))])
end of epoch 23: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.8782e-03,  5.0669e-04,  7.4143e-05,  1.0104e-03, -1.0754e-03,
          2.3012e-03,  2.1250e-01, -2.3488e-04,  4.0825e-05, -1.6821e-03,
         -1.4325e-03,  6.9672e-04, -1.4909e-03]], device='cuda:1'))])
end of epoch 24: val_loss 2.232187618460557e-06, val_acc 1.0
trigger times: 1
end of epoch 25: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.0575e-03, -1.0107e-03,  1.6444e-03, -1.0688e-03, -1.2359e-03,
         -1.8958e-03,  1.5584e-02, -5.8184e-04, -1.3199e-03,  3.0828e-05,
         -1.4326e-03,  1.3312e-03, -1.6524e-04]], device='cuda:1'))])
end of epoch 26: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0017,  0.0006,  0.0011,  0.0022, -0.0025,  0.0003,  0.2792,  0.0015,
         -0.0017, -0.0008, -0.0014, -0.0007, -0.0023]], device='cuda:1'))])
end of epoch 27: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.0007,  0.0006, -0.0028,  0.0007, -0.0028, -0.0007,  0.1539,  0.0007,
         -0.0018,  0.0010, -0.0014, -0.0046,  0.0026]], device='cuda:1'))])
end of epoch 28: val_loss 2.017016242348291e-06, val_acc 1.0
trigger times: 1
end of epoch 29: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-6.7339e-04, -2.9730e-03,  5.7568e-04, -2.1960e-04,  6.8234e-04,
          8.5203e-04,  2.9246e-01, -2.8037e-05,  4.1821e-04,  8.8247e-04,
         -1.4327e-03,  1.0727e-03,  7.2090e-04]], device='cuda:1'))])
end of epoch 30: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.1231e-03, -3.0242e-03,  1.6503e-04, -4.5539e-04,  7.4079e-04,
          8.5214e-04,  1.1610e-01, -8.7415e-05,  4.1910e-04,  4.1999e-04,
         -1.4327e-03,  1.0883e-03, -4.2326e-04]], device='cuda:1'))])
end of epoch 31: val_loss 5.3644174649036815e-08, val_acc 1.0
trigger times: 1
end of epoch 32: val_loss 5.151007298991317e-06, val_acc 1.0
trigger times: 2
end of epoch 33: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 9.3858e-04,  3.9261e-05, -2.6380e-04, -1.9122e-03, -6.4172e-04,
          6.7597e-05,  1.8263e-01,  7.7610e-04, -2.6980e-04,  2.5307e-04,
         -1.4328e-03,  1.3577e-03, -5.4047e-04]], device='cuda:1'))])
end of epoch 34: val_loss 7.685954146836593e-06, val_acc 1.0
trigger times: 1
end of epoch 35: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.0043, -0.0040, -0.0017, -0.0017,  0.0025,  0.0009,  0.0426, -0.0002,
          0.0002, -0.0004, -0.0014, -0.0008, -0.0008]], device='cuda:1'))])
end of epoch 36: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 1
end of epoch 37: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0023, -0.0002,  0.0028, -0.0009,  0.0009, -0.0025,  0.0189,  0.0004,
          0.0031, -0.0002, -0.0014,  0.0009, -0.0013]], device='cuda:1'))])
end of epoch 38: val_loss 2.684585572296783e-06, val_acc 1.0
trigger times: 1
end of epoch 39: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-3.0589e-04, -1.0956e-03, -2.1812e-04,  1.4470e-03,  7.8202e-04,
         -1.9170e-03,  2.1121e-01, -4.4962e-04, -6.1990e-04,  1.6673e-03,
         -1.4331e-03,  1.3723e-04, -6.5869e-04]], device='cuda:1'))])
end of epoch 40: val_loss 5.432339459048308e-06, val_acc 1.0
trigger times: 1
end of epoch 41: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0026, -0.0013,  0.0013, -0.0009,  0.0043,  0.0013,  0.0450, -0.0005,
          0.0011, -0.0001, -0.0014,  0.0017,  0.0006]], device='cuda:1'))])
end of epoch 42: val_loss 3.317582069257696e-06, val_acc 1.0
trigger times: 1
end of epoch 43: val_loss 6.986212777064793e-06, val_acc 1.0
trigger times: 2
end of epoch 44: val_loss 4.184243697125112e-07, val_acc 1.0
trigger times: 3
end of epoch 45: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 7.8754e-04, -2.8440e-03,  4.8689e-05, -1.0846e-03, -1.4313e-03,
          6.2209e-04,  1.8716e-01, -4.0992e-04, -7.7194e-04,  1.4777e-03,
         -1.4333e-03, -1.4184e-04, -2.1924e-03]], device='cuda:1'))])
end of epoch 46: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.3089e-05, -7.0110e-04, -1.2121e-03, -1.1773e-03,  2.5876e-04,
         -2.3338e-04,  2.5080e-01, -2.7874e-04, -8.1510e-04,  1.1406e-03,
         -1.4333e-03,  1.3131e-03,  3.3717e-05]], device='cuda:1'))])
end of epoch 47: val_loss 9.163151589746122e-05, val_acc 1.0
trigger times: 1
end of epoch 48: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.0007e-03,  8.5365e-04,  1.0846e-04,  2.6392e-03, -6.9671e-04,
          7.9366e-04,  1.2888e-01,  5.1890e-03,  4.5247e-04,  5.0188e-04,
         -1.4334e-03,  1.2309e-03, -2.0777e-03]], device='cuda:1'))])
end of epoch 49: val_loss 1.543759907463027e-07, val_acc 1.0
trigger times: 1
end of epoch 50: val_loss 1.5640231578117892e-06, val_acc 1.0
trigger times: 2
end of epoch 51: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0004, -0.0018, -0.0015, -0.0002, -0.0006, -0.0005,  0.0878, -0.0010,
         -0.0008,  0.0006, -0.0014, -0.0022, -0.0010]], device='cuda:1'))])
end of epoch 52: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 7.8834e-04, -3.4136e-03,  1.4086e-05, -1.0768e-03, -1.1274e-03,
         -2.5083e-03,  3.1224e-01, -1.5980e-01,  1.1505e-03, -6.7772e-04,
         -1.4335e-03, -1.0179e-03,  2.0206e-03]], device='cuda:1'))])
end of epoch 53: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.3966e-03, -1.5816e-04,  1.3424e-04, -9.9888e-04, -6.5157e-04,
         -2.6390e-03,  1.8867e-01, -2.2929e-04,  1.3633e-03, -2.7231e-04,
         -1.4335e-03, -1.0175e-03,  2.9112e-04]], device='cuda:1'))])
end of epoch 54: val_loss 4.928086896143213e-06, val_acc 1.0
trigger times: 1
end of epoch 55: val_loss 1.6659467394219974e-06, val_acc 1.0
trigger times: 2
end of epoch 56: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-5.9735e-04,  2.8408e-04, -2.2738e-04,  2.8515e-05, -2.1804e-03,
          2.9448e-04,  6.5685e-02, -2.9772e-04, -8.6202e-04,  2.9348e-03,
         -1.4336e-03,  1.6241e-03,  1.1657e-03]], device='cuda:1'))])
end of epoch 57: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-4.1961e-04, -2.0620e-03, -1.7092e-03,  4.0170e-03, -1.3333e-03,
          8.3599e-04,  5.8320e-03, -1.9312e-03, -9.0795e-05, -3.6061e-04,
         -1.4337e-03,  1.0519e-03,  4.5526e-04]], device='cuda:1'))])
end of epoch 58: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.5788e-03, -2.4992e-06,  3.1261e-03,  1.9529e-04,  3.5800e-04,
          1.3043e-04,  1.9106e-01,  1.3346e-03, -7.6053e-04, -5.3048e-04,
         -1.4337e-03, -6.9553e-04,  3.1948e-03]], device='cuda:1'))])
end of epoch 59: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0010,  0.0022,  0.0027,  0.0003,  0.0013, -0.0017,  0.0283, -0.0009,
          0.0007,  0.0003, -0.0014,  0.0019, -0.0015]], device='cuda:1'))])
end of epoch 60: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0010,  0.0014,  0.0017,  0.0006,  0.0008, -0.0005,  0.0064, -0.0019,
          0.0015,  0.0032, -0.0014, -0.0015,  0.0007]], device='cuda:1'))])
end of epoch 61: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-7.2032e-05, -4.9379e-04, -6.4833e-05, -1.3858e-03, -3.8530e-04,
         -1.7312e-03,  1.5755e-01, -7.1877e-04,  2.6176e-03,  1.4671e-03,
         -1.4338e-03, -2.5242e-04,  1.9391e-03]], device='cuda:1'))])
end of epoch 62: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.0036, -0.0026, -0.0007, -0.0009,  0.0009, -0.0025,  0.1032, -0.0012,
         -0.0004,  0.0002, -0.0014,  0.0011,  0.0011]], device='cuda:1'))])
end of epoch 63: val_loss 2.2870241298278413e-06, val_acc 1.0
trigger times: 1
end of epoch 64: val_loss 2.3996761996158965e-06, val_acc 1.0
trigger times: 2
end of epoch 65: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.4743e-03, -1.6936e-03,  1.0329e-03,  2.5959e-04,  1.0534e-03,
         -2.9480e-05,  2.0072e-02, -2.2455e-03,  4.3357e-04, -3.0168e-04,
         -1.4340e-03, -8.7425e-05,  3.8637e-05]], device='cuda:1'))])
end of epoch 66: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.4184e-03, -3.0726e-04, -4.1818e-05, -1.6597e-03, -6.0581e-04,
          4.7389e-04,  1.1899e-01,  1.5057e-03, -7.2095e-04, -4.0743e-04,
         -1.4340e-03,  8.6852e-04,  2.2729e-04]], device='cuda:1'))])
end of epoch 67: val_loss 2.5051759820371446e-06, val_acc 1.0
trigger times: 1
end of epoch 68: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.3904e-04, -1.6514e-03,  1.1195e-05,  5.2006e-04,  1.8890e-03,
          3.1895e-04,  2.3559e-01, -2.8960e-04,  3.4634e-04, -1.2950e-03,
         -1.4341e-03, -1.1156e-03,  1.1544e-03]], device='cuda:1'))])
end of epoch 69: val_loss 5.084272483202312e-07, val_acc 1.0
trigger times: 1
end of epoch 70: val_loss 4.208085537982242e-07, val_acc 1.0
trigger times: 2
end of epoch 71: val_loss 3.379581872309245e-07, val_acc 1.0
trigger times: 3
end of epoch 72: val_loss 3.242336047151184e-05, val_acc 1.0
trigger times: 4
end of epoch 73: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.1401e-04, -1.8895e-03,  2.2011e-03,  7.3590e-04,  1.7243e-03,
         -2.3564e-03,  3.9379e-02, -2.3443e-05,  1.3710e-03,  4.5635e-04,
         -1.4342e-03,  1.2454e-03,  8.8161e-04]], device='cuda:1'))])
end of epoch 74: val_loss 1.2159344993989408e-07, val_acc 1.0
trigger times: 1
end of epoch 75: val_loss 2.692574944376247e-05, val_acc 1.0
trigger times: 2
end of epoch 76: val_loss 4.410743255078842e-08, val_acc 1.0
trigger times: 3
end of epoch 77: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-3.2081e-03,  7.5620e-04, -2.0077e-03, -1.9744e-03, -4.6445e-04,
          6.5824e-05,  2.1342e-01, -2.3510e-04,  1.2006e-04,  1.0714e-04,
         -1.4344e-03, -1.3372e-03,  2.0147e-03]], device='cuda:1'))])
end of epoch 78: val_loss 2.0992705952949107e-06, val_acc 1.0
trigger times: 1
end of epoch 79: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0004,  0.0024, -0.0039, -0.0020,  0.0003, -0.0001,  0.0094,  0.0015,
          0.0009,  0.0002, -0.0014,  0.0003, -0.0003]], device='cuda:1'))])
end of epoch 80: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.0014,  0.0007, -0.0013, -0.0020,  0.0002,  0.0008,  0.1343, -0.0008,
         -0.0028, -0.0005, -0.0014,  0.0003, -0.0013]], device='cuda:1'))])
end of epoch 81: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-7.0207e-04, -1.6074e-03, -7.0713e-05,  1.0007e-03, -1.7351e-03,
          1.3876e-03,  1.8232e-02,  1.2527e-03,  1.9144e-03, -9.9933e-04,
         -1.4345e-03,  1.9145e-04,  2.9001e-04]], device='cuda:1'))])
end of epoch 82: val_loss 1.381632858397097e-06, val_acc 1.0
trigger times: 1
end of epoch 83: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.4310e-03,  7.1048e-04, -6.2932e-04,  7.6255e-04, -1.9033e-03,
          1.3220e-03,  1.6826e-01, -3.8543e-04, -2.1595e-03, -1.2555e-03,
         -1.4346e-03, -1.4880e-04, -6.1374e-04]], device='cuda:1'))])
end of epoch 84: val_loss 2.6088878280461358e-06, val_acc 1.0
trigger times: 1
end of epoch 85: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.3345e-03,  5.1491e-04, -1.9668e-03, -6.9567e-04,  9.8870e-04,
         -1.0651e-03,  8.1813e-02, -1.3292e-03, -2.1809e-04, -3.7518e-04,
         -1.4347e-03, -3.5001e-05,  6.1003e-04]], device='cuda:1'))])
end of epoch 86: val_loss 3.1471140562189246e-06, val_acc 1.0
trigger times: 1
end of epoch 87: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 6.7889e-06,  6.3007e-04,  8.3112e-04, -2.6458e-04,  1.3969e-03,
         -1.6042e-04,  2.1611e-01,  4.2219e-05,  1.4855e-03,  5.4807e-04,
         -1.4347e-03,  3.7748e-04,  3.9270e-04]], device='cuda:1'))])
end of epoch 88: val_loss 2.706041823330452e-06, val_acc 1.0
trigger times: 1
end of epoch 89: val_loss 4.149657222569658e-06, val_acc 1.0
trigger times: 2
end of epoch 90: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.7160e-03,  4.2033e-05, -5.2393e-04, -9.0779e-04, -2.0522e-03,
         -8.8683e-04,  1.7451e-01, -2.2154e-04, -2.3831e-04, -1.1967e-03,
         -1.4348e-03,  2.6164e-03, -6.6322e-04]], device='cuda:1'))])
end of epoch 91: val_loss 2.3841856489070778e-09, val_acc 1.0
trigger times: 1
end of epoch 92: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.8262e-03, -3.8271e-04,  3.6262e-03,  5.2017e-03,  2.0874e-03,
          1.4458e-03,  4.1222e-02, -7.3484e-05,  7.3106e-05, -8.4781e-04,
         -1.4349e-03, -4.7703e-04,  1.2083e-04]], device='cuda:1'))])
end of epoch 93: val_loss 6.04390616274486e-07, val_acc 1.0
trigger times: 1
end of epoch 94: val_loss 2.069468032459554e-06, val_acc 1.0
trigger times: 2
end of epoch 95: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0006, -0.0028,  0.0010,  0.0018, -0.0012, -0.0010,  0.2640, -0.0004,
          0.0005,  0.0003, -0.0014,  0.0018,  0.0006]], device='cuda:1'))])
end of epoch 96: val_loss 9.238709225201092e-07, val_acc 1.0
trigger times: 1
end of epoch 97: val_loss 1.374480739855244e-06, val_acc 1.0
trigger times: 2
end of epoch 98: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 5.2775e-04,  7.5923e-04,  2.8264e-04, -1.9079e-04,  1.8604e-03,
          1.1386e-03,  2.2356e-01, -8.0954e-04,  2.5606e-03, -1.7603e-03,
         -1.4351e-03, -2.1715e-03, -1.7371e-03]], device='cuda:1'))])
end of epoch 99: val_loss 1.680850532892464e-07, val_acc 1.0
trigger times: 1
Finished training.
0 -15.408801576704718 -76.49560211093441
1 -15.433385000447743 -76.43254290478275
2 -15.555950857815333 -76.39400052111216
3 -15.591777411755174 -76.39288655578054
4 -15.600564260501415 -75.5117555919354
5 -15.687705002725124 -75.45491471691871
6 -15.805204657488503 -75.37590376736138
7 -15.39407003368251 -75.23051262723985
8 -15.75283587782178 -75.12844559248974
9 -15.807992583373562 -74.94647424071502
10 -15.441406595753506 -74.79011195009352
11 -15.058927813312039 -74.77244137283637
12 -15.930736707756296 -74.67481249989291
13 -15.327772196847945 -73.72336317611419
14 -15.727182827191427 -73.56431969207013
15 -15.756342643639073 -73.4909912784752
16 -15.587557705119252 -73.40639184113184
17 -15.457650076597929 -73.24050384585722
18 -15.586259375675581 -73.20947906298412
19 -15.669410365866497 -73.04035109001411
20 -15.7068209805293 -73.02698225933851
21 -15.555675391107798 -73.01645609596025
22 -15.759160501533188 -72.87357241135757
23 -15.444231790257618 -72.82662623422087
24 -15.74092262564227 -72.75980644594084
25 -15.454581894678995 -72.68194170578586
26 -15.89288907777518 -72.40058497328435
27 -15.185576702468097 -72.01711227783501
28 -15.720431981608272 -71.94714540234806
29 -15.433322767843492 -71.92263145436405
30 -15.251711996970698 -71.702358351366
31 -15.676121716969647 -71.38296357274709
32 -15.700306082260795 -71.30478131047195
33 -15.13320494198706 -70.31193013113204
34 -15.611348724924028 -70.25790212597492
35 -15.545441422378644 -70.21863359524349
36 -15.655940207187086 -70.17159014791179
37 -14.920716323889792 -70.16337966986907
38 -15.557536458829418 -70.00060899533194
39 -15.428743532975204 -69.55155652371944
40 -15.085289697977714 -69.4588764822744
41 -15.577635635854676 -69.34168125087837
42 -15.603577654575929 -69.31877251379912
43 -15.398325886460952 -69.21666769169597
44 -15.338058556430042 -69.01198925045854
45 -15.51460952393245 -68.96022190464915
46 -15.474015195155516 -68.91236468899692
47 -15.675043786875904 -68.89798972795377
48 -15.449768322054297 -68.27776122884012
49 -15.44177637156099 -68.17059012554348
50 -15.143259365228005 -68.07523885792283
51 -15.64037205814384 -67.81491337155057
52 -15.496288993628696 -67.72610322532728
53 -15.67440428165719 -67.6298498683123
54 -15.154527831473388 -67.4328785935544
55 -14.932247948716395 -67.05456976533648
56 -15.257783473003656 -65.6226880787607
57 -15.627875174744986 -65.20606877303754
58 -15.420774103607982 -65.15619694739955
59 -14.933341474155895 -64.8200904908804
60 15.5396040660562 -63.0930439253028
61 15.566451948485337 -62.87231006153974
62 15.447413194924593 -62.228046573671705
63 15.609857925330289 -61.965961387876746
64 15.35284280916676 -61.74945371844752
65 15.616053037927486 -61.65641260048595
66 15.691158513305709 -61.43159516774143
67 15.46802556863986 -61.08141395797017
68 15.256829340709373 -60.8878377268014
69 15.743093103636056 -60.86613250598757
70 15.62106312403921 -60.72338817308264
71 15.690012478502467 -60.53416651569491
72 15.336944528738968 -60.4674871268045
73 15.502146141370758 -60.37812138002903
74 15.646697545656934 -60.296336176761976
75 15.73239585920237 -59.9465805812333
76 15.246236853068694 -59.86522600456503
77 15.646972725284286 -59.855935946610316
78 15.384704633615911 -59.6686370215618
79 15.274824368068948 -59.59787071674172
80 15.437346003600396 -59.120194511305954
81 15.274161217967048 -58.67385353944724
82 15.645525905652903 -58.6415911232248
83 15.45471463096328 -57.685206343682104
84 15.619955941103399 -57.56226575834924
85 15.603143552783877 -57.56028277892836
86 15.55227127589751 -57.52739998432471
87 15.519610504154116 -57.26759583085017
88 15.68248647917062 -56.90952284500719
89 15.52238541340921 -56.63008780137557
90 0.4836802762001753 -38.41270390343083
91 -0.1879484867240535 -20.13839114930498
92 0.4259724920921144 -19.634363962764166
93 -0.09125566654984141 -13.281607874517208
94 -2.227819271502085 -12.768483977935247
95 0.2483578365354333 -12.68135972540495
96 0.5994491337260115 -9.392089735112547
97 0.4728677838575095 -8.455797636261352
98 0.5425461321137846 -7.951803348570104
99 0.4719801425526384 -7.699177836325561
100 -0.264543400509865 -7.375657083130067
101 -0.41604852286309324 -7.086057940132588
102 0.31356044198037125 -6.99889967022435
103 -0.43583900984958746 -6.97807785651095
104 -0.31218984501902014 -6.96052527538595
105 -0.4407647620064381 -6.659491729217256
106 -0.03602125062025152 -6.4928277503270895
107 -0.5113158028907492 -6.220257269860126
108 -0.3639504657185171 -5.914637632847621
109 -0.09373473173764069 -5.5181009563867125
110 -0.1827722263369651 -5.299844141339399
111 -0.21875532322883373 -5.2111324399751355
112 0.22063409615657292 -5.060611718283424
113 -0.23330408203764819 -4.920371428871764
114 -0.19006231376260985 -4.918038444677467
115 0.12253422444337048 -4.76155944913195
116 -0.016898799716727808 -4.288124884141435
117 0.20363680127775297 -3.925549655249319
118 0.04925805129460059 -3.916865221951316
119 0.043395654882260715 -3.5121297730673273
train accuracy: 1.0
validation accuracy: 1.0
[-81.31229094 -81.16681132 -80.80695955 -79.91606976 -79.7509397
 -78.81917787 -78.76408281 -78.34589185 -77.54890557 -77.52218702
 -77.49466288 -77.46472656 -77.18932328 -77.18344174 -77.17324833
 -77.10563801 -76.93882058 -76.9005049  -76.7476581  -76.74724629
 -76.58975407 -76.51422759 -76.49560211 -76.42870411 -76.4157121
 -76.39288656 -76.24255247 -76.24242256 -76.18485557 -76.12276702
 -76.07624252 -75.97723401 -75.52106293 -75.52068246 -75.45491472
 -75.37590377 -75.21514862 -75.07997353 -75.05658443 -75.03586792
 -75.02388249 -74.97700682 -74.92225041 -74.85097802 -74.77244137
 -74.54269389 -74.53988544 -74.44205049 -74.19594718 -74.02591542
 -73.87523453 -73.74571992 -73.69271153 -73.66462884 -73.56431969
 -73.49819572 -73.41208315 -73.40639184 -73.32144136 -73.30435944
 -73.234831   -73.20947906 -73.19206611 -73.16511777 -72.93401148
 -72.87357241 -72.82662623 -72.70889393 -72.68194171 -72.01711228
 -71.9471454  -71.85472427 -71.70235835 -71.38296357 -71.30478131
 -71.19572271 -70.31193013 -70.16337967 -70.000609   -69.55155652
 -69.45887648 -69.21666769 -69.01198925 -68.91236469 -68.89798973
 -67.81491337 -67.72610323 -67.43287859 -67.05456977 -65.62268808
 -61.96596139 -61.6564126  -61.43159517 -61.08141396 -60.88783773
 -60.86613251 -60.72338817 -60.37812138 -59.865226   -59.85593595
 -59.66863702 -57.68520634 -57.26759583 -56.6300878  -38.4127039
 -19.63436396 -12.76848398  -8.45579764  -7.69917784  -7.37565708
  -6.99889967  -6.97807786  -6.96052528  -6.65949173  -6.22025727
  -5.91463763  -5.51810096  -5.21113244  -3.92554966  -3.91686522]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:1
end of epoch 0: val_loss 0.04630177367507258, val_acc 0.995
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.4009, -0.3946,  0.0600, -0.2898,  0.2779, -0.3129, -0.0138, -0.4232,
         -0.3443,  0.5658, -0.0014, -1.3719, -0.9285]], device='cuda:1'))])
end of epoch 1: val_loss 0.08589016868128965, val_acc 0.995
trigger times: 1
end of epoch 2: val_loss 0.08459961216081852, val_acc 0.995
trigger times: 2
end of epoch 3: val_loss 1.1741000198526308e-05, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 6.1597e-01, -1.2077e+00,  5.6610e-05, -1.2836e-01,  2.5025e-01,
         -4.8227e-01, -1.8081e-02, -3.4370e-01, -9.5104e-02,  7.8244e-01,
         -1.4320e-03, -4.3245e+00, -3.1228e+00]], device='cuda:1'))])
end of epoch 4: val_loss 0.029784735280844927, val_acc 0.995
trigger times: 1
end of epoch 5: val_loss 0.024072505218937293, val_acc 0.995
trigger times: 2
end of epoch 6: val_loss 1.1920857559744036e-07, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.5596e-01, -2.3718e+00, -3.5978e-04,  7.6669e-02,  1.8475e-01,
         -5.1482e-01, -2.9514e-02, -6.0630e-01,  1.9887e-01,  9.4668e-01,
         -1.4320e-03, -7.2989e+00, -5.4185e+00]], device='cuda:1'))])
end of epoch 7: val_loss 3.409276428101293e-07, val_acc 1.0
trigger times: 1
end of epoch 8: val_loss 4.1723234289747776e-09, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.7934e-05, -2.5901e+00, -9.6585e-06,  4.3297e-02,  9.6045e-02,
         -4.9964e-01, -1.1781e-02, -4.7047e-01, -9.3237e-02,  9.4095e-01,
         -1.4320e-03, -7.3817e+00, -6.4557e+00]], device='cuda:1'))])
end of epoch 9: val_loss 0.7905507016298219, val_acc 0.965
trigger times: 1
end of epoch 10: val_loss 7.1525522571391775e-09, val_acc 1.0
trigger times: 2
end of epoch 11: val_loss 1.132487000177207e-08, val_acc 1.0
trigger times: 3
end of epoch 12: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.0085e-04, -3.2287e+00,  5.9992e-05,  3.4755e-01,  3.9980e-01,
         -5.3173e-01, -1.9103e-02, -3.3727e-01, -3.4161e-01,  1.1152e+00,
         -1.4321e-03, -7.2847e+00, -8.6453e+00]], device='cuda:1'))])
end of epoch 13: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.1677e-04, -2.8026e+00, -1.2557e-04,  2.4480e-01, -6.9724e-05,
         -6.2113e-02, -1.8576e-02, -2.5207e-01,  2.1567e-05,  6.5532e-01,
         -1.4321e-03, -6.2368e+00, -8.0921e+00]], device='cuda:1'))])
end of epoch 14: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.5922e-04, -2.9074e+00, -4.0316e-01,  6.5722e-02,  5.8373e-01,
         -4.6436e-01, -1.2772e-02, -5.0888e-01, -4.1259e-01,  8.7770e-01,
         -1.4322e-03, -7.0753e+00, -9.2154e+00]], device='cuda:1'))])
end of epoch 15: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.7648e-05, -2.6921e+00,  7.2827e-05,  6.6392e-02,  1.8054e-04,
         -7.8134e-02, -1.5479e-02, -3.1741e-01,  1.7100e-05,  4.6878e-01,
         -1.4322e-03, -5.9188e+00, -9.0281e+00]], device='cuda:1'))])
end of epoch 16: val_loss 0.3473503159731626, val_acc 0.99
trigger times: 1
end of epoch 17: val_loss 8.413945324718952e-05, val_acc 1.0
trigger times: 2
end of epoch 18: val_loss 2.9802313861182485e-09, val_acc 1.0
trigger times: 3
end of epoch 19: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.3273e-04, -3.2426e+00, -1.2452e-04,  1.3150e-01,  4.8236e-01,
         -4.7523e-01, -7.1228e-03, -3.1913e-01, -5.7672e-01,  4.6712e-01,
         -1.4324e-03, -5.0928e+00, -1.0032e+01]], device='cuda:1'))])
end of epoch 20: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-5.7096e-02, -2.4000e+00, -6.7904e-04,  2.3545e-01,  1.4186e-01,
         -7.7055e-02, -1.3814e-02, -2.3422e-01, -1.4393e-01,  7.3541e-02,
         -1.4324e-03, -3.4771e+00, -9.1040e+00]], device='cuda:1'))])
end of epoch 21: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-4.3299e-04, -2.4706e+00, -1.7197e-05,  2.8915e-01,  4.8498e-01,
         -2.8017e-01, -1.8101e-02, -2.6298e-01, -4.8628e-01,  2.7641e-01,
         -1.4324e-03, -3.3426e+00, -9.0455e+00]], device='cuda:1'))])
end of epoch 22: val_loss 20.657412362095638, val_acc 0.925
trigger times: 1
end of epoch 23: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 2
end of epoch 24: val_loss 4.768369308294495e-09, val_acc 1.0
trigger times: 3
end of epoch 25: val_loss 2.0265538296371232e-08, val_acc 1.0
trigger times: 4
end of epoch 26: val_loss 4.96489374164355e-07, val_acc 1.0
trigger times: 5
end of epoch 27: val_loss 11.387969619866114, val_acc 0.93
trigger times: 6
end of epoch 28: val_loss 0.7846223944907852, val_acc 0.915
trigger times: 7
end of epoch 29: val_loss 0.11367638755693633, val_acc 0.985
trigger times: 8
end of epoch 30: val_loss 0.014219776391977917, val_acc 0.995
trigger times: 9
end of epoch 31: val_loss 3.7781416685902514e-05, val_acc 1.0
trigger times: 10
Early stopping.
0 -607.5220475196838 -81.31229094219519
1 -630.7114591598511 -81.16681132445915
2 -605.3841390609741 -80.80695955137281
3 -602.6523208618164 -79.91606976299887
4 -608.6313900947571 -79.75093969704696
5 -599.5380573272705 -78.81917787456322
6 -635.1415162086487 -78.76408280532729
7 -626.2877216339111 -78.34589185322793
8 -630.4198513031006 -77.54890557085545
9 -634.5218677520752 -77.52218701627886
10 -595.6155519485474 -77.49466288251266
11 -612.0581502914429 -77.46472656220253
12 -620.1848630905151 -77.18932327512927
13 -604.3651866912842 -77.18344174308601
14 -584.9045362472534 -77.17324832543733
15 -606.2661228179932 -77.10563800972555
16 -558.111870765686 -76.938820581755
17 -577.9992256164551 -76.900504898231
18 -622.0802478790283 -76.74765809564116
19 -599.3654451370239 -76.74724629158203
20 -610.1294927597046 -76.58975407218243
21 -626.973560333252 -76.51422758992818
22 -359.5935661792755 -76.49560211093441
23 -602.0359840393066 -76.42870411262139
24 -583.833981513977 -76.41571209518483
25 -375.27510046958923 -76.39288655578054
26 -620.7338352203369 -76.24255246798964
27 -606.0825481414795 -76.24242255621769
28 -590.8700618743896 -76.1848555669152
29 -601.0795111656189 -76.12276702053674
30 -610.6959857940674 -76.0762425167399
31 -596.4625873565674 -75.97723400818109
32 -615.6588373184204 -75.52106292931623
33 -599.3904056549072 -75.52068245896544
34 -351.35573506355286 -75.45491471691871
35 -348.07294368743896 -75.37590376736138
36 -586.4159250259399 -75.21514861887772
37 -598.4268798828125 -75.07997353108946
38 -592.1717977523804 -75.05658442859406
39 -603.9649496078491 -75.03586792181682
40 -581.9958667755127 -75.0238824868006
41 -585.3978099822998 -74.9770068192206
42 -594.2432861328125 -74.92225041450517
43 -608.4154901504517 -74.85097802195526
44 -333.25934529304504 -74.77244137283637
45 -598.1385841369629 -74.54269389350043
46 -594.0995082855225 -74.53988543997262
47 -604.4363689422607 -74.442050491461
48 -613.6803970336914 -74.19594717680853
49 -591.0559391975403 -74.02591542297523
50 -591.0408110618591 -73.87523453440666
51 -601.4818592071533 -73.74571992034893
52 -575.6563396453857 -73.69271152583889
53 -600.2335014343262 -73.66462884232755
54 -325.146856546402 -73.56431969207013
55 -591.373119354248 -73.4981957154367
56 -588.6350522041321 -73.41208315086176
57 -361.247745513916 -73.40639184113184
58 -585.6112022399902 -73.32144135704175
59 -599.6889505386353 -73.30435943621555
60 -579.4451537132263 -73.2348310033391
61 -331.1949305534363 -73.20947906298412
62 -608.7110185623169 -73.1920661098377
63 -587.6655130386353 -73.1651177678614
64 -452.3667583465576 -72.93401148446968
65 -215.56677055358887 -72.87357241135757
66 -336.01602149009705 -72.82662623422087
67 -448.75532126426697 -72.70889393200369
68 -319.0604040622711 -72.68194170578586
69 -353.47369027137756 -72.01711227783501
70 -330.57885932922363 -71.94714540234806
71 -596.1699361801147 -71.85472426806568
72 -319.8243646621704 -71.702358351366
73 -304.5542335510254 -71.38296357274709
74 -310.37806153297424 -71.30478131047195
75 -594.6059293746948 -71.1957227081929
76 -365.5157992839813 -70.31193013113204
77 -321.8480975627899 -70.16337966986907
78 -364.0670156478882 -70.00060899533194
79 -325.01673793792725 -69.55155652371944
80 -342.1056876182556 -69.4588764822744
81 -327.5624873638153 -69.21666769169597
82 -325.26764154434204 -69.01198925045854
83 -345.4930877685547 -68.91236468899692
84 -331.3530972003937 -68.89798972795377
85 -311.48929738998413 -67.81491337155057
86 -341.29092359542847 -67.72610322532728
87 -336.9741129875183 -67.4328785935544
88 -317.99834990501404 -67.05456976533648
89 -304.97471737861633 -65.6226880787607
90 -335.30787897109985 -61.965961387876746
91 -341.2456679344177 -61.65641260048595
92 -362.15961146354675 -61.43159516774143
93 -331.90060472488403 -61.08141395797017
94 -343.0607397556305 -60.8878377268014
95 -345.0623016357422 -60.86613250598757
96 -335.0135407447815 -60.72338817308264
97 -355.2046751976013 -60.37812138002903
98 -354.4071536064148 -59.86522600456503
99 -343.18968391418457 -59.855935946610316
100 -327.4901065826416 -59.6686370215618
101 -327.10626316070557 -57.685206343682104
102 -336.861004114151 -57.26759583085017
103 -326.17633032798767 -56.63008780137557
104 -254.16174149513245 -38.41270390343083
105 -177.51088213920593 -19.634363962764166
106 -32.27110783755779 -12.768483977935247
107 -151.69219374656677 -8.455797636261352
108 -161.17066180706024 -7.699177836325561
109 -138.2456247806549 -7.375657083130067
110 -150.5839879512787 -6.99889967022435
111 -2.720530688762665 -6.97807785651095
112 -66.03391672670841 -6.96052527538595
113 -136.03661179542542 -6.659491729217256
114 -149.4762020111084 -6.220257269860126
115 -143.74971878528595 -5.914637632847621
116 -122.30469000339508 -5.5181009563867125
117 -129.66621124744415 -5.2111324399751355
118 -10.777969509363174 -3.925549655249319
119 -48.68683832883835 -3.916865221951316
train accuracy: 0.9966666666666667
validation accuracy: 1.0
[-80.80695955 -78.76408281 -77.54890557 -77.46472656 -77.18932328
 -77.17324833 -76.93882058 -76.74724629 -76.42870411 -76.39288656
 -76.24255247 -76.24242256 -76.18485557 -76.12276702 -76.07624252
 -75.52068246 -75.21514862 -75.03586792 -75.02388249 -74.54269389
 -74.53988544 -74.44205049 -74.02591542 -73.74571992 -73.69271153
 -73.66462884 -73.56431969 -73.40639184 -73.32144136 -73.234831
 -73.19206611 -72.93401148 -72.70889393 -72.68194171 -72.01711228
 -71.9471454  -71.70235835 -70.16337967 -70.000609   -69.45887648
 -69.21666769 -68.91236469 -68.89798973 -65.62268808 -61.6564126
 -60.88783773 -60.72338817 -60.37812138 -59.66863702 -57.68520634
 -57.26759583 -14.58250933 -14.43775742 -14.19011283 -14.17472098
 -13.98140134 -13.81903984 -13.59071202 -13.41775596 -13.2907001
 -13.13113317 -12.76848398 -12.7448116  -12.66036515 -12.62471514
 -12.54477323 -11.99279085 -11.97202591 -11.89919796 -11.85244692
 -11.79151575 -11.57280284 -11.5405907  -11.21787457 -11.13545354
 -11.12866073 -11.05895837 -10.91193981 -10.83245358 -10.690009
 -10.54270898 -10.53041363 -10.27643605 -10.23308529 -10.22123152
  -9.89835248  -9.55086002  -9.46249277  -9.40614996  -9.33584201
  -9.243075    -9.21467878  -9.15158468  -9.08154711  -8.90846823
  -8.79032718  -8.66732138  -8.66151025  -8.56695667  -8.48953997
  -8.4785276   -8.45579764  -8.32497744  -8.16660986  -7.96828822
  -7.73575127  -7.69917784  -7.69793827  -7.21350056  -7.12085089
  -6.99889967  -6.99562914  -6.96052528  -6.76394236  -6.65949173
  -6.28621581  -6.22025727  -6.18209059  -5.91463763  -3.91686522]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:3
end of epoch 0: val_loss 0.001051313571388306, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.9436e-01,  1.3861e-01, -7.9564e-02, -1.6155e-02, -1.2650e-04,
         -1.5048e-05, -7.3695e-04,  7.1350e-07, -1.1453e-04, -2.8348e-05,
         -1.4320e-03, -3.4144e-01, -2.4218e-01]], device='cuda:3'))])
end of epoch 1: val_loss 9.916680592141346e-06, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 8.3810e-01,  6.8276e-01, -3.1741e-01, -4.6031e-01,  8.5730e-04,
         -3.3268e-01, -1.0311e-02, -3.4910e-01, -1.9623e-02,  1.2409e-02,
         -1.4320e-03, -1.4285e+00, -1.4090e+00]], device='cuda:3'))])
end of epoch 2: val_loss 1.0734590468928217e-05, val_acc 1.0
trigger times: 1
end of epoch 3: val_loss 0.0004389386977391041, val_acc 1.0
trigger times: 2
end of epoch 4: val_loss 2.6226013822849836e-08, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 6.4392e-01,  9.1151e-01, -6.3478e-02, -5.1789e-02,  1.2333e-01,
         -4.3213e-01, -2.2694e-02, -4.9832e-01, -2.0413e-01,  3.6768e-01,
         -1.4320e-03, -1.5642e+00, -2.1861e+00]], device='cuda:3'))])
end of epoch 5: val_loss 2.331785944988951e-06, val_acc 1.0
trigger times: 1
end of epoch 6: val_loss 0.0002411844610469416, val_acc 1.0
trigger times: 2
end of epoch 7: val_loss 0.008629758087335517, val_acc 0.995
trigger times: 3
end of epoch 8: val_loss 0.00012407701462500143, val_acc 1.0
trigger times: 4
end of epoch 9: val_loss 0.003498645199414341, val_acc 0.995
trigger times: 5
end of epoch 10: val_loss 0.0033528921975448257, val_acc 1.0
trigger times: 6
end of epoch 11: val_loss 5.9604610669339305e-09, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 6.8047e-01,  6.9124e-01, -3.9479e-01, -3.8221e-01,  1.1756e-01,
         -9.0851e-01, -8.4989e-03, -2.3854e-01, -2.0516e-01,  6.0775e-01,
         -1.4321e-03, -1.4292e+00, -2.0693e+00]], device='cuda:3'))])
end of epoch 12: val_loss 5.414271727204323e-05, val_acc 1.0
trigger times: 1
end of epoch 13: val_loss 0.001710950990091078, val_acc 1.0
trigger times: 2
end of epoch 14: val_loss 9.535833669360727e-07, val_acc 1.0
trigger times: 3
end of epoch 15: val_loss 0.00018224982735429052, val_acc 1.0
trigger times: 4
end of epoch 16: val_loss 0.0014479999027616941, val_acc 1.0
trigger times: 5
end of epoch 17: val_loss 0.046755365262532676, val_acc 0.99
trigger times: 6
end of epoch 18: val_loss 4.726355836055518e-05, val_acc 1.0
trigger times: 7
end of epoch 19: val_loss 2.917617017030716, val_acc 0.97
trigger times: 8
end of epoch 20: val_loss 2.5033887141034938e-08, val_acc 1.0
trigger times: 9
end of epoch 21: val_loss 1.2189181288704277e-05, val_acc 1.0
trigger times: 10
Early stopping.
0 -227.19172036647797 -80.80695955137281
1 -252.19163966178894 -78.76408280532729
2 -266.19857704639435 -77.54890557085545
3 -215.03399217128754 -77.46472656220253
4 -221.86512506008148 -77.18932327512927
5 -216.25410854816437 -77.17324832543733
6 -314.965615272522 -76.938820581755
7 -233.55270409584045 -76.74724629158203
8 -221.5020775794983 -76.42870411262139
9 -117.91276097297668 -76.39288655578054
10 -283.5031088590622 -76.24255246798964
11 -240.7838817834854 -76.24242255621769
12 -210.87935769557953 -76.1848555669152
13 -212.59254229068756 -76.12276702053674
14 -342.39464926719666 -76.0762425167399
15 -220.69923841953278 -75.52068245896544
16 -205.71588456630707 -75.21514861887772
17 -253.769140958786 -75.03586792181682
18 -325.3050614595413 -75.0238824868006
19 -219.46712052822113 -74.54269389350043
20 -224.94347751140594 -74.53988543997262
21 -220.2955001592636 -74.442050491461
22 -216.7759701013565 -74.02591542297523
23 -284.72811818122864 -73.74571992034893
24 -206.23181009292603 -73.69271152583889
25 -214.42577075958252 -73.66462884232755
26 -121.86722719669342 -73.56431969207013
27 -105.17778885364532 -73.40639184113184
28 -241.65592432022095 -73.32144135704175
29 -237.74826979637146 -73.2348310033391
30 -232.35159373283386 -73.1920661098377
31 -237.19456088542938 -72.93401148446968
32 -192.2649381160736 -72.70889393200369
33 -120.74470520019531 -72.68194170578586
34 -112.6599782705307 -72.01711227783501
35 -101.69724774360657 -71.94714540234806
36 -116.28615999221802 -71.702358351366
37 -99.0868866443634 -70.16337966986907
38 -86.1835367679596 -70.00060899533194
39 -95.85399115085602 -69.4588764822744
40 -98.73278677463531 -69.21666769169597
41 -65.93903934955597 -68.91236468899692
42 -104.83360779285431 -68.89798972795377
43 -108.35341775417328 -65.6226880787607
44 -219.52962493896484 -61.65641260048595
45 -216.60777413845062 -60.8878377268014
46 -222.61572861671448 -60.72338817308264
47 -225.90619659423828 -60.37812138002903
48 -219.75259351730347 -59.6686370215618
49 -220.9300229549408 -57.685206343682104
50 -220.62051916122437 -57.26759583085017
51 -0.3492358326911926 -14.58250933387046
52 53.51037418842316 -14.437757420363038
53 7.74677973985672 -14.190112827586777
54 30.201881408691406 -14.174720981098872
55 31.20641326904297 -13.981401338041339
56 52.65223878622055 -13.819039837530202
57 12.996583938598633 -13.590712024814795
58 24.41102010011673 -13.417755956610373
59 36.5652831196785 -13.290700099872396
60 51.2091406583786 -13.13113317215055
61 55.30605374276638 -12.768483977935247
62 37.62107801437378 -12.744811603880509
63 75.45142062008381 -12.660365152080647
64 42.55267596244812 -12.624715141274706
65 69.05295246466994 -12.54477322585289
66 36.1824049949646 -11.992790852336395
67 67.1500773653388 -11.972025910018488
68 33.521966338157654 -11.899197963982685
69 60.174238592386246 -11.852446921029859
70 77.07366147637367 -11.791515752129413
71 60.02230986952782 -11.572802838730563
72 49.898392021656036 -11.540590702922245
73 62.13121670484543 -11.21787456515775
74 41.98901987075806 -11.135453542930229
75 56.25570422410965 -11.128660728264808
76 72.8744542747736 -11.058958369700678
77 59.34986791014671 -10.911939810306514
78 67.69844618439674 -10.832453584420993
79 45.46197921037674 -10.69000900128925
80 54.84534355998039 -10.54270897678891
81 45.98219132423401 -10.530413627819081
82 49.96188086271286 -10.276436050490627
83 47.332305341959 -10.233085294656876
84 65.0210748910904 -10.221231519720886
85 70.92304727807641 -9.898352480956024
86 54.99742269515991 -9.550860016338612
87 74.07806714624166 -9.462492766873485
88 79.37515655532479 -9.406149956760274
89 51.97468921542168 -9.33584201264156
90 69.78607605397701 -9.24307499734176
91 62.30838930606842 -9.214678781535703
92 64.36076340079308 -9.151584678380766
93 39.399318635463715 -9.081547112722339
94 62.734958082437515 -8.908468233381466
95 72.394530326128 -8.790327180294941
96 51.844821095466614 -8.66732138163796
97 69.70494791865349 -8.661510245435492
98 72.72240257263184 -8.566956670258746
99 66.54175600409508 -8.489539968923486
100 62.129963994026184 -8.478527598591981
101 44.1430888697505 -8.455797636261352
102 69.81485016644001 -8.324977442124407
103 74.76424352824688 -8.166609855475295
104 69.93520297855139 -7.968288218466813
105 70.35737278312445 -7.735751266858284
106 26.93820722401142 -7.699177836325561
107 72.82831472158432 -7.69793827028237
108 66.66353423893452 -7.213500563420653
109 68.77087387442589 -7.120850890222868
110 -8.397273369133472 -6.99889967022435
111 67.11385035514832 -6.995629136287063
112 102.4454454779625 -6.96052527538595
113 63.4541771709919 -6.7639423596630746
114 94.04112911224365 -6.659491729217256
115 59.525832176208496 -6.2862158147592675
116 70.69899386167526 -6.220257269860126
117 75.43556810170412 -6.18209059363143
118 93.26511061191559 -5.914637632847621
119 134.04545739293098 -3.916865221951316
train accuracy: 1.0
validation accuracy: 1.0
[-78.76408281 -77.46472656 -77.18932328 -76.74724629 -76.24255247
 -76.18485557 -76.07624252 -75.02388249 -74.54269389 -73.74571992
 -73.69271153 -73.56431969 -73.40639184 -73.32144136 -72.93401148
 -72.70889393 -72.68194171 -70.16337967 -70.000609   -69.21666769
 -68.89798973 -61.6564126  -60.88783773 -60.72338817 -60.37812138
 -19.79334113 -19.25700364 -18.74347798 -18.43627902 -18.30163247
 -18.02977337 -17.61877338 -17.54207172 -17.16137033 -17.00602727
 -17.00420108 -16.12064234 -15.9537681  -15.85383724 -15.08471829
 -15.06789919 -14.57298671 -14.43775742 -14.33284955 -14.19898765
 -14.19011283 -14.1721181  -14.07873481 -13.81903984 -13.59071202
 -13.53296392 -13.48685067 -13.41775596 -13.28244642 -13.23572075
 -13.17741334 -13.13113317 -13.08334468 -13.02172812 -12.82980957
 -12.76848398 -12.7448116  -12.64256502 -12.27215991 -11.99279085
 -11.34671155 -11.21787457 -11.05895837 -11.05375118 -10.83245358
 -10.57724732 -10.54270898 -10.53041363 -10.39212581 -10.22123152
 -10.20817069  -9.89835248  -9.66841492  -9.46249277  -9.45494382
  -9.40614996  -9.33584201  -9.28587085  -9.243075    -9.21467878
  -8.96336676  -8.90846823  -8.87443153  -8.79032718  -8.66151025
  -8.48953997  -8.4785276   -8.32497744  -7.97418041  -7.96828822
  -7.94625628  -7.84832264  -7.73530245  -7.69917784  -7.68296763
  -7.60446834  -7.30449076  -7.08890986  -7.08774711  -6.99889967
  -6.99562914  -6.87652685  -6.76394236  -6.65949173  -6.43142794
  -6.29382439  -6.22025727  -6.18209059  -5.48262678  -5.24637319
  -5.14770296  -4.92341078  -4.74263846  -4.55579752  -3.28060724]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:3
end of epoch 0: val_loss 0.0007274227596538907, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 5.6246e-02,  1.5860e-02, -5.3845e-04,  5.1764e-02, -1.5600e-05,
          1.2377e-04, -1.5997e-04, -2.9358e-03, -1.7428e-01,  1.4768e-01,
         -1.4320e-03, -4.6781e-01, -1.8178e-01]], device='cuda:3'))])
end of epoch 1: val_loss 0.007283269241258345, val_acc 0.995
trigger times: 1
end of epoch 2: val_loss 6.675697019176141e-08, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-4.8813e-06,  7.1478e-01,  1.9352e-01,  1.7654e-01,  1.5790e-01,
          6.0578e-05, -3.4671e-02, -3.3737e-01, -5.6466e-01,  2.3706e-01,
         -1.4320e-03, -2.4984e+00, -1.4835e+00]], device='cuda:3'))])
end of epoch 3: val_loss 0.0006624291280737893, val_acc 1.0
trigger times: 1
end of epoch 4: val_loss 0.004379248249254992, val_acc 0.995
trigger times: 2
end of epoch 5: val_loss 0.27858067732992686, val_acc 0.97
trigger times: 3
end of epoch 6: val_loss 0.017313701101228922, val_acc 0.995
trigger times: 4
end of epoch 7: val_loss 4.4463596829302785e-07, val_acc 1.0
trigger times: 5
end of epoch 8: val_loss 5.197254722588695e-07, val_acc 1.0
trigger times: 6
end of epoch 9: val_loss 3.679889994145924e-06, val_acc 1.0
trigger times: 7
end of epoch 10: val_loss 2.3245781335390347e-08, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.2219e-01,  2.1319e-01,  2.3259e-01,  1.8767e-01,  1.6522e-02,
         -4.6963e-01, -1.3032e-03, -1.7588e-01, -3.5398e-01,  4.5839e-01,
         -1.4320e-03, -2.0939e+00, -1.5763e+00]], device='cuda:3'))])
end of epoch 11: val_loss 0.003628171216628715, val_acc 1.0
trigger times: 1
end of epoch 12: val_loss 0.00012039507271762062, val_acc 1.0
trigger times: 2
end of epoch 13: val_loss 3.1907232141747953e-06, val_acc 1.0
trigger times: 3
end of epoch 14: val_loss 1.5113853714526977, val_acc 0.965
trigger times: 4
end of epoch 15: val_loss 2.384185471271394e-09, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.7301e-01,  7.6672e-01,  3.8378e-01,  9.9119e-02,  3.0798e-05,
         -3.8040e-01, -2.5928e-02, -4.2947e-01, -6.1477e-01,  1.0001e+00,
         -1.4322e-03, -3.3757e+00, -2.2036e+00]], device='cuda:3'))])
end of epoch 16: val_loss 5.053721884451079e-05, val_acc 1.0
trigger times: 1
end of epoch 17: val_loss 0.00033927890188344633, val_acc 1.0
trigger times: 2
end of epoch 18: val_loss 5.954269135344248e-07, val_acc 1.0
trigger times: 3
end of epoch 19: val_loss 1.1687410004057597e-06, val_acc 1.0
trigger times: 4
end of epoch 20: val_loss 0.045237351768646475, val_acc 0.99
trigger times: 5
end of epoch 21: val_loss 0.04810663439740864, val_acc 0.99
trigger times: 6
end of epoch 22: val_loss 1.8630442209541798e-05, val_acc 1.0
trigger times: 7
end of epoch 23: val_loss 0.004984370999636667, val_acc 0.995
trigger times: 8
end of epoch 24: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.1952e-01,  4.2542e-01,  2.9470e-01,  2.5670e-01,  3.3497e-05,
         -5.1975e-02,  1.6927e-02, -1.5735e-01, -2.8018e-01,  3.7102e-01,
         -1.4325e-03, -2.8732e+00, -2.2684e+00]], device='cuda:3'))])
end of epoch 25: val_loss 0.0001672793168624409, val_acc 1.0
trigger times: 1
end of epoch 26: val_loss 1.7300279989740376e-06, val_acc 1.0
trigger times: 2
end of epoch 27: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.7639e-02,  6.5420e-01,  2.7133e-01,  1.8611e-01,  3.6956e-05,
         -1.8828e-01, -6.9508e-03, -2.9799e-01, -6.8501e-01,  6.1952e-01,
         -1.4326e-03, -3.4150e+00, -2.6043e+00]], device='cuda:3'))])
end of epoch 28: val_loss 0.014970914947667745, val_acc 0.995
trigger times: 1
end of epoch 29: val_loss 1.0806257632474114e-05, val_acc 1.0
trigger times: 2
end of epoch 30: val_loss 0.00012202346151777732, val_acc 1.0
trigger times: 3
end of epoch 31: val_loss 0.9658931759405257, val_acc 0.925
trigger times: 4
end of epoch 32: val_loss 0.0037345938916403653, val_acc 0.995
trigger times: 5
end of epoch 33: val_loss 6.65585782312661e-05, val_acc 1.0
trigger times: 6
end of epoch 34: val_loss 1.9327179187591526e-05, val_acc 1.0
trigger times: 7
end of epoch 35: val_loss 4.947169244928773e-08, val_acc 1.0
trigger times: 8
end of epoch 36: val_loss 3.787089262907273e-05, val_acc 1.0
trigger times: 9
end of epoch 37: val_loss 0.0047490648836490835, val_acc 0.995
trigger times: 10
Early stopping.
0 -406.3897306919098 -78.76408280532729
1 -379.5237809419632 -77.46472656220253
2 -385.3943839073181 -77.18932327512927
3 -385.68430256843567 -76.74724629158203
4 -421.3598784208298 -76.24255246798964
5 -369.00900769233704 -76.1848555669152
6 -458.0115737915039 -76.0762425167399
7 -449.11343681812286 -75.0238824868006
8 -379.07636404037476 -74.54269389350043
9 -415.59351205825806 -73.74571992034893
10 -366.94969844818115 -73.69271152583889
11 -46.68416976928711 -73.56431969207013
12 -36.22395586967468 -73.40639184113184
13 -384.7607350349426 -73.32144135704175
14 -373.4335823059082 -72.93401148446968
15 -343.47918021678925 -72.70889393200369
16 -43.90324592590332 -72.68194170578586
17 -26.136141180992126 -70.16337966986907
18 -17.51534068584442 -70.00060899533194
19 -26.687999486923218 -69.21666769169597
20 -25.490299463272095 -68.89798972795377
21 -349.04296040534973 -61.65641260048595
22 -347.7062895298004 -60.8878377268014
23 -343.9256339073181 -60.72338817308264
24 -352.4418635368347 -60.37812138002903
25 -28.97105446457863 -19.79334112573677
26 -21.14422431588173 -19.257003642644204
27 -21.084712870419025 -18.74347798331982
28 -29.930355712771416 -18.436279021155336
29 -21.890006959438324 -18.301632468121728
30 -18.533044785261154 -18.0297733699979
31 -16.639970883727074 -17.618773379590163
32 -22.844708040356636 -17.542071717965907
33 -17.15636546909809 -17.161370327775582
34 -20.92464918270707 -17.006027269653373
35 -18.19305969774723 -17.00420108034535
36 -10.420741960406303 -16.120642341911868
37 -13.459195703268051 -15.953768097271652
38 -14.95207092911005 -15.853837241018153
39 -5.3430396765470505 -15.084718288938372
40 -6.7668212205171585 -15.067899192691872
41 -9.187841929495335 -14.572986706147592
42 -22.140597581863403 -14.437757420363038
43 -6.552541736513376 -14.332849550440162
44 -3.169406294822693 -14.198987645115075
45 -34.25249171257019 -14.190112827586777
46 -2.1736337915062904 -14.172118097067315
47 -4.053928144276142 -14.078734811863981
48 -22.87160873413086 -13.819039837530202
49 -22.89880633354187 -13.590712024814795
50 -4.723938003182411 -13.532963919835161
51 -3.067152202129364 -13.486850665593792
52 -32.98530203104019 -13.417755956610373
53 -1.097041878849268 -13.282446418634482
54 -3.3568311780691147 -13.235720748817414
55 -5.043005079030991 -13.17741333688593
56 -16.799163460731506 -13.13113317215055
57 0.41673921048641205 -13.083344683033713
58 -0.6019529774785042 -13.021728123435354
59 2.9710031151771545 -12.829809568364816
60 4.7224747240543365 -12.768483977935247
61 -24.656639337539673 -12.744811603880509
62 -0.596272200345993 -12.64256502021252
63 6.322060763835907 -12.272159910080829
64 -23.693435192108154 -11.992790852336395
65 9.418887168169022 -11.346711551518009
66 -9.853630363941193 -11.21787456515775
67 6.32344713807106 -11.058958369700678
68 4.312771804630756 -11.053751182675533
69 2.6337780952453613 -10.832453584420993
70 10.994347624480724 -10.57724731517047
71 -11.787133157253265 -10.54270897678891
72 16.59954810142517 -10.530413627819081
73 9.956589102745056 -10.392125810424734
74 -1.0252586007118225 -10.221231519720886
75 3.810112476348877 -10.20817069321172
76 7.068253934383392 -9.898352480956024
77 16.687214821577072 -9.668414924825717
78 11.151625961065292 -9.462492766873485
79 13.940029010176659 -9.454943823107167
80 17.51056796312332 -9.406149956760274
81 -9.782066971063614 -9.33584201264156
82 8.2322588711977 -9.285870845705936
83 13.193607792258263 -9.24307499734176
84 -3.8920966386795044 -9.214678781535703
85 9.578969322144985 -8.963366764062346
86 24.0000701546669 -8.908468233381466
87 14.779189549386501 -8.874431530343422
88 7.411385715007782 -8.790327180294941
89 3.318308264017105 -8.661510245435492
90 17.768209278583527 -8.489539968923486
91 21.995539247989655 -8.478527598591981
92 11.747562527656555 -8.324977442124407
93 20.098235562443733 -7.974180405158328
94 20.267026484012604 -7.968288218466813
95 12.178970739245415 -7.946256281478245
96 18.611138381063938 -7.848322642074705
97 17.44972652196884 -7.735302450476708
98 14.946061581373215 -7.699177836325561
99 20.983675867319107 -7.682967633341143
100 22.436613768339157 -7.604468337148936
101 19.836381405591965 -7.304490755086312
102 21.928176380693913 -7.088909863647382
103 20.502476811408997 -7.087747111559815
104 -5.787861630320549 -6.99889967022435
105 4.870667986571789 -6.995629136287063
106 18.37667527794838 -6.876526852804886
107 25.352291852235794 -6.7639423596630746
108 6.9363419860601425 -6.659491729217256
109 24.119522213935852 -6.431427943465945
110 26.52004212141037 -6.293824385399592
111 3.0706832855939865 -6.220257269860126
112 17.7124063372612 -6.18209059363143
113 33.3158078417182 -5.482626781192597
114 32.016261115670204 -5.246373193979391
115 28.166929602622986 -5.14770295846802
116 32.58340872824192 -4.923410778134453
117 29.10289604961872 -4.742638462602822
118 36.62548691034317 -4.555797520532631
119 39.560550689697266 -3.2806072371510973
train accuracy: 1.0
validation accuracy: 0.995
[-77.46472656 -76.18485557 -76.07624252 -74.54269389 -73.74571992
 -73.56431969 -73.40639184 -73.32144136 -72.93401148 -72.68194171
 -70.16337967 -60.88783773 -60.37812138 -19.25700364 -18.74347798
 -18.43627902 -18.30163247 -18.02977337 -17.66906451 -17.50873913
 -16.21116831 -15.66376153 -15.06789919 -14.57298671 -14.36600388
 -14.33284955 -14.19898765 -14.1721181  -13.98941117 -13.91691393
 -13.81903984 -13.53296392 -13.48685067 -13.41775596 -13.22816142
 -13.17741334 -13.13113317 -13.08334468 -12.95744603 -12.7448116
 -12.6652999  -12.64256502 -12.49231778 -12.36692641 -12.21926309
 -12.11029796 -12.08687671 -11.64621098 -11.35573206 -11.31096144
 -11.24112498 -11.23464443 -10.96804372 -10.95827354 -10.89535508
 -10.83245358 -10.78793156 -10.74130524 -10.70115017 -10.69533947
 -10.37251906 -10.30367093 -10.20817069  -9.89835248  -9.8089675
  -9.76775973  -9.56681477  -9.46249277  -9.45494382  -9.243075
  -9.08897605  -8.96634804  -8.90846823  -8.87443153  -8.79978149
  -8.79032718  -8.51769707  -8.48953997  -8.4785276   -8.24870488
  -8.13849954  -8.081595    -7.97418041  -7.94625628  -7.86498895
  -7.79717701  -7.73530245  -7.69917784  -7.33277235  -7.30449076
  -7.27846773  -7.21162954  -7.08774711  -6.99889967  -6.99562914
  -6.39617423  -6.36629827  -6.29382439  -6.22025727  -6.18209059
  -6.15886286  -6.07596952  -5.75707029  -5.72560868  -5.70592463
  -5.60175711  -5.59126754  -5.48262678  -5.46214499  -5.24637319
  -5.14770296  -5.07842228  -5.07461283  -4.92341078  -4.74263846
  -3.99782757  -3.90710287  -3.28060724  -2.64914192  -2.53027839]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:1
end of epoch 0: val_loss 0.011567552436972156, val_acc 0.99
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.7625e-01,  6.8871e-01,  2.1533e-01, -2.0280e-02,  1.8786e-01,
         -1.9399e-02, -3.6272e-02, -2.7597e-01, -5.6542e-01,  1.2044e-01,
         -1.4320e-03, -1.8493e+00, -1.1526e+00]], device='cuda:1'))])
end of epoch 1: val_loss 1.0698521337815237e-06, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.5516e-01,  6.0804e-01,  2.0958e-01,  2.3878e-01, -1.3967e-06,
         -2.3358e-06, -3.8766e-02, -3.6990e-01, -4.8631e-01,  6.3077e-02,
         -1.4320e-03, -2.4320e+00, -1.4879e+00]], device='cuda:1'))])
end of epoch 2: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.3087e-01,  1.1471e+00,  2.3646e-01,  3.4660e-01,  8.8765e-06,
         -1.4748e-01, -3.6568e-03, -5.4936e-01, -4.3617e-01,  1.0775e-01,
         -1.4320e-03, -4.2550e+00, -2.5362e+00]], device='cuda:1'))])
end of epoch 3: val_loss 1.1920927533992654e-09, val_acc 1.0
trigger times: 1
end of epoch 4: val_loss 4.580189233678312e-06, val_acc 1.0
trigger times: 2
end of epoch 5: val_loss 1.1682458293194032e-07, val_acc 1.0
trigger times: 3
end of epoch 6: val_loss 7.554069150028653e-05, val_acc 1.0
trigger times: 4
end of epoch 7: val_loss 2.2475429722845773e-06, val_acc 1.0
trigger times: 5
end of epoch 8: val_loss 2.384185506798531e-09, val_acc 1.0
trigger times: 6
end of epoch 9: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 7
end of epoch 10: val_loss 0.01851566969442782, val_acc 0.995
trigger times: 8
end of epoch 11: val_loss 1.904163300245496, val_acc 0.885
trigger times: 9
end of epoch 12: val_loss 3.5762780470349754e-09, val_acc 1.0
trigger times: 10
Early stopping.
0 -93.42553627490997 -77.46472656220253
1 -88.54905426502228 -76.1848555669152
2 -161.03112691640854 -76.0762425167399
3 -105.98764735460281 -74.54269389350043
4 -124.76884478330612 -73.74571992034893
5 -192.01671063899994 -73.56431969207013
6 -173.8721045255661 -73.40639184113184
7 -104.58546483516693 -73.32144135704175
8 -89.65833216905594 -72.93401148446968
9 -183.70809519290924 -72.68194170578586
10 -160.1797878742218 -70.16337966986907
11 -88.52620857954025 -60.8878377268014
12 -78.82540893554688 -60.37812138002903
13 -29.320979721844196 -19.257003642644204
14 -30.94858779013157 -18.74347798331982
15 -36.373317055404186 -18.436279021155336
16 -27.106060586869717 -18.301632468121728
17 -25.66162510588765 -18.0297733699979
18 -26.25019420310855 -17.669064509425194
19 -23.7812477722764 -17.508739128560165
20 -19.459934912621975 -16.21116831178735
21 -24.910835031419992 -15.663761529672561
22 -17.492310989648104 -15.067899192691872
23 -17.042323917150497 -14.572986706147592
24 -14.396027609705925 -14.36600388150955
25 -13.965889357030392 -14.332849550440162
26 -8.83961308002472 -14.198987645115075
27 -11.896376453340054 -14.172118097067315
28 -8.011596631258726 -13.989411169975746
29 -6.218135271221399 -13.916913927362822
30 -25.387290716171265 -13.819039837530202
31 -10.645428143441677 -13.532963919835161
32 -8.778431599959731 -13.486850665593792
33 -34.90052178502083 -13.417755956610373
34 -12.050898559391499 -13.22816141568135
35 -15.166324645280838 -13.17741333688593
36 -28.73414695262909 -13.13113317215055
37 -9.532983586192131 -13.083344683033713
38 -1.7009577304124832 -12.957446033838883
39 -26.513306379318237 -12.744811603880509
40 -4.853524163365364 -12.665299896665791
41 -9.273757830262184 -12.64256502021252
42 -4.942743580788374 -12.492317779981084
43 -1.2301909364759922 -12.366926405814961
44 -3.2467302568256855 -12.219263092075002
45 -6.395877975970507 -12.11029796129969
46 -5.840996287763119 -12.086876712968603
47 -8.518218275159597 -11.646210984741181
48 -1.9960176795721054 -11.355732058924012
49 0.8477247394621372 -11.310961436719035
50 2.3113321140408516 -11.24112497891954
51 0.7843026593327522 -11.234644431682344
52 -4.390261135995388 -10.968043720247685
53 -1.7997617274522781 -10.958273540359581
54 -2.5507326126098633 -10.895355081672767
55 -3.21169376373291 -10.832453584420993
56 4.742361769080162 -10.787931564119216
57 0.9950678497552872 -10.741305243145407
58 10.902245353907347 -10.701150172166436
59 -0.003444395959377289 -10.69533946537654
60 0.7486347109079361 -10.372519056072141
61 12.328279599547386 -10.303670932253828
62 -7.456927742809057 -10.20817069321172
63 -3.436465561389923 -9.898352480956024
64 1.6504418700933456 -9.808967500999604
65 0.594391169026494 -9.767759727416266
66 1.6758994609117508 -9.566814771754526
67 -0.40181148052215576 -9.462492766873485
68 4.887435778975487 -9.454943823107167
69 2.3023948669433594 -9.24307499734176
70 11.104206331074238 -9.088976046912355
71 13.695327252149582 -8.966348037534537
72 13.769976735115051 -8.908468233381466
73 5.8905645832419395 -8.874431530343422
74 7.3368251621723175 -8.799781490993245
75 0.9241150617599487 -8.790327180294941
76 16.959854446351528 -8.517697066848108
77 10.63099855184555 -8.489539968923486
78 13.470130562782288 -8.478527598591981
79 9.443202055990696 -8.24870488442067
80 16.154117666184902 -8.13849954360235
81 16.412407636642456 -8.081594999624762
82 13.664344556629658 -7.974180405158328
83 3.7068154215812683 -7.946256281478245
84 13.648920804262161 -7.864988947204226
85 18.304593116044998 -7.797177011869974
86 6.340226527303457 -7.735302450476708
87 19.108425058424473 -7.699177836325561
88 17.713284850120544 -7.332772346246218
89 12.153656505048275 -7.304490755086312
90 13.067146830260754 -7.2784677331318814
91 20.21142965555191 -7.211629537527341
92 8.41263610124588 -7.087747111559815
93 -1.9104827046394348 -6.99889967022435
94 0.22581034898757935 -6.995629136287063
95 10.103910855948925 -6.396174225159866
96 12.423597753047943 -6.366298265799662
97 16.451470479369164 -6.293824385399592
98 -1.3367193974554539 -6.220257269860126
99 11.456924974918365 -6.18209059363143
100 28.424036651849747 -6.158862863008094
101 25.368223160505295 -6.075969518750416
102 23.577406011521816 -5.757070285001149
103 25.586656898260117 -5.725608683423558
104 10.729193389415741 -5.705924629773825
105 25.4616556763649 -5.601757109347627
106 18.213049948215485 -5.591267540382466
107 23.191246688365936 -5.482626781192597
108 28.997360944747925 -5.462144986299337
109 20.9038301743567 -5.246373193979391
110 18.197524704039097 -5.14770295846802
111 28.977510929107666 -5.078422278002651
112 28.25960871577263 -5.074612829383829
113 22.46328879892826 -4.923410778134453
114 18.91153958439827 -4.742638462602822
115 34.83243536949158 -3.9978275728123402
116 35.08459457010031 -3.907102872937271
117 31.242149084806442 -3.2806072371510973
118 32.02104288339615 -2.649141920271377
119 31.79376707971096 -2.5302783886718787
train accuracy: 1.0
validation accuracy: 1.0
