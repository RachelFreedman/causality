[-54.98547503 -50.4922686  -50.03933802 -49.75347185 -49.72654641
 -46.98011874 -45.73515428 -45.67057988 -44.99030608 -44.14602409
 -43.81326882 -43.18878399 -42.29180715 -42.00401746 -41.69100444
 -41.68588229 -41.2817771  -40.44278203 -40.34838366 -39.59970115
 -39.57586365 -39.31972693 -39.02461056 -38.45534494 -38.4127039
 -38.35634328 -37.79713617 -37.74152899 -37.66475324 -37.51313938
 -37.1809993  -37.10070314 -37.00630589 -36.82191677 -36.48799015
 -36.2096527  -36.19207562 -36.11445903 -35.78149902 -35.39450387
 -35.262825   -35.24303541 -35.20970524 -35.06544085 -34.80241748
 -34.64469045 -33.84284986 -32.70706485 -31.9690994  -31.7109134
 -31.64414356 -31.39238276 -31.22319602 -31.12953085 -29.3915714
 -29.34012561 -29.10618999 -27.4110235  -27.34372236 -27.19668163
 -27.07399029 -26.70472176 -26.2447949  -25.54836509 -25.45878529
 -24.879107   -24.82869536 -24.59274514 -23.97874558 -23.57262108
 -23.44970808 -22.74530916 -22.60679894 -22.19891032 -20.65686376
 -20.44447256 -20.1969901  -20.13839115 -19.63760344 -19.51559872
 -18.9283881  -17.99477406 -17.5574237  -16.82307393 -14.8550828
 -14.5314246  -14.44242009 -13.59601285 -12.68135973 -12.66418206
 -12.30017947 -12.15190477 -11.78885214 -10.8699891  -10.3276815
  -9.85721598  -8.330117    -8.13319584  -8.10819769  -7.57539849
  -7.36244313  -7.10832736  -6.95906356  -6.77694649  -6.72206384
  -6.71997062  -6.53544734  -6.51820418  -5.61579673  -5.3472021
  -5.07848501  -5.02795798  -4.82757292  -4.63049542  -4.230832
  -4.03104862  -3.38446715  -3.3322555   -2.64166233  -1.91361965]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Could not find existing model weights. Training from scratch...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:1
end of epoch 0: val_loss 1.485391225770627e-05, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.3933e-08,  2.3951e-02,  7.3328e-02, -2.0048e-06, -5.6122e-06,
         -1.6519e-04, -7.3494e-04, -2.8699e-06,  5.4908e-05,  6.7828e-06,
         -2.3655e-03, -2.5001e-01, -5.3214e-01]], device='cuda:1'))])
end of epoch 1: val_loss 0.0004558915230305161, val_acc 1.0
trigger times: 1
end of epoch 2: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 5.0744e-02,  1.6581e-01,  3.6617e-02, -4.5260e-02, -1.6779e-05,
         -1.5639e-02,  2.2383e-07,  7.3669e-07, -1.5481e-04, -2.9418e-05,
         -2.5089e-03, -2.8572e-01, -1.4107e+00]], device='cuda:1'))])
end of epoch 3: val_loss 6.5565099660602754e-09, val_acc 1.0
trigger times: 1
end of epoch 4: val_loss 0.08008709829393496, val_acc 0.99
trigger times: 2
end of epoch 5: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-5.7386e-02,  2.7315e-02,  1.2264e-01, -6.6314e-06,  6.6077e-02,
          5.3750e-07,  1.3739e-02, -2.7585e-06,  1.5770e-04,  1.4990e-04,
          1.5752e-03, -7.3283e-01, -1.6812e+00]], device='cuda:1'))])
end of epoch 6: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 6.7553e-06, -2.3462e-06, -1.3315e-05, -4.2806e-05, -1.7315e-04,
          1.5520e-04, -2.1644e-06, -6.1703e-06,  3.7667e-04,  8.5894e-05,
         -1.2028e-03,  2.0378e-06, -1.3624e+00]], device='cuda:1'))])
end of epoch 7: val_loss 1.7453582216298004e-05, val_acc 1.0
trigger times: 1
end of epoch 8: val_loss 1.013277938000101e-08, val_acc 1.0
trigger times: 2
end of epoch 9: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 3
end of epoch 10: val_loss 2.4038126406722425e-06, val_acc 1.0
trigger times: 4
end of epoch 11: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-7.3850e-06,  4.9292e-02,  1.1863e-01, -2.8288e-01,  1.0494e-04,
         -1.6852e-01,  5.4318e-07,  4.3023e-02,  1.6175e-04, -3.0278e-05,
         -2.3633e-03, -6.9090e-01, -1.4263e+00]], device='cuda:1'))])
end of epoch 12: val_loss 3.516669121239602e-08, val_acc 1.0
trigger times: 1
end of epoch 13: val_loss 3.5349004811344935, val_acc 0.71
trigger times: 2
end of epoch 14: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-7.4687e-03,  4.2008e-01,  1.6907e-01, -2.6917e-01, -9.4448e-05,
          3.1385e-05, -2.2777e-02,  2.6094e-02, -1.1739e-05, -1.0203e-01,
          9.7824e-06, -1.1105e+00, -2.0897e+00]], device='cuda:1'))])
end of epoch 15: val_loss 1.1920927533992654e-09, val_acc 1.0
trigger times: 1
end of epoch 16: val_loss 3.5762784023063432e-09, val_acc 1.0
trigger times: 2
end of epoch 17: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.3569e-01, -9.2607e-02,  5.5456e-02, -1.6754e-01,  2.9089e-01,
         -1.3447e-01, -9.6825e-03,  5.3921e-02, -1.3183e-01, -6.7023e-02,
         -1.2006e-03, -1.6074e+00, -2.0703e+00]], device='cuda:1'))])
end of epoch 18: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.5538e-02, -2.1852e-02,  1.6805e-05, -8.3721e-02, -9.7925e-06,
          2.1210e-05, -2.2831e-02,  3.2126e-02,  9.6743e-05, -1.2258e-04,
          3.5707e-04, -1.1204e+00, -1.9494e+00]], device='cuda:1'))])
end of epoch 19: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.8965e-05,  8.2424e-06,  4.3980e-05, -2.4612e-05, -3.3590e-05,
          2.4860e-05, -7.2484e-03,  3.6770e-06,  4.1276e-05, -3.0398e-04,
         -3.1727e-04, -2.2512e-05, -1.6262e+00]], device='cuda:1'))])
end of epoch 20: val_loss 3.910050129363185e-07, val_acc 1.0
trigger times: 1
end of epoch 21: val_loss 1.1920927533992654e-09, val_acc 1.0
trigger times: 2
end of epoch 22: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-4.7064e-05, -3.0025e-05,  2.9024e-01, -1.1860e-01,  3.3087e-05,
         -3.4935e-05, -2.1098e-02,  2.7051e-02, -5.7964e-05,  1.2177e-05,
         -2.3611e-03, -6.7159e-01, -1.9731e+00]], device='cuda:1'))])
end of epoch 23: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.1107e-04, -6.5305e-05,  3.7627e-02, -1.7763e-05,  7.1343e-05,
         -1.0382e-04, -1.5648e-03,  1.5013e-05, -1.2026e-04,  4.0384e-05,
          3.8004e-03,  3.9267e-05, -1.5347e+00]], device='cuda:1'))])
end of epoch 24: val_loss 0.00016028102797950084, val_acc 1.0
trigger times: 1
end of epoch 25: val_loss 1.681893365457654e-05, val_acc 1.0
trigger times: 2
end of epoch 26: val_loss 8.904142304899665e-07, val_acc 1.0
trigger times: 3
end of epoch 27: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 4
end of epoch 28: val_loss 2.5331607047007765e-06, val_acc 1.0
trigger times: 5
end of epoch 29: val_loss 1.9713553319533616e-06, val_acc 1.0
trigger times: 6
end of epoch 30: val_loss 7.212155818336896e-08, val_acc 1.0
trigger times: 7
end of epoch 31: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-3.9362e-02,  2.1889e-01,  1.8524e-01, -7.5711e-02,  2.5531e-01,
         -3.9593e-01,  1.5483e-02,  2.0517e-02, -7.8650e-07,  1.1115e-01,
         -5.1686e-04, -1.4584e+00, -2.2448e+00]], device='cuda:1'))])
end of epoch 32: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.6040e-05,  1.2156e-01,  7.7089e-02,  1.0424e-05,  2.8691e-05,
         -2.2569e-02,  8.4556e-03,  4.9838e-04, -3.3858e-05, -2.0011e-05,
          8.1852e-04, -6.7063e-01, -2.0809e+00]], device='cuda:1'))])
end of epoch 33: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.3431e-06, -2.0303e-05, -1.8599e-05,  2.4496e-05,  1.5024e-04,
          5.6757e-05,  1.3534e-06,  2.6578e-06,  4.8496e-05, -9.9642e-05,
         -2.3589e-03,  5.9167e-04, -1.6778e+00]], device='cuda:1'))])
end of epoch 34: val_loss 3.396191794600156e-06, val_acc 1.0
trigger times: 1
end of epoch 35: val_loss 7.676500473507985e-07, val_acc 1.0
trigger times: 2
end of epoch 36: val_loss 6.556509610788907e-09, val_acc 1.0
trigger times: 3
end of epoch 37: val_loss 6.276570529507808e-05, val_acc 1.0
trigger times: 4
end of epoch 38: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 5.8069e-02,  1.5591e-01,  1.5172e-01,  1.0960e-02,  1.4638e-01,
         -7.3539e-02, -9.3518e-03,  7.7220e-02, -4.1523e-06,  2.2893e-05,
          1.5818e-03, -1.7325e+00, -2.5952e+00]], device='cuda:1'))])
end of epoch 39: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-3.5267e-05,  4.0627e-02,  3.1346e-02,  6.2931e-06,  4.9256e-05,
          6.8814e-05, -2.2983e-03,  5.0277e-02, -2.1278e-05,  5.1857e-05,
         -1.1962e-03, -9.6800e-01, -2.3661e+00]], device='cuda:1'))])
end of epoch 40: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-9.2472e-05, -2.3563e-05,  3.7530e-05, -3.0328e-05, -2.2064e-04,
          6.4679e-05,  4.7039e-06, -4.9347e-06, -6.3028e-05, -2.6588e-04,
          3.6147e-04,  3.3734e-04, -1.8027e+00]], device='cuda:1'))])
end of epoch 41: val_loss 0.0003262604124827817, val_acc 1.0
trigger times: 1
end of epoch 42: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.4194e-03,  1.2936e-01,  4.6961e-02, -3.0002e-01, -8.9366e-05,
         -5.6084e-02,  4.1870e-03,  3.4821e-02, -1.9486e-05, -5.7228e-05,
         -5.1466e-04, -1.0838e+00, -2.0042e+00]], device='cuda:1'))])
end of epoch 43: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.0979e-05,  2.1421e-05,  2.6171e-05, -1.2426e-01, -2.2901e-04,
          8.1569e-05,  2.3955e-07,  5.7283e-04, -5.5060e-05, -1.1451e-04,
          8.2072e-04, -1.5172e-04, -1.7161e+00]], device='cuda:1'))])
end of epoch 44: val_loss 3.039835707596694e-08, val_acc 1.0
trigger times: 1
end of epoch 45: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 2
end of epoch 46: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-6.9393e-02, -5.5032e-02,  1.3498e-01, -1.6140e-01, -9.5902e-05,
          1.5356e-01, -1.7481e-02, -1.1375e-02,  5.5796e-05, -8.8412e-02,
         -2.5001e-03, -1.2816e+00, -2.3333e+00]], device='cuda:1'))])
end of epoch 47: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.0273e-04, -2.6519e-05, -2.9995e-05, -3.6197e-05,  3.9324e-05,
         -1.1629e-04, -6.0215e-04, -1.2991e-05, -2.9201e-04,  6.6508e-06,
          1.6383e-05,  9.6751e-05, -1.9593e+00]], device='cuda:1'))])
end of epoch 48: val_loss 1.847743508420763e-08, val_acc 1.0
trigger times: 1
end of epoch 49: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.5786e-02,  2.1370e-01,  1.9537e-01, -1.3068e-01,  8.7170e-02,
         -3.1067e-01,  1.3930e-03,  4.6698e-02, -1.7768e-05, -3.3340e-05,
          1.5840e-03, -1.2570e+00, -2.0635e+00]], device='cuda:1'))])
end of epoch 50: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.0046e-05,  6.9100e-02,  5.4130e-02, -1.5821e-02, -1.9363e-05,
          5.1893e-05, -4.5947e-07,  1.3662e-02, -5.1984e-05, -1.0777e-04,
         -1.1940e-03, -2.3222e-01, -1.8224e+00]], device='cuda:1'))])
end of epoch 51: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 1
end of epoch 52: val_loss 3.5762775496550603e-09, val_acc 1.0
trigger times: 2
end of epoch 53: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 6.7878e-02,  1.6373e-02,  1.3011e-01, -1.4158e-01, -4.8968e-05,
         -4.5826e-05, -1.5220e-03,  9.3728e-07,  1.3934e-04,  3.6938e-05,
         -5.1246e-04, -8.4461e-01, -1.8844e+00]], device='cuda:1'))])
end of epoch 54: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 9.5989e-05, -3.3708e-05, -3.8575e-05, -3.1606e-05,  1.2128e-04,
         -1.0191e-04, -1.3352e-06,  2.4510e-06,  3.7782e-04, -1.4460e-04,
          8.2292e-04,  7.3882e-05, -1.5084e+00]], device='cuda:1'))])
end of epoch 55: val_loss 1.6336188156920174e-05, val_acc 1.0
trigger times: 1
end of epoch 56: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.5612e-01,  4.4214e-01,  1.9090e-01, -2.1323e-02,  3.2495e-01,
         -2.5525e-01, -7.2232e-03,  5.2272e-02, -1.7003e-02, -4.1378e-05,
          3.8070e-03, -1.8393e+00, -2.6536e+00]], device='cuda:1'))])
end of epoch 57: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.9850e-02,  2.8921e-01,  5.0978e-02,  3.0125e-06, -2.6602e-05,
         -4.3752e-05,  1.3262e-06,  3.1190e-02,  5.0042e-05, -1.0942e-04,
         -2.4979e-03, -1.0409e+00, -2.4590e+00]], device='cuda:1'))])
end of epoch 58: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-7.8449e-05,  3.8015e-05, -3.5383e-05,  6.9424e-06, -7.5628e-05,
         -1.1025e-04, -2.6617e-06,  2.1694e-05,  1.2180e-04, -2.7414e-04,
          1.8583e-05, -3.5006e-06, -1.9804e+00]], device='cuda:1'))])
end of epoch 59: val_loss 5.829303763604799e-07, val_acc 1.0
trigger times: 1
end of epoch 60: val_loss 1.013277938000101e-08, val_acc 1.0
trigger times: 2
end of epoch 61: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-9.7146e-06,  1.5326e-02,  2.8244e-01, -2.3652e-01,  3.2350e-05,
         -1.2092e-04,  4.2059e-03,  7.9013e-02, -1.4828e-04,  7.3644e-05,
         -1.1918e-03, -8.2128e-01, -2.0639e+00]], device='cuda:1'))])
end of epoch 62: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.9740e-05,  1.2232e-05, -1.2317e-04, -6.5943e-06,  1.1652e-04,
         -2.9519e-04, -1.5595e-07,  5.4309e-06, -3.9201e-04,  2.0057e-04,
          3.6587e-04,  1.5634e-04, -1.5446e+00]], device='cuda:1'))])
end of epoch 63: val_loss 0.06318557149363144, val_acc 0.99
trigger times: 1
end of epoch 64: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.6711e-05, -3.3220e-06,  3.3104e-01, -1.1332e-01,  3.0383e-01,
         -3.7809e-05, -5.1002e-03,  1.2059e-02, -3.8368e-05, -4.6515e-06,
         -5.1026e-04, -6.1035e-01, -1.6221e+00]], device='cuda:1'))])
end of epoch 65: val_loss 1.7881391656260348e-09, val_acc 1.0
trigger times: 1
end of epoch 66: val_loss 3.597543588604424e-05, val_acc 1.0
trigger times: 2
end of epoch 67: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.7504e-01,  2.7106e-01,  1.1677e-01, -3.5219e-01,  3.5749e-01,
          4.0027e-05,  4.1365e-02,  8.2043e-02, -2.5244e-04, -2.1251e-01,
          3.8092e-03, -1.7739e+00, -2.5129e+00]], device='cuda:1'))])
end of epoch 68: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-8.2794e-03,  1.3707e-01, -5.1138e-06, -2.6241e-01,  4.4389e-05,
          1.4710e-06,  3.3390e-02,  5.7743e-02, -9.9104e-05,  8.1042e-06,
         -2.4957e-03, -1.0589e+00, -2.2869e+00]], device='cuda:1'))])
end of epoch 69: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 1
end of epoch 70: val_loss 0.00028857197950941325, val_acc 1.0
trigger times: 2
end of epoch 71: val_loss 1.668927325226832e-08, val_acc 1.0
trigger times: 3
end of epoch 72: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 4
end of epoch 73: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.2526e-05, -9.9422e-05, -1.8254e-05,  1.0894e-05, -5.3096e-05,
          4.0193e-04,  2.3814e-06,  8.8112e-03,  2.9411e-04, -7.1081e-05,
          3.6807e-04,  1.6588e-04, -1.6917e+00]], device='cuda:1'))])
end of epoch 74: val_loss 0.00019870158299141848, val_acc 1.0
trigger times: 1
end of epoch 75: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 9.7051e-02,  2.8699e-01,  2.6497e-01, -5.9126e-06, -4.7819e-05,
          5.5092e-05, -1.5728e-02, -3.1055e-02,  8.6662e-05, -1.3377e-01,
         -5.0806e-04, -1.2278e+00, -2.1550e+00]], device='cuda:1'))])
end of epoch 76: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.3095e-05,  9.5389e-02,  8.7309e-02, -1.1980e-05,  1.8039e-06,
          1.3464e-04, -3.9231e-03, -6.5118e-06,  2.1078e-04,  1.8871e-04,
          8.2732e-04, -8.7895e-02, -1.8825e+00]], device='cuda:1'))])
end of epoch 77: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 1
end of epoch 78: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-3.7743e-04,  2.3337e-03, -7.8112e-02, -1.9669e-02,  2.4241e-01,
          3.2223e-02,  1.1202e-02,  6.8249e-02,  8.3176e-05, -5.9210e-01,
          3.8114e-03, -1.2702e+00, -1.9842e+00]], device='cuda:1'))])
end of epoch 79: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.6277e-05, -1.0429e-05, -1.4056e-05,  3.7564e-06,  1.0327e-05,
          3.2160e-05,  1.3930e-03,  2.4232e-02,  2.1477e-04, -4.4254e-05,
         -2.4935e-03, -5.2188e-01, -1.7874e+00]], device='cuda:1'))])
end of epoch 80: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-6.0102e-05, -4.3961e-05, -3.2423e-05, -1.8126e-05,  6.0706e-05,
          3.2553e-04,  2.3586e-06, -1.0281e-05,  5.3509e-04, -4.4821e-04,
          2.2984e-05, -2.6499e-04, -1.3031e+00]], device='cuda:1'))])
end of epoch 81: val_loss 4.559547596727498e-07, val_acc 1.0
trigger times: 1
end of epoch 82: val_loss 2.3841852225814363e-09, val_acc 1.0
trigger times: 2
end of epoch 83: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 3
end of epoch 84: val_loss 1.0073173857705342e-07, val_acc 1.0
trigger times: 4
end of epoch 85: val_loss 1.4901138456480112e-08, val_acc 1.0
trigger times: 5
end of epoch 86: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.2574e-05,  2.5442e-01,  2.6962e-01, -2.0575e-01,  9.5851e-05,
         -7.3137e-05,  2.9177e-02,  9.1131e-02,  6.4319e-05,  2.4286e-05,
         -5.0586e-04, -1.1693e+00, -2.4581e+00]], device='cuda:1'))])
end of epoch 87: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-7.9421e-06, -2.2655e-05,  2.6324e-02, -1.8235e-02,  3.2795e-04,
         -2.6147e-04,  1.1466e-02,  5.1046e-02, -3.0986e-05,  1.1432e-04,
          8.2952e-04, -1.1969e-05, -2.0639e+00]], device='cuda:1'))])
end of epoch 88: val_loss 7.1525563782870446e-09, val_acc 1.0
trigger times: 1
end of epoch 89: val_loss 0.030532718041213228, val_acc 0.995
trigger times: 2
end of epoch 90: val_loss 5.215174405748257e-07, val_acc 1.0
trigger times: 3
end of epoch 91: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 4
end of epoch 92: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-4.2118e-05,  1.5088e-04,  1.9348e-05, -3.4573e-05, -9.4618e-04,
          3.1859e-06, -3.6946e-06,  4.3710e-05,  5.1267e-05,  1.6458e-04,
         -4.6618e-06,  5.8673e-05, -1.7282e+00]], device='cuda:1'))])
end of epoch 93: val_loss 0.00023484642594667093, val_acc 1.0
trigger times: 1
end of epoch 94: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.0399e-02,  2.4804e-01,  1.5573e-01, -2.1906e-02,  6.6269e-02,
         -3.2021e-02,  2.4255e-02,  9.4712e-02,  1.7632e-05,  6.2566e-05,
         -1.1852e-03, -1.2582e+00, -2.1869e+00]], device='cuda:1'))])
end of epoch 95: val_loss 4.172324139517514e-09, val_acc 1.0
trigger times: 1
end of epoch 96: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.9879e-05,  3.3627e-05, -7.1141e-05, -5.4062e-05, -2.2815e-05,
          2.1116e-04,  4.7071e-06, -8.6228e-06, -3.4472e-05, -3.8346e-04,
         -3.0186e-04, -1.1126e-04, -1.2612e+00]], device='cuda:1'))])
end of epoch 97: val_loss 4.054632503535771e-05, val_acc 1.0
trigger times: 1
end of epoch 98: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-5.2797e-06,  4.3472e-02,  1.8677e-01, -1.6847e-01, -1.0158e-04,
         -1.4316e-01,  1.0998e-02, -1.2879e-02,  1.1440e-05, -4.9461e-06,
          8.3172e-04, -9.1455e-01, -1.9208e+00]], device='cuda:1'))])
end of epoch 99: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.6335e-05, -8.3769e-06, -1.8325e-06,  1.4897e-06,  3.2846e-05,
         -1.3807e-04,  2.3635e-06,  7.4185e-06, -1.3596e-04, -6.2993e-05,
         -2.3457e-03,  2.3479e-04, -1.5165e+00]], device='cuda:1'))])
Finished training.
0 -64.38146372139454 -54.98547503240923
1 -66.89357435703278 -50.492268601198035
2 -59.92769366502762 -50.03933801517046
3 -61.66294130682945 -49.75347184620696
4 -61.030520260334015 -49.72654640753777
5 -64.8118037879467 -46.98011874490918
6 -61.394774824380875 -45.7351542845057
7 -58.95765345916152 -45.670579884154705
8 -60.713507890701294 -44.99030608142343
9 -57.054116770625114 -44.14602409201361
10 -57.68504664301872 -43.81326882122305
11 -58.436571445316076 -43.18878399086166
12 -59.692764922976494 -42.29180714825394
13 -56.48152784258127 -42.00401746161006
14 -62.38413891196251 -41.6910044370425
15 -57.57753345370293 -41.68588229294918
16 -58.17140930891037 -41.281777102712205
17 -55.7122408747673 -40.44278203413966
18 -57.50900536775589 -40.34838365523108
19 -55.116860300302505 -39.599701153458774
20 -55.16500783711672 -39.57586365327889
21 -52.53359255194664 -39.31972693233231
22 -50.101134687662125 -39.024610555047154
23 -52.64988470077515 -38.45534493538269
24 -52.59317719936371 -38.41270390343083
25 -54.24130855500698 -38.35634328077039
26 -50.92294754087925 -37.79713616772368
27 -48.25316500663757 -37.741528994987384
28 -57.2925728559494 -37.66475323879293
29 -51.937954023480415 -37.513139380385574
30 -57.80044749379158 -37.1809993033689
31 -52.81559357047081 -37.100703136010694
32 -51.68086093664169 -37.00630588930485
33 -53.869610607624054 -36.821916772458344
34 -53.18749335408211 -36.48799015296732
35 -49.87568259239197 -36.20965269874363
36 -51.36282246932387 -36.19207561676116
37 -54.15098676085472 -36.114459029559086
38 -50.66158011555672 -35.78149902167743
39 -47.78855008631945 -35.394503873250635
40 -52.70395378768444 -35.26282499693737
41 -51.08985163271427 -35.24303541418371
42 -53.319557167589664 -35.209705244501436
43 -51.53059795498848 -35.0654408505187
44 -49.62759489938617 -34.80241747531743
45 -49.59778590500355 -34.64469044638467
46 -46.95528405532241 -33.84284985953318
47 -44.54818311333656 -32.70706485357069
48 -44.144055277109146 -31.969099402548657
49 -45.26514285802841 -31.7109134007892
50 -47.39221262931824 -31.64414355845032
51 -46.465940311551094 -31.392382758954444
52 -49.24317529797554 -31.223196019713853
53 -43.84539443254471 -31.12953085092458
54 -45.6218758225441 -29.39157139549552
55 -46.74217876791954 -29.340125609942326
56 -38.03114095330238 -29.106189988903285
57 -42.19362134486437 -27.41102349748205
58 -42.974175579845905 -27.343722362182305
59 -43.5742072686553 -27.196681629483837
60 -41.93499691784382 -27.07399028854534
61 -38.187134981155396 -26.7047217556024
62 -40.923846274614334 -26.244794902859052
63 -41.37176722288132 -25.548365085275513
64 -37.525128081440926 -25.45878528601009
65 -39.90652436763048 -24.879106999799365
66 -39.0026855096221 -24.828695359328833
67 -40.3244189620018 -24.592745144504722
68 -38.883035972714424 -23.978745577896312
69 -37.447308383882046 -23.57262108435893
70 -35.45107824355364 -23.44970807952351
71 -37.29733492434025 -22.745309160183492
72 -35.71405676752329 -22.60679894414887
73 -35.911539264023304 -22.19891031871716
74 -35.49446968920529 -20.656863763892378
75 -32.447965923696756 -20.444472560731253
76 -32.396833926439285 -20.19699010077007
77 -35.83749159425497 -20.13839114930498
78 -34.13888733834028 -19.63760343800059
79 -34.574418194592 -19.515598718228343
80 -32.604018304497004 -18.92838809611677
81 -32.38611386716366 -17.994774057192853
82 -29.83783581107855 -17.55742370467821
83 -28.678369142115116 -16.823073927842348
84 -27.493043826892972 -14.855082803515382
85 -26.596436955034733 -14.531424598833084
86 -25.256019979715347 -14.442420089224363
87 -27.361867241561413 -13.596012850960644
88 -20.18600389547646 -12.68135972540495
89 -26.172610368579626 -12.66418205637357
90 -24.811680667102337 -12.30017947419658
91 -23.27116570621729 -12.151904772081672
92 -23.088498068973422 -11.788852141676486
93 -22.211370561271906 -10.869989101210326
94 -22.691012870986015 -10.327681503524177
95 -18.991274043917656 -9.8572159761571
96 -18.428677214775234 -8.330116995310416
97 -18.89939733222127 -8.133195842510668
98 -20.10806331411004 -8.108197691178031
99 -13.832594890147448 -7.57539849177145
100 -13.267675798386335 -7.362443126623615
101 -12.806239983998239 -7.108327355338034
102 -13.615984805393964 -6.959063561385431
103 -13.306355107575655 -6.776946485018116
104 -12.304881019052118 -6.7220638398623045
105 -13.6421467512846 -6.719970621583102
106 -18.971837393939495 -6.535447341844848
107 -15.675395034253597 -6.51820418055673
108 -15.258210748434067 -5.615796733870542
109 -12.999563715420663 -5.34720210027791
110 -12.649664947763085 -5.078485007852753
111 -13.034208612516522 -5.027957977402961
112 -11.8644303297624 -4.827572916892203
113 -12.379784037359059 -4.63049541560991
114 -11.992417879402637 -4.230832004686763
115 -12.313598454929888 -4.031048624093466
116 -11.332721155136824 -3.3844671463622564
117 -11.587159687653184 -3.3322555012187633
118 -12.018795602023602 -2.6416623314910934
119 -9.776183106936514 -1.9136196540088464
train accuracy: 1.0
validation accuracy: 1.0
[-54.98547503 -50.4922686  -50.03933802 -49.75347185 -49.72654641
 -46.98011874 -45.73515428 -45.67057988 -44.99030608 -44.14602409
 -43.81326882 -43.18878399 -42.29180715 -42.00401746 -41.69100444
 -41.68588229 -41.2817771  -40.44278203 -40.34838366 -39.59970115
 -39.57586365 -39.31972693 -39.02461056 -38.45534494 -38.4127039
 -38.35634328 -37.79713617 -37.74152899 -37.66475324 -37.51313938
 -37.1809993  -37.10070314 -37.00630589 -36.82191677 -36.48799015
 -36.2096527  -36.19207562 -36.11445903 -35.78149902 -35.39450387
 -35.262825   -35.24303541 -35.20970524 -35.06544085 -34.80241748
 -34.64469045 -33.84284986 -32.70706485 -31.9690994  -31.7109134
 -31.64414356 -31.39238276 -31.22319602 -31.12953085 -29.3915714
 -29.34012561 -29.10618999 -27.4110235  -27.34372236 -27.19668163
 -27.07399029 -26.70472176 -26.2447949  -25.54836509 -25.45878529
 -24.879107   -24.82869536 -24.59274514 -23.97874558 -23.57262108
 -23.44970808 -22.74530916 -22.60679894 -22.19891032 -20.65686376
 -20.44447256 -20.1969901  -20.13839115 -19.63760344 -19.51559872
 -19.4608337  -18.9283881  -18.73129823 -17.99477406 -17.5574237
 -17.2877303  -16.99919682 -16.82307393 -16.73124049 -16.67001724
 -16.58659093 -16.32507254 -15.89510862 -15.83529718 -15.71653035
 -15.65454388 -15.29900699 -15.2719524  -15.13026299 -15.09811232
 -15.05822392 -14.89671643 -14.8550828  -14.594561   -14.5314246
 -14.44242009 -14.23740337 -14.04266231 -14.00356944 -13.99901576
 -13.96863183 -13.94553084 -13.86308449 -13.82168222 -13.67248689
 -13.608892   -13.59601285 -13.5769007  -13.53717325 -13.48391162
 -13.35053773 -13.24746818 -13.17814269 -13.17193674 -13.13997741
 -12.98804567 -12.94572355 -12.93760188 -12.89533945 -12.70915032
 -12.68787728 -12.68476663 -12.68135973 -12.66418206 -12.58492544
 -12.5568266  -12.54337072 -12.48846703 -12.37013582 -12.34671509
 -12.30017947 -12.24340388 -12.19488362 -12.17081576 -12.15190477
 -12.10286355 -11.97628117 -11.9718797  -11.94387787 -11.80244434
 -11.78885214 -11.78173063 -11.7724129  -11.70702865 -11.675454
 -11.67485775 -11.6440414  -11.54576322 -11.48214076 -11.27863965
 -11.10389205 -11.07648117 -11.07460556 -10.98789819 -10.96193206
 -10.89368728 -10.88447672 -10.8699891  -10.84529073 -10.83771365
 -10.7626531  -10.72252648 -10.4627546  -10.4515603  -10.37561746
 -10.3276815  -10.32701661 -10.17869462 -10.15370275 -10.06917835
 -10.05434057  -9.98600954  -9.97495295  -9.93667404  -9.89890309
  -9.87343312  -9.85721598  -9.84325222  -9.70803505  -9.63006997
  -9.47919626  -9.43633846  -9.41778779  -9.40824698  -9.35990043
  -9.34459136  -9.34125766  -9.34040597  -9.31853289  -9.25632952
  -9.22954286  -9.22723903  -9.13624814  -9.09796099  -9.09284414
  -8.93076101  -8.77833829  -8.77596385  -8.75445976  -8.49185067
  -8.330117    -8.30246843  -8.19902254  -8.13319584  -8.10819769
  -7.57539849  -7.51737497  -7.36244313  -7.10832736  -6.95906356
  -6.77694649  -6.72206384  -6.71997062  -6.68501373  -6.53544734
  -6.51820418  -6.43176687  -5.61579673  -5.3472021   -5.2737561
  -5.07848501  -5.02795798  -4.82757292  -4.63049542  -4.230832
  -4.03104862  -3.38446715  -3.3322555   -2.64166233  -1.91361965]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Found existing model weights! Loading state dict...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:3
end of epoch 0: val_loss 1.1494097970512484e-05, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.3474e-02, -7.3796e-02, -8.1372e-02, -2.3370e-01,  1.4026e-01,
          4.5636e-01,  4.1971e-03,  2.8054e-02,  1.0399e-01, -5.9948e-01,
          9.1622e-04, -6.5142e-01, -1.8200e+00]], device='cuda:3'))])
end of epoch 1: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.6465e-01,  1.7847e-01,  2.1697e-01, -1.3806e-01, -3.2706e-01,
          5.2579e-01, -4.3187e-02, -9.6554e-03,  1.0468e+00, -1.0300e+00,
         -6.2782e-04, -1.3136e+00, -2.4290e+00]], device='cuda:3'))])
end of epoch 2: val_loss 3.176865447684918e-07, val_acc 1.0
trigger times: 1
end of epoch 3: val_loss 0.00020592733752849312, val_acc 1.0
trigger times: 2
end of epoch 4: val_loss 1.2183325725558803e-05, val_acc 1.0
trigger times: 3
end of epoch 5: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.0598e-03,  1.6568e-01,  3.5241e-01,  2.3489e-02, -1.9412e-01,
          7.6522e-01, -1.0470e-01, -1.1318e-01,  2.5577e-01, -9.3236e-01,
         -6.9649e-04, -1.4008e+00, -3.1887e+00]], device='cuda:3'))])
end of epoch 6: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 1
end of epoch 7: val_loss 0.000550700380790623, val_acc 1.0
trigger times: 2
end of epoch 8: val_loss 2.980231634808206e-09, val_acc 1.0
trigger times: 3
end of epoch 9: val_loss 8.344583847019749e-08, val_acc 1.0
trigger times: 4
end of epoch 10: val_loss 2.0099322311679657e-05, val_acc 1.0
trigger times: 5
end of epoch 11: val_loss 1.8284603881255636e-05, val_acc 1.0
trigger times: 6
end of epoch 12: val_loss 0.004907961699738301, val_acc 1.0
trigger times: 7
end of epoch 13: val_loss 2.7418093395681354e-08, val_acc 1.0
trigger times: 8
end of epoch 14: val_loss 0.0037317696982943007, val_acc 1.0
trigger times: 9
end of epoch 15: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.2950e-01,  1.5775e-05,  2.6708e-02,  9.7709e-07, -2.0297e-01,
          6.5507e-01, -2.2543e-02, -3.4195e-02,  5.5052e-01, -6.0885e-01,
         -3.4282e-05, -1.3692e+00, -2.3801e+00]], device='cuda:3'))])
end of epoch 16: val_loss 0.001060627158548151, val_acc 1.0
trigger times: 1
end of epoch 17: val_loss 2.187615881439342e-06, val_acc 1.0
trigger times: 2
end of epoch 18: val_loss 0.0002996260620994562, val_acc 1.0
trigger times: 3
end of epoch 19: val_loss 0.00015918876721269016, val_acc 1.0
trigger times: 4
end of epoch 20: val_loss 7.682783505202906e-07, val_acc 1.0
trigger times: 5
end of epoch 21: val_loss 1.358896521423958e-06, val_acc 1.0
trigger times: 6
end of epoch 22: val_loss 1.5334655760739224e-05, val_acc 1.0
trigger times: 7
end of epoch 23: val_loss 0.0004926045785528288, val_acc 1.0
trigger times: 8
end of epoch 24: val_loss 2.5033927677498013e-08, val_acc 1.0
trigger times: 9
end of epoch 25: val_loss 0.00020529040933872978, val_acc 1.0
trigger times: 10
Early stopping.
0 -92.32234598696232 -54.98547503240923
1 -96.07488536834717 -50.03933801517046
2 -89.87583953142166 -49.72654640753777
3 -85.65007191896439 -45.7351542845057
4 -70.47939002513885 -44.99030608142343
5 -77.76313254237175 -43.81326882122305
6 -105.52026456594467 -42.29180714825394
7 -92.11791542172432 -41.6910044370425
8 -68.73295482993126 -41.281777102712205
9 -93.57515966892242 -40.34838365523108
10 -84.02984377741814 -39.57586365327889
11 -74.71440470218658 -39.024610555047154
12 -82.41810175776482 -38.41270390343083
13 -82.00576193630695 -37.79713616772368
14 -77.17331263422966 -37.66475323879293
15 -94.046395778656 -37.1809993033689
16 -77.81265786290169 -37.00630588930485
17 -57.78355652093887 -36.48799015296732
18 -67.9461210668087 -36.19207561676116
19 -79.83936834335327 -35.78149902167743
20 -86.94788843393326 -35.26282499693737
21 -70.25628513097763 -35.209705244501436
22 -59.45782808959484 -34.80241747531743
23 -78.44589963555336 -33.84284985953318
24 -54.02052392065525 -31.969099402548657
25 -67.41440553963184 -31.64414355845032
26 -55.22449854016304 -31.223196019713853
27 -64.46262626349926 -29.39157139549552
28 -59.48713901638985 -29.106189988903285
29 -54.88919600844383 -27.343722362182305
30 -66.72992600500584 -27.07399028854534
31 -54.7469597607851 -26.244794902859052
32 -55.86316558718681 -25.45878528601009
33 -45.9042399674654 -24.828695359328833
34 -45.19702619314194 -23.978745577896312
35 -52.55971224606037 -23.44970807952351
36 -65.25536674261093 -22.60679894414887
37 -54.07784977555275 -20.656863763892378
38 -41.820662058889866 -20.19699010077007
39 -41.90048786997795 -19.63760343800059
40 -33.90622514486313 -19.4608336980355
41 -31.627896815538406 -18.731298228582755
42 -43.429524287581444 -17.55742370467821
43 -34.9719417989254 -16.999196821113756
44 -28.376089215278625 -16.731240494206556
45 -32.55983452498913 -16.586590930336246
46 -27.68971934914589 -15.895108619308635
47 -29.159087032079697 -15.716530350593484
48 -35.6622820943594 -15.29900699234506
49 -34.36351990699768 -15.130262992826164
50 -27.94252997636795 -15.058223915588862
51 -38.154454953968525 -14.855082803515382
52 -25.82261760532856 -14.531424598833084
53 -31.736726440489292 -14.237403369666614
54 -31.24795988202095 -14.003569443724066
55 -27.626850962638855 -13.968631831022643
56 -29.459974229335785 -13.86308448731226
57 -29.308640629053116 -13.672486891155406
58 -34.15009422600269 -13.596012850960644
59 -29.78357483446598 -13.537173252032721
60 -30.38579171895981 -13.247468178452921
61 -28.674952417612076 -13.171936739318621
62 -32.12958115339279 -12.988045670217158
63 -20.21824251115322 -12.937601880303525
64 -29.348132498562336 -12.709150323057631
65 -24.830664604902267 -12.684766625629942
66 -22.350197464227676 -12.66418205637357
67 -30.222019851207733 -12.556826596461217
68 -27.464364305138588 -12.48846702822902
69 -26.749300330877304 -12.346715089027569
70 -29.079585149884224 -12.243403879196388
71 -32.460474252700806 -12.170815759622592
72 -20.328584909439087 -12.10286355263865
73 -28.98427264392376 -11.971879704988003
74 -28.46187360212207 -11.802444341088956
75 -25.734303057193756 -11.781730626483084
76 -30.17169615626335 -11.707028646158562
77 -26.434204041957855 -11.674857754603973
78 -25.96393971890211 -11.545763222571745
79 -28.027526631951332 -11.278639647398466
80 -23.803957030177116 -11.076481171996228
81 -27.212693840265274 -10.987898185149746
82 -29.5822930932045 -10.8936872753186
83 -30.67023115605116 -10.869989101210326
84 -27.17453543841839 -10.837713645707614
85 -27.570417642593384 -10.722526479931577
86 -23.04622507095337 -10.451560303375969
87 -27.9230900965631 -10.327681503524177
88 -26.70536309480667 -10.178694623110099
89 -29.293575286865234 -10.069178353474605
90 -23.43823617696762 -9.986009544966164
91 -23.518028050661087 -9.936674043396035
92 -24.972662329673767 -9.873433124041318
93 -24.004901617765427 -9.843252216045357
94 -23.155791379511356 -9.630069973226872
95 -25.478960633277893 -9.436338457972072
96 -18.893026940524578 -9.408246981646435
97 -23.59408114850521 -9.344591359124774
98 -16.805640399456024 -9.340405972508886
99 -22.52974910289049 -9.256329515217804
100 -22.178641095757484 -9.227239032064794
101 -19.17068348824978 -9.097960985817739
102 -21.940294429659843 -8.930761014077454
103 -14.771348878741264 -8.775963851048022
104 -17.08312140405178 -8.491850672526503
105 -12.83110723644495 -8.302468427151881
106 -12.858103945851326 -8.133195842510668
107 -27.96206919848919 -7.57539849177145
108 -26.697966769337654 -7.362443126623615
109 -25.908133924007416 -6.959063561385431
110 -23.892647452652454 -6.7220638398623045
111 -14.77982186153531 -6.685013730616453
112 -22.179595321416855 -6.51820418055673
113 -19.164945241063833 -5.615796733870542
114 -9.874826822429895 -5.273756100604971
115 -18.862214157357812 -5.027957977402961
116 -13.258390337228775 -4.63049541560991
117 -4.041109211742878 -4.031048624093466
118 -2.8781794160604477 -3.3322555012187633
119 -0.09797948598861694 -1.9136196540088464
train accuracy: 0.9994444444444445
validation accuracy: 1.0
[-54.98547503 -50.4922686  -50.03933802 -49.75347185 -49.72654641
 -46.98011874 -45.73515428 -45.67057988 -44.99030608 -44.14602409
 -43.81326882 -43.18878399 -42.29180715 -42.00401746 -41.69100444
 -41.68588229 -41.2817771  -40.44278203 -40.34838366 -39.59970115
 -39.57586365 -39.31972693 -39.02461056 -38.45534494 -38.4127039
 -38.35634328 -37.79713617 -37.74152899 -37.66475324 -37.51313938
 -37.1809993  -37.10070314 -37.00630589 -36.82191677 -36.48799015
 -36.2096527  -36.19207562 -36.11445903 -35.78149902 -35.39450387
 -35.262825   -35.24303541 -35.20970524 -35.06544085 -34.80241748
 -34.64469045 -33.84284986 -32.70706485 -31.9690994  -31.7109134
 -31.64414356 -31.39238276 -31.22319602 -31.12953085 -29.3915714
 -29.34012561 -29.10618999 -27.4110235  -27.34372236 -27.19668163
 -27.07399029 -26.70472176 -26.2447949  -25.54836509 -25.45878529
 -24.879107   -24.82869536 -24.59274514 -23.97874558 -23.57262108
 -23.44970808 -22.74530916 -22.60679894 -22.19891032 -20.65686376
 -20.44447256 -20.1969901  -20.13839115 -19.63760344 -19.51559872
 -19.4608337  -18.9283881  -18.73129823 -17.99477406 -17.5574237
 -17.2877303  -16.99919682 -16.82307393 -16.73124049 -16.67001724
 -16.58659093 -16.32507254 -15.89510862 -15.83529718 -15.71653035
 -15.65454388 -15.64362673 -15.4996426  -15.29900699 -15.2719524
 -15.1811829  -15.16489019 -15.13026299 -15.11310895 -15.09811232
 -15.05822392 -14.92482994 -14.89671643 -14.8550828  -14.7994931
 -14.77118432 -14.594561   -14.5314246  -14.46874354 -14.44242009
 -14.36850066 -14.32950177 -14.32942426 -14.23740337 -14.08340118
 -14.04266231 -14.00356944 -13.99901576 -13.96863183 -13.94553084
 -13.86308449 -13.82682946 -13.82168222 -13.74201371 -13.67248689
 -13.608892   -13.59601285 -13.58322451 -13.5769007  -13.53717325
 -13.50058897 -13.48391162 -13.42154574 -13.35053773 -13.33224936
 -13.24746818 -13.17814269 -13.17193674 -13.13997741 -12.9932924
 -12.9911753  -12.98804567 -12.94572355 -12.93760188 -12.89533945
 -12.7141283  -12.71256262 -12.70915032 -12.68787728 -12.68476663
 -12.68135973 -12.67795632 -12.66418206 -12.60505429 -12.58492544
 -12.5568266  -12.54337072 -12.48960663 -12.48846703 -12.41787343
 -12.37245474 -12.37013582 -12.36609991 -12.34671509 -12.30017947
 -12.24340388 -12.19488362 -12.17081576 -12.1638277  -12.15190477
 -12.11267893 -12.10286355 -12.07990884 -12.07648199 -11.97628117
 -11.9718797  -11.94387787 -11.91392797 -11.80244434 -11.78885214
 -11.78173063 -11.7724129  -11.76007221 -11.72649421 -11.70702865
 -11.675454   -11.67485775 -11.6440414  -11.54576322 -11.48214076
 -11.47061442 -11.39809208 -11.39514232 -11.31835075 -11.27863965
 -11.10389205 -11.07648117 -11.07460556 -10.9955771  -10.98789819
 -10.96193206 -10.89368728 -10.88947284 -10.88447672 -10.8699891
 -10.84529073 -10.83771365 -10.7626531  -10.72252648 -10.68754535
 -10.59932568 -10.54372397 -10.4627546  -10.4515603  -10.44415981
 -10.37561746 -10.3276815  -10.32701661 -10.30373604 -10.17869462
 -10.15370275 -10.06917835 -10.05434057  -9.98600954  -9.97495295
  -9.93667404  -9.89890309  -9.87343312  -9.85721598  -9.84325222
  -9.76873248  -9.70803505  -9.70232992  -9.63006997  -9.60162068
  -9.47919626  -9.43866282  -9.43633846  -9.41778779  -9.41052059
  -9.40824698  -9.35990043  -9.34459136  -9.34125766  -9.34040597
  -9.31853289  -9.29755911  -9.28970959  -9.25632952  -9.22954286
  -9.22723903  -9.1921269   -9.15969438  -9.13624814  -9.12404452
  -9.09796099  -9.09284414  -9.00748237  -8.9703478   -8.93076101
  -8.8972749   -8.77833829  -8.77596385  -8.75445976  -8.60684626
  -8.49185067  -8.43284839  -8.39800134  -8.33111246  -8.330117
  -8.30246843  -8.19902254  -8.13319584  -8.1092657   -8.10819769
  -7.76388228  -7.75584261  -7.65808398  -7.61173669  -7.57539849
  -7.55046962  -7.51737497  -7.44092012  -7.36244313  -7.23588878
  -7.10832736  -6.95906356  -6.94047157  -6.91427984  -6.91024552
  -6.77694649  -6.72206384  -6.71997062  -6.70339024  -6.68501373
  -6.55035087  -6.53637975  -6.53544734  -6.51820418  -6.48528917
  -6.47362572  -6.43176687  -6.42315718  -6.32418263  -6.28834113
  -6.23383601  -5.73843016  -5.6559233   -5.62903448  -5.61579673
  -5.58211056  -5.56808905  -5.41773478  -5.41681175  -5.39914398
  -5.3472021   -5.34113623  -5.32351909  -5.2737561   -5.11968813
  -5.08944247  -5.07848501  -5.02795798  -4.88350688  -4.87565908
  -4.82757292  -4.77444392  -4.6362783   -4.63049542  -4.60697954
  -4.42297854  -4.36932192  -4.28918088  -4.230832    -4.11600409
  -4.07483063  -4.03306984  -4.03104862  -3.89657065  -3.8858411
  -3.80709015  -3.75328905  -3.7297162   -3.61904238  -3.61173136
  -3.59536414  -3.56149099  -3.38726063  -3.38446715  -3.3322555
  -3.21746212  -2.64166233  -2.38277218  -1.91361965  -1.90178954]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Found existing model weights! Loading state dict...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:2
end of epoch 0: val_loss 0.00044735666737111046, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 8.3968e-06, -2.3661e-06,  4.8432e-02, -8.4266e-02, -1.8127e-05,
          1.3270e-05, -4.0079e-03,  6.0218e-02,  7.8227e-05, -1.5118e-05,
         -1.7490e-03, -1.6068e+00, -1.0733e+00]], device='cuda:2'))])
end of epoch 1: val_loss 6.455043853748066e-07, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.2714e-02,  2.0764e-02,  5.0436e-03, -1.0973e-02, -2.8313e-05,
          3.0969e-05,  5.9787e-03,  2.9774e-05,  2.5433e-05, -5.6225e-05,
         -3.8930e-04, -1.5965e+00, -1.3739e+00]], device='cuda:2'))])
end of epoch 2: val_loss 0.06828631531565364, val_acc 0.985
trigger times: 1
end of epoch 3: val_loss 0.00011863507490282643, val_acc 1.0
trigger times: 2
end of epoch 4: val_loss 0.000145158071094329, val_acc 1.0
trigger times: 3
end of epoch 5: val_loss 4.1785289362650246e-06, val_acc 1.0
trigger times: 4
end of epoch 6: val_loss 6.8249090127991965e-06, val_acc 1.0
trigger times: 5
end of epoch 7: val_loss 9.428197061335908e-05, val_acc 1.0
trigger times: 6
end of epoch 8: val_loss 0.0001241854613007476, val_acc 1.0
trigger times: 7
end of epoch 9: val_loss 2.2530371431628283e-07, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.6749e-01, -3.3475e-06,  1.9779e-01,  8.3093e-06, -7.2598e-05,
         -2.0687e-05, -4.9930e-02,  8.7884e-02, -4.7610e-05,  2.1606e-05,
         -3.7816e-04, -2.0087e+00, -1.7176e+00]], device='cuda:2'))])
end of epoch 10: val_loss 0.0001135758200858561, val_acc 1.0
trigger times: 1
end of epoch 11: val_loss 1.303111597351858e-05, val_acc 1.0
trigger times: 2
end of epoch 12: val_loss 3.4382099977428026e-05, val_acc 1.0
trigger times: 3
end of epoch 13: val_loss 0.0029731532685228147, val_acc 1.0
trigger times: 4
end of epoch 14: val_loss 3.9425502151431144e-05, val_acc 1.0
trigger times: 5
end of epoch 15: val_loss 4.4463960190199715e-07, val_acc 1.0
trigger times: 6
end of epoch 16: val_loss 2.3126359330660761e-07, val_acc 1.0
trigger times: 7
end of epoch 17: val_loss 7.569748714075786e-08, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.2671e-01, -1.1227e-01,  1.4578e-01, -6.8534e-02,  4.6451e-01,
         -4.7384e-01, -4.3745e-02,  1.0447e-01, -2.3512e-05,  8.0574e-02,
         -1.7574e-03, -1.9541e+00, -2.3348e+00]], device='cuda:2'))])
end of epoch 18: val_loss 2.241093754307144e-07, val_acc 1.0
trigger times: 1
end of epoch 19: val_loss 2.872804758315084e-05, val_acc 1.0
trigger times: 2
end of epoch 20: val_loss 0.0004367066286885901, val_acc 1.0
trigger times: 3
end of epoch 21: val_loss 1.140305809041564e-05, val_acc 1.0
trigger times: 4
end of epoch 22: val_loss 0.10594285183979046, val_acc 0.985
trigger times: 5
end of epoch 23: val_loss 2.806372112686972e-06, val_acc 1.0
trigger times: 6
end of epoch 24: val_loss 0.40255799778755813, val_acc 0.95
trigger times: 7
end of epoch 25: val_loss 3.130125301495923e-06, val_acc 1.0
trigger times: 8
end of epoch 26: val_loss 0.0004806328912296465, val_acc 1.0
trigger times: 9
end of epoch 27: val_loss 9.291804070343802e-06, val_acc 1.0
trigger times: 10
Early stopping.
0 -117.34128439426422 -54.98547503240923
1 -99.45434701442719 -49.75347184620696
2 -90.55638241767883 -45.7351542845057
3 -112.32218146324158 -44.14602409201361
4 -137.55103361606598 -42.29180714825394
5 -95.92909693717957 -41.68588229294918
6 -72.68826514482498 -40.34838365523108
7 -132.55207931995392 -39.31972693233231
8 -103.14032953977585 -38.41270390343083
9 -105.53856438398361 -37.741528994987384
10 -82.33204215765 -37.1809993033689
11 -63.64338576793671 -36.821916772458344
12 -98.80246835947037 -36.19207561676116
13 -57.52654372155666 -35.394503873250635
14 -86.66955927014351 -35.209705244501436
15 -65.8908007144928 -34.64469044638467
16 -61.336193203926086 -31.969099402548657
17 -75.45218964666128 -31.392382758954444
18 -75.3100169301033 -29.39157139549552
19 -79.32294015586376 -27.41102349748205
20 -89.44649901241064 -27.07399028854534
21 -60.3051523566246 -25.548365085275513
22 -64.52997972816229 -24.828695359328833
23 -51.838187754154205 -23.57262108435893
24 -65.55382460355759 -22.60679894414887
25 -47.286330826580524 -20.444472560731253
26 -45.47669254243374 -19.63760343800059
27 -51.39827083051205 -18.92838809611677
28 -56.159979194402695 -17.55742370467821
29 -45.87382301688194 -16.823073927842348
30 -49.17601251602173 -16.325072543773945
31 -44.91974103450775 -15.716530350593484
32 -59.356155782938 -15.499642599313287
33 -58.149549543857574 -15.181182902809962
34 -57.75520649552345 -15.113108946963987
35 -56.44238793849945 -14.924829935510232
36 -53.13907232880592 -14.79949309890538
37 -46.53213246911764 -14.531424598833084
38 -56.49467805027962 -14.368500664576029
39 -45.8321887254715 -14.237403369666614
40 -44.996578216552734 -14.003569443724066
41 -42.484488010406494 -13.945530841132388
42 -43.38934338092804 -13.821682224843855
43 -43.23954510688782 -13.608891999152753
44 -41.36682748794556 -13.57690069878421
45 -41.831374764442444 -13.483911619341129
46 -52.313220381736755 -13.332249355787466
47 -39.65378624200821 -13.171936739318621
48 -48.90626202523708 -12.99117530335262
49 -39.07411390542984 -12.937601880303525
50 -49.63148060441017 -12.712562621425914
51 -40.42032626271248 -12.684766625629942
52 -34.74166087806225 -12.66418205637357
53 -43.66559782624245 -12.556826596461217
54 -39.610068917274475 -12.48846702822902
55 -40.97178000211716 -12.370135820080268
56 -41.84333761315793 -12.30017947419658
57 -42.052028357982635 -12.170815759622592
58 -41.72583958506584 -12.11267892819539
59 -46.855648666620255 -12.076481989890604
60 -37.84523922204971 -11.943877868597472
61 -57.5966822039336 -11.788852141676486
62 -40.140113562345505 -11.760072210591307
63 -39.83181646466255 -11.67545400252302
64 -37.90981665253639 -11.545763222571745
65 -43.329207211732864 -11.39809207860808
66 -39.913408041000366 -11.278639647398466
67 -38.28960781171918 -11.074605562523185
68 -38.059567242860794 -10.961932060164017
69 -41.466560393571854 -10.884476715792978
70 -41.373982548713684 -10.837713645707614
71 -45.15638279914856 -10.687545353047717
72 -37.307401061058044 -10.462754599027946
73 -38.724670469760895 -10.375617458556032
74 -42.581837221980095 -10.303736040160652
75 -38.04052007198334 -10.069178353474605
76 -35.42872175574303 -9.974952948632556
77 -32.8245148062706 -9.873433124041318
78 -41.556980930268764 -9.768732478455368
79 -36.1223258972168 -9.630069973226872
80 -41.87492263317108 -9.438662818695786
81 -42.65014459937811 -9.410520593324348
82 -33.34595587849617 -9.344591359124774
83 -31.558211505413055 -9.318532890899364
84 -34.28676971793175 -9.256329515217804
85 -39.576235078275204 -9.192126898690297
86 -39.676050528883934 -9.124044524201393
87 -35.95095834136009 -9.007482366079063
88 -41.47276771068573 -8.897274903905352
89 -30.993816256523132 -8.754459760935882
90 -39.567010432481766 -8.398001337047377
91 -26.523725301027298 -8.302468427151881
92 -34.51352310180664 -8.109265697684156
93 -29.609652929008007 -7.755842605484458
94 -29.83010173588991 -7.57539849177145
95 -34.40759275108576 -7.440920124149799
96 -14.597849041223526 -7.108327355338034
97 -29.49906938523054 -6.9142798394018055
98 -24.286976620554924 -6.7220638398623045
99 -19.64669831097126 -6.685013730616453
100 -29.337012097239494 -6.535447341844848
101 -31.518271327018738 -6.473625724565205
102 -32.214768290519714 -6.3241826341847105
103 -23.509982891380787 -5.738430155643535
104 -33.62115306407213 -5.615796733870542
105 -23.930160343647003 -5.417734778175555
106 -28.10560554265976 -5.34720210027791
107 -20.004657045006752 -5.273756100604971
108 -28.116204150021076 -5.078485007852753
109 -21.505799010396004 -4.875659084774348
110 -25.17905130982399 -4.636278300562541
111 -20.69154281914234 -4.422978544752843
112 -22.124160021543503 -4.230832004686763
113 -19.261604707688093 -4.033069837874189
114 -20.212375596165657 -3.885841100341837
115 -17.84122960269451 -3.7297162032160345
116 -18.930144801735878 -3.595364142259748
117 -21.826242968440056 -3.3844671463622564
118 -16.73926793038845 -2.6416623314910934
119 -14.770740874111652 -1.901789541388503
train accuracy: 1.0
validation accuracy: 1.0
[-63.24332377 -63.23599055 -63.21105585 -63.1277899  -63.03088591
 -62.97836141 -62.80700329 -62.59841154 -62.45659058 -62.22052465
 -62.05545976 -61.99823876 -61.90503048 -61.9024977  -61.84514296
 -61.80958936 -61.60739549 -61.57987077 -61.52954719 -61.49152331
 -61.42319103 -61.37818898 -61.3242033  -61.18861045 -61.11705014
 -61.1111952  -61.05040259 -60.70125881 -60.55874128 -60.49758829
 -60.33754647 -60.3056539  -60.27108478 -60.26518611 -60.24509979
 -60.22805253 -60.15029758 -60.10592506 -60.09749463 -60.0319431
 -60.02722508 -59.93393272 -59.80496242 -59.7917769  -59.65998034
 -59.5305981  -59.50104536 -59.42996515 -59.42210572 -59.38924773
 -59.38736621 -59.38054209 -59.3637735  -59.35705669 -59.33804201
 -59.3275818  -59.30965762 -59.10615862 -59.10256234 -58.91394416
 -58.85869868 -58.83781287 -58.805901   -58.78928523 -58.78920472
 -58.74515985 -58.7335467  -58.6909254  -58.60985472 -58.59427563
 -58.58165728 -58.52164071 -58.47633979 -58.46066973 -58.43515991
 -58.42948108 -58.34687794 -58.3224997  -58.26697037 -58.26037219
 -58.18129208 -58.0861159  -57.99583108 -57.97256269 -57.92377717
 -57.89906439 -57.86612124 -57.85252143 -57.79024149 -57.78201503
 -57.76493642 -57.72031285 -57.55593357 -57.38102245 -57.37258309
 -57.21444707 -57.21200816 -57.16061789 -57.12957694 -57.07621127
 -57.06529087 -57.04573717 -56.88160157 -56.87555564 -56.72292153
 -56.70057749 -56.62581458 -56.40969062 -56.40899696 -56.32819744
 -56.0810036  -56.05279704 -55.96543435 -55.96407105 -55.93162024
 -55.67010668 -55.50073526 -55.32975789 -54.98547503 -54.6753876
 -53.06095904 -50.4922686  -50.03933802 -49.75347185 -49.72654641
 -46.98011874 -45.73515428 -45.67057988 -44.99030608 -44.14602409
 -43.81326882 -43.18878399 -42.29180715 -42.00401746 -41.69100444
 -41.68588229 -41.2817771  -40.44278203 -40.34838366 -39.59970115
 -39.57586365 -39.31972693 -39.02461056 -38.45534494 -38.4127039
 -38.35634328 -37.79713617 -37.74152899 -37.66475324 -37.51313938
 -37.1809993  -37.10070314 -37.00630589 -36.82191677 -36.48799015
 -36.2096527  -36.19207562 -36.11445903 -35.78149902 -35.39450387
 -35.262825   -35.24303541 -35.20970524 -35.06544085 -34.80241748
 -34.64469045 -33.84284986 -32.70706485 -31.9690994  -31.7109134
 -31.64414356 -31.39238276 -31.22319602 -31.12953085 -29.3915714
 -29.34012561 -29.10618999 -27.4110235  -27.34372236 -27.19668163
 -27.07399029 -26.70472176 -26.2447949  -25.54836509 -25.45878529
 -24.879107   -24.82869536 -24.59274514 -23.97874558 -23.57262108
 -23.44970808 -22.74530916 -22.60679894 -22.19891032 -20.65686376
 -20.44447256 -20.1969901  -20.13839115 -19.63760344 -19.51559872
 -19.4608337  -18.9283881  -18.73129823 -17.99477406 -17.5574237
 -17.2877303  -16.99919682 -16.82307393 -16.73124049 -16.67001724
 -16.58659093 -16.32507254 -15.89510862 -15.83529718 -15.71653035
 -15.65454388 -15.64362673 -15.4996426  -15.29900699 -15.2719524
 -15.1811829  -15.16489019 -15.13026299 -15.11310895 -15.09811232
 -15.05822392 -14.92482994 -14.89671643 -14.8550828  -14.7994931
 -14.77118432 -14.594561   -14.5314246  -14.46874354 -14.44242009
 -14.36850066 -14.32950177 -14.32942426 -14.23740337 -14.08340118
 -14.04266231 -14.00356944 -13.99901576 -13.96863183 -13.94553084
 -13.86308449 -13.82682946 -13.82168222 -13.74201371 -13.67248689
 -13.608892   -13.59601285 -13.58322451 -13.5769007  -13.53717325
 -13.50058897 -13.48391162 -13.42154574 -13.35053773 -13.33224936
 -13.24746818 -13.17814269 -13.17193674 -13.13997741 -12.9932924
 -12.9911753  -12.98804567 -12.94572355 -12.93760188 -12.89533945
 -12.7141283  -12.71256262 -12.70915032 -12.68787728 -12.68476663
 -12.68135973 -12.67795632 -12.66418206 -12.60505429 -12.58492544
 -12.5568266  -12.54337072 -12.48960663 -12.48846703 -12.41787343
 -12.37245474 -12.37013582 -12.36609991 -12.34671509 -12.30017947
 -12.24340388 -12.19488362 -12.17081576 -12.1638277  -12.15190477
 -12.11267893 -12.10286355 -12.07990884 -12.07648199 -11.97628117
 -11.9718797  -11.94387787 -11.91392797 -11.80244434 -11.78885214
 -11.78173063 -11.7724129  -11.76007221 -11.72649421 -11.70702865
 -11.675454   -11.67485775 -11.6440414  -11.54576322 -11.48214076
 -11.47061442 -11.39809208 -11.39514232 -11.31835075 -11.27863965
 -11.10389205 -11.07648117 -11.07460556 -10.9955771  -10.98789819
 -10.96193206 -10.89368728 -10.88947284 -10.88447672 -10.8699891
 -10.84529073 -10.83771365 -10.7626531  -10.72252648 -10.68754535
 -10.59932568 -10.54372397 -10.4627546  -10.4515603  -10.44415981
 -10.37561746 -10.3276815  -10.32701661 -10.30373604 -10.17869462
 -10.15370275 -10.06917835 -10.05434057  -9.98600954  -9.97495295
  -9.93667404  -9.89890309  -9.87343312  -9.85721598  -9.84325222
  -9.76873248  -9.70803505  -9.70232992  -9.63006997  -9.60162068
  -9.47919626  -9.43866282  -9.43633846  -9.41778779  -9.41052059
  -9.40824698  -9.35990043  -9.34459136  -9.34125766  -9.34040597
  -9.31853289  -9.29755911  -9.28970959  -9.25632952  -9.22954286
  -9.22723903  -9.1921269   -9.15969438  -9.13624814  -9.12404452
  -9.09796099  -9.09284414  -9.00748237  -8.9703478   -8.93076101
  -8.8972749   -8.77833829  -8.77596385  -8.75445976  -8.60684626
  -8.49185067  -8.43284839  -8.39800134  -8.33111246  -8.330117
  -8.30246843  -8.19902254  -8.13319584  -8.1092657   -8.10819769
  -7.76388228  -7.75584261  -7.65808398  -7.61173669  -7.57539849
  -7.55046962  -7.51737497  -7.44092012  -7.36244313  -7.23588878
  -7.10832736  -6.95906356  -6.94047157  -6.91427984  -6.91024552
  -6.77694649  -6.72206384  -6.71997062  -6.70339024  -6.68501373
  -6.55035087  -6.53637975  -6.53544734  -6.51820418  -6.48528917
  -6.47362572  -6.43176687  -6.42315718  -6.32418263  -6.28834113
  -6.23383601  -5.73843016  -5.6559233   -5.62903448  -5.61579673
  -5.58211056  -5.56808905  -5.41773478  -5.41681175  -5.39914398
  -5.3472021   -5.34113623  -5.32351909  -5.2737561   -5.11968813
  -5.08944247  -5.07848501  -5.02795798  -4.88350688  -4.87565908
  -4.82757292  -4.77444392  -4.6362783   -4.63049542  -4.60697954
  -4.42297854  -4.36932192  -4.28918088  -4.230832    -4.11600409
  -4.07483063  -4.03306984  -4.03104862  -3.89657065  -3.8858411
  -3.80709015  -3.75328905  -3.7297162   -3.61904238  -3.61173136
  -3.59536414  -3.56149099  -3.38726063  -3.38446715  -3.3322555
  -3.21746212  -2.64166233  -2.38277218  -1.91361965  -1.90178954]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Found existing model weights! Loading state dict...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:1
end of epoch 0: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.0076e-01, -3.2404e-06,  1.6064e-01, -1.9263e-01,  6.2569e-02,
          2.9884e-05,  3.7525e-02,  5.1190e-06,  2.4630e-05, -8.1880e-03,
          1.4535e-03, -4.8314e-01, -2.3008e+00]], device='cuda:1'))])
end of epoch 1: val_loss 0.9686711436509653, val_acc 0.98
trigger times: 1
end of epoch 2: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.7712e-01,  2.5194e-01, -1.0171e-02,  5.4008e-03,  1.2554e-01,
          1.4479e-01,  4.3254e-02, -1.4531e-03, -4.5914e-02, -3.4663e-01,
          1.4531e-03, -8.4089e-01, -2.8750e+00]], device='cuda:1'))])
end of epoch 3: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.5593e-01,  4.1884e-02, -2.2572e-02, -7.0725e-02,  2.7720e-02,
         -4.6799e-02,  3.0515e-02,  3.5701e-05, -4.5359e-06, -1.8598e-04,
          1.4530e-03, -2.7732e-01, -2.5686e+00]], device='cuda:1'))])
end of epoch 4: val_loss 3.5762777983450177e-09, val_acc 1.0
trigger times: 1
end of epoch 5: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.5161e-01,  1.9868e-01, -9.8265e-02, -4.3242e-02,  5.0564e-05,
          2.2327e-05,  4.5801e-03, -1.2032e-01,  1.8163e-05, -5.9918e-06,
          1.4526e-03, -6.0529e-01, -3.0721e+00]], device='cuda:1'))])
end of epoch 6: val_loss 5.483326458488591e-07, val_acc 1.0
trigger times: 1
end of epoch 7: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.3513e-01,  2.7913e-01, -2.0172e-01, -2.4960e-02,  2.7626e-01,
          6.2654e-05,  2.7422e-02, -1.5230e-01,  2.2951e-05,  1.6638e-05,
          1.4522e-03, -5.3999e-01, -3.5068e+00]], device='cuda:1'))])
end of epoch 8: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.2640e-01,  2.1478e-01,  1.8930e-01, -3.9189e-01,  2.5966e-01,
          4.2091e-02,  2.9603e-02, -1.6251e-01, -6.7114e-03, -3.6518e-02,
          1.4520e-03, -7.2065e-01, -3.1238e+00]], device='cuda:1'))])
end of epoch 9: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 5.2561e-01,  7.2714e-06, -1.8174e-01, -1.7804e-01, -1.6204e-05,
          3.7656e-05,  5.9417e-02, -3.3010e-02, -4.6900e-05, -4.0787e-05,
          1.4518e-03, -4.8819e-01, -2.9961e+00]], device='cuda:1'))])
end of epoch 10: val_loss 4.702695696323644e-07, val_acc 1.0
trigger times: 1
end of epoch 11: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 5.0375e-01,  1.0342e-01, -1.7031e-05, -2.8812e-02,  3.8980e-01,
         -2.5618e-05,  8.8596e-02, -2.0828e-02, -1.1381e-04, -1.9909e-01,
          1.4514e-03, -5.1953e-01, -2.7545e+00]], device='cuda:1'))])
end of epoch 12: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.0050e-01,  2.9549e-06, -7.5451e-04, -2.4074e-01,  2.5287e-01,
         -5.0917e-05,  3.3156e-02,  2.8135e-02, -5.1808e-04, -4.2490e-06,
          1.4512e-03, -4.2724e-01, -2.6143e+00]], device='cuda:1'))])
end of epoch 13: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 8.0857e-02, -8.3767e-05, -8.9595e-04, -1.3187e-01, -7.3544e-05,
         -1.0704e-04,  2.9918e-03,  4.4035e-06,  1.9008e-04, -7.7915e-05,
          1.4510e-03,  4.9246e-05, -1.9558e+00]], device='cuda:1'))])
end of epoch 14: val_loss 6.755276188528114e-06, val_acc 1.0
trigger times: 1
end of epoch 15: val_loss 0.13984144872174512, val_acc 0.99
trigger times: 2
end of epoch 16: val_loss 1.1920927533992654e-09, val_acc 1.0
trigger times: 3
end of epoch 17: val_loss 1.3232055607659276e-07, val_acc 1.0
trigger times: 4
end of epoch 18: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.3331e-01,  5.7132e-01, -1.6638e-01, -1.1708e-06,  1.3666e-01,
          5.7347e-02,  7.7917e-02, -1.8996e-01, -1.7871e-05, -2.5070e-01,
          1.4501e-03, -7.5279e-01, -3.6807e+00]], device='cuda:1'))])
end of epoch 19: val_loss 2.515252708690241e-07, val_acc 1.0
trigger times: 1
end of epoch 20: val_loss 2.6880972654907963e-07, val_acc 1.0
trigger times: 2
end of epoch 21: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 5.3266e-01,  1.8276e-01, -2.5399e-01, -8.0585e-02,  3.1431e-01,
          3.7378e-01,  1.2363e-01, -9.4657e-02,  1.9159e-06, -6.5973e-01,
          1.4495e-03, -1.2003e+00, -4.0721e+00]], device='cuda:1'))])
end of epoch 22: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.0256e-01,  5.7651e-07,  1.8697e-05, -1.2630e-05,  1.2094e-04,
         -6.0819e-05,  1.1786e-01, -5.0568e-02, -1.5228e-05, -7.5407e-02,
          1.4493e-03, -5.4775e-01, -3.7937e+00]], device='cuda:1'))])
end of epoch 23: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.0192e-01,  2.4645e-01, -4.9876e-03, -1.8713e-01,  1.6413e-01,
         -1.3935e-01,  5.9995e-02,  1.3177e-01, -1.6830e-04,  9.3125e-02,
          1.4491e-03, -8.5012e-01, -3.2184e+00]], device='cuda:1'))])
end of epoch 24: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.1265e-05,  2.1648e-05,  6.7606e-05, -2.6953e-01, -1.0361e-04,
         -1.5317e-04,  3.3294e-03, -1.8334e-05, -1.0033e-04,  8.1445e-05,
          1.4489e-03, -6.1785e-01, -1.6293e+00]], device='cuda:1'))])
end of epoch 25: val_loss 1.8505527259549126e-06, val_acc 1.0
trigger times: 1
end of epoch 26: val_loss 3.6595924001403547e-07, val_acc 1.0
trigger times: 2
end of epoch 27: val_loss 2.6642566808732226e-07, val_acc 1.0
trigger times: 3
end of epoch 28: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.3443e-01,  1.6191e-01, -3.4220e-02, -1.5463e-01,  2.9658e-01,
          1.9312e-05,  3.4014e-02, -1.5260e-05,  4.6978e-05,  1.1413e-05,
          1.4481e-03, -9.2884e-01, -2.5674e+00]], device='cuda:1'))])
end of epoch 29: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 8.4784e-02,  2.4967e-01,  7.7693e-06, -1.9995e-01,  3.7386e-01,
         -1.0156e-05,  2.5701e-02, -1.0081e-01, -1.6263e-05, -9.3300e-03,
          1.4479e-03, -8.2960e-01, -2.8402e+00]], device='cuda:1'))])
end of epoch 30: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-3.6083e-05,  6.1295e-02,  6.2131e-04, -7.8595e-02,  1.3539e-02,
         -7.5896e-03,  1.2897e-02, -3.8876e-02, -4.2203e-03,  7.3314e-03,
          1.4477e-03, -1.3843e-01, -2.4808e+00]], device='cuda:1'))])
end of epoch 31: val_loss 9.380890696775168e-07, val_acc 1.0
trigger times: 1
end of epoch 32: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.4750e-01,  2.5503e-01,  3.9614e-05, -2.5986e-01,  9.9828e-02,
         -7.0049e-06,  6.8040e-02, -1.4951e-01, -1.3503e-04, -4.8431e-05,
          1.4473e-03, -6.2911e-01, -3.0147e+00]], device='cuda:1'))])
end of epoch 33: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.4700e-02,  1.6147e-01,  1.3862e-01, -4.0744e-01,  2.5403e-01,
         -6.2251e-05,  5.0945e-02, -1.1938e-01, -1.7563e-04,  7.0169e-07,
          1.4471e-03, -4.3329e-01, -2.4139e+00]], device='cuda:1'))])
end of epoch 34: val_loss 2.8192202080390414e-07, val_acc 1.0
trigger times: 1
end of epoch 35: val_loss 9.16635399335064e-07, val_acc 1.0
trigger times: 2
end of epoch 36: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.3007e-01,  1.2031e-01, -1.3773e-01, -5.0717e-06, -1.3700e-04,
         -6.9756e-05,  6.7261e-02, -1.0626e-01,  5.9950e-05,  1.2800e-04,
          1.4465e-03, -2.5761e-01, -2.9390e+00]], device='cuda:1'))])
end of epoch 37: val_loss 1.1920927533992654e-09, val_acc 1.0
trigger times: 1
end of epoch 38: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.5883e-01,  2.5489e-01, -6.1196e-06, -2.3933e-01,  2.9700e-01,
          1.1615e-02, -2.0479e-03, -1.5616e-02, -8.9639e-05, -2.6816e-01,
          1.4461e-03, -8.1489e-01, -3.3793e+00]], device='cuda:1'))])
end of epoch 39: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-5.8668e-05,  3.4676e-02, -3.2995e-05, -6.5280e-02, -5.5389e-05,
         -2.3902e-05,  2.6301e-08, -5.0699e-07,  9.5442e-05, -1.0746e-05,
          1.4459e-03, -2.0790e-01, -2.8975e+00]], device='cuda:1'))])
end of epoch 40: val_loss 1.847740577431978e-08, val_acc 1.0
trigger times: 1
end of epoch 41: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 5.5505e-01,  1.0793e-01, -6.9680e-02, -5.2431e-02, -3.6870e-05,
         -4.6233e-05,  4.1594e-02, -3.3644e-02, -8.9973e-05,  2.1603e-06,
          1.4455e-03, -6.6733e-01, -3.3227e+00]], device='cuda:1'))])
end of epoch 42: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.1673e-01,  2.9331e-02,  3.5028e-01, -3.2116e-01,  2.8349e-01,
          3.9156e-02,  4.6116e-02, -4.8706e-02,  5.0659e-05, -1.5941e-03,
          1.4453e-03, -4.7608e-01, -2.6885e+00]], device='cuda:1'))])
end of epoch 43: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 8.5404e-02, -2.8323e-03,  1.2026e-02, -2.0484e-01,  3.7469e-04,
          3.1910e-02, -2.6122e-03, -3.3168e-02,  4.4409e-03, -2.7917e-02,
          1.4451e-03, -2.3612e-02, -1.3167e+00]], device='cuda:1'))])
end of epoch 44: val_loss 1.907344994833693e-08, val_acc 1.0
trigger times: 1
end of epoch 45: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.4462e-01,  2.2316e-01,  2.0887e-05, -2.1605e-01,  4.7815e-05,
          9.5594e-05,  2.6829e-02, -7.7999e-02, -5.2914e-05,  3.5694e-05,
          1.4447e-03, -7.0629e-01, -2.2900e+00]], device='cuda:1'))])
end of epoch 46: val_loss 0.0002578979358076694, val_acc 1.0
trigger times: 1
end of epoch 47: val_loss 1.1920915312657598e-08, val_acc 1.0
trigger times: 2
end of epoch 48: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.0865e-01,  2.6019e-01,  9.5412e-06, -1.7232e-01,  4.8119e-05,
         -6.3584e-05,  5.8147e-02, -1.6529e-02, -1.1653e-04, -4.7152e-05,
          1.4441e-03, -2.3553e-01, -2.5104e+00]], device='cuda:1'))])
end of epoch 49: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.4748e-01,  2.7630e-01,  8.3798e-02, -3.9153e-02,  6.0954e-05,
          3.1134e-01,  1.0577e-01, -3.4741e-02,  3.1810e-01, -4.5359e-01,
          1.4439e-03, -6.4985e-01, -3.1189e+00]], device='cuda:1'))])
end of epoch 50: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.5545e-01,  7.6628e-01, -2.1604e-01, -5.4638e-02,  3.6630e-01,
          1.2390e-01,  9.6654e-02, -1.6927e-01, -1.1848e-01, -5.5734e-01,
          1.4437e-03, -9.3838e-01, -3.8718e+00]], device='cuda:1'))])
end of epoch 51: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 5.6506e-02,  5.6611e-01,  2.6161e-06, -2.5199e-01,  4.3271e-04,
          8.4494e-05,  8.8976e-02, -2.1918e-01,  3.2934e-05, -3.5415e-02,
          1.4435e-03, -7.4263e-01, -3.6363e+00]], device='cuda:1'))])
end of epoch 52: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.0313e-04,  2.2998e-01,  1.0565e-04, -8.9055e-02, -5.7323e-05,
         -4.8435e-05,  7.0418e-02, -1.7526e-01,  9.8707e-06, -1.1506e-04,
          1.4433e-03, -4.1503e-03, -3.1120e+00]], device='cuda:1'))])
end of epoch 53: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.8749e-01,  1.2970e-01, -3.3319e-02, -1.8467e-01,  1.0229e-04,
          2.0544e-01,  9.4987e-02, -6.7729e-07,  1.6297e-04, -3.7152e-01,
          1.4431e-03, -7.9033e-01, -3.7281e+00]], device='cuda:1'))])
end of epoch 54: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.4655e-01,  9.5955e-02,  4.1818e-05, -2.7729e-01,  3.7744e-02,
          1.4237e-05,  8.8748e-02,  5.1620e-02, -1.4639e-04,  1.5225e-06,
          1.4429e-03, -6.3431e-01, -3.4242e+00]], device='cuda:1'))])
end of epoch 55: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.8871e-01,  1.6172e-05, -2.9553e-02, -4.2259e-01,  4.6514e-05,
          1.4769e-04,  3.4755e-02,  2.7866e-07,  1.2289e-04, -8.4195e-05,
          1.4427e-03, -5.5927e-01, -2.6838e+00]], device='cuda:1'))])
end of epoch 56: val_loss 5.602818973216017e-08, val_acc 1.0
trigger times: 1
end of epoch 57: val_loss 1.1699023161781951e-06, val_acc 1.0
trigger times: 2
end of epoch 58: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.0485e-01,  1.1079e-01,  6.1228e-03, -2.9299e-01,  6.4832e-02,
         -3.0769e-05,  8.2322e-02, -7.4838e-06,  5.5697e-05, -4.0770e-05,
          1.4421e-03, -5.7256e-01, -2.7434e+00]], device='cuda:1'))])
end of epoch 59: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.1074e-01,  6.3256e-02,  8.0746e-05, -2.6376e-01,  1.2804e-05,
         -6.9749e-06,  5.3313e-02,  1.9968e-02,  6.3648e-05,  4.5377e-05,
          1.4419e-03, -9.8468e-02, -2.2312e+00]], device='cuda:1'))])
end of epoch 60: val_loss 1.0609513992676511e-07, val_acc 1.0
trigger times: 1
end of epoch 61: val_loss 1.3255355415822123e-05, val_acc 1.0
trigger times: 2
end of epoch 62: val_loss 0.0003405081346846828, val_acc 1.0
trigger times: 3
end of epoch 63: val_loss 0.00010420712875202299, val_acc 1.0
trigger times: 4
end of epoch 64: val_loss 5.9604610669339305e-09, val_acc 1.0
trigger times: 5
end of epoch 65: val_loss 1.0715767711744206e-06, val_acc 1.0
trigger times: 6
end of epoch 66: val_loss 4.1723234289747776e-09, val_acc 1.0
trigger times: 7
end of epoch 67: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.1869e-01,  1.0218e-01, -1.3717e-02, -2.2786e-01,  9.3142e-05,
          2.6832e-01,  4.6414e-02, -2.9545e-01,  1.3806e-01, -2.6298e-01,
          1.4404e-03, -9.8412e-01, -3.7665e+00]], device='cuda:1'))])
end of epoch 68: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.0328e-04,  1.9247e-01, -1.2882e-05, -1.0528e-01, -3.7931e-05,
         -1.4417e-05,  4.2622e-02, -5.4021e-02,  1.9209e-04, -8.8820e-06,
          1.4402e-03, -6.5478e-01, -3.3226e+00]], device='cuda:1'))])
end of epoch 69: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.8628e-02,  1.2603e-01, -3.7463e-05, -2.0511e-01, -8.3330e-06,
          1.4119e-04,  5.3389e-08,  4.5556e-02, -1.1883e-04,  5.6432e-05,
          1.4400e-03, -2.5055e-01, -2.2353e+00]], device='cuda:1'))])
end of epoch 70: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.9379e-01,  4.1074e-01, -1.1450e-01, -4.8991e-02,  1.6096e-01,
         -1.2192e-01,  4.0188e-02, -1.3588e-01, -1.1878e-01, -4.6622e-01,
          1.4398e-03, -1.0548e+00, -3.4470e+00]], device='cuda:1'))])
end of epoch 71: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.3349e-01,  2.9740e-01,  9.4023e-02, -2.9056e-01,  1.6024e-01,
          5.6360e-06,  3.2452e-02, -1.0674e-01, -2.7290e-05, -2.1659e-05,
          1.4396e-03, -9.1543e-01, -3.2052e+00]], device='cuda:1'))])
end of epoch 72: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.9548e-01,  1.1369e-01,  1.4865e-01, -5.7994e-01,  2.5314e-01,
          4.4185e-02,  1.6200e-03, -9.1359e-02,  3.2345e-02, -1.1080e-01,
          1.4394e-03, -9.0647e-01, -2.5810e+00]], device='cuda:1'))])
end of epoch 73: val_loss 0.016210402807291757, val_acc 0.995
trigger times: 1
end of epoch 74: val_loss 5.400549671179533e-06, val_acc 1.0
trigger times: 2
end of epoch 75: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 3
end of epoch 76: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.1206e-01,  1.3559e-01,  2.4359e-06, -3.5918e-01,  9.0627e-05,
         -1.1320e-05,  1.2615e-02, -4.9871e-02,  1.3256e-04, -5.1566e-05,
          1.4386e-03, -2.2998e-01, -3.2263e+00]], device='cuda:1'))])
end of epoch 77: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.6066e-04,  8.8436e-03,  1.8817e-04, -1.8960e-01,  7.9893e-05,
         -5.5743e-05, -2.0755e-04, -2.4807e-04, -1.3958e-04, -2.6145e-04,
          1.4384e-03,  2.2827e-04, -2.6994e+00]], device='cuda:1'))])
end of epoch 78: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.4719e-01,  3.3441e-01, -2.4649e-01, -7.9057e-02,  1.8351e-01,
         -5.7499e-06,  8.7080e-02, -2.5692e-01, -3.6631e-05, -1.2493e-01,
          1.4382e-03, -7.4618e-01, -3.2621e+00]], device='cuda:1'))])
end of epoch 79: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 5.3599e-02,  2.3523e-01, -4.6766e-02,  3.1745e-06, -2.5638e-07,
          1.8171e-04,  8.2417e-02, -1.1880e-01, -9.1226e-05,  9.4777e-05,
          1.4380e-03, -2.0129e-02, -3.0299e+00]], device='cuda:1'))])
end of epoch 80: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.0069e-01,  1.9003e-01, -6.5740e-02, -3.1556e-01,  7.1355e-05,
          1.8502e-04,  3.5140e-02, -1.2432e-01,  1.8115e-04,  2.6795e-05,
          1.4378e-03, -1.0351e-01, -2.4891e+00]], device='cuda:1'))])
end of epoch 81: val_loss 0.0002553052129223943, val_acc 1.0
trigger times: 1
end of epoch 82: val_loss 1.4231563545763492e-06, val_acc 1.0
trigger times: 2
end of epoch 83: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.9515e-01,  8.1655e-01, -3.9752e-01, -1.3628e-01,  2.2024e-01,
         -1.1225e-01,  7.5139e-02, -1.7683e-02, -6.3934e-02, -2.0673e-02,
          1.4372e-03, -1.2596e+00, -3.5701e+00]], device='cuda:1'))])
end of epoch 84: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.4515e-01,  3.5238e-01, -1.9275e-01, -3.0237e-01,  5.7713e-05,
          4.0346e-02,  5.8136e-02, -1.8982e-01,  7.0804e-06, -1.3942e-01,
          1.4370e-03, -1.0573e+00, -3.3167e+00]], device='cuda:1'))])
end of epoch 85: val_loss 2.9802313861182485e-09, val_acc 1.0
trigger times: 1
end of epoch 86: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.8782e-01,  3.1609e-01,  1.3752e-01, -1.8715e-01,  1.8272e-01,
          2.3253e-01,  1.1049e-01, -9.7336e-02, -4.0374e-06, -5.3034e-01,
          1.4366e-03, -1.1300e+00, -3.1112e+00]], device='cuda:1'))])
end of epoch 87: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.3625e-01,  1.5422e-01,  4.1141e-05, -7.1103e-02, -5.2238e-05,
         -3.4495e-05,  1.0022e-01, -4.5031e-02, -4.9192e-06, -1.7937e-04,
          1.4364e-03, -4.8220e-01, -2.9067e+00]], device='cuda:1'))])
end of epoch 88: val_loss 1.1920927533992654e-09, val_acc 1.0
trigger times: 1
end of epoch 89: val_loss 1.3351262168725952e-07, val_acc 1.0
trigger times: 2
end of epoch 90: val_loss 9.179030712402891e-08, val_acc 1.0
trigger times: 3
end of epoch 91: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.2981e-01,  3.4584e-01,  1.7981e-01, -3.2946e-01,  2.3275e-01,
          3.2646e-02,  2.2086e-02, -1.4831e-01, -6.2162e-05, -3.2110e-02,
          1.4356e-03, -6.6991e-01, -1.8828e+00]], device='cuda:1'))])
end of epoch 92: val_loss 5.9604610669339305e-09, val_acc 1.0
trigger times: 1
end of epoch 93: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.7301e-01,  1.7577e-01,  2.1474e-05, -7.3844e-02, -1.3160e-04,
         -5.9595e-06,  1.7938e-02, -1.4602e-01, -8.7311e-05,  1.0146e-05,
          1.4352e-03, -3.6790e-01, -2.3366e+00]], device='cuda:1'))])
end of epoch 94: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 5.0426e-02,  9.7224e-02, -2.0725e-03, -6.0126e-02,  2.6625e-03,
         -1.2383e-02, -2.9338e-03, -2.7727e-03,  2.3992e-03,  3.9559e-03,
          1.4350e-03, -4.7324e-03, -1.6252e+00]], device='cuda:1'))])
end of epoch 95: val_loss 2.9622631700476634e-07, val_acc 1.0
trigger times: 1
end of epoch 96: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.2347e-01,  4.4767e-01,  7.2649e-02, -2.1898e-01,  7.0477e-01,
         -1.1546e-05,  9.0356e-02, -7.8990e-02,  5.3558e-05, -2.5615e-01,
          1.4346e-03, -1.1041e+00, -2.8269e+00]], device='cuda:1'))])
end of epoch 97: val_loss 0.14892656326293946, val_acc 0.99
trigger times: 1
end of epoch 98: val_loss 3.279576078057289e-05, val_acc 1.0
trigger times: 2
end of epoch 99: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.7418e-01,  2.3804e-01, -3.5450e-01, -1.5417e-02,  6.3763e-06,
          1.0103e-04,  8.0196e-03, -6.7657e-02,  1.7939e-05, -6.0460e-02,
          1.4340e-03, -6.9389e-01, -3.1394e+00]], device='cuda:1'))])
Finished training.
0 -211.0231111049652 -63.24332377487188
1 -209.53434038162231 -63.030885905493825
2 -187.48763811588287 -62.456590578936265
3 -207.93472146987915 -61.90503048142668
4 -209.4765293598175 -61.60739548938859
5 -210.37102913856506 -61.42319102765305
6 -210.38906741142273 -61.11705014319021
7 -209.0624279975891 -60.558741281972964
8 -207.07504415512085 -60.27108477913709
9 -208.20069861412048 -60.150297575665455
10 -209.48593759536743 -60.02722507553617
11 -207.4495747089386 -59.659980343930265
12 -184.73411321640015 -59.42210571514803
13 -203.44061088562012 -59.36377349868506
14 -207.86600875854492 -59.30965761818191
15 -183.943514585495 -58.85869868155896
16 -181.35227727890015 -58.78920471727304
17 -208.2180519104004 -58.60985472039149
18 -209.2741105556488 -58.476339788678885
19 -184.14944565296173 -58.346877938980676
20 -204.49890995025635 -58.08611589826112
21 -181.85831236839294 -57.89906438864594
22 -205.9449725151062 -57.78201502659843
23 -205.54591369628906 -57.38102245265812
24 -180.7928717136383 -57.1606178908599
25 -204.899405002594 -57.04573717234338
26 -206.48938012123108 -56.70057749407034
27 -205.27780628204346 -56.32819743601017
28 -202.91208577156067 -55.96407104627361
29 -202.22617554664612 -55.329757893435094
30 -133.4898999929428 -50.492268601198035
31 -134.64171797037125 -46.98011874490918
32 -133.7609157562256 -44.14602409201361
33 -117.02021178603172 -42.00401746161006
34 -144.18592435121536 -40.44278203413966
35 -99.79841953516006 -39.31972693233231
36 -121.46689647436142 -38.35634328077039
37 -125.23099875450134 -37.513139380385574
38 -123.23711982369423 -36.821916772458344
39 -106.42141482234001 -36.114459029559086
40 -117.72673749923706 -35.24303541418371
41 -85.60828901827335 -34.64469044638467
42 -97.81240743398666 -31.7109134007892
43 -90.11812600493431 -31.12953085092458
44 -85.46019184589386 -27.41102349748205
45 -79.24687841534615 -26.7047217556024
46 -96.6009979993105 -24.879106999799365
47 -95.41245645284653 -23.57262108435893
48 -69.86825594305992 -22.19891031871716
49 -52.90849834680557 -20.13839114930498
50 -75.36313323676586 -18.92838809611677
51 -30.66520318388939 -17.287730301408818
52 -27.915177166461945 -16.67001723842762
53 -31.846854373812675 -15.835297177460307
54 -12.208408430218697 -15.499642599313287
55 -14.588774062693119 -15.164890192965451
56 -31.247322648763657 -15.058223915588862
57 -14.300988182425499 -14.79949309890538
58 -12.568922832608223 -14.468743544178729
59 -13.412069290876389 -14.32942425861741
60 -28.735404431819916 -13.999015758512774
61 -11.647667661309242 -13.826829460074968
62 -29.440037101507187 -13.608891999152753
63 -30.954633206129074 -13.537173252032721
64 -27.55761408805847 -13.350537733785846
65 -29.219813525676727 -13.171936739318621
66 -32.872679352760315 -12.988045670217158
67 -8.32522964477539 -12.714128301472396
68 -26.475098118185997 -12.684766625629942
69 -8.207632567733526 -12.60505428627584
70 -12.329193621873856 -12.489606634434601
71 -29.426588021218777 -12.370135820080268
72 -27.40019914507866 -12.243403879196388
73 -64.31159180402756 -12.151904772081672
74 -12.226080313324928 -12.076481989890604
75 -9.10628379136324 -11.913927973039872
76 -28.889908000826836 -11.772412895153552
77 -29.97384661436081 -11.67545400252302
78 -26.47202794253826 -11.482140762671794
79 -7.276863344013691 -11.318350751526424
80 -30.32205517590046 -11.074605562523185
81 -30.4652928262949 -10.8936872753186
82 -26.36016261205077 -10.845290734893993
83 -11.817351207137108 -10.687545353047717
84 -29.729067236185074 -10.451560303375969
85 -34.346899181604385 -10.3270166115354
86 -25.573572725057602 -10.069178353474605
87 -22.316018417477608 -9.936674043396035
88 -22.88522132486105 -9.843252216045357
89 -24.39312992990017 -9.630069973226872
90 -29.79483813047409 -9.436338457972072
91 -24.958506546914577 -9.359900431081572
92 -24.41428352892399 -9.318532890899364
93 -26.0958119481802 -9.229542857842185
94 -25.285180754959583 -9.136248135880153
95 -5.902024894952774 -9.007482366079063
96 -25.95545084774494 -8.77833829395191
97 -25.987223103642464 -8.491850672526503
98 -42.69733937084675 -8.330116995310416
99 -3.8775045052170753 -8.109265697684156
100 -4.542238436639309 -7.6117366904762305
101 -8.874762684106827 -7.440920124149799
102 -32.5124121978879 -6.959063561385431
103 -25.79591217637062 -6.776946485018116
104 -4.53937067091465 -6.685013730616453
105 -43.17937192320824 -6.51820418055673
106 -4.475093714892864 -6.423157183581381
107 -3.3244860991835594 -5.738430155643535
108 -4.8831717520952225 -5.582110560177944
109 -8.924564585089684 -5.399143980669317
110 0.8949621021747589 -5.273756100604971
111 -31.441621720790863 -5.027957977402961
112 -4.581136524677277 -4.774443920126966
113 -2.8100441433489323 -4.422978544752843
114 -1.37954605743289 -4.116004088000472
115 -3.3173626959323883 -3.8965706545663026
116 1.9604062139987946 -3.7297162032160345
117 0.8585210740566254 -3.5614909941883552
118 0.1469295471906662 -3.21746212350103
119 2.2814661413431168 -1.901789541388503
train accuracy: 0.9988888888888889
validation accuracy: 1.0
[-63.24332377 -63.23599055 -63.21105585 -63.1277899  -63.03088591
 -62.97836141 -62.80700329 -62.59841154 -62.45659058 -62.22052465
 -62.05545976 -61.99823876 -61.90503048 -61.9024977  -61.84514296
 -61.80958936 -61.60739549 -61.57987077 -61.52954719 -61.49152331
 -61.42319103 -61.37818898 -61.3242033  -61.18861045 -61.11705014
 -61.1111952  -61.05040259 -60.70125881 -60.55874128 -60.49758829
 -60.33754647 -60.3056539  -60.27108478 -60.26518611 -60.24509979
 -60.22805253 -60.15029758 -60.10592506 -60.09749463 -60.0319431
 -60.02722508 -59.93393272 -59.80496242 -59.7917769  -59.65998034
 -59.5305981  -59.50104536 -59.42996515 -59.42210572 -59.38924773
 -59.38736621 -59.38054209 -59.3637735  -59.35705669 -59.33804201
 -59.3275818  -59.30965762 -59.10615862 -59.10256234 -58.91394416
 -58.85869868 -58.83781287 -58.805901   -58.78928523 -58.78920472
 -58.74515985 -58.7335467  -58.6909254  -58.60985472 -58.59427563
 -58.58165728 -58.52164071 -58.47633979 -58.46066973 -58.43515991
 -58.42948108 -58.34687794 -58.3224997  -58.26697037 -58.26037219
 -58.18129208 -58.0861159  -57.99583108 -57.97256269 -57.92377717
 -57.89906439 -57.86612124 -57.85252143 -57.79024149 -57.78201503
 -57.76493642 -57.72031285 -57.55593357 -57.38102245 -57.37258309
 -57.21444707 -57.21200816 -57.16061789 -57.12957694 -57.07621127
 -57.06529087 -57.04573717 -56.88160157 -56.87555564 -56.72292153
 -56.70057749 -56.62581458 -56.40969062 -56.40899696 -56.32819744
 -56.0810036  -56.05279704 -55.96543435 -55.96407105 -55.93162024
 -55.67010668 -55.50073526 -55.32975789 -54.98547503 -54.6753876
 -53.06095904 -50.4922686  -50.03933802 -49.75347185 -49.72654641
 -46.98011874 -45.73515428 -45.67057988 -44.99030608 -44.14602409
 -43.81326882 -43.18878399 -42.29180715 -42.00401746 -41.69100444
 -41.68588229 -41.2817771  -40.44278203 -40.34838366 -39.59970115
 -39.57586365 -39.31972693 -39.02461056 -38.45534494 -38.4127039
 -38.35634328 -37.79713617 -37.74152899 -37.66475324 -37.51313938
 -37.1809993  -37.10070314 -37.00630589 -36.82191677 -36.48799015
 -36.2096527  -36.19207562 -36.11445903 -35.78149902 -35.39450387
 -35.262825   -35.24303541 -35.20970524 -35.06544085 -34.80241748
 -34.64469045 -33.84284986 -32.70706485 -31.9690994  -31.7109134
 -31.64414356 -31.39238276 -31.22319602 -31.12953085 -29.3915714
 -29.34012561 -29.10618999 -27.4110235  -27.34372236 -27.19668163
 -27.07399029 -26.70472176 -26.2447949  -25.54836509 -25.45878529
 -24.879107   -24.82869536 -24.59274514 -23.97874558 -23.57262108
 -23.44970808 -22.74530916 -22.60679894 -22.19891032 -20.65686376
 -20.44447256 -20.29688418 -20.23141807 -20.1969901  -20.13839115
 -20.13020095 -19.84155928 -19.71548984 -19.68899137 -19.68187944
 -19.63760344 -19.51559872 -19.46242624 -19.4608337  -19.4041006
 -19.3558728  -18.9283881  -18.73129823 -18.6143711  -18.59559194
 -18.46499943 -18.43877077 -18.38621926 -18.27561534 -17.99477406
 -17.82791039 -17.5574237  -17.4225533  -17.32401372 -17.2877303
 -17.27734589 -17.17142851 -17.09111514 -16.99919682 -16.94289066
 -16.90794731 -16.87179876 -16.82307393 -16.73124049 -16.67001724
 -16.58659093 -16.32507254 -16.14499025 -16.11471807 -15.99550761
 -15.96630994 -15.89510862 -15.83529718 -15.73508957 -15.71653035
 -15.65454388 -15.64362673 -15.4996426  -15.47055242 -15.37516569
 -15.29900699 -15.2719524  -15.1811829  -15.16489019 -15.13026299
 -15.1168859  -15.11310895 -15.09811232 -15.05822392 -14.9375075
 -14.92482994 -14.89671643 -14.8550828  -14.7994931  -14.77688108
 -14.77118432 -14.65980608 -14.594561   -14.56214362 -14.5314246
 -14.51447881 -14.50408185 -14.46874354 -14.44242009 -14.42193758
 -14.36850066 -14.33258    -14.32950177 -14.32942426 -14.25516391
 -14.23740337 -14.21922258 -14.08340118 -14.04266231 -14.00918138
 -14.00356944 -13.99901576 -13.98069366 -13.96863183 -13.94553084
 -13.92064094 -13.86308449 -13.82682946 -13.82168222 -13.74201371
 -13.73538513 -13.70157677 -13.67248689 -13.65984887 -13.608892
 -13.59601285 -13.58322451 -13.5769007  -13.56118218 -13.53717325
 -13.50058897 -13.49625934 -13.48391162 -13.42154574 -13.35053773
 -13.33224936 -13.24746818 -13.21474879 -13.17814269 -13.17193674
 -13.13997741 -13.07123989 -12.9932924  -12.9911753  -12.98804567
 -12.97789981 -12.94572355 -12.93760188 -12.89533945 -12.89281313
 -12.7141283  -12.71256262 -12.70915032 -12.69913989 -12.68787728
 -12.68476663 -12.68403935 -12.68135973 -12.67795632 -12.66418206
 -12.60694569 -12.60505429 -12.59604001 -12.59146077 -12.58492544
 -12.5568266  -12.54337072 -12.48960663 -12.48846703 -12.47314213
 -12.41787343 -12.38653875 -12.37245474 -12.37013582 -12.36609991
 -12.34671509 -12.30017947 -12.24340388 -12.21444028 -12.20423388
 -12.19488362 -12.17081576 -12.1638277  -12.15190477 -12.11267893
 -12.10286355 -12.07990884 -12.07648199 -11.97628117 -11.9718797
 -11.94387787 -11.91392797 -11.80244434 -11.78885214 -11.78173063
 -11.7724129  -11.76007221 -11.72649421 -11.70702865 -11.675454
 -11.67485775 -11.6440414  -11.54576322 -11.48214076 -11.47061442
 -11.40958857 -11.39809208 -11.39514232 -11.35591972 -11.31835075
 -11.27863965 -11.11165846 -11.10389205 -11.077133   -11.07648117
 -11.07460556 -10.9955771  -10.98789819 -10.96193206 -10.89368728
 -10.88947284 -10.88447672 -10.8699891  -10.84529073 -10.83771365
 -10.77157448 -10.7626531  -10.72252648 -10.68754535 -10.61795776
 -10.59932568 -10.56525508 -10.54372397 -10.503667   -10.4627546
 -10.4515603  -10.44415981 -10.37561746 -10.3276815  -10.32701661
 -10.31898966 -10.30373604 -10.17869462 -10.15370275 -10.129968
 -10.12345655 -10.06917835 -10.05434057 -10.04940452  -9.98600954
  -9.97495295  -9.93667404  -9.89890309  -9.87343312  -9.85721598
  -9.84881233  -9.84325222  -9.79295249  -9.76873248  -9.70803505
  -9.70232992  -9.63006997  -9.61577792  -9.60162068  -9.58053743
  -9.49727871  -9.47919626  -9.43866282  -9.43633846  -9.41778779
  -9.41052059  -9.40824698  -9.4057227   -9.35990043  -9.34464202
  -9.34459136  -9.34125766  -9.34040597  -9.31853289  -9.29755911
  -9.28970959  -9.25632952  -9.22954286  -9.22723903  -9.1921269
  -9.15969438  -9.13624814  -9.12404452  -9.09796099  -9.09284414
  -9.0417146   -9.00748237  -8.99211937  -8.9703478   -8.93076101
  -8.8972749   -8.77833829  -8.77596385  -8.75445976  -8.74668312
  -8.60684626  -8.49185067  -8.43284839  -8.39800134  -8.3384229
  -8.33111246  -8.330117    -8.30246843  -8.28329195  -8.25863217
  -8.19902254  -8.13319584  -8.1092657   -8.10819769  -8.1047694
  -7.76388228  -7.75584261  -7.65826784  -7.65808398  -7.61173669
  -7.57539849  -7.55046962  -7.51737497  -7.44092012  -7.41820171
  -7.37450683  -7.36244313  -7.23588878  -7.17946489  -7.10832736
  -6.95906356  -6.94047157  -6.92998266  -6.91436759  -6.91427984
  -6.91024552  -6.87856825  -6.78323296  -6.77694649  -6.72206384
  -6.71997062  -6.70339024  -6.68501373  -6.5779849   -6.57146323
  -6.55182982  -6.55035087  -6.53637975  -6.53544734  -6.52502436
  -6.51820418  -6.48528917  -6.47362572  -6.43176687  -6.42315718
  -6.4216571   -6.37598427  -6.32418263  -6.28899961  -6.28834113
  -6.24441631  -6.23383601  -6.15634472  -6.13122052  -5.88131406
  -5.73843016  -5.6559233   -5.62903448  -5.61579673  -5.58211056
  -5.56808905  -5.41773478  -5.41681175  -5.39914398  -5.3472021
  -5.34113623  -5.32351909  -5.2737561   -5.11968813  -5.1133638
  -5.08944247  -5.07848501  -5.02795798  -4.88350688  -4.87565908
  -4.82757292  -4.77444392  -4.6362783   -4.63120683  -4.63049542
  -4.60697954  -4.48417321  -4.47381185  -4.42297854  -4.36932192
  -4.28918088  -4.2741627   -4.27150294  -4.230832    -4.15758284
  -4.11600409  -4.07483063  -4.03306984  -4.03104862  -3.98692761
  -3.89657065  -3.8858411   -3.88252014  -3.80709015  -3.80423161
  -3.75328905  -3.7297162   -3.61904238  -3.61173136  -3.59536414
  -3.56149099  -3.38726063  -3.38446715  -3.3322555   -3.26399767
  -3.21746212  -2.64166233  -2.38277218  -1.91361965  -1.90178954]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Found existing model weights! Loading state dict...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:1
end of epoch 0: val_loss 0.10661418967531035, val_acc 0.995
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.2028e-01,  1.6527e-01, -1.5884e-01, -4.1835e-01,  6.2881e-01,
         -2.2782e-01,  1.3301e-01,  4.5385e-02, -2.3010e-01,  5.1413e-02,
          4.8525e-04, -1.5624e+00, -3.1184e+00]], device='cuda:1'))])
end of epoch 1: val_loss 0.01710881541773347, val_acc 0.99
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.1199e-01, -1.3438e-01,  7.8231e-02, -2.5490e-01,  3.5110e-01,
         -3.7966e-01,  3.0034e-02,  1.0825e-01, -1.5625e-01,  2.0497e-01,
         -8.0777e-04, -1.9177e+00, -3.0538e+00]], device='cuda:1'))])
end of epoch 2: val_loss 6.923905066198443e-05, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-5.3836e-02, -1.0602e-05, -1.6244e-05, -1.2798e-01,  7.4426e-05,
         -6.1195e-05,  1.9343e-02,  6.4893e-02,  2.2650e-05, -4.9825e-05,
         -5.5106e-05, -1.4915e+00, -2.6598e+00]], device='cuda:1'))])
end of epoch 3: val_loss 3.796677582101893e-07, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.2582e-01,  2.6500e-01, -2.2089e-01, -3.9617e-01,  6.7934e-01,
         -5.1241e-01,  9.6032e-02,  1.5266e-01, -1.7286e-01,  2.7768e-01,
          5.5457e-04, -2.2250e+00, -2.9509e+00]], device='cuda:1'))])
end of epoch 4: val_loss 1.7673497059149667e-05, val_acc 1.0
trigger times: 1
end of epoch 5: val_loss 6.534817099222323e-05, val_acc 1.0
trigger times: 2
end of epoch 6: val_loss 0.00016702169298689286, val_acc 1.0
trigger times: 3
end of epoch 7: val_loss 0.13558992028236388, val_acc 0.99
trigger times: 4
end of epoch 8: val_loss 5.251685157418251e-05, val_acc 1.0
trigger times: 5
end of epoch 9: val_loss 3.4443114598694536e-05, val_acc 1.0
trigger times: 6
end of epoch 10: val_loss 0.22825570343483378, val_acc 0.985
trigger times: 7
end of epoch 11: val_loss 0.2723557668924331, val_acc 0.99
trigger times: 8
end of epoch 12: val_loss 4.589536729326937e-08, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.0045e-01, -7.4912e-02, -1.2575e-01, -1.1132e-02,  1.1872e-05,
         -5.6464e-01,  9.8840e-02,  7.3241e-02, -2.2638e-05, -7.6346e-06,
         -1.6414e-03, -3.1807e+00, -3.1547e+00]], device='cuda:1'))])
end of epoch 13: val_loss 0.000136525807797625, val_acc 1.0
trigger times: 1
end of epoch 14: val_loss 0.0007631665645360642, val_acc 1.0
trigger times: 2
end of epoch 15: val_loss 0.29355713337123235, val_acc 0.985
trigger times: 3
end of epoch 16: val_loss 3.2967855804599822e-06, val_acc 1.0
trigger times: 4
end of epoch 17: val_loss 1.1920927533992654e-09, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.2590e-05, -4.2394e-02, -5.3056e-05, -1.0658e-01, -1.5346e-04,
          1.8902e-05,  3.3309e-02,  5.4583e-03, -4.2077e-04,  5.5319e-06,
          3.1271e-04, -2.1595e+00, -2.6012e+00]], device='cuda:1'))])
end of epoch 18: val_loss 0.00017256696750902022, val_acc 1.0
trigger times: 1
end of epoch 19: val_loss 0.037454655486121737, val_acc 0.995
trigger times: 2
end of epoch 20: val_loss 0.04267533957958108, val_acc 0.995
trigger times: 3
end of epoch 21: val_loss 0.004434269815624248, val_acc 0.995
trigger times: 4
end of epoch 22: val_loss 5.148569203438313e-05, val_acc 1.0
trigger times: 5
end of epoch 23: val_loss 0.0017936262488344923, val_acc 1.0
trigger times: 6
end of epoch 24: val_loss 0.0015904650092120676, val_acc 1.0
trigger times: 7
end of epoch 25: val_loss 0.0004403676402829504, val_acc 1.0
trigger times: 8
end of epoch 26: val_loss 2.1963167600915767e-05, val_acc 1.0
trigger times: 9
end of epoch 27: val_loss 8.21326928956978e-07, val_acc 1.0
trigger times: 10
Early stopping.
0 -212.86562848091125 -63.24332377487188
1 -213.8763930797577 -62.97836140843108
2 -211.59040427207947 -62.05545975816537
3 -210.83720231056213 -61.809589362036306
4 -210.56455183029175 -61.42319102765305
5 -210.29732584953308 -61.11119519527381
6 -206.3153305053711 -60.337546473897575
7 -202.47859692573547 -60.22805253280421
8 -208.05253100395203 -60.02722507553617
9 -207.55401992797852 -59.5305981022574
10 -206.43152832984924 -59.38736621066678
11 -202.0488085746765 -59.32758179937661
12 -201.35118675231934 -58.85869868155896
13 -200.16780710220337 -58.74515985173664
14 -206.60539889335632 -58.581657282953636
15 -199.981586933136 -58.346877938980676
16 -205.16962361335754 -58.08611589826112
17 -205.6386845111847 -57.86612123508526
18 -204.83252358436584 -57.72031284894193
19 -204.35668396949768 -57.2120081575398
20 -203.88116312026978 -57.04573717234338
21 -202.1990101337433 -56.625814583124
22 -202.22758197784424 -56.05279704179098
23 -200.81439089775085 -55.50073525963863
24 -103.65925660729408 -50.492268601198035
25 -111.96633636951447 -45.7351542845057
26 -88.45160151273012 -43.18878399086166
27 -94.80744379758835 -41.281777102712205
28 -84.40598380565643 -39.31972693233231
29 -90.31999093294144 -37.79713616772368
30 -94.82108122110367 -37.100703136010694
31 -81.88368144631386 -36.19207561676116
32 -105.6801415681839 -35.24303541418371
33 -74.18885046243668 -33.84284985953318
34 -79.54112470149994 -31.392382758954444
35 -89.2985902428627 -29.106189988903285
36 -73.75709649920464 -26.7047217556024
37 -66.37664260715246 -24.828695359328833
38 -77.18141585588455 -22.745309160183492
39 -49.29134654998779 -20.29688417998109
40 -48.07421827316284 -19.841559282674098
41 -51.21049304306507 -19.515598718228343
42 -44.52935428917408 -18.92838809611677
43 -44.12173867225647 -18.438770773379506
44 -43.90169108659029 -17.55742370467821
45 -43.18506038188934 -17.091115141548915
46 -50.58182245492935 -16.823073927842348
47 -40.497770726680756 -16.14499025185365
48 -32.542154267430305 -15.835297177460307
49 -36.09457156062126 -15.499642599313287
50 -35.69605112075806 -15.181182902809962
51 -30.882915884256363 -15.098112319720741
52 -36.78182902559638 -14.855082803515382
53 -28.424622863531113 -14.594561003997004
54 -33.41378492116928 -14.468743544178729
55 -32.36737668514252 -14.329501769060094
56 -30.02322480082512 -14.083401177177324
57 -37.184252083301544 -13.980693659734555
58 -33.687220364809036 -13.826829460074968
59 -29.7375685274601 -13.672486891155406
60 -28.947888523340225 -13.57690069878421
61 -28.828042078763247 -13.483911619341129
62 -38.41985535621643 -13.214748785789967
63 -30.80203513801098 -12.99329240440629
64 -45.46770077943802 -12.937601880303525
65 -26.784769006073475 -12.709150323057631
66 -37.6613540276885 -12.68135972540495
67 -34.967663794755936 -12.596040009189341
68 -28.66220822930336 -12.489606634434601
69 -30.47988224029541 -12.372454739549003
70 -28.594463676214218 -12.243403879196388
71 -30.438629418611526 -12.163827700006971
72 -29.365714013576508 -12.076481989890604
73 -25.873302698135376 -11.802444341088956
74 -27.184984028339386 -11.72649421388079
75 -25.865425389260054 -11.482140762671794
76 -35.73284536600113 -11.355919719105126
77 -33.01667985320091 -11.077132998261037
78 -24.70411078631878 -10.961932060164017
79 -22.87495030462742 -10.845290734893993
80 -26.690339490771294 -10.687545353047717
81 -31.846627950668335 -10.503667002151765
82 -26.208171039819717 -10.327681503524177
83 -22.226487904787064 -10.153702747757642
84 -32.04687374830246 -10.04940451848228
85 -22.851825565099716 -9.873433124041318
86 -25.154693067073822 -9.768732478455368
87 -21.910240814089775 -9.60162068006752
88 -23.97682248055935 -9.436338457972072
89 -21.471404135227203 -9.359900431081572
90 -18.353945530951023 -9.318532890899364
91 -16.566091530025005 -9.227239032064794
92 -19.187051571905613 -9.097960985817739
93 -21.57714506983757 -8.970347800326815
94 -21.41134472936392 -8.754459760935882
95 -22.99205121397972 -8.398001337047377
96 -28.78663831949234 -8.283291948883095
97 -21.90848431736231 -8.108197691178031
98 -20.344325579702854 -7.658083984004526
99 -20.015340633690357 -7.440920124149799
100 -25.195126622915268 -7.179464892257731
101 -25.88421604037285 -6.914367593932078
102 -39.9038762152195 -6.776946485018116
103 -28.454412311315536 -6.577984896291955
104 -19.440306544303894 -6.535447341844848
105 -13.492424285039306 -6.423157183581381
106 -13.848619498312473 -6.2883411317323175
107 -25.284123867750168 -5.881314064604837
108 -17.25521057099104 -5.582110560177944
109 -22.972655080258846 -5.34720210027791
110 -24.447727903723717 -5.1133637954859665
111 -13.62943135201931 -4.875659084774348
112 -9.497749000787735 -4.63049541560991
113 -10.090485153719783 -4.369321915713366
114 -21.185743421316147 -4.15758283790416
115 -21.935156777501106 -3.9869276101340616
116 -21.387545481324196 -3.8042316132412286
117 -7.792492799460888 -3.595364142259748
118 -21.157256186008453 -3.263997667566093
119 -8.694974383339286 -1.901789541388503
train accuracy: 1.0
validation accuracy: 1.0
[-63.24332377 -63.23599055 -63.21105585 -63.1277899  -63.03088591
 -62.97836141 -62.80700329 -62.59841154 -62.45659058 -62.22052465
 -62.05545976 -61.99823876 -61.90503048 -61.9024977  -61.84514296
 -61.80958936 -61.60739549 -61.57987077 -61.52954719 -61.49152331
 -61.42319103 -61.37818898 -61.3242033  -61.18861045 -61.11705014
 -61.1111952  -61.05040259 -60.70125881 -60.55874128 -60.49758829
 -60.33754647 -60.3056539  -60.27108478 -60.26518611 -60.24509979
 -60.22805253 -60.15029758 -60.10592506 -60.09749463 -60.0319431
 -60.02722508 -59.93393272 -59.80496242 -59.7917769  -59.65998034
 -59.5305981  -59.50104536 -59.42996515 -59.42210572 -59.38924773
 -59.38736621 -59.38054209 -59.3637735  -59.35705669 -59.33804201
 -59.3275818  -59.30965762 -59.10615862 -59.10256234 -58.91394416
 -58.85869868 -58.83781287 -58.805901   -58.78928523 -58.78920472
 -58.74515985 -58.7335467  -58.6909254  -58.60985472 -58.59427563
 -58.58165728 -58.52164071 -58.47633979 -58.46066973 -58.43515991
 -58.42948108 -58.34687794 -58.3224997  -58.26697037 -58.26037219
 -58.18129208 -58.0861159  -57.99583108 -57.97256269 -57.92377717
 -57.89906439 -57.86612124 -57.85252143 -57.79024149 -57.78201503
 -57.76493642 -57.72031285 -57.55593357 -57.38102245 -57.37258309
 -57.21444707 -57.21200816 -57.16061789 -57.12957694 -57.07621127
 -57.06529087 -57.04573717 -56.88160157 -56.87555564 -56.72292153
 -56.70057749 -56.62581458 -56.40969062 -56.40899696 -56.32819744
 -56.0810036  -56.05279704 -55.96543435 -55.96407105 -55.93162024
 -55.67010668 -55.50073526 -55.32975789 -54.98547503 -54.6753876
 -53.06095904 -50.4922686  -50.03933802 -49.75347185 -49.72654641
 -46.98011874 -45.73515428 -45.67057988 -44.99030608 -44.14602409
 -43.81326882 -43.18878399 -42.29180715 -42.00401746 -41.69100444
 -41.68588229 -41.2817771  -40.44278203 -40.34838366 -39.59970115
 -39.57586365 -39.31972693 -39.02461056 -38.45534494 -38.4127039
 -38.35634328 -37.79713617 -37.74152899 -37.66475324 -37.51313938
 -37.1809993  -37.10070314 -37.00630589 -36.82191677 -36.48799015
 -36.2096527  -36.19207562 -36.11445903 -35.78149902 -35.39450387
 -35.262825   -35.24303541 -35.20970524 -35.06544085 -34.80241748
 -34.64469045 -33.84284986 -32.70706485 -31.9690994  -31.7109134
 -31.64414356 -31.39238276 -31.22319602 -31.12953085 -29.3915714
 -29.34012561 -29.10618999 -27.4110235  -27.34372236 -27.19668163
 -27.07399029 -26.70472176 -26.2447949  -25.54836509 -25.45878529
 -24.879107   -24.82869536 -24.59274514 -23.97874558 -23.57262108
 -23.44970808 -22.74530916 -22.60679894 -22.19891032 -20.65686376
 -20.44447256 -20.29688418 -20.23141807 -20.1969901  -20.13839115
 -20.13020095 -19.84155928 -19.71548984 -19.68899137 -19.68187944
 -19.63760344 -19.51559872 -19.46242624 -19.4608337  -19.4041006
 -19.3558728  -18.9283881  -18.73129823 -18.6143711  -18.59559194
 -18.46499943 -18.43877077 -18.38621926 -18.27561534 -17.99477406
 -17.82791039 -17.5574237  -17.4225533  -17.32401372 -17.2877303
 -17.27734589 -17.17142851 -17.09111514 -16.99919682 -16.94289066
 -16.90794731 -16.87179876 -16.82307393 -16.73124049 -16.67001724
 -16.58659093 -16.32507254 -16.14499025 -16.11471807 -15.99550761
 -15.96630994 -15.89510862 -15.83529718 -15.73508957 -15.71653035
 -15.65454388 -15.64362673 -15.53069614 -15.4996426  -15.47055242
 -15.37516569 -15.29900699 -15.29752692 -15.27492849 -15.2719524
 -15.1811829  -15.16489019 -15.13026299 -15.1168859  -15.11310895
 -15.09811232 -15.08546181 -15.05822392 -14.9375075  -14.92482994
 -14.89671643 -14.8550828  -14.7994931  -14.77688108 -14.77118432
 -14.65980608 -14.65234189 -14.594561   -14.56214362 -14.5314246
 -14.51447881 -14.50408185 -14.50203248 -14.46874354 -14.4570134
 -14.44242009 -14.42193758 -14.36850066 -14.33258    -14.32950177
 -14.32942426 -14.26617393 -14.25516391 -14.23740337 -14.21922258
 -14.08340118 -14.04266231 -14.00918138 -14.00356944 -13.99901576
 -13.98069366 -13.96863183 -13.94553084 -13.92064094 -13.86308449
 -13.82682946 -13.82168222 -13.75062761 -13.74201371 -13.73538513
 -13.70157677 -13.67248689 -13.66926268 -13.65984887 -13.608892
 -13.59887363 -13.59601285 -13.58322451 -13.5769007  -13.56118218
 -13.53717325 -13.50058897 -13.49625934 -13.48391162 -13.48040306
 -13.46555991 -13.42154574 -13.35053773 -13.33800376 -13.33243944
 -13.33224936 -13.24746818 -13.21474879 -13.17814269 -13.17193674
 -13.15006142 -13.13997741 -13.13985916 -13.07123989 -13.05737342
 -12.9932924  -12.9911753  -12.98804567 -12.97789981 -12.96736491
 -12.94572355 -12.93760188 -12.9165571  -12.89533945 -12.89281313
 -12.88420468 -12.84456867 -12.80256509 -12.7141283  -12.71256262
 -12.70915032 -12.69913989 -12.68886431 -12.68787728 -12.68476663
 -12.68403935 -12.68135973 -12.67795632 -12.66418206 -12.65197265
 -12.61294478 -12.60694569 -12.60505429 -12.59604001 -12.59146077
 -12.58492544 -12.5568266  -12.54337072 -12.53922889 -12.49952894
 -12.48960663 -12.48846703 -12.47314213 -12.44235814 -12.42234736
 -12.42037973 -12.41787343 -12.39846884 -12.38653875 -12.37245474
 -12.37013582 -12.36609991 -12.34671509 -12.30017947 -12.29446786
 -12.28928631 -12.24340388 -12.23008134 -12.21444028 -12.20423388
 -12.19488362 -12.19257471 -12.17081576 -12.1638277  -12.15190477
 -12.14087299 -12.11267893 -12.10286355 -12.0912212  -12.09013272
 -12.07990884 -12.07648199 -11.98617858 -11.97628117 -11.9718797
 -11.94883147 -11.94387787 -11.91392797 -11.80244434 -11.78885214
 -11.78173063 -11.7724129  -11.76007221 -11.72649421 -11.72030375
 -11.70915921 -11.70702865 -11.675454   -11.67485775 -11.65292186
 -11.65251864 -11.6440414  -11.54576322 -11.48214076 -11.47061442
 -11.40958857 -11.39809208 -11.39514232 -11.35591972 -11.32808601
 -11.31835075 -11.31313567 -11.27863965 -11.11165846 -11.10389205
 -11.1024487  -11.077133   -11.07648117 -11.07460556 -10.9955771
 -10.98789819 -10.96193206 -10.90788214 -10.89368728 -10.88947284
 -10.88447672 -10.8699891  -10.84926681 -10.84529073 -10.83771365
 -10.77708705 -10.77157448 -10.76373532 -10.7626531  -10.72252648
 -10.69169161 -10.68754535 -10.64812666 -10.61795776 -10.59932568
 -10.59550004 -10.59047519 -10.56525508 -10.54372397 -10.50417679
 -10.503667   -10.48131303 -10.4627546  -10.4515603  -10.44415981
 -10.37561746 -10.3276815  -10.32701661 -10.31898966 -10.30373604
 -10.2845271  -10.17869462 -10.15370275 -10.14523977 -10.129968
 -10.12345655 -10.11680526 -10.06917835 -10.05434057 -10.0537485
 -10.04940452 -10.04140071 -10.01117366  -9.98600954  -9.97495295
  -9.9444303   -9.93667404  -9.92882525  -9.89890309  -9.88877311
  -9.87343312  -9.85721598  -9.84881233  -9.84325222  -9.8069955
  -9.79295249  -9.76873248  -9.7513432   -9.70803505  -9.70232992
  -9.63006997  -9.61577792  -9.60231899  -9.60162068  -9.58053743
  -9.49727871  -9.47919626  -9.45788629  -9.43866282  -9.43633846
  -9.41778779  -9.41052059  -9.40824698  -9.4057227   -9.35990043
  -9.34464202  -9.34459136  -9.34125766  -9.34040597  -9.31853289
  -9.29755911  -9.28970959  -9.25632952  -9.23447361  -9.22954286
  -9.22723903  -9.1921269   -9.15969438  -9.13624814  -9.12404452
  -9.09796099  -9.09284414  -9.0417146   -9.00748237  -8.99211937
  -8.9703478   -8.95330348  -8.94881416  -8.94199734  -8.93076101
  -8.8988321   -8.8972749   -8.89093899  -8.87173684  -8.86797947
  -8.77833829  -8.77695015  -8.77596385  -8.75445976  -8.74668312
  -8.70278642  -8.60684626  -8.56096114  -8.49185067  -8.48581154
  -8.43284839  -8.39800134  -8.3384229   -8.33111246  -8.330117
  -8.30246843  -8.28329195  -8.25863217  -8.19902254  -8.18210422
  -8.17588348  -8.15886463  -8.13319584  -8.13106665  -8.11585115
  -8.1092657   -8.10819769  -8.1047694   -8.10257672  -8.07304872
  -8.01910703  -8.00046014  -7.99115734  -7.77734704  -7.76388228
  -7.75584261  -7.6960871   -7.65826784  -7.65808398  -7.61173669
  -7.5816518   -7.57539849  -7.55046962  -7.51737497  -7.51150784
  -7.45535888  -7.45456821  -7.44092012  -7.41820171  -7.40249522
  -7.37450683  -7.36244313  -7.28247429  -7.23588878  -7.17946489
  -7.12894301  -7.10832736  -7.03999095  -7.00869413  -6.95906356
  -6.94047157  -6.92998266  -6.91436759  -6.91427984  -6.91024552
  -6.90972002  -6.87856825  -6.86314327  -6.78323296  -6.77694649
  -6.72206384  -6.71997062  -6.70339024  -6.68501373  -6.65203062
  -6.61930532  -6.5779849   -6.57146323  -6.55636471  -6.55182982
  -6.55035087  -6.54227962  -6.53637975  -6.53544734  -6.52502436
  -6.51820418  -6.51142145  -6.48528917  -6.47362572  -6.43176687
  -6.42315718  -6.4216571   -6.38246417  -6.37598427  -6.32418263
  -6.28899961  -6.28834113  -6.24441631  -6.23383601  -6.15634472
  -6.14521167  -6.13122052  -6.12398433  -6.05079552  -6.03741498
  -5.88727041  -5.88131406  -5.7888028   -5.73843016  -5.73206497
  -5.6559233   -5.62903448  -5.61579673  -5.58211056  -5.56808905
  -5.41773478  -5.41681175  -5.39914398  -5.39325437  -5.3472021
  -5.34113623  -5.32351909  -5.2737561   -5.11968813  -5.1133638
  -5.08944247  -5.07848501  -5.02795798  -4.88350688  -4.87565908
  -4.82757292  -4.77444392  -4.6362783   -4.63120683  -4.63049542
  -4.60697954  -4.48417321  -4.47381185  -4.42297854  -4.36932192
  -4.28918088  -4.2741627   -4.27150294  -4.230832    -4.15758284
  -4.11600409  -4.07483063  -4.03306984  -4.03104862  -3.98692761
  -3.89657065  -3.8858411   -3.88252014  -3.80709015  -3.80423161
  -3.75328905  -3.7297162   -3.61904238  -3.61173136  -3.59536414
  -3.56149099  -3.38726063  -3.38446715  -3.3322555   -3.26399767
  -3.21746212  -2.64166233  -2.38277218  -1.91361965  -1.90178954]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Found existing model weights! Loading state dict...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:1
end of epoch 0: val_loss 0.015865517140964302, val_acc 0.995
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.0054e-01,  2.5841e-01,  1.9421e-02, -3.0110e-01,  2.1132e-01,
         -1.3915e-05,  2.9576e-02, -2.6736e-02,  1.8855e-05, -7.9821e-03,
         -1.6146e-03, -1.0225e+00, -1.2543e+00]], device='cuda:1'))])
end of epoch 1: val_loss 0.025158387738047096, val_acc 0.995
trigger times: 1
end of epoch 2: val_loss 0.0681128974911394, val_acc 0.995
trigger times: 2
end of epoch 3: val_loss 0.007898430818504493, val_acc 0.995
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 5.3926e-01,  7.0389e-01,  3.7645e-01, -7.3314e-01,  6.6853e-01,
         -2.1831e-01,  1.4041e-01, -3.5388e-02, -3.7580e-01, -6.8790e-02,
         -1.6142e-03, -2.4975e+00, -2.3799e+00]], device='cuda:1'))])
end of epoch 4: val_loss 6.582569525335202e-06, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.4119e-01,  6.2009e-01,  3.3539e-01, -6.8544e-01,  1.8429e-01,
         -1.9313e-05,  3.9587e-02,  1.6549e-02, -2.7299e-06, -3.1170e-02,
         -1.6141e-03, -2.4168e+00, -2.3572e+00]], device='cuda:1'))])
end of epoch 5: val_loss 0.0003095229896457852, val_acc 1.0
trigger times: 1
end of epoch 6: val_loss 0.00043024120286091263, val_acc 1.0
trigger times: 2
end of epoch 7: val_loss 0.13066619524732, val_acc 0.995
trigger times: 3
end of epoch 8: val_loss 0.37936376921446935, val_acc 0.985
trigger times: 4
end of epoch 9: val_loss 0.06932424420889674, val_acc 0.995
trigger times: 5
end of epoch 10: val_loss 0.07616524219511916, val_acc 0.995
trigger times: 6
end of epoch 11: val_loss 0.002481318561864292, val_acc 1.0
trigger times: 7
end of epoch 12: val_loss 0.00016671447083297153, val_acc 1.0
trigger times: 8
end of epoch 13: val_loss 0.00030501014349194834, val_acc 1.0
trigger times: 9
end of epoch 14: val_loss 0.05620022814841374, val_acc 0.995
trigger times: 10
Early stopping.
0 -528.9821970462799 -63.24332377487188
1 -536.9980072975159 -62.80700329025705
2 -520.8387483358383 -61.90503048142668
3 -527.992694735527 -61.52954718804281
4 -524.4021528959274 -61.11705014319021
5 -512.6374787092209 -60.337546473897575
6 -520.5961475372314 -60.150297575665455
7 -465.93580627441406 -59.80496242001055
8 -467.88686776161194 -59.42210571514803
9 -518.2251930236816 -59.33804200996001
10 -469.4030418395996 -58.85869868155896
11 -461.97673213481903 -58.73354670235131
12 -529.4815598726273 -58.46066972510246
13 -460.0682895183563 -58.260372187686066
14 -460.13259422779083 -57.89906438864594
15 -518.760865688324 -57.72031284894193
16 -458.0644870996475 -57.1606178908599
17 -521.8145885467529 -56.8755556430246
18 -509.2086876630783 -56.32819743601017
19 -518.7789295911789 -55.67010667707793
20 -54.342556059360504 -50.492268601198035
21 -111.15943843126297 -45.670579884154705
22 -119.80728402733803 -42.00401746161006
23 -152.7710196375847 -39.599701153458774
24 -140.77693265676498 -38.35634328077039
25 -101.81719985604286 -37.100703136010694
26 -22.514175981283188 -36.114459029559086
27 -83.96091410517693 -35.0654408505187
28 -3.850881040096283 -31.7109134007892
29 -50.69518554210663 -29.340125609942326
30 -64.05167388916016 -26.7047217556024
31 -27.07339818775654 -24.592745144504722
32 11.816439360380173 -22.19891031871716
33 28.94014084339142 -20.13839114930498
34 17.439647763967514 -19.63760343800059
35 15.188682496547699 -18.92838809611677
36 18.936517611145973 -18.27561534160692
37 12.890186592936516 -17.287730301408818
38 24.252936750650406 -16.907947312722616
39 19.53948435932398 -16.325072543773945
40 6.35342551022768 -15.835297177460307
41 3.915292926132679 -15.499642599313287
42 -3.33693390712142 -15.27195239970661
43 4.289487339556217 -15.098112319720741
44 -14.969522893428802 -14.855082803515382
45 16.214789405465126 -14.594561003997004
46 4.471533924341202 -14.468743544178729
47 -2.993280775845051 -14.329501769060094
48 19.46667082607746 -14.083401177177324
49 -7.158825658261776 -13.968631831022643
50 31.3807725161314 -13.750627613362438
51 10.70421926677227 -13.659848873402819
52 33.90397796034813 -13.56118217868397
53 22.230636343359947 -13.465559907139045
54 -25.58726491034031 -13.247468178452921
55 25.194891542196274 -13.139859160076545
56 39.09909597039223 -12.977899810681784
57 17.451778694987297 -12.892813128746589
58 16.683919847011566 -12.709150323057631
59 -55.31635130941868 -12.68135972540495
60 36.90666827559471 -12.596040009189341
61 28.400149047374725 -12.499528939654995
62 22.439049765467644 -12.420379729392865
63 38.51838756352663 -12.366099911819555
64 28.265315398573875 -12.230081339442261
65 -1.876619666814804 -12.163827700006971
66 20.141246154904366 -12.090132715561564
67 30.014401718974113 -11.948831474142246
68 2.0332661494612694 -11.772412895153552
69 -13.15575547516346 -11.67545400252302
70 12.504217267036438 -11.482140762671794
71 31.750345408916473 -11.328086014022071
72 22.78718477487564 -11.1024487042696
73 7.021831303834915 -10.961932060164017
74 24.714249595999718 -10.849266812135143
75 -5.710882246494293 -10.762653097658218
76 5.099377006292343 -10.599325677585078
77 21.982157975435257 -10.503667002151765
78 43.3109535574913 -10.327681503524177
79 16.186247780919075 -10.153702747757642
80 -4.457538291811943 -10.054340569736782
81 29.310395948588848 -9.974952948632556
82 3.1659896671772003 -9.873433124041318
83 9.827591970562935 -9.768732478455368
84 46.17336688935757 -9.60162068006752
85 -5.462912768125534 -9.436338457972072
86 31.921041041612625 -9.34464202035242
87 28.71393422782421 -9.28970959306215
88 27.79404181241989 -9.159694381138166
89 37.119681268930435 -9.007482366079063
90 18.860587254166603 -8.930761014077454
91 34.37447302788496 -8.77833829395191
92 70.40308427810669 -8.606846259809434
93 37.66499862074852 -8.338422897120289
94 17.74320486187935 -8.199022537534278
95 25.36182728409767 -8.115851147367104
96 31.097857788205147 -8.019107026116492
97 34.01297178119421 -7.696087100058409
98 57.597514629364014 -7.550469616919059
99 36.9444146156311 -7.418201709745239
100 50.27746623754501 -7.179464892257731
101 31.49189070612192 -6.940471573081336
102 37.44107884168625 -6.8785682524371365
103 48.88378167152405 -6.703390244943952
104 27.851048529148102 -6.556364713803207
105 49.28861486911774 -6.525024358296319
106 82.35942208766937 -6.423157183581381
107 76.76758515834808 -6.2883411317323175
108 35.964568719267845 -6.050795522088052
109 23.559977933764458 -5.732064972054174
110 60.57392740249634 -5.417734778175555
111 76.68058323860168 -5.323519088860305
112 52.43499052524567 -5.027957977402961
113 53.938769698143005 -4.631206826089856
114 98.55804419517517 -4.369321915713366
115 65.71178096532822 -4.116004088000472
116 90.19739425182343 -3.885841100341837
117 81.13082098960876 -3.6190423757374197
118 81.06667214632034 -3.3322555012187633
119 99.77135801315308 -1.901789541388503
train accuracy: 0.9977777777777778
validation accuracy: 0.995
[-64.24997756 -63.70374526 -63.24332377 -63.23599055 -63.21105585
 -63.1277899  -63.03088591 -62.97836141 -62.8880408  -62.80700329
 -62.68654572 -62.59841154 -62.45659058 -62.22052465 -62.19961806
 -62.05545976 -61.99823876 -61.95028984 -61.90503048 -61.9024977
 -61.84514296 -61.82022345 -61.80958936 -61.60739549 -61.57987077
 -61.52954719 -61.49152331 -61.42319103 -61.37818898 -61.3242033
 -61.18861045 -61.11705014 -61.1111952  -61.05040259 -61.02959876
 -60.86594116 -60.76820853 -60.71067263 -60.70125881 -60.65715619
 -60.65245125 -60.56996954 -60.55874128 -60.5547045  -60.49758829
 -60.48258467 -60.45707335 -60.33754647 -60.3056539  -60.27108478
 -60.26518611 -60.24509979 -60.24180628 -60.22805253 -60.19573103
 -60.17226654 -60.15274555 -60.15029758 -60.11717494 -60.10592506
 -60.09749463 -60.0319431  -60.02722508 -60.00583218 -59.93393272
 -59.91659544 -59.87274329 -59.82531105 -59.80496242 -59.7917769
 -59.72419126 -59.70853732 -59.65998034 -59.65022384 -59.59719498
 -59.5305981  -59.50104536 -59.42996515 -59.42210572 -59.38924773
 -59.38736621 -59.38054209 -59.37607349 -59.37547196 -59.3637735
 -59.35769976 -59.35705669 -59.33804201 -59.3275818  -59.30965762
 -59.28574006 -59.23387086 -59.18464036 -59.10615862 -59.10256234
 -59.09671972 -59.00308265 -59.00287135 -58.98079589 -58.97692474
 -58.94034584 -58.91786584 -58.91394416 -58.85869868 -58.83781287
 -58.805901   -58.78928523 -58.78920472 -58.74515985 -58.7335467
 -58.6909254  -58.66521312 -58.60985472 -58.59427563 -58.58165728
 -58.52164071 -58.47633979 -58.46066973 -58.43515991 -58.42948108
 -58.34687794 -58.33955225 -58.3224997  -58.2747748  -58.26697037
 -58.26037219 -58.25791715 -58.25674195 -58.23564869 -58.23557227
 -58.18129208 -58.17849633 -58.12762104 -58.0861159  -58.07195587
 -58.05496853 -57.99583108 -57.97256269 -57.92377717 -57.89906439
 -57.86612124 -57.85252143 -57.79744436 -57.79024149 -57.78201503
 -57.76493642 -57.72031285 -57.55593357 -57.41744447 -57.41601846
 -57.38102245 -57.37258309 -57.22142181 -57.21444707 -57.21200816
 -57.16061789 -57.12957694 -57.07621127 -57.06529087 -57.04573717
 -56.92828118 -56.88160157 -56.87555564 -56.87062934 -56.72292153
 -56.70057749 -56.62581458 -56.40969062 -56.40899696 -56.32819744
 -56.18471197 -56.16037157 -56.0810036  -56.05279704 -55.96543435
 -55.96407105 -55.93162024 -55.80238333 -55.67010668 -55.50073526
 -55.32975789 -54.98547503 -54.6753876  -53.06095904 -50.4922686
 -50.03933802 -49.75347185 -49.72654641 -46.98011874 -45.73515428
 -45.67057988 -44.99030608 -44.14602409 -43.81326882 -43.18878399
 -42.29180715 -42.00401746 -41.69100444 -41.68588229 -41.2817771
 -40.44278203 -40.34838366 -39.59970115 -39.57586365 -39.31972693
 -39.02461056 -38.45534494 -38.4127039  -38.35634328 -37.79713617
 -37.74152899 -37.66475324 -37.51313938 -37.1809993  -37.10070314
 -37.00630589 -36.82191677 -36.48799015 -36.2096527  -36.19207562
 -36.11445903 -35.78149902 -35.39450387 -35.262825   -35.24303541
 -35.20970524 -35.06544085 -34.80241748 -34.64469045 -33.84284986
 -32.70706485 -31.9690994  -31.7109134  -31.64414356 -31.39238276
 -31.22319602 -31.12953085 -29.3915714  -29.34012561 -29.10618999
 -27.4110235  -27.34372236 -27.19668163 -27.07399029 -26.70472176
 -26.2447949  -25.54836509 -25.45878529 -24.879107   -24.82869536
 -24.59274514 -23.97874558 -23.57262108 -23.44970808 -22.74530916
 -22.60679894 -22.19891032 -20.65686376 -20.44447256 -20.29688418
 -20.23141807 -20.1969901  -20.13839115 -20.13020095 -19.84155928
 -19.71548984 -19.68899137 -19.68187944 -19.63760344 -19.51559872
 -19.46242624 -19.4608337  -19.4041006  -19.3558728  -18.9283881
 -18.73129823 -18.6143711  -18.59559194 -18.46499943 -18.43877077
 -18.38621926 -18.27561534 -17.99477406 -17.82791039 -17.5574237
 -17.4225533  -17.32401372 -17.2877303  -17.27734589 -17.17142851
 -17.09111514 -16.99919682 -16.94289066 -16.90794731 -16.87179876
 -16.82307393 -16.73124049 -16.67001724 -16.58659093 -16.32507254
 -16.14499025 -16.11471807 -15.99550761 -15.96630994 -15.89510862
 -15.83529718 -15.73508957 -15.71653035 -15.65454388 -15.64362673
 -15.53069614 -15.4996426  -15.47055242 -15.37516569 -15.29900699
 -15.29752692 -15.27492849 -15.2719524  -15.1811829  -15.16489019
 -15.13026299 -15.1168859  -15.11310895 -15.09811232 -15.08546181
 -15.05822392 -14.9375075  -14.92482994 -14.89671643 -14.8550828
 -14.7994931  -14.77688108 -14.77118432 -14.65980608 -14.65234189
 -14.594561   -14.56214362 -14.5314246  -14.51447881 -14.50408185
 -14.50203248 -14.46874354 -14.4570134  -14.44242009 -14.42193758
 -14.36850066 -14.33258    -14.32950177 -14.32942426 -14.26617393
 -14.25516391 -14.23740337 -14.21922258 -14.08340118 -14.04266231
 -14.00918138 -14.00356944 -13.99901576 -13.98069366 -13.96863183
 -13.94553084 -13.92064094 -13.86308449 -13.82682946 -13.82168222
 -13.75062761 -13.74201371 -13.73538513 -13.70157677 -13.67248689
 -13.66926268 -13.65984887 -13.608892   -13.59887363 -13.59601285
 -13.58322451 -13.5769007  -13.56118218 -13.53717325 -13.50058897
 -13.49625934 -13.48391162 -13.48040306 -13.46555991 -13.42154574
 -13.35053773 -13.33800376 -13.33243944 -13.33224936 -13.24746818
 -13.21474879 -13.17814269 -13.17193674 -13.15006142 -13.13997741
 -13.13985916 -13.07123989 -13.05737342 -12.9932924  -12.9911753
 -12.98804567 -12.97789981 -12.96736491 -12.94572355 -12.93760188
 -12.9165571  -12.89533945 -12.89281313 -12.88420468 -12.84456867
 -12.80256509 -12.7141283  -12.71256262 -12.70915032 -12.69913989
 -12.68886431 -12.68787728 -12.68476663 -12.68403935 -12.68135973
 -12.67795632 -12.66418206 -12.65197265 -12.61294478 -12.60694569
 -12.60505429 -12.59604001 -12.59146077 -12.58492544 -12.5568266
 -12.54337072 -12.53922889 -12.49952894 -12.48960663 -12.48846703
 -12.47314213 -12.44235814 -12.42234736 -12.42037973 -12.41787343
 -12.39846884 -12.38653875 -12.37245474 -12.37013582 -12.36609991
 -12.34671509 -12.30017947 -12.29446786 -12.28928631 -12.24340388
 -12.23008134 -12.21444028 -12.20423388 -12.19488362 -12.19257471
 -12.17081576 -12.1638277  -12.15190477 -12.14087299 -12.11267893
 -12.10286355 -12.0912212  -12.09013272 -12.07990884 -12.07648199
 -11.98617858 -11.97628117 -11.9718797  -11.94883147 -11.94387787
 -11.91392797 -11.80244434 -11.78885214 -11.78173063 -11.7724129
 -11.76007221 -11.72649421 -11.72030375 -11.70915921 -11.70702865
 -11.675454   -11.67485775 -11.65292186 -11.65251864 -11.6440414
 -11.54576322 -11.48214076 -11.47061442 -11.40958857 -11.39809208
 -11.39514232 -11.35591972 -11.32808601 -11.31835075 -11.31313567
 -11.27863965 -11.11165846 -11.10389205 -11.1024487  -11.077133
 -11.07648117 -11.07460556 -10.9955771  -10.98789819 -10.96193206
 -10.90788214 -10.89368728 -10.88947284 -10.88447672 -10.8699891
 -10.84926681 -10.84529073 -10.83771365 -10.77708705 -10.77157448
 -10.76373532 -10.7626531  -10.72252648 -10.69169161 -10.68754535
 -10.64812666 -10.61795776 -10.59932568 -10.59550004 -10.59047519
 -10.56525508 -10.54372397 -10.50417679 -10.503667   -10.48131303
 -10.4627546  -10.4515603  -10.44415981 -10.37561746 -10.3276815
 -10.32701661 -10.31898966 -10.30373604 -10.2845271  -10.17869462
 -10.15370275 -10.14523977 -10.129968   -10.12345655 -10.11680526
 -10.06917835 -10.05434057 -10.0537485  -10.04940452 -10.04140071
 -10.01117366  -9.98600954  -9.97495295  -9.9444303   -9.93667404
  -9.92882525  -9.89890309  -9.88877311  -9.87343312  -9.85721598
  -9.84881233  -9.84325222  -9.8069955   -9.79295249  -9.76873248
  -9.7513432   -9.70803505  -9.70232992  -9.63006997  -9.61577792
  -9.60231899  -9.60162068  -9.58053743  -9.49727871  -9.47919626
  -9.45788629  -9.43866282  -9.43633846  -9.41778779  -9.41052059
  -9.40824698  -9.4057227   -9.35990043  -9.34464202  -9.34459136
  -9.34125766  -9.34040597  -9.31853289  -9.31176385  -9.29755911
  -9.28970959  -9.25632952  -9.23447361  -9.22954286  -9.22723903
  -9.1921269   -9.15969438  -9.13624814  -9.12404452  -9.09796099
  -9.09284414  -9.0417146   -9.00748237  -8.99211937  -8.9703478
  -8.95330348  -8.94881416  -8.94199734  -8.93076101  -8.90666429
  -8.8988321   -8.8972749   -8.89093899  -8.87173684  -8.86797947
  -8.77833829  -8.77695015  -8.77596385  -8.75445976  -8.74668312
  -8.70278642  -8.65783194  -8.60684626  -8.56096114  -8.53555109
  -8.51210379  -8.49185067  -8.48581154  -8.43284839  -8.39800134
  -8.3384229   -8.33111246  -8.330117    -8.32432318  -8.30246843
  -8.28329195  -8.28213149  -8.25863217  -8.23181323  -8.19902254
  -8.18210422  -8.17588348  -8.15886463  -8.13319584  -8.13106665
  -8.11585115  -8.1092657   -8.10819769  -8.1047694   -8.10257672
  -8.07304872  -8.05532635  -8.03652725  -8.01910703  -8.00046014
  -7.99115734  -7.96879715  -7.8910885   -7.77734704  -7.76388228
  -7.75584261  -7.6960871   -7.68055163  -7.65826784  -7.65808398
  -7.65274073  -7.61173669  -7.5816518   -7.57539849  -7.57456638
  -7.55651839  -7.55046962  -7.52235456  -7.51737497  -7.51150784
  -7.45535888  -7.45456821  -7.44092012  -7.41845597  -7.41820171
  -7.40249522  -7.37450683  -7.36244313  -7.36120452  -7.3111193
  -7.28247429  -7.26120305  -7.23588878  -7.17946489  -7.12894301
  -7.10832736  -7.03999095  -7.00869413  -6.95906356  -6.94047157
  -6.92998266  -6.91891198  -6.91436759  -6.91427984  -6.91024552
  -6.90972002  -6.87856825  -6.86314327  -6.83788793  -6.78323296
  -6.77694649  -6.76115764  -6.73166861  -6.72206384  -6.71997062
  -6.70339024  -6.68501373  -6.65203062  -6.61930532  -6.61249558
  -6.5779849   -6.57146323  -6.55636471  -6.55182982  -6.55035087
  -6.54227962  -6.53637975  -6.53544734  -6.52502436  -6.51820418
  -6.51142145  -6.48528917  -6.47362572  -6.43176687  -6.42315718
  -6.4216571   -6.38246417  -6.37598427  -6.32418263  -6.31062378
  -6.29192791  -6.28899961  -6.2883933   -6.28834113  -6.24441631
  -6.23383601  -6.17467673  -6.15634472  -6.14521167  -6.13122052
  -6.12398433  -6.05079552  -6.03741498  -5.92948534  -5.90738164
  -5.88727041  -5.88131406  -5.7888028   -5.73843016  -5.73206497
  -5.6559233   -5.62903448  -5.61579673  -5.58211056  -5.56808905
  -5.41773478  -5.41681175  -5.39914398  -5.39325437  -5.3472021
  -5.34113623  -5.32351909  -5.2737561   -5.20076027  -5.11968813
  -5.1133638   -5.08944247  -5.07848501  -5.02795798  -4.93844638
  -4.89374732  -4.88350688  -4.87565908  -4.85614197  -4.82757292
  -4.82078597  -4.77444392  -4.76804903  -4.71791317  -4.69132254
  -4.66121849  -4.6362783   -4.63120683  -4.63049542  -4.60697954
  -4.48417321  -4.47381185  -4.42297854  -4.37854279  -4.36932192
  -4.34616693  -4.29378326  -4.28918088  -4.2741627   -4.27150294
  -4.23731636  -4.230832    -4.18805978  -4.15758284  -4.11600409
  -4.07483063  -4.03306984  -4.03104862  -3.98692761  -3.97905459
  -3.89657065  -3.8858411   -3.88252014  -3.80709015  -3.80423161
  -3.75328905  -3.7297162   -3.7044508   -3.61904238  -3.61173136
  -3.59536414  -3.56149099  -3.38726063  -3.38446715  -3.3322555
  -3.30953002  -3.26399767  -3.21746212  -3.16707079  -3.01592538
  -2.9831913   -2.87807425  -2.64166233  -2.56607549  -2.38281504
  -2.38277218  -1.91361965  -1.90178954  -1.84200761  -1.55139937]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Found existing model weights! Loading state dict...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:1
end of epoch 0: val_loss 4.8445622357107255e-06, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.0170e-01,  2.7078e-01,  1.1661e-01,  2.8416e-01,  2.1720e-01,
         -1.9995e-01, -1.6511e-02, -2.0060e-01, -1.0033e-01,  1.1516e-05,
         -6.2704e-04, -1.1931e+00, -1.6520e+00]], device='cuda:1'))])
end of epoch 1: val_loss 3.4316645519538726e-06, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 7.2827e-02,  2.1247e-01,  2.7544e-03,  7.2460e-03,  2.1654e-02,
         -1.3837e-04, -1.2512e-02, -1.3513e-01,  7.1131e-05, -8.9328e-05,
         -1.7494e-03, -1.0882e+00, -1.5301e+00]], device='cuda:1'))])
end of epoch 2: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.8708e-01,  5.6906e-01,  1.4754e-01,  5.9420e-02,  1.1826e+00,
         -6.3384e-01, -2.5939e-02, -4.3212e-01, -7.8434e-01,  4.6740e-01,
         -6.9596e-04, -2.0319e+00, -3.1559e+00]], device='cuda:1'))])
end of epoch 3: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.0598e-01,  4.8879e-01,  1.0709e-01,  5.3866e-02,  7.8128e-01,
         -3.9699e-01, -2.6689e-02, -3.6800e-01, -9.1145e-02,  1.3790e-01,
          7.8724e-04, -1.6851e+00, -3.1214e+00]], device='cuda:1'))])
end of epoch 4: val_loss 4.768369308294495e-09, val_acc 1.0
trigger times: 1
end of epoch 5: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.7656e-01,  6.6278e-01,  7.6002e-02,  2.9751e-01,  1.4109e+00,
         -3.5906e-01, -3.3528e-02, -5.4041e-01, -7.9022e-01,  3.0648e-01,
          1.5083e-03, -2.0952e+00, -3.9139e+00]], device='cuda:1'))])
end of epoch 6: val_loss 1.4901138456480112e-08, val_acc 1.0
trigger times: 1
end of epoch 7: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.5937e-03,  5.0294e-01,  1.2129e-01, -4.1399e-01,  8.1239e-01,
         -3.4518e-01, -3.1841e-02, -3.3983e-01, -2.3698e-01,  3.0603e-01,
         -6.2742e-04, -1.7211e+00, -3.5730e+00]], device='cuda:1'))])
end of epoch 8: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.5946e-01,  3.7344e-01,  8.4780e-02,  2.2408e-01,  1.0037e+00,
         -7.3468e-02, -3.5270e-02, -2.5907e-01, -2.3611e-01, -5.1505e-04,
         -1.7498e-03, -1.9634e+00, -4.5921e+00]], device='cuda:1'))])
end of epoch 9: val_loss 0.022662916865538705, val_acc 0.995
trigger times: 1
end of epoch 10: val_loss 4.0171969729385636e-07, val_acc 1.0
trigger times: 2
end of epoch 11: val_loss 9.816481610869231e-07, val_acc 1.0
trigger times: 3
end of epoch 12: val_loss 5.256900567474076e-07, val_acc 1.0
trigger times: 4
end of epoch 13: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 5
end of epoch 14: val_loss 1.5257646701769545e-05, val_acc 1.0
trigger times: 6
end of epoch 15: val_loss 1.1920928244535389e-09, val_acc 1.0
trigger times: 7
end of epoch 16: val_loss 3.4807976874162704e-07, val_acc 1.0
trigger times: 8
end of epoch 17: val_loss 0.00013939964186302945, val_acc 1.0
trigger times: 9
end of epoch 18: val_loss 3.771217088619494e-06, val_acc 1.0
trigger times: 10
Early stopping.
0 -76.08330869674683 -64.24997755966005
1 -222.3632369041443 -62.97836140843108
2 -76.1385532617569 -62.199618056821606
3 -70.71650433540344 -61.820223449641695
4 -219.3340561389923 -61.378188979419534
5 -69.18393242359161 -60.86594116204209
6 -213.55728244781494 -60.558741281972964
7 -216.24434852600098 -60.27108477913709
8 -70.25572514533997 -60.15274554520394
9 -71.89180809259415 -60.005832176913664
10 -70.97378951311111 -59.70853732071692
11 -170.94459903240204 -59.42210571514803
12 -73.15175807476044 -59.357699757617
13 -71.34818875789642 -59.18464036243623
14 -72.0480227470398 -58.976924739539946
15 -211.7967975139618 -58.78928522591294
16 -209.76458764076233 -58.59427563494649
17 -170.5209605693817 -58.346877938980676
18 -65.89940190315247 -58.25674194963877
19 -65.54980707168579 -58.071955867423135
20 -209.43992733955383 -57.85252143275963
21 -70.73378586769104 -57.417444474368935
22 -168.19217336177826 -57.1606178908599
23 -208.65189933776855 -56.8755556430246
24 -206.53945469856262 -56.32819743601017
25 -206.99048495292664 -55.93162023503412
26 -202.96218705177307 -53.06095904185309
27 -133.86989068984985 -45.670579884154705
28 -87.807776927948 -41.6910044370425
29 -69.48025420308113 -39.31972693233231
30 -124.02982100844383 -37.513139380385574
31 -71.56817361712456 -36.19207561676116
32 -119.56653666496277 -35.0654408505187
33 -116.45026117563248 -31.64414355845032
34 -64.03847807645798 -27.41102349748205
35 -77.73900464177132 -25.45878528601009
36 -66.8887834250927 -22.745309160183492
37 -73.47766304016113 -20.19699010077007
38 -57.926519989967346 -19.63760343800059
39 -31.407480716705322 -18.731298228582755
40 -82.71495267748833 -17.994774057192853
41 -29.128388673067093 -17.17142851250265
42 -23.29878194630146 -16.731240494206556
43 -22.620278418064117 -15.966309942157581
44 -12.762246526777744 -15.530696139159659
45 -34.97371146082878 -15.27195239970661
46 -15.964931935071945 -15.08546181434559
47 -18.582191787660122 -14.776881084178083
48 -19.32452555000782 -14.514478811012838
49 -23.087134145200253 -14.368500664576029
50 -22.256475195288658 -14.083401177177324
51 -31.737492859363556 -13.945530841132388
52 -15.583591578528285 -13.735385127446426
53 -32.417962700128555 -13.596012850960644
54 -34.96913864463568 -13.483911619341129
55 -23.457149654626846 -13.332249355787466
56 -7.9419436901807785 -13.139859160076545
57 -8.508002206683159 -12.96736490740605
58 -16.007940843701363 -12.84456867066915
59 -32.57944270968437 -12.687877277875348
60 -10.107744559645653 -12.612944778604612
61 -32.250312104821205 -12.543370724726458
62 -8.323033705353737 -12.422347360432031
63 -15.742208927869797 -12.366099911819555
64 -13.587065242230892 -12.214440278141408
65 -15.450385361909866 -12.14087298898016
66 -11.71957053244114 -11.986178575407772
67 -24.902668669819832 -11.788852141676486
68 -36.77527379989624 -11.707028646158562
69 -30.635012716054916 -11.482140762671794
70 -15.027523145079613 -11.313135672281511
71 -40.80778858065605 -11.074605562523185
72 -16.568939432501793 -10.884476715792978
73 -14.176583260297775 -10.763735316928473
74 -16.175907880067825 -10.599325677585078
75 -6.3667746260762215 -10.481313034443842
76 -15.6715217679739 -10.318989664989916
77 -13.317313469946384 -10.123456547275655
78 -4.3845910876989365 -10.011173661379722
79 -3.5358878634870052 -9.888773106956679
80 -13.355941355228424 -9.768732478455368
81 -12.843782007694244 -9.60162068006752
82 -32.78253722190857 -9.417787792759777
83 -30.145207583904266 -9.341257661417394
84 -9.838725969195366 -9.234473609296703
85 -21.517071286216378 -9.097960985817739
86 -5.373417943716049 -8.948814161027466
87 -9.611759051680565 -8.871736843520306
88 -5.319370090961456 -8.702786420730115
89 -2.7951642237603664 -8.48581153986115
90 -13.531035028398037 -8.283291948883095
91 -7.160679444670677 -8.158864633346008
92 -2.430210843682289 -8.102576723243399
93 -2.196336455643177 -7.96879715212365
94 -5.568964548408985 -7.658267844933078
95 -1.148206952959299 -7.556518392620508
96 -9.944959297776222 -7.440920124149799
97 -3.263685818761587 -7.311119301911722
98 -7.5019709169864655 -7.0399909507689955
99 -4.5808796510100365 -6.9142798394018055
100 -36.72963713109493 -6.776946485018116
101 -5.445914402604103 -6.652030620028519
102 -8.920011140406132 -6.550350872157854
103 -8.066950410604477 -6.485289165371682
104 -8.372724086046219 -6.3241826341847105
105 -5.4646559953689575 -6.233836010332017
106 -3.4489142559468746 -6.037414980024737
107 -2.7463738340884447 -5.732064972054174
108 1.2991830557584763 -5.416811752857713
109 -1.3988436609506607 -5.200760270303204
110 1.93726347386837 -4.8835068792504
111 1.0215918645262718 -4.717913171258486
112 -0.9423295333981514 -4.484173208288868
113 -1.5478166490793228 -4.289180880345788
114 2.6132498644292355 -4.116004088000472
115 -3.288563258945942 -3.885841100341837
116 2.2087791115045547 -3.6190423757374197
117 -2.954755112528801 -3.30953001960166
118 -3.964561454951763 -2.6416623314910934
119 4.033515185117722 -1.5513993748408543
train accuracy: 1.0
validation accuracy: 1.0
[-64.24997756 -63.70374526 -63.24332377 -63.23599055 -63.21105585
 -63.1277899  -63.03088591 -62.97836141 -62.8880408  -62.80700329
 -62.68654572 -62.59841154 -62.45659058 -62.22052465 -62.19961806
 -62.05545976 -61.99823876 -61.95028984 -61.90503048 -61.9024977
 -61.84514296 -61.82022345 -61.80958936 -61.60739549 -61.57987077
 -61.52954719 -61.49152331 -61.42319103 -61.37818898 -61.3242033
 -61.18861045 -61.11705014 -61.1111952  -61.05040259 -61.02959876
 -60.86594116 -60.76820853 -60.71067263 -60.70125881 -60.65715619
 -60.65245125 -60.56996954 -60.55874128 -60.5547045  -60.49758829
 -60.48258467 -60.45707335 -60.33754647 -60.3056539  -60.27108478
 -60.26518611 -60.24509979 -60.24180628 -60.22805253 -60.19573103
 -60.17226654 -60.15274555 -60.15029758 -60.11717494 -60.10592506
 -60.09749463 -60.0319431  -60.02722508 -60.00583218 -59.93393272
 -59.91659544 -59.87274329 -59.82531105 -59.80496242 -59.7917769
 -59.72419126 -59.70853732 -59.65998034 -59.65022384 -59.59719498
 -59.5305981  -59.50104536 -59.42996515 -59.42210572 -59.38924773
 -59.38736621 -59.38054209 -59.37607349 -59.37547196 -59.3637735
 -59.35769976 -59.35705669 -59.33804201 -59.3275818  -59.30965762
 -59.28574006 -59.23387086 -59.18464036 -59.10615862 -59.10256234
 -59.09671972 -59.00308265 -59.00287135 -58.98079589 -58.97692474
 -58.94034584 -58.91786584 -58.91394416 -58.85869868 -58.83781287
 -58.805901   -58.78928523 -58.78920472 -58.74515985 -58.7335467
 -58.6909254  -58.66521312 -58.60985472 -58.59427563 -58.58165728
 -58.52164071 -58.47633979 -58.46066973 -58.43515991 -58.42948108
 -58.34687794 -58.33955225 -58.3224997  -58.2747748  -58.26697037
 -58.26037219 -58.25791715 -58.25674195 -58.23564869 -58.23557227
 -58.18129208 -58.17849633 -58.12762104 -58.0861159  -58.07195587
 -58.05496853 -57.99583108 -57.97256269 -57.92377717 -57.89906439
 -57.86612124 -57.85252143 -57.79744436 -57.79024149 -57.78201503
 -57.76493642 -57.72031285 -57.55593357 -57.41744447 -57.41601846
 -57.38102245 -57.37258309 -57.22142181 -57.21444707 -57.21200816
 -57.16061789 -57.12957694 -57.07621127 -57.06529087 -57.04573717
 -56.92828118 -56.88160157 -56.87555564 -56.87062934 -56.72292153
 -56.70057749 -56.62581458 -56.40969062 -56.40899696 -56.32819744
 -56.18471197 -56.16037157 -56.0810036  -56.05279704 -55.96543435
 -55.96407105 -55.93162024 -55.80238333 -55.67010668 -55.50073526
 -55.32975789 -54.98547503 -54.6753876  -53.06095904 -50.4922686
 -50.03933802 -49.75347185 -49.72654641 -46.98011874 -45.73515428
 -45.67057988 -44.99030608 -44.14602409 -43.81326882 -43.18878399
 -42.29180715 -42.00401746 -41.69100444 -41.68588229 -41.2817771
 -40.44278203 -40.34838366 -39.59970115 -39.57586365 -39.31972693
 -39.02461056 -38.45534494 -38.4127039  -38.35634328 -37.79713617
 -37.74152899 -37.66475324 -37.51313938 -37.1809993  -37.10070314
 -37.00630589 -36.82191677 -36.48799015 -36.2096527  -36.19207562
 -36.11445903 -35.78149902 -35.39450387 -35.262825   -35.24303541
 -35.20970524 -35.06544085 -34.80241748 -34.64469045 -33.84284986
 -32.70706485 -31.9690994  -31.7109134  -31.64414356 -31.39238276
 -31.22319602 -31.12953085 -29.3915714  -29.34012561 -29.10618999
 -27.4110235  -27.34372236 -27.19668163 -27.07399029 -26.70472176
 -26.2447949  -25.54836509 -25.45878529 -24.879107   -24.82869536
 -24.59274514 -23.97874558 -23.57262108 -23.44970808 -22.74530916
 -22.60679894 -22.19891032 -20.65686376 -20.44447256 -20.29688418
 -20.23141807 -20.1969901  -20.13839115 -20.13020095 -19.84155928
 -19.71548984 -19.68899137 -19.68187944 -19.63760344 -19.51559872
 -19.46242624 -19.4608337  -19.4041006  -19.3558728  -18.9283881
 -18.73129823 -18.6143711  -18.59559194 -18.46499943 -18.43877077
 -18.38621926 -18.27561534 -17.99477406 -17.82791039 -17.5574237
 -17.4225533  -17.32401372 -17.2877303  -17.27734589 -17.17142851
 -17.12274042 -17.09111514 -16.99919682 -16.94289066 -16.93072955
 -16.90794731 -16.87179876 -16.82307393 -16.73124049 -16.67001724
 -16.58659093 -16.5598434  -16.32507254 -16.14499025 -16.11471807
 -15.99550761 -15.96630994 -15.89510862 -15.83529718 -15.81907162
 -15.73508957 -15.71653035 -15.68809365 -15.65454388 -15.64362673
 -15.53069614 -15.4996426  -15.47055242 -15.37516569 -15.31961676
 -15.29900699 -15.29752692 -15.27492849 -15.2719524  -15.18762033
 -15.1811829  -15.16489019 -15.13026299 -15.1168859  -15.11310895
 -15.09811232 -15.08546181 -15.05822392 -14.97059258 -14.9521175
 -14.9375075  -14.92482994 -14.89671643 -14.8550828  -14.7994931
 -14.77688108 -14.77118432 -14.65980608 -14.65234189 -14.594561
 -14.56214362 -14.5314246  -14.51447881 -14.50408185 -14.50203248
 -14.46874354 -14.4570134  -14.44242009 -14.42193758 -14.36850066
 -14.33258    -14.32950177 -14.32942426 -14.26617393 -14.25516391
 -14.23740337 -14.21922258 -14.1241903  -14.08340118 -14.04266231
 -14.04259387 -14.00918138 -14.00356944 -13.99901576 -13.98069366
 -13.96863183 -13.94553084 -13.92064094 -13.86308449 -13.82682946
 -13.82168222 -13.75062761 -13.74201371 -13.73538513 -13.7087974
 -13.70157677 -13.68760857 -13.67248689 -13.66926268 -13.65984887
 -13.65074556 -13.64233053 -13.608892   -13.59887363 -13.59601285
 -13.58322451 -13.5769007  -13.56118218 -13.53717325 -13.50058897
 -13.49625934 -13.48391162 -13.48040306 -13.46555991 -13.42154574
 -13.35053773 -13.34797433 -13.33800376 -13.33243944 -13.33224936
 -13.27632422 -13.26824662 -13.24746818 -13.21474879 -13.20797174
 -13.17814269 -13.17193674 -13.15006142 -13.13997741 -13.13985916
 -13.07123989 -13.05737342 -12.9932924  -12.9911753  -12.98804567
 -12.97789981 -12.96800891 -12.96736491 -12.94572355 -12.93760188
 -12.9165571  -12.90055132 -12.89533945 -12.89281313 -12.88420468
 -12.84456867 -12.80256509 -12.71571938 -12.7141283  -12.71256262
 -12.70915032 -12.69913989 -12.69796265 -12.68886431 -12.68787728
 -12.68476663 -12.68403935 -12.68135973 -12.67795632 -12.67412975
 -12.66418206 -12.65197265 -12.61294478 -12.60694569 -12.60505429
 -12.59604001 -12.59146077 -12.58492544 -12.56515032 -12.5568266
 -12.54337072 -12.53922889 -12.51687733 -12.49952894 -12.48960663
 -12.48846703 -12.47314213 -12.44235814 -12.42234736 -12.42037973
 -12.41787343 -12.39846884 -12.38653875 -12.37245474 -12.37013582
 -12.36915201 -12.36609991 -12.35920177 -12.34671509 -12.30017947
 -12.29446786 -12.28928631 -12.28346844 -12.24340388 -12.23008134
 -12.21444028 -12.20423388 -12.19488362 -12.19257471 -12.17081576
 -12.1680306  -12.1638277  -12.15190477 -12.14087299 -12.11267893
 -12.10286355 -12.0912212  -12.09013272 -12.07990884 -12.07648199
 -12.00031666 -11.99202899 -11.98617858 -11.97628117 -11.9718797
 -11.95815995 -11.94883147 -11.94387787 -11.92756804 -11.91392797
 -11.88741887 -11.8428853  -11.80244434 -11.79569585 -11.78885214
 -11.78173063 -11.7724129  -11.77120286 -11.76007221 -11.75199835
 -11.72866778 -11.72649421 -11.72030375 -11.70915921 -11.70702865
 -11.675454   -11.67485775 -11.65292186 -11.65251864 -11.64515292
 -11.6440414  -11.60903136 -11.56305121 -11.56047769 -11.54576322
 -11.48214076 -11.47061442 -11.40958857 -11.39809208 -11.39514232
 -11.35591972 -11.34816955 -11.32808601 -11.31835075 -11.31313567
 -11.27863965 -11.19948457 -11.11165846 -11.10389205 -11.1024487
 -11.077133   -11.07648117 -11.07460556 -11.05764881 -11.02152402
 -10.9955771  -10.99259242 -10.98789819 -10.96193206 -10.93551543
 -10.90788214 -10.89368728 -10.88947284 -10.88447672 -10.8699891
 -10.86367615 -10.84926681 -10.84529073 -10.83771365 -10.80258622
 -10.77708705 -10.77157448 -10.76373532 -10.7626531  -10.72252648
 -10.69169161 -10.68754535 -10.67394766 -10.64812666 -10.63577352
 -10.61795776 -10.59932568 -10.59550004 -10.59047519 -10.56525508
 -10.54372397 -10.50417679 -10.503667   -10.48131303 -10.47515775
 -10.4627546  -10.4515603  -10.44415981 -10.37561746 -10.3276815
 -10.32701661 -10.3238002  -10.31898966 -10.30373604 -10.2845271
 -10.2748125  -10.2212937  -10.17869462 -10.15370275 -10.14523977
 -10.129968   -10.12345655 -10.11680526 -10.10322222 -10.06917835
 -10.05434057 -10.0537485  -10.04940452 -10.04140071 -10.01117366
  -9.98600954  -9.97495295  -9.9649289   -9.9444303   -9.93667404
  -9.92882525  -9.89890309  -9.88877311  -9.87343312  -9.85721598
  -9.84881233  -9.84325222  -9.81081686  -9.8069955   -9.80144387
  -9.79295249  -9.76873248  -9.7513432   -9.70803505  -9.70232992
  -9.63006997  -9.61577792  -9.60231899  -9.60162068  -9.58783569
  -9.58053743  -9.52172806  -9.49727871  -9.47919626  -9.45788629
  -9.43866282  -9.43633846  -9.41778779  -9.41052059  -9.40824698
  -9.4057227   -9.35990043  -9.35743875  -9.34464202  -9.34459136
  -9.34125766  -9.34040597  -9.31853289  -9.31176385  -9.29755911
  -9.28970959  -9.25632952  -9.25412016  -9.23447361  -9.22954286
  -9.22723903  -9.1921269   -9.18824957  -9.1675625   -9.16101609
  -9.15969438  -9.1506692   -9.13624814  -9.12404452  -9.09796099
  -9.09284414  -9.07857942  -9.0417146   -9.00748237  -8.99211937
  -8.9703478   -8.95607401  -8.95330348  -8.94881416  -8.94199734
  -8.93518264  -8.93076101  -8.90666429  -8.8988321   -8.8972749
  -8.89093899  -8.87173684  -8.86797947  -8.83604846  -8.77833829
  -8.77695015  -8.77596385  -8.75445976  -8.74668312  -8.70278642
  -8.70262547  -8.65783194  -8.60684626  -8.56096114  -8.53555109
  -8.51901016  -8.51490444  -8.51210379  -8.49185067  -8.48581154
  -8.47990489  -8.47159783  -8.44199753  -8.43284839  -8.39800134
  -8.3384229   -8.33111246  -8.330117    -8.32432318  -8.32008606
  -8.30998059  -8.30771382  -8.30246843  -8.28329195  -8.28213149
  -8.27766006  -8.25863217  -8.23181323  -8.19902254  -8.18210422
  -8.17588348  -8.17526572  -8.15886463  -8.13319584  -8.13106665
  -8.11585115  -8.1092657   -8.10819769  -8.1047694   -8.10257672
  -8.07304872  -8.05532635  -8.03652725  -8.01910703  -8.00046014
  -7.99115734  -7.96879715  -7.8910885   -7.77734704  -7.77040944
  -7.76388228  -7.75584261  -7.6960871   -7.68055163  -7.65826784
  -7.65808398  -7.65274073  -7.61173669  -7.5816518   -7.57539849
  -7.57456638  -7.55651839  -7.55046962  -7.52235456  -7.51737497
  -7.51150784  -7.47253037  -7.45535888  -7.45456821  -7.44092012
  -7.41845597  -7.41820171  -7.40249522  -7.37568337  -7.37450683
  -7.36244313  -7.36120452  -7.3111193   -7.30007717  -7.28247429
  -7.27920819  -7.26120305  -7.23588878  -7.20531651  -7.17946489
  -7.12894301  -7.10832736  -7.03999095  -7.00869413  -6.95906356
  -6.95796342  -6.94830983  -6.94047157  -6.92998266  -6.91891198
  -6.91436759  -6.91427984  -6.91024552  -6.90972002  -6.87856825
  -6.86314327  -6.83788793  -6.78323296  -6.77694649  -6.76115764
  -6.73166861  -6.72206384  -6.71997062  -6.70339024  -6.68501373
  -6.65203062  -6.61930532  -6.61249558  -6.5779849   -6.57146323
  -6.55636471  -6.55182982  -6.55035087  -6.54227962  -6.53637975
  -6.53544734  -6.52502436  -6.51820418  -6.51142145  -6.49930281
  -6.48528917  -6.47362572  -6.43440264  -6.43176687  -6.42315718
  -6.4216571   -6.38246417  -6.37598427  -6.32418263  -6.31062378
  -6.29926238  -6.29192791  -6.28899961  -6.2883933   -6.28834113
  -6.24441631  -6.23383601  -6.17467673  -6.15634472  -6.14521167
  -6.13122052  -6.12398433  -6.05079552  -6.03741498  -6.0367839
  -5.93107726  -5.92948534  -5.90738164  -5.88727041  -5.88131406
  -5.79756389  -5.7888028   -5.73843016  -5.73206497  -5.67047791
  -5.6559233   -5.62903448  -5.61579673  -5.58211056  -5.56808905
  -5.4253026   -5.41773478  -5.41681175  -5.39914398  -5.39325437
  -5.38985093  -5.37005903  -5.3472021   -5.34113623  -5.32351909
  -5.2737561   -5.23946787  -5.22931427  -5.2113232   -5.21009546
  -5.20076027  -5.11968813  -5.1133638   -5.08944247  -5.07848501
  -5.07293845  -5.02795798  -4.94890606  -4.93844638  -4.9092485
  -4.89374732  -4.88350688  -4.87565908  -4.85614197  -4.82757292
  -4.82078597  -4.77444392  -4.76804903  -4.71791317  -4.69132254
  -4.66121849  -4.6362783   -4.63120683  -4.63049542  -4.60697954
  -4.48417321  -4.47381185  -4.42297854  -4.37854279  -4.37469524
  -4.36932192  -4.34616693  -4.29378326  -4.28918088  -4.2741627
  -4.27150294  -4.23731636  -4.230832    -4.18805978  -4.15758284
  -4.12643082  -4.11600409  -4.07483063  -4.03306984  -4.03104862
  -3.98730144  -3.98692761  -3.97905459  -3.89657065  -3.8858411
  -3.88252014  -3.80709015  -3.80423161  -3.7632261   -3.75328905
  -3.7297162   -3.7044508   -3.61904238  -3.61173136  -3.60327534
  -3.59536414  -3.56149099  -3.41390986  -3.38726063  -3.38446715
  -3.3582192   -3.3322555   -3.30953002  -3.26399767  -3.21746212
  -3.16707079  -3.01592538  -2.9831913   -2.87807425  -2.85217503
  -2.64166233  -2.56607549  -2.4075214   -2.38281504  -2.38277218
  -1.91361965  -1.90178954  -1.84200761  -1.58468169  -1.55139937]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Found existing model weights! Loading state dict...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:1
end of epoch 0: val_loss 3.6132021242423204e-05, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-7.7186e-03, -1.5673e-01, -2.6392e-03,  1.1330e-01,  4.8848e-01,
         -2.1524e-01, -2.2352e-02, -1.4718e-02, -3.5560e-01,  2.4993e-01,
          1.4611e-03, -1.4874e+00, -3.2134e+00]], device='cuda:1'))])
end of epoch 1: val_loss 5.2247035637051906e-05, val_acc 1.0
trigger times: 1
end of epoch 2: val_loss 0.13497382164001465, val_acc 0.995
trigger times: 2
end of epoch 3: val_loss 2.805884450793883e-06, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.6052e-01,  1.4719e-01,  1.0265e-05,  2.0220e-01,  1.1722e-01,
         -7.1556e-02,  8.3683e-03, -2.7435e-02, -5.1948e-05,  1.0079e-05,
          1.4606e-03, -2.1517e+00, -3.5367e+00]], device='cuda:1'))])
end of epoch 4: val_loss 0.0005170415597651612, val_acc 1.0
trigger times: 1
end of epoch 5: val_loss 0.035145688056945804, val_acc 0.995
trigger times: 2
end of epoch 6: val_loss 0.0007455606013524018, val_acc 1.0
trigger times: 3
end of epoch 7: val_loss 7.932825904788388e-07, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 7.3311e-05, -9.3747e-06,  1.1098e-06, -9.1372e-06, -1.3474e-04,
          9.8681e-06,  5.1333e-08,  3.8499e-06, -6.7943e-05,  1.2885e-05,
          1.4598e-03, -1.8276e+00, -3.1882e+00]], device='cuda:1'))])
end of epoch 8: val_loss 0.3969572207426813, val_acc 0.97
trigger times: 1
end of epoch 9: val_loss 0.11227265339322287, val_acc 0.99
trigger times: 2
end of epoch 10: val_loss 0.004485183072028391, val_acc 0.995
trigger times: 3
end of epoch 11: val_loss 0.10613504049209724, val_acc 0.99
trigger times: 4
end of epoch 12: val_loss 0.043802205342472006, val_acc 0.995
trigger times: 5
end of epoch 13: val_loss 6.788508471800015e-07, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.7763e-01,  4.1047e-01,  7.3314e-02,  5.0994e-01,  9.7276e-01,
          2.8918e-05,  4.0041e-03, -1.6531e-01, -2.5078e-01,  1.3686e-05,
          1.4587e-03, -4.1963e+00, -4.6721e+00]], device='cuda:1'))])
end of epoch 14: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.4506e-01,  3.2422e-01, -1.2728e-05,  4.1745e-01,  2.8930e-01,
          2.5927e-05,  2.3318e-03, -1.3439e-01,  8.5518e-05,  9.9582e-06,
          1.4585e-03, -3.6732e+00, -4.5435e+00]], device='cuda:1'))])
end of epoch 15: val_loss 2.2817886383208476e-06, val_acc 1.0
trigger times: 1
end of epoch 16: val_loss 0.1089735221862793, val_acc 0.995
trigger times: 2
end of epoch 17: val_loss 2.602967105218568e-06, val_acc 1.0
trigger times: 3
end of epoch 18: val_loss 8.9310886807894e-05, val_acc 1.0
trigger times: 4
end of epoch 19: val_loss 0.05161987707018568, val_acc 0.995
trigger times: 5
end of epoch 20: val_loss 3.3710249772411772e-06, val_acc 1.0
trigger times: 6
end of epoch 21: val_loss 0.0001797511427994536, val_acc 1.0
trigger times: 7
end of epoch 22: val_loss 5.316477881578407e-07, val_acc 1.0
trigger times: 8
end of epoch 23: val_loss 3.866224136395147e-06, val_acc 1.0
trigger times: 9
end of epoch 24: val_loss 0.004198136675695316, val_acc 0.995
trigger times: 10
Early stopping.
0 -149.25167751312256 -64.24997755966005
1 -147.8909707069397 -62.88804080478943
2 -355.25430488586426 -61.99823875652866
3 -338.6878716945648 -61.579870773756845
4 -352.7128973007202 -61.11119519527381
5 -142.60865092277527 -60.65245125321905
6 -335.24198269844055 -60.30565389715317
7 -142.13232266902924 -60.15274554520394
8 -349.6091055870056 -59.93393271991266
9 -140.9249448776245 -59.65022383714258
10 -347.27907705307007 -59.38054208716919
11 -348.08666944503784 -59.30965761818191
12 -139.2738757133484 -59.002871349259806
13 -348.0714063644409 -58.80590100141775
14 -346.19505167007446 -58.59427563494649
15 -140.50242829322815 -58.33955224939051
16 -138.5623824596405 -58.23557226747384
17 -344.37500953674316 -57.97256269034124
18 -343.8442130088806 -57.76493641696005
19 -342.39113998413086 -57.21444707225147
20 -344.1255521774292 -56.88160156565213
21 -339.6433815956116 -56.32819743601017
22 -137.30770897865295 -55.8023833347529
23 -176.06305849552155 -50.03933801517046
24 -193.48786407709122 -43.81326882122305
25 -191.68236070871353 -40.34838365523108
26 -156.76135140657425 -37.741528994987384
27 -137.58179485797882 -36.20965269874363
28 -160.29326170682907 -35.0654408505187
29 -132.23523443937302 -31.392382758954444
30 -133.38340508937836 -27.196681629483837
31 -109.67434909939766 -24.592745144504722
32 -115.9694516658783 -20.444472560731253
33 -55.47282260656357 -19.688991370547306
34 -104.98706930875778 -18.92838809611677
35 -102.27796737849712 -17.994774057192853
36 -48.56774598360062 -17.122740424617255
37 -55.58653363585472 -16.731240494206556
38 -48.9102481007576 -15.966309942157581
39 -37.90239903330803 -15.643626730923627
40 -40.292103454470634 -15.27492848809101
41 -53.49560847878456 -15.098112319720741
42 -81.1779679954052 -14.855082803515382
43 -40.047700852155685 -14.514478811012838
44 -44.543060928583145 -14.332580004205116
45 -33.53368307650089 -14.083401177177324
46 -50.67063796520233 -13.945530841132388
47 -34.40657549351454 -13.708797395444524
48 -49.26196935772896 -13.608891999152753
49 -43.17965358495712 -13.49625933783258
50 -39.680930223315954 -13.33243944471695
51 -49.51727885007858 -13.171936739318621
52 -52.22685742378235 -12.988045670217158
53 -46.97288289666176 -12.895339452657973
54 -48.24456798285246 -12.709150323057631
55 -27.99323619902134 -12.677956322862864
56 -41.98404133319855 -12.591460773750322
57 -37.7983411103487 -12.489606634434601
58 -36.99554508924484 -12.386538751612271
59 -33.8846814930439 -12.294467860490283
60 -51.05009388923645 -12.170815759622592
61 -35.152223125100136 -12.090132715561564
62 -35.9755595177412 -11.958159945926957
63 -27.89562037587166 -11.79569585480859
64 -30.32173791527748 -11.72649421388079
65 -33.793887078762054 -11.645152917994393
66 -36.18956410884857 -11.409588574446387
67 -46.816955626010895 -11.278639647398466
68 -35.07090425491333 -11.057648811376822
69 -47.355930387973785 -10.8936872753186
70 -26.427680492401123 -10.80258622313121
71 -24.81488584727049 -10.67394766025975
72 -27.787405610084534 -10.543723966966787
73 -44.11657679080963 -10.375617458556032
74 -29.444209218025208 -10.221293700781203
75 -41.24772575497627 -10.069178353474605
76 -29.25845217704773 -9.964928903646708
77 -41.50192905217409 -9.843252216045357
78 -28.173419535160065 -9.70232991745162
79 -36.30610117316246 -9.497278713464329
80 -33.96175932884216 -9.405722697401767
81 -33.52532361447811 -9.311763851426697
82 -24.13178487122059 -9.192126898690297
83 -38.29005005955696 -9.097960985817739
84 -29.60864007472992 -8.953303475404077
85 -26.98359263688326 -8.890938994788185
86 -32.773894026875496 -8.746683116661854
87 -27.926040947437286 -8.514904439728918
88 -20.158853940665722 -8.398001337047377
89 -32.50825238227844 -8.302468427151881
90 -25.281389266252518 -8.175883476010872
91 -27.32964998483658 -8.104769395081362
92 -24.133745156228542 -7.96879715212365
93 -29.52800290286541 -7.658267844933078
94 -25.151033520698547 -7.522354560083883
95 -27.78073614835739 -7.418201709745239
96 -21.939244657754898 -7.282474286389515
97 -22.386559285223484 -7.0399909507689955
98 -25.417716421186924 -6.914367593932078
99 -55.860194995999336 -6.776946485018116
100 -19.43179703503847 -6.619305321127111
101 -24.32323917001486 -6.536379750179507
102 -25.502056941390038 -6.43440263596193
103 -20.181964855641127 -6.299262377814018
104 -26.021785840392113 -6.156344716177216
105 -28.506804779171944 -5.929485339829026
106 -19.618036456406116 -5.670477906548994
107 -21.651638820767403 -5.416811752857713
108 -22.413671500980854 -5.273756100604971
109 -18.42774772644043 -5.08944247281534
110 -17.52651136368513 -4.8835068792504
111 -26.347703240811825 -4.661218488586161
112 -18.192257396876812 -4.378542787064294
113 -15.240200288593769 -4.237316361327979
114 -27.68154001235962 -4.031048624093466
115 -20.796524189412594 -3.8042316132412286
116 -13.203734375536442 -3.595364142259748
117 -18.56200383976102 -3.263997667566093
118 -17.111898869276047 -2.5660754865197153
119 -15.75219327583909 -1.5513993748408543
train accuracy: 0.9994444444444445
validation accuracy: 0.995
[-64.24997756 -63.70374526 -63.24332377 ...  -1.58468169  -1.55139937
  -1.52518957]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Found existing model weights! Loading state dict...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:1
end of epoch 0: val_loss 3.450993240150524e-07, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.6690e-01,  1.2819e-01, -1.3492e-01,  2.3255e-01,  3.9130e-01,
         -2.7610e-01, -1.4449e-02, -1.6672e-01, -1.2567e-05,  1.2919e-01,
          1.0552e-03, -2.2197e+00, -2.1727e+00]], device='cuda:1'))])
end of epoch 1: val_loss 38.19840731683652, val_acc 0.675
trigger times: 1
end of epoch 2: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.5337e-01,  2.1826e-01, -8.3437e-02,  5.5672e-01,  9.9546e-01,
         -1.4355e-01,  2.6304e-02, -2.3059e-01, -6.6502e-02, -3.0796e-02,
         -2.5234e-03, -3.9127e+00, -3.4537e+00]], device='cuda:1'))])
end of epoch 3: val_loss 2.622597548906924e-08, val_acc 1.0
trigger times: 1
end of epoch 4: val_loss 1.0907115013480961e-06, val_acc 1.0
trigger times: 2
end of epoch 5: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.7681e-01,  5.9349e-01, -1.1653e-01,  4.1814e-01,  1.2947e+00,
         -6.0399e-01,  2.6905e-04, -3.8565e-01, -8.9101e-01,  4.7708e-01,
          1.6335e-03, -3.0192e+00, -3.6548e+00]], device='cuda:1'))])
end of epoch 6: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.1349e-02,  3.9593e-01, -2.0715e-01,  4.5192e-01,  8.1166e-01,
         -2.3486e-01, -1.9912e-02, -2.7050e-01, -1.2670e-01, -1.2851e-05,
         -1.1966e-03, -3.4604e+00, -3.5296e+00]], device='cuda:1'))])
end of epoch 7: val_loss 2.1457580885453352e-07, val_acc 1.0
trigger times: 1
end of epoch 8: val_loss 4.447318767205388e-05, val_acc 1.0
trigger times: 2
end of epoch 9: val_loss 7.021395960009613e-06, val_acc 1.0
trigger times: 3
end of epoch 10: val_loss 2.444005125833546, val_acc 0.91
trigger times: 4
end of epoch 11: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.9817e-01,  2.4966e-01, -1.9374e-01,  6.5864e-01,  5.7115e-01,
         -1.0253e+00,  1.3327e-03, -2.9849e-01,  9.5156e-02,  4.6183e-01,
         -8.0887e-04, -3.7614e+00, -3.8108e+00]], device='cuda:1'))])
end of epoch 12: val_loss 1.4901150926505124e-08, val_acc 1.0
trigger times: 1
end of epoch 13: val_loss 4.982733137026685e-07, val_acc 1.0
trigger times: 2
end of epoch 14: val_loss 0.10786128369940115, val_acc 0.995
trigger times: 3
end of epoch 15: val_loss 1.7881391656260348e-09, val_acc 1.0
trigger times: 4
end of epoch 16: val_loss 5.304801522498792e-08, val_acc 1.0
trigger times: 5
end of epoch 17: val_loss 2.0126313282524678e-05, val_acc 1.0
trigger times: 6
end of epoch 18: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.0469e-01,  3.5685e-01, -4.3072e-02,  6.0732e-01,  1.0431e+00,
         -8.8989e-01,  1.0363e-04, -2.9494e-01,  2.6551e-02,  6.5322e-01,
          5.6004e-04, -3.6438e+00, -4.0337e+00]], device='cuda:1'))])
end of epoch 19: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.0701e-01,  2.7726e-01, -2.7943e-06,  5.0749e-01,  5.5694e-01,
         -3.6363e-01, -2.4344e-07, -2.6487e-01,  7.6307e-06,  1.7564e-01,
         -2.5222e-03, -3.2347e+00, -3.8874e+00]], device='cuda:1'))])
end of epoch 20: val_loss 1.0019329576138603e-06, val_acc 1.0
trigger times: 1
end of epoch 21: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.1761e-01,  2.6782e-01, -1.7486e-01,  6.7339e-01,  1.0008e+00,
         -1.4093e+00, -1.0808e-02, -3.3008e-01, -1.9732e-01,  7.4560e-01,
          1.9272e-03, -4.2725e+00, -4.6574e+00]], device='cuda:1'))])
end of epoch 22: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.2055e-01,  1.8404e-01, -5.0571e-02,  5.5566e-01,  6.1090e-01,
         -8.0704e-01, -9.0418e-03, -2.9977e-01,  7.9060e-06,  2.4103e-01,
          1.6349e-03, -3.8671e+00, -4.5274e+00]], device='cuda:1'))])
end of epoch 23: val_loss 2.8660081130382764e-06, val_acc 1.0
trigger times: 1
end of epoch 24: val_loss 1.0728830908135479e-08, val_acc 1.0
trigger times: 2
end of epoch 25: val_loss 5.6028299084687204e-08, val_acc 1.0
trigger times: 3
end of epoch 26: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.3259e-04,  2.6790e-01, -2.6055e-05,  2.0478e-01,  6.6256e-01,
         -2.4818e-01, -3.5812e-02, -1.8177e-01, -1.9863e-01,  1.3733e-01,
          5.6172e-04, -3.0199e+00, -4.4841e+00]], device='cuda:1'))])
end of epoch 27: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 1
end of epoch 28: val_loss 4.14243837347783e-07, val_acc 1.0
trigger times: 2
end of epoch 29: val_loss 1.1538900567842348e-06, val_acc 1.0
trigger times: 3
end of epoch 30: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.2514e-01,  1.2357e-01,  2.4470e-02,  2.4674e-01,  9.9105e-01,
         -9.7904e-01, -2.5259e-02, -2.3369e-01, -5.8950e-01,  5.0387e-01,
         -1.5126e-04, -3.3213e+00, -4.3805e+00]], device='cuda:1'))])
end of epoch 31: val_loss 0.09099964159502122, val_acc 0.99
trigger times: 1
end of epoch 32: val_loss 4.172324530316018e-09, val_acc 1.0
trigger times: 2
end of epoch 33: val_loss 4.398752396284067e-07, val_acc 1.0
trigger times: 3
end of epoch 34: val_loss 3.6573823312799904e-05, val_acc 1.0
trigger times: 4
end of epoch 35: val_loss 1.1920924656294574e-08, val_acc 1.0
trigger times: 5
end of epoch 36: val_loss 1.4305109452550369e-08, val_acc 1.0
trigger times: 6
end of epoch 37: val_loss 1.7988103840949067e-06, val_acc 1.0
trigger times: 7
end of epoch 38: val_loss 1.1138876281435728e-06, val_acc 1.0
trigger times: 8
end of epoch 39: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.2327e-01,  1.3807e-01, -7.9196e-02,  1.7109e-01,  6.6197e-01,
         -4.1172e-01, -1.4373e-02, -1.1968e-01,  1.1238e-01,  8.0522e-02,
          1.6361e-03, -2.8893e+00, -2.9090e+00]], device='cuda:1'))])
end of epoch 40: val_loss 1.7881387712748166e-08, val_acc 1.0
trigger times: 1
end of epoch 41: val_loss 9.065382182594561e-05, val_acc 1.0
trigger times: 2
end of epoch 42: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.5502e-01,  1.7207e-01, -1.0400e-01,  4.9715e-01,  7.2360e-01,
         -5.0371e-01,  7.6789e-03, -3.4920e-01, -1.7277e-01,  1.3960e-01,
         -7.4069e-04, -3.9613e+00, -3.9572e+00]], device='cuda:1'))])
end of epoch 43: val_loss 9.5121661615849e-07, val_acc 1.0
trigger times: 1
end of epoch 44: val_loss 4.1723246724245655e-09, val_acc 1.0
trigger times: 2
end of epoch 45: val_loss 1.4256716103133726e-06, val_acc 1.0
trigger times: 3
end of epoch 46: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 4
end of epoch 47: val_loss 1.3925397778216108e-05, val_acc 1.0
trigger times: 5
end of epoch 48: val_loss 2.0806850882841843e-05, val_acc 1.0
trigger times: 6
end of epoch 49: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.0589e-01,  4.3678e-01, -8.7234e-02,  7.6461e-01,  8.3474e-01,
         -8.9117e-01, -3.0895e-02, -3.0174e-01, -1.6722e-02,  3.4161e-01,
          3.2904e-04, -3.4845e+00, -3.7404e+00]], device='cuda:1'))])
end of epoch 50: val_loss 9.119472718310817e-08, val_acc 1.0
trigger times: 1
end of epoch 51: val_loss 1.3947406724668098e-07, val_acc 1.0
trigger times: 2
end of epoch 52: val_loss 3.3394199817244896e-05, val_acc 1.0
trigger times: 3
end of epoch 53: val_loss 1.1920927533992654e-09, val_acc 1.0
trigger times: 4
end of epoch 54: val_loss 2.0444126562324526e-07, val_acc 1.0
trigger times: 5
end of epoch 55: val_loss 2.6960700882909805e-05, val_acc 1.0
trigger times: 6
end of epoch 56: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.3420e-01,  3.1901e-01, -5.0335e-02,  6.5074e-01,  8.4584e-01,
         -9.2401e-01, -5.0804e-03, -2.3535e-01,  8.9578e-02,  4.7383e-01,
          1.6374e-03, -3.5797e+00, -4.2619e+00]], device='cuda:1'))])
end of epoch 57: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.8321e-01,  2.1775e-01,  4.1842e-06,  4.8475e-01,  6.2556e-01,
         -5.2558e-01, -1.8214e-03, -2.1749e-01, -2.2510e-05,  5.9635e-02,
         -1.1928e-03, -3.4167e+00, -4.1153e+00]], device='cuda:1'))])
end of epoch 58: val_loss 1.5239969671654307e-06, val_acc 1.0
trigger times: 1
end of epoch 59: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 6.5053e-01,  1.4160e-04,  1.0068e-01,  3.8522e-01,  7.3580e-01,
         -5.1113e-01,  1.4002e-02, -1.6906e-01,  2.8020e-05,  2.3988e-01,
         -7.3944e-04, -3.7448e+00, -4.4255e+00]], device='cuda:1'))])
end of epoch 60: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.1844e-01, -8.7794e-02, -2.8305e-05,  3.4314e-01,  2.4441e-01,
         -2.6947e-01,  3.5091e-03, -9.8704e-02, -9.2912e-05,  2.5290e-05,
          5.6423e-04, -3.8281e+00, -4.2347e+00]], device='cuda:1'))])
end of epoch 61: val_loss 1.7881392366803084e-09, val_acc 1.0
trigger times: 1
end of epoch 62: val_loss 0.08907203215884238, val_acc 0.995
trigger times: 2
end of epoch 63: val_loss 9.596255949873011e-08, val_acc 1.0
trigger times: 3
end of epoch 64: val_loss 2.145765492400642e-08, val_acc 1.0
trigger times: 4
end of epoch 65: val_loss 7.193178743154504e-05, val_acc 1.0
trigger times: 5
end of epoch 66: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.6102e-01,  2.5352e-01,  4.4946e-02,  5.6045e-01,  1.2487e+00,
         -5.2117e-01, -2.1451e-03, -3.2959e-01, -1.4587e-01,  5.2893e-01,
          3.3030e-04, -3.5658e+00, -4.3990e+00]], device='cuda:1'))])
end of epoch 67: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 1
end of epoch 68: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 5.2166e-02,  8.9656e-02, -4.3430e-02,  1.4943e-01,  2.2823e-01,
          6.2217e-05, -9.5169e-03, -1.2200e-01, -2.2018e-04, -1.6413e-04,
          1.0604e-03, -3.0985e+00, -3.8377e+00]], device='cuda:1'))])
end of epoch 69: val_loss 3.936249254508084e-06, val_acc 1.0
trigger times: 1
end of epoch 70: val_loss 8.582998759720795e-08, val_acc 1.0
trigger times: 2
end of epoch 71: val_loss 0.020735219434136525, val_acc 0.995
trigger times: 3
end of epoch 72: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.3812e-01,  2.8858e-01, -1.6731e-01,  7.5660e-01,  8.6888e-01,
         -6.7827e-01,  1.8476e-02, -2.8053e-01,  3.7331e-02,  3.6405e-01,
          1.9310e-03, -3.8691e+00, -4.4952e+00]], device='cuda:1'))])
end of epoch 73: val_loss 4.410693338030569e-07, val_acc 1.0
trigger times: 1
end of epoch 74: val_loss 2.6822073060372985e-08, val_acc 1.0
trigger times: 2
end of epoch 75: val_loss 7.5224448653088415e-06, val_acc 1.0
trigger times: 3
end of epoch 76: val_loss 1.5380364422981075e-05, val_acc 1.0
trigger times: 4
end of epoch 77: val_loss 1.3827598221993753e-06, val_acc 1.0
trigger times: 5
end of epoch 78: val_loss 0.25317094056022954, val_acc 0.985
trigger times: 6
end of epoch 79: val_loss 5.18533524882514e-07, val_acc 1.0
trigger times: 7
end of epoch 80: val_loss 1.936543568124449e-05, val_acc 1.0
trigger times: 8
end of epoch 81: val_loss 1.7881390590446245e-09, val_acc 1.0
trigger times: 9
end of epoch 82: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 10
Early stopping.
0 -242.26007175445557 -64.24997755966005
1 -294.7640190124512 -62.80700329025705
2 -291.6792240142822 -61.90503048142668
3 -282.3514702320099 -61.42319102765305
4 -231.29500699043274 -60.768208531618576
5 -232.45893263816833 -60.48258466842324
6 -225.07239699363708 -60.1957310292123
7 -226.29875946044922 -60.005832176913664
8 -224.53631711006165 -59.65022383714258
9 -221.06607937812805 -59.37607349488517
10 -224.73889112472534 -59.23387085670412
11 -221.79531931877136 -58.94034583502592
12 -238.6269497871399 -58.73354670235131
13 -276.72589111328125 -58.435159913106844
14 -217.00888633728027 -58.25674194963877
15 -271.76802039146423 -57.99583107700068
16 -269.3767583370209 -57.76493641696005
17 -270.8268404006958 -57.2120081575398
18 -217.48879742622375 -56.87062934242708
19 -268.21564245224 -56.08100359683293
20 -201.970064163208 -54.98547503240923
21 -212.6397004723549 -45.670579884154705
22 -185.06612503528595 -41.281777102712205
23 -123.82662290334702 -37.79713616772368
24 -115.77000284194946 -36.20965269874363
25 -126.83423262834549 -34.80241747531743
26 -130.05888313055038 -31.12953085092458
27 -114.70914250612259 -26.244794902859052
28 -108.83287778496742 -22.745309160183492
29 -76.73305171728134 -20.130200951335638
30 -71.6224952340126 -19.404100596970896
31 -64.88052636384964 -18.27561534160692
32 -69.0355252623558 -17.122740424617255
33 -55.70237070322037 -16.67001723842762
34 -50.49892544746399 -15.835297177460307
35 -63.52988123893738 -15.470552415272056
36 -59.090733759105206 -15.164890192965451
37 -57.27112287282944 -14.937507500431966
38 -53.68213778734207 -14.562143622584056
39 -48.68164098262787 -14.415969828843615
40 -48.85656923055649 -14.16450857777311
41 -47.635620921850204 -13.968631831022643
42 -45.95239019393921 -13.708797395444524
43 -55.575160562992096 -13.642330526293769
44 -42.44789558649063 -13.50058896501544
45 -55.29289722442627 -13.33243944471695
46 -53.64470690488815 -13.171936739318621
47 -51.33658382296562 -12.988045670217158
48 -49.35938847064972 -12.892813128746589
49 -46.0329655110836 -12.69913989049741
50 -68.3296000957489 -12.66418205637357
51 -42.424741953611374 -12.562398832400792
52 -43.29599133133888 -12.442358135712283
53 -41.23114953935146 -12.366099911819555
54 -44.49092215299606 -12.230081339442261
55 -47.587008982896805 -12.14087298898016
56 -52.67527496814728 -11.992028988148608
57 -46.156947672367096 -11.8894336466025
58 -51.923754543066025 -11.760072210591307
59 -38.067406095564365 -11.667284945982953
60 -45.830415949225426 -11.545763222571745
61 -37.85453852266073 -11.358714206443526
62 -36.95101052522659 -11.241732156098267
63 -46.453973948955536 -11.057648811376822
64 -24.878148660063744 -10.935515434552395
65 -48.91957013309002 -10.845290734893993
66 -37.174660712480545 -10.691691612870416
67 -39.20050060749054 -10.565255076788409
68 -39.32777348160744 -10.462754599027946
69 -36.32183362543583 -10.318989664989916
70 -42.59064030647278 -10.153702747757642
71 -42.16519033908844 -10.053748498225925
72 -43.958527237176895 -9.936674043396035
73 -41.975048780441284 -9.806995500901422
74 -34.18137055635452 -9.615777917408376
75 -33.21955782175064 -9.457886286988117
76 -39.13882890343666 -9.405722697401767
77 -34.76696163415909 -9.29755910956558
78 -39.18444633483887 -9.188249565177488
79 -34.66331070661545 -9.078579418069605
80 -42.56522595882416 -8.953303475404077
81 -31.494134306907654 -8.897274903905352
82 -34.306766748428345 -8.768010831745558
83 -29.991134241223335 -8.552142496825635
84 -40.772731721401215 -8.46533136670873
85 -33.01143418252468 -8.32008606301258
86 -41.70118710398674 -8.21701593710685
87 -30.046200424432755 -8.115851147367104
88 -23.812408708035946 -8.044773984158212
89 -37.349212646484375 -7.851295186295653
90 -35.06399147212505 -7.658083984004526
91 -29.175642922520638 -7.550469616919059
92 -25.140621662139893 -7.454568213253934
93 -33.8710884898901 -7.311119301911722
94 -26.564110800623894 -7.154370792254874
95 -29.13294281065464 -6.957963417531223
96 -20.536817222833633 -6.909720024820889
97 -43.71903535723686 -6.719970621583102
98 -15.676723822951317 -6.556364713803207
99 -23.930507391691208 -6.499302807669057
100 -13.279315501451492 -6.382464170725696
101 -22.598839446902275 -6.2883411317323175
102 -22.419895470142365 -6.101957831720261
103 -13.961908385157585 -5.88727040936199
104 -33.72323787212372 -5.615796733870542
105 -26.35166335105896 -5.399143980669317
106 -26.22160452604294 -5.323519088860305
107 -26.48306977748871 -5.119688133000968
108 -23.561911642551422 -4.944223417942701
109 -31.50088845193386 -4.827572916892203
110 -20.271208450198174 -4.6913225421922755
111 -15.831970289349556 -4.494520222313786
112 -15.656626239418983 -4.274162702601513
113 -14.181633718311787 -4.074830630124018
114 -9.237340241670609 -3.882520144516984
115 -23.213291227817535 -3.611731361378978
116 -26.970091462135315 -3.3322555012187633
117 -8.080001935362816 -2.9321988135982404
118 -7.6698714680969715 -2.3827721822698673
119 -3.8913265243172646 -1.5251895695875948
train accuracy: 1.0
validation accuracy: 1.0
[-64.24997756 -63.70374526 -63.24332377 ...  -1.58468169  -1.55139937
  -1.52518957]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Found existing model weights! Loading state dict...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:0
end of epoch 0: val_loss 0.00019760621466478057, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.0222e-02,  1.5378e-02, -1.1907e-05,  1.3229e-01,  1.0721e-01,
         -4.3801e-05, -1.0258e-02, -3.8451e-02, -3.9418e-05,  2.7203e-05,
         -1.3811e-03, -1.0889e+00, -1.2730e+00]], device='cuda:0'))])
end of epoch 1: val_loss 0.3841142101120187, val_acc 0.98
trigger times: 1
end of epoch 2: val_loss 0.04467235494585111, val_acc 0.995
trigger times: 2
end of epoch 3: val_loss 2.2887718358788334e-07, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.3064e-01,  1.8566e-01,  1.8304e-01,  6.3076e-01,  5.7635e-01,
         -7.0774e-05, -3.2078e-02, -1.8635e-01,  7.4098e-05, -3.4265e-05,
         -1.3806e-03, -3.0529e+00, -2.7226e+00]], device='cuda:0'))])
end of epoch 4: val_loss 0.005062170575069977, val_acc 0.995
trigger times: 1
end of epoch 5: val_loss 0.023027550922087414, val_acc 0.995
trigger times: 2
end of epoch 6: val_loss 1.7344821571896317e-07, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.0269e-01,  1.7881e-01, -1.1125e-03,  1.4749e-01,  6.6755e-01,
         -1.4732e-01, -2.6603e-02, -6.6389e-02, -1.2638e-06, -1.7041e-05,
         -1.3801e-03, -2.6802e+00, -2.6918e+00]], device='cuda:0'))])
end of epoch 7: val_loss 3.1053558917193415e-07, val_acc 1.0
trigger times: 1
end of epoch 8: val_loss 0.0005225054724684952, val_acc 1.0
trigger times: 2
end of epoch 9: val_loss 0.007529167249449315, val_acc 0.995
trigger times: 3
end of epoch 10: val_loss 0.02087372072040999, val_acc 0.995
trigger times: 4
end of epoch 11: val_loss 0.00013389347983618904, val_acc 1.0
trigger times: 5
end of epoch 12: val_loss 1.5560269039802677e-05, val_acc 1.0
trigger times: 6
end of epoch 13: val_loss 0.04565619681961831, val_acc 0.995
trigger times: 7
end of epoch 14: val_loss 0.04262705742067947, val_acc 0.995
trigger times: 8
end of epoch 15: val_loss 0.1865464705039335, val_acc 0.995
trigger times: 9
end of epoch 16: val_loss 0.07168383240699767, val_acc 0.995
trigger times: 10
Early stopping.
0 -228.30495691299438 -64.24997755966005
1 -224.22421193122864 -62.68654572343652
2 -223.50846886634827 -61.8451429617405
3 -218.00950980186462 -61.18861045261629
4 -212.90764117240906 -60.65245125321905
5 -212.2200207710266 -60.265186114810795
6 -215.1236114501953 -60.097494627344915
7 -217.61485624313354 -59.70853732071692
8 -206.97469973564148 -59.38054208716919
9 -209.17135858535767 -59.23387085670412
10 -210.15750217437744 -58.917865836248325
11 -207.67492198944092 -58.665213124551194
12 -207.4455435872078 -58.33955224939051
13 -209.65238428115845 -58.17849633005532
14 -207.78315663337708 -57.85252143275963
15 -170.89408922195435 -57.37258308967305
16 -202.9567301273346 -56.88160156565213
17 -199.966810464859 -56.160371572001424
18 -152.2302641272545 -54.98547503240923
19 -131.6040490269661 -44.99030608142343
20 -108.11588740348816 -39.599701153458774
21 -174.35824665427208 -37.513139380385574
22 -136.6644721031189 -35.394503873250635
23 -108.21892082691193 -31.7109134007892
24 -96.9481708407402 -27.196681629483837
25 -92.47055661678314 -23.57262108435893
26 -37.573429584503174 -20.13839114930498
27 -48.12074573338032 -19.404100596970896
28 -73.35192930698395 -17.994774057192853
29 -56.34271550178528 -16.999196821113756
30 -53.32380636036396 -16.325072543773945
31 -27.88121424615383 -15.688093648724399
32 -56.603963777422905 -15.27492848809101
33 -51.628676280379295 -15.058223915588862
34 -58.74794928729534 -14.652341887250738
35 -93.77096794173121 -14.442420089224363
36 -16.88115629553795 -14.219222576235238
37 -44.71401157975197 -13.968631831022643
38 -30.251192301511765 -13.735385127446426
39 -18.24687883257866 -13.642330526293769
40 -91.8862011730671 -13.498675852241899
41 -10.876863896846771 -13.332249355787466
42 -53.41746839880943 -13.139977413001635
43 -56.2444172501564 -12.96736490740605
44 -4.186928808689117 -12.715719378618282
45 -18.062280222773552 -12.684039348363536
46 -84.24637424945831 -12.59534011974936
47 -43.59954020380974 -12.48846702822902
48 -78.75906521081924 -12.376423021064726
49 -4.448184281587601 -12.29164822881694
50 7.973334111273289 -12.168030602691552
51 -11.823309153318405 -12.076481989890604
52 -86.93186068534851 -11.947269485081954
53 -40.21944475919008 -11.781730626483084
54 -45.61625340208411 -11.707028646158562
55 -0.012566342949867249 -11.563051213932392
56 -7.741372734308243 -11.39809207860808
57 -73.76356446743011 -11.313065548445687
58 -11.961710348725319 -11.077132998261037
59 6.669803209602833 -10.992592424150928
60 -8.097757071256638 -10.863676145188224
61 -35.25236025452614 -10.763735316928473
62 -9.91931688785553 -10.635773524216969
63 -4.431037060916424 -10.515780269573856
64 -10.642590463161469 -10.40376100213295
65 -12.160384133458138 -10.323800197325069
66 8.81572012975812 -10.200877130093161
67 -52.12385278940201 -10.054340569736782
68 -30.340409725904465 -9.94443029602658
69 -1.4587973728775978 -9.810816856292112
70 -32.26359261572361 -9.630069973226872
71 -23.9311403632164 -9.457886286988117
72 -16.59880543500185 -9.405722697401767
73 9.699701637029648 -9.28970959306215
74 -1.379467561841011 -9.188249565177488
75 2.6464565843343735 -9.078579418069605
76 13.286640278995037 -8.956074008201085
77 6.199217081069946 -8.897274903905352
78 2.6712521389126778 -8.768010831745558
79 6.123542428016663 -8.552142496825635
80 -13.938540041446686 -8.46533136670873
81 -41.03063082695007 -8.330116995310416
82 -0.5941582843661308 -8.258632170516377
83 -27.152574837207794 -8.131066653944105
84 6.336198851466179 -8.044773984158212
85 3.4951837211847305 -7.926534465840871
86 3.906928814947605 -7.6805516256712325
87 -13.13827657699585 -7.581651798213588
88 7.015500247478485 -7.50482940406956
89 8.087136656045914 -7.3745068343861355
90 -31.508420646190643 -7.247979832121363
91 -15.144453957676888 -7.107939203599948
92 8.464004337787628 -6.957963417531223
93 -6.9654401242733 -6.909720024820889
94 -50.21226945519447 -6.719970621583102
95 -2.7829905301332474 -6.619305321127111
96 -1.520429104566574 -6.536379750179507
97 9.616513058543205 -6.43440263596193
98 -3.460714876651764 -6.352317477012622
99 10.702147468924522 -6.233836010332017
100 10.058525502681732 -6.067603068214523
101 4.134303569793701 -5.881314064604837
102 -24.996438086032867 -5.615796733870542
103 6.826132111251354 -5.416811752857713
104 -6.875510418787599 -5.354412159613684
105 18.311474353075027 -5.239467874854168
106 14.707571260631084 -5.08944247281534
107 19.330494672060013 -4.94273958001726
108 12.007492363452911 -4.820785966238399
109 16.6939058303833 -4.695569938002047
110 21.204782634973526 -4.561345866390777
111 18.090676680207253 -4.369321915713366
112 12.249313533306122 -4.1880597794186025
113 15.472738593816757 -3.979054588972897
114 22.365136206150055 -3.75829470540406
115 22.94045788049698 -3.5372968251606522
116 18.69633349776268 -3.263997667566093
117 17.201003819704056 -2.87807425126718
118 31.668691754341125 -2.3626902806502343
119 30.523739993572235 -1.5251895695875948
train accuracy: 0.9994444444444445
validation accuracy: 0.995
[-64.24997756 -63.70374526 -63.24332377 ...  -1.58468169  -1.55139937
  -1.52518957]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Found existing model weights! Loading state dict...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:0
end of epoch 0: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 8.7573e-01,  1.4851e-01,  2.5916e-01,  4.6570e-01,  1.0110e+00,
         -7.7422e-02, -8.8218e-03, -1.3583e-01, -8.2746e-01,  1.9609e-01,
         -3.1013e-04, -2.4239e+00, -1.8874e+00]], device='cuda:0'))])
end of epoch 1: val_loss 0.06023346424102783, val_acc 0.995
trigger times: 1
end of epoch 2: val_loss 0.0012416263669558702, val_acc 1.0
trigger times: 2
end of epoch 3: val_loss 1.995391212403774e-05, val_acc 1.0
trigger times: 3
end of epoch 4: val_loss 1.4305103945844166e-08, val_acc 1.0
trigger times: 4
end of epoch 5: val_loss 0.0743395757675171, val_acc 0.995
trigger times: 5
end of epoch 6: val_loss 0.10739646911621094, val_acc 0.995
trigger times: 6
end of epoch 7: val_loss 1.311300479756028e-08, val_acc 1.0
trigger times: 7
end of epoch 8: val_loss 3.0269994749687613e-06, val_acc 1.0
trigger times: 8
end of epoch 9: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-4.4403e-05,  1.0808e-04, -2.0043e-05, -7.7704e-06, -4.5199e-04,
         -1.3048e-04, -9.2408e-03,  4.0462e-06,  2.2776e-04,  3.7582e-05,
         -3.1132e-04, -3.0655e+00, -2.4453e+00]], device='cuda:0'))])
end of epoch 10: val_loss 0.7402208916247756, val_acc 0.965
trigger times: 1
end of epoch 11: val_loss 0.014191436767578124, val_acc 0.995
trigger times: 2
end of epoch 12: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.0648e+00,  3.7282e-01,  3.4542e-01,  8.9425e-01,  1.5632e+00,
          1.4915e-02,  4.0064e-03, -2.1974e-01, -2.8168e-01, -8.9562e-02,
         -3.1167e-04, -4.5882e+00, -3.0157e+00]], device='cuda:0'))])
end of epoch 13: val_loss 2.1436701717902904e-06, val_acc 1.0
trigger times: 1
end of epoch 14: val_loss 3.1311187194660305e-06, val_acc 1.0
trigger times: 2
end of epoch 15: val_loss 0.002397455346148405, val_acc 1.0
trigger times: 3
end of epoch 16: val_loss 9.536734069115482e-09, val_acc 1.0
trigger times: 4
end of epoch 17: val_loss 0.00012799955904483796, val_acc 1.0
trigger times: 5
end of epoch 18: val_loss 7.562074865326452e-05, val_acc 1.0
trigger times: 6
end of epoch 19: val_loss 3.5762775496550603e-09, val_acc 1.0
trigger times: 7
end of epoch 20: val_loss 0.0005590471997856738, val_acc 1.0
trigger times: 8
end of epoch 21: val_loss 8.063752282438941e-06, val_acc 1.0
trigger times: 9
end of epoch 22: val_loss 4.11270366384997e-08, val_acc 1.0
trigger times: 10
Early stopping.
0 -213.930992603302 -64.24997755966005
1 -249.63733553886414 -62.59841153803112
2 -261.06592440605164 -61.809589362036306
3 -258.3619239330292 -61.050402593543744
4 -256.6689453125 -60.49758828967985
5 -197.16296088695526 -60.17226654461828
6 -194.55346059799194 -59.825311050300975
7 -252.43977808952332 -59.42210571514803
8 -243.79731607437134 -59.30965761818191
9 -193.19292378425598 -58.94034583502592
10 -192.28715443611145 -58.665213124551194
11 -247.58094549179077 -58.32249970026953
12 -239.14640021324158 -58.08611589826112
13 -244.8135862350464 -57.78201502659843
14 -248.29126715660095 -57.1606178908599
15 -234.4219446182251 -56.625814583124
16 -185.08715242147446 -55.8023833347529
17 -162.88877177238464 -46.98011874490918
18 -155.7516526579857 -40.44278203413966
19 -148.46790742874146 -37.66475323879293
20 -158.80214655399323 -35.394503873250635
21 -107.50131413340569 -31.64414355845032
22 -120.73926532268524 -26.7047217556024
23 -100.99251878261566 -22.60679894414887
24 -48.555030807852745 -19.688991370547306
25 -59.750622630119324 -18.595591936263194
26 -59.4896794706583 -17.277345890894125
27 -57.63920225203037 -16.67001723842762
28 -40.74144374579191 -15.735089566059182
29 -66.00297731161118 -15.297526915441711
30 -8.280590280890465 -14.970592581101988
31 -29.925099462270737 -14.594561003997004
32 -6.346883915364742 -14.415969828843615
33 6.255994454026222 -14.083401177177324
34 -64.13410809636116 -13.829736942690364
35 -45.67746450006962 -13.672486891155406
36 -16.045621693134308 -13.56118217868397
37 -28.64417163282633 -13.350537733785846
38 1.263108029961586 -13.207971739412438
39 -36.39579430222511 -12.988045670217158
40 -57.606673292815685 -12.84456867066915
41 -36.56486365199089 -12.687877277875348
42 -57.003889724612236 -12.59534011974936
43 -32.69871807843447 -12.48846702822902
44 -3.048891894519329 -12.372454739549003
45 -53.48241338133812 -12.289286310495852
46 1.2005463540554047 -12.163827700006971
47 -65.62127785384655 -12.016266975296274
48 -60.188708052039146 -11.947269485081954
49 -26.687894016504288 -11.781730626483084
50 -60.21695217490196 -11.69079072486885
51 16.77384325861931 -11.560477692344522
52 -56.36845310777426 -11.38118722962053
53 -22.698833853006363 -11.289088865080624
54 16.99221321940422 -11.069123073674547
55 -39.435330763459206 -10.961932060164017
56 -41.529721308499575 -10.845290734893993
57 -48.33802428282797 -10.763789404707998
58 -46.15456376969814 -10.64812665625825
59 3.711635962128639 -10.518545426611109
60 14.318091258406639 -10.444159805265594
61 -33.13797906041145 -10.3270166115354
62 6.0798076540231705 -10.200877130093161
63 -53.50862196087837 -10.054340569736782
64 -43.0643260627985 -9.936674043396035
65 -43.07406009733677 -9.806995500901422
66 15.509250164031982 -9.60162068006752
67 19.155345380306244 -9.438662818695786
68 5.462030082941055 -9.357438754682539
69 -33.7299919128418 -9.256329515217804
70 2.7921009957790375 -9.159694381138166
71 21.438700206577778 -9.02429177712088
72 29.17733044922352 -8.939566468751115
73 -15.815250054001808 -8.867979473590646
74 30.214926302433014 -8.768010831745558
75 28.232748448848724 -8.552142496825635
76 11.888610810041428 -8.471597832230726
77 -12.840930014848709 -8.35836685280887
78 12.395593822002411 -8.277660060667706
79 -0.8770680129528046 -8.133195842510668
80 -3.6312526762485504 -8.055326352604826
81 1.9846451580524445 -7.942294500081729
82 25.79111334681511 -7.763882277048493
83 -8.62729698419571 -7.624649872831982
84 8.407790437340736 -7.522354560083883
85 -8.655399173498154 -7.418455966155553
86 26.35943314433098 -7.300077165719589
87 -27.079949237406254 -7.18285783578708
88 22.408268600702286 -7.057394746274088
89 28.762018233537674 -6.957963417531223
90 1.6974750757217407 -6.8785682524371365
91 7.341723054647446 -6.755072603151492
92 34.27789455652237 -6.654334999258685
93 -14.461754329502583 -6.571463226505149
94 33.09701991081238 -6.499302807669057
95 3.422237291932106 -6.382464170725696
96 23.96727640926838 -6.2883411317323175
97 -20.143248930573463 -6.148528312896329
98 28.371176674962044 -6.047742034414677
99 4.626627802848816 -5.788802796658158
100 11.116812273859978 -5.568089048796324
101 40.306358218193054 -5.404508556788289
102 37.62473398447037 -5.354412159613684
103 43.002370446920395 -5.261039441193645
104 42.8062441945076 -5.111258208695365
105 38.715739727020264 -4.948906055358659
106 13.40096352994442 -4.856141973464731
107 32.988628685474396 -4.729970294786983
108 27.614838108420372 -4.636278300562541
109 32.05169692635536 -4.563691325720186
110 33.45423102378845 -4.405758740133117
111 27.124787628650665 -4.237316361327979
112 34.035859405994415 -4.056350182280639
113 49.53217250108719 -3.876309332005798
114 40.17282462120056 -3.6032753361471737
115 47.88299536705017 -3.3582191968366444
116 52.24345779418945 -3.1147160869532926
117 50.35191631317139 -2.772292016233898
118 52.330350160598755 -2.34232539897597
119 51.75380778312683 -1.5251895695875948
train accuracy: 0.9961111111111111
validation accuracy: 1.0
