Using trajectories from checkpointed policy...
demos: (120, 50, 6)
demo_rewards: (120,)
[-21.69821725 -19.94971558 -18.76832347 -18.75880435 -17.53896742
 -16.91541103 -16.05718211 -15.9158157  -15.33402057 -15.27125207
 -15.20814575 -14.05004525 -13.75955414 -13.39623908 -12.46790305
 -12.22796644 -11.94379352 -11.87115519 -10.82229745  -9.81219779
  -8.90867378  -8.51516035  -8.43290063  -8.15747033  -8.1146239
  -8.04631087  -8.03343465  -7.98766352  -7.94131282  -7.91179285
  -7.84030855  -7.66953461  -7.62363147  -7.51709285  -7.3757734
  -7.33772246  -7.21259597  -7.2093722   -7.13670272  -6.75273631
  -6.73935817  -6.70709366  -6.69433129  -6.68932186  -6.6866521
  -6.61544671  -6.52446054  -6.50477382  -6.43754025  -6.43068453
  -6.42890937  -6.34792127  -6.2684225   -6.10365611  -6.10254984
  -6.05423058  -6.02183849  -5.96007173  -5.8890902   -5.85687032
  -5.83226818  -5.75896465  -5.72527157  -5.52196502  -5.4824461
  -5.40267414  -5.37320827  -5.32799616  -5.31925116  -5.24662899
  -5.21834999  -5.16776359  -5.15853674  -5.1511849   -5.08742482
  -4.89452842  -4.80127878  -4.78055079  -4.77995973  -4.68485898
  -4.63376638  -4.54476592  -4.54110176  -4.49970512  -4.46305723
  -4.36008279  -4.34755779  -4.3271761   -4.29314903  -4.28328411
  -4.26185799  -4.2556554   -4.21892375  -4.21276078  -4.18947176
  -4.07705538  -4.03922652  -4.02257413  -4.00080732  -3.9582595
  -3.90261084  -3.89806248  -3.87360582  -3.81557661  -3.77940125
  -3.74563942  -3.58313093  -3.54832839  -3.4694241   -3.46787449
  -3.35553609  -3.25823781  -3.24892507  -3.22881263  -3.15658161
  -3.09886194  -2.66512749  -2.16158281  -1.95222172  -1.85802134]
maximum traj length 50
num training_obs 171
num training_labels 171
num val_obs 19
num val_labels 19
ModuleList(
  (0): Linear(in_features=6, out_features=1, bias=False)
)
Total number of parameters: 6
Number of trainable paramters: 6
device: cuda:0
end of epoch 0: val_loss 0.5615003111352531, val_acc 0.8947368421052632
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.2619,  0.0043,  0.0435, -0.0312,  0.0982, -0.4259]],
       device='cuda:0'))])
end of epoch 1: val_loss 0.14709122909689062, val_acc 0.9473684210526315
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.1372,  0.0341,  0.0628, -0.0143,  0.1775, -0.5848]],
       device='cuda:0'))])
end of epoch 2: val_loss 0.024259390295619118, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0606,  0.0223,  0.0306, -0.0225,  0.2094, -0.6790]],
       device='cuda:0'))])
end of epoch 3: val_loss 0.025121524890245814, val_acc 1.0
trigger times: 1
end of epoch 4: val_loss 0.029666710267879114, val_acc 1.0
trigger times: 2
end of epoch 5: val_loss 0.015870102581695727, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0218,  0.0225,  0.0117, -0.0338,  0.2295, -0.7785]],
       device='cuda:0'))])
end of epoch 6: val_loss 0.012604417645936911, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0227,  0.0212,  0.0082, -0.0299,  0.2269, -0.8050]],
       device='cuda:0'))])
end of epoch 7: val_loss 0.011683762055380803, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0152,  0.0205,  0.0113, -0.0341,  0.2282, -0.8309]],
       device='cuda:0'))])
end of epoch 8: val_loss 0.00629183145464726, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0193,  0.0092,  0.0181, -0.0228,  0.2277, -0.8510]],
       device='cuda:0'))])
end of epoch 9: val_loss 0.011967652307954555, val_acc 1.0
trigger times: 1
end of epoch 10: val_loss 0.007807484067178905, val_acc 1.0
trigger times: 2
end of epoch 11: val_loss 0.011149329249542162, val_acc 1.0
trigger times: 3
end of epoch 12: val_loss 0.04097566001795029, val_acc 1.0
trigger times: 4
end of epoch 13: val_loss 0.0253721610642188, val_acc 1.0
trigger times: 5
end of epoch 14: val_loss 0.007143747403267678, val_acc 1.0
trigger times: 6
end of epoch 15: val_loss 0.00603377492038024, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.8618e-02,  1.8452e-02, -8.6030e-04, -3.1795e-02,  2.3759e-01,
         -9.5659e-01]], device='cuda:0'))])
end of epoch 16: val_loss 0.005659858575103795, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.1562e-02,  1.7640e-02, -4.3509e-04, -3.2326e-02,  2.6080e-01,
         -9.7788e-01]], device='cuda:0'))])
end of epoch 17: val_loss 0.0064423375857148215, val_acc 1.0
trigger times: 1
end of epoch 18: val_loss 0.006958695028585582, val_acc 1.0
trigger times: 2
end of epoch 19: val_loss 0.13114726210435895, val_acc 0.8947368421052632
trigger times: 3
end of epoch 20: val_loss 0.0028747659339705485, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0097,  0.0982,  0.0684, -0.0266,  0.5973, -1.6520]],
       device='cuda:0'))])
end of epoch 21: val_loss 0.003114746312791277, val_acc 1.0
trigger times: 1
end of epoch 22: val_loss 0.0030442295773019175, val_acc 1.0
trigger times: 2
end of epoch 23: val_loss 0.0026050439460211065, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 8.1187e-04,  3.7712e-02,  2.3414e-02, -4.2661e-02,  3.9629e-01,
         -1.3070e+00]], device='cuda:0'))])
end of epoch 24: val_loss 0.0018513726854926542, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0033,  0.0216,  0.0147, -0.0278,  0.3307, -1.1921]],
       device='cuda:0'))])
end of epoch 25: val_loss 0.003710268746981695, val_acc 1.0
trigger times: 1
end of epoch 26: val_loss 0.0036651577696774572, val_acc 1.0
trigger times: 2
end of epoch 27: val_loss 0.0962395378806274, val_acc 0.9473684210526315
trigger times: 3
end of epoch 28: val_loss 0.0015994801032960775, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.0405,  0.0731,  0.0721, -0.0361,  0.5108, -1.7448]],
       device='cuda:0'))])
end of epoch 29: val_loss 0.0013724789522091903, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.0116,  0.0672,  0.0379, -0.0433,  0.4519, -1.6228]],
       device='cuda:0'))])
end of epoch 30: val_loss 0.001287442067148516, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.9022e-05,  4.9600e-02,  2.8521e-02, -4.2255e-02,  3.8904e-01,
         -1.4868e+00]], device='cuda:0'))])
end of epoch 31: val_loss 0.0012477293165774558, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0017,  0.0326,  0.0182, -0.0373,  0.3254, -1.3519]],
       device='cuda:0'))])
end of epoch 32: val_loss 0.0016146683537655055, val_acc 1.0
trigger times: 1
end of epoch 33: val_loss 0.0021035047613954076, val_acc 1.0
trigger times: 2
end of epoch 34: val_loss 0.004244661340344928, val_acc 1.0
trigger times: 3
end of epoch 35: val_loss 0.0043126907778361255, val_acc 1.0
trigger times: 4
end of epoch 36: val_loss 0.001208485989123849, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0262, -0.0158,  0.0231, -0.0376,  0.2252, -1.0994]],
       device='cuda:0'))])
end of epoch 37: val_loss 0.008711378489447136, val_acc 1.0
trigger times: 1
end of epoch 38: val_loss 0.23330854074477483, val_acc 0.9473684210526315
trigger times: 2
end of epoch 39: val_loss 0.004606221852114719, val_acc 1.0
trigger times: 3
end of epoch 40: val_loss 0.0031503979926214534, val_acc 1.0
trigger times: 4
end of epoch 41: val_loss 0.002507081826293918, val_acc 1.0
trigger times: 5
end of epoch 42: val_loss 0.002336951320219932, val_acc 1.0
trigger times: 6
end of epoch 43: val_loss 0.0023340228404824877, val_acc 1.0
trigger times: 7
end of epoch 44: val_loss 0.00409294225637817, val_acc 1.0
trigger times: 8
end of epoch 45: val_loss 0.0010525298519460673, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0240, -0.0112,  0.0095, -0.0083,  0.2865, -1.1841]],
       device='cuda:0'))])
end of epoch 46: val_loss 0.010148802772574217, val_acc 1.0
trigger times: 1
end of epoch 47: val_loss 0.005469283598309005, val_acc 1.0
trigger times: 2
end of epoch 48: val_loss 0.003557308226989239, val_acc 1.0
trigger times: 3
end of epoch 49: val_loss 0.0029138167619247738, val_acc 1.0
trigger times: 4
end of epoch 50: val_loss 0.002699705451923469, val_acc 1.0
trigger times: 5
end of epoch 51: val_loss 0.003572576290662853, val_acc 1.0
trigger times: 6
end of epoch 52: val_loss 0.0024186650745632895, val_acc 1.0
trigger times: 7
end of epoch 53: val_loss 0.003048225497610103, val_acc 1.0
trigger times: 8
end of epoch 54: val_loss 0.0019792176907039425, val_acc 1.0
trigger times: 9
end of epoch 55: val_loss 0.005606514063640813, val_acc 1.0
trigger times: 10
Early stopping.
0 -20.427611112594604 -21.698217245906225
1 -17.399891823530197 -19.949715584796184
2 -13.146999225020409 -18.768323469697297
3 -16.119801312685013 -18.758804345874903
4 -12.785981923341751 -17.538967424246174
5 -13.592132091522217 -16.915411032748093
6 -11.541791282594204 -16.05718210808024
7 -9.486002967692912 -15.915815703668287
8 -9.71061958372593 -15.33402056686152
9 -8.752106864005327 -15.271252072853205
10 -8.699658066034317 -15.208145749687734
11 -9.598643247038126 -14.050045254361477
12 -13.206646956503391 -13.75955413810145
13 -5.388128712773323 -13.396239081718472
14 -5.855049088597298 -12.467903050162427
15 -6.175885051488876 -12.22796644484045
16 -6.792578719556332 -11.94379352386303
17 -5.570029804715887 -11.871155187939209
18 -5.852982148528099 -10.822297454194436
19 -3.8114937990903854 -9.812197786666262
20 -8.844911865890026 -8.908673775575991
21 -7.317310117185116 -8.515160348153305
22 -8.37295950204134 -8.432900628058379
23 -8.208274945616722 -8.1574703320884
24 -7.410455524921417 -8.114623899357289
25 -9.057148844003677 -8.046310874369832
26 -7.415111064910889 -8.033434648498933
27 -7.792390078306198 -7.987663518560797
28 -7.011906497180462 -7.941312820022507
29 -7.045174039900303 -7.911792849843923
30 -5.132275700569153 -7.8403085472035166
31 -5.839219029992819 -7.6695346082072655
32 -7.555084999650717 -7.623631472187833
33 -7.1329653188586235 -7.517092847713959
34 -6.269209861755371 -7.375773401152629
35 -5.667909245938063 -7.337722462601442
36 -6.604314349591732 -7.212595973698941
37 -6.644977319985628 -7.209372197564873
38 -3.7608931632712483 -7.13670271909991
39 -5.625428669154644 -6.752736311974305
40 -6.79585924372077 -6.739358173065801
41 -5.358681738376617 -6.707093660958046
42 -5.161341313272715 -6.6943312910442465
43 -5.204365722835064 -6.689321861831577
44 -5.560229428112507 -6.686652102155316
45 -6.1925211772322655 -6.6154467075651695
46 -5.808331664651632 -6.524460542127663
47 -4.3767746444791555 -6.5047738194148765
48 -6.405690498650074 -6.437540250165604
49 -5.4854578748345375 -6.430684532606243
50 -5.941674634814262 -6.428909365437914
51 -5.0749466717243195 -6.347921267036356
52 -3.8923592306673527 -6.268422498242901
53 -3.6374574545770884 -6.103656113764034
54 -5.623228631913662 -6.102549838089866
55 -5.127944748848677 -6.0542305827232905
56 -4.492556570097804 -6.021838489818482
57 -5.903671648353338 -5.960071728074796
58 -4.4384990110993385 -5.889090204198977
59 -4.40939324349165 -5.85687031698118
60 -1.3178077535703778 -5.832268177877353
61 -5.098058965057135 -5.758964645019952
62 -5.4482665956020355 -5.725271574488492
63 -4.906473247334361 -5.521965023222128
64 -3.2088968493044376 -5.482446099710484
65 -4.839143857359886 -5.402674139281961
66 -1.4726292351260781 -5.37320826895953
67 -4.986242920160294 -5.327996155721218
68 -3.919413896277547 -5.319251163344653
69 -4.813869025558233 -5.246628989103434
70 -2.914826598018408 -5.218349993849201
71 -4.826860919594765 -5.167763591366873
72 -2.23574165860191 -5.158536740652007
73 -3.5506074726581573 -5.15118490151008
74 -4.653194196522236 -5.087424824193218
75 -2.744983224198222 -4.8945284164838885
76 0.019300347194075584 -4.8012787804619315
77 -3.9081158079206944 -4.780550794817313
78 -4.162260107696056 -4.779959729642383
79 -0.014734224416315556 -4.684858983685201
80 0.5260938480496407 -4.63376638301532
81 -1.4734756911639124 -4.544765918076566
82 -2.0309029733762145 -4.541101762358445
83 0.6441073659807444 -4.499705122960396
84 -0.04093644209206104 -4.46305722691507
85 -3.1127211041748524 -4.360082787577702
86 -0.025710363872349262 -4.347557790582064
87 -0.18555522244423628 -4.32717610371528
88 -0.7056013664696366 -4.293149032506209
89 -0.7719405959360301 -4.28328411059534
90 -0.9151255651377141 -4.261857985421295
91 -0.07032490614801645 -4.2556554048544175
92 -1.3638823742512614 -4.21892374827055
93 -2.615574525669217 -4.212760778810066
94 -0.07687518268357962 -4.189471756120161
95 1.400939790531993 -4.077055383091453
96 -2.324960634112358 -4.039226517389183
97 -0.11391243722755462 -4.022574133686165
98 -3.5326328091323376 -4.000807316013546
99 -1.5178746543824673 -3.958259499152596
100 0.6235943683423102 -3.9026108386832026
101 0.8694966221228242 -3.898062481547635
102 -0.1327637117356062 -3.8736058235511592
103 0.9741334142163396 -3.815576608227037
104 0.9033856568858027 -3.7794012502260146
105 2.4095215275883675 -3.7456394227913563
106 0.06268417369574308 -3.58313093174521
107 2.2559374161064625 -3.548328387478394
108 2.328355949372053 -3.4694240992184446
109 1.1128764674067497 -3.467874494555462
110 1.7104850029572845 -3.355536092072393
111 -0.9572073575109243 -3.2582378101026293
112 1.1488932352513075 -3.2489250657416147
113 1.7904051234945655 -3.2288126285346226
114 0.981616117991507 -3.1565816117673453
115 2.362090490758419 -3.098861944472417
116 -0.5093993470072746 -2.6651274851973605
117 0.38216615829151124 -2.161582813943857
118 3.4715138897299767 -1.9522217156632942
119 1.3358279401436448 -1.8580213384140898
train accuracy: 1.0
validation accuracy: 1.0
