[-54.98547503 -50.4922686  -50.03933802 -49.75347185 -49.72654641
 -46.98011874 -45.73515428 -45.67057988 -44.99030608 -44.14602409
 -43.81326882 -43.18878399 -42.29180715 -42.00401746 -41.69100444
 -41.68588229 -41.2817771  -40.44278203 -40.34838366 -39.59970115
 -39.57586365 -39.31972693 -39.02461056 -38.45534494 -38.4127039
 -38.35634328 -37.79713617 -37.74152899 -37.66475324 -37.51313938
 -37.1809993  -37.10070314 -37.00630589 -36.82191677 -36.48799015
 -36.2096527  -36.19207562 -36.11445903 -35.78149902 -35.39450387
 -35.262825   -35.24303541 -35.20970524 -35.06544085 -34.80241748
 -34.64469045 -33.84284986 -32.70706485 -31.9690994  -31.7109134
 -31.64414356 -31.39238276 -31.22319602 -31.12953085 -29.3915714
 -29.34012561 -29.10618999 -27.4110235  -27.34372236 -27.19668163
 -27.07399029 -26.70472176 -26.2447949  -25.54836509 -25.45878529
 -24.879107   -24.82869536 -24.59274514 -23.97874558 -23.57262108
 -23.44970808 -22.74530916 -22.60679894 -22.19891032 -20.65686376
 -20.44447256 -20.1969901  -20.13839115 -19.63760344 -19.51559872
 -18.9283881  -17.99477406 -17.5574237  -16.82307393 -14.8550828
 -14.5314246  -14.44242009 -13.59601285 -12.68135973 -12.66418206
 -12.30017947 -12.15190477 -11.78885214 -10.8699891  -10.3276815
  -9.85721598  -8.330117    -8.13319584  -8.10819769  -7.57539849
  -7.36244313  -7.10832736  -6.95906356  -6.77694649  -6.72206384
  -6.71997062  -6.53544734  -6.51820418  -5.61579673  -5.3472021
  -5.07848501  -5.02795798  -4.82757292  -4.63049542  -4.230832
  -4.03104862  -3.38446715  -3.3322555   -2.64166233  -1.91361965]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:2
end of epoch 0: val_loss 4.053112508728418e-08, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-4.5801e-06,  9.4920e-02,  7.2793e-02, -6.0650e-02, -2.6848e-02,
         -1.0409e-05,  8.3804e-04, -1.2667e-02, -4.2668e-05, -1.0290e-05,
         -1.4320e-03, -7.3769e-01, -9.0043e-01]], device='cuda:2'))])
end of epoch 1: val_loss 3.838529057276219e-07, val_acc 1.0
trigger times: 1
end of epoch 2: val_loss 0.00016264474358830937, val_acc 1.0
trigger times: 2
end of epoch 3: val_loss 1.8035395769118167e-05, val_acc 1.0
trigger times: 3
end of epoch 4: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 6.5565e-06,  2.2388e-01,  3.4402e-01, -7.6654e-02, -2.9708e-05,
         -7.7138e-06,  3.8098e-03,  3.6863e-02,  2.1129e-07,  1.0585e-04,
         -1.4320e-03, -1.3970e+00, -2.7137e+00]], device='cuda:2'))])
end of epoch 5: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.2145e-05, -4.0056e-05,  1.1318e-01,  1.8308e-05, -9.1442e-05,
          1.5299e-04, -8.2469e-08, -7.5541e-07,  3.1226e-05,  2.4508e-04,
         -1.4320e-03, -1.1824e-02, -2.3710e+00]], device='cuda:2'))])
end of epoch 6: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 6.0366e-05,  4.5927e-06, -5.3862e-05, -4.9570e-05, -2.3551e-04,
          2.0369e-04, -6.2716e-07, -7.9942e-06,  1.0450e-04,  5.5306e-04,
         -1.4320e-03,  1.7238e-04, -1.5287e+00]], device='cuda:2'))])
end of epoch 7: val_loss 1.4606965123675764e-06, val_acc 1.0
trigger times: 1
end of epoch 8: val_loss 7.1525522571391775e-09, val_acc 1.0
trigger times: 2
end of epoch 9: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.8080e-05,  8.8906e-06,  4.5368e-06,  1.1575e-06,  2.8995e-04,
         -1.8347e-04, -1.9212e-06,  3.7206e-03,  1.8520e-04,  2.3085e-04,
         -1.4320e-03, -1.4036e-04, -1.7760e+00]], device='cuda:2'))])
end of epoch 10: val_loss 3.5881901435885763e-07, val_acc 1.0
trigger times: 1
end of epoch 11: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.1400e-02,  2.8609e-01,  2.5474e-01, -5.8271e-02,  1.6340e-02,
         -4.8073e-02, -5.5286e-03,  5.0340e-02,  7.7394e-03, -1.4174e-01,
         -1.4321e-03, -1.4848e+00, -2.0466e+00]], device='cuda:2'))])
end of epoch 12: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.0067e-06,  1.0765e-01,  8.9646e-02, -1.1154e-05,  9.2487e-05,
         -5.0512e-05, -4.3598e-03,  2.0032e-02, -7.9242e-05, -9.0028e-05,
         -1.4321e-03, -6.4833e-01, -1.8538e+00]], device='cuda:2'))])
end of epoch 13: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.3402e-05,  1.1012e-05, -5.8717e-05, -2.9423e-05,  2.3592e-04,
         -1.0515e-04,  1.9438e-06, -2.3738e-05, -1.8150e-04,  7.1593e-05,
         -1.4321e-03,  2.1256e-05, -1.3593e+00]], device='cuda:2'))])
end of epoch 14: val_loss 0.0006836509758267084, val_acc 1.0
trigger times: 1
end of epoch 15: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-4.3912e-02,  6.8169e-02,  1.2184e-01, -3.8944e-01,  1.1433e-01,
         -1.0284e-04, -2.4843e-02,  6.0486e-02, -6.8748e-05, -3.2085e-01,
         -1.4322e-03, -1.7116e+00, -2.2419e+00]], device='cuda:2'))])
end of epoch 16: val_loss 1.7881390590446245e-09, val_acc 1.0
trigger times: 1
end of epoch 17: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.8414e-07, -1.7842e-07, -1.8821e-05,  9.0247e-05, -7.4974e-04,
         -2.1191e-04,  4.4214e-06,  1.8580e-05, -3.0419e-04,  3.9810e-05,
         -1.4323e-03,  1.0411e-04, -1.2927e+00]], device='cuda:2'))])
end of epoch 18: val_loss 0.49726098471740754, val_acc 0.96
trigger times: 1
end of epoch 19: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.5931e-01,  3.4352e-01,  1.8829e-01, -1.5250e-01,  3.6424e-05,
          7.3807e-06, -1.3168e-02,  3.7084e-06,  2.9506e-05, -2.5865e-05,
         -1.4324e-03, -1.1007e+00, -2.1206e+00]], device='cuda:2'))])
end of epoch 20: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-3.8530e-05,  8.9500e-02, -2.5434e-05, -3.8661e-05,  9.3193e-05,
          3.1384e-05,  1.2753e-06, -1.3043e-06,  5.5025e-05, -9.1654e-05,
         -1.4324e-03,  2.0812e-05, -1.7880e+00]], device='cuda:2'))])
end of epoch 21: val_loss 5.006787656469669e-08, val_acc 1.0
trigger times: 1
end of epoch 22: val_loss 7.771172677131233e-06, val_acc 1.0
trigger times: 2
end of epoch 23: val_loss 1.0430703696329147e-07, val_acc 1.0
trigger times: 3
end of epoch 24: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 8.2647e-05, -1.4222e-04, -3.6271e-05,  3.8789e-06,  1.9733e-05,
         -5.1191e-05,  2.2971e-07,  2.8580e-06, -2.1168e-04, -2.7316e-05,
         -1.4325e-03, -4.8022e-04, -1.2745e+00]], device='cuda:2'))])
end of epoch 25: val_loss 1.7285317426285475e-08, val_acc 1.0
trigger times: 1
end of epoch 26: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.2265e-02,  2.1364e-01,  2.9596e-02, -1.3877e-01, -4.2882e-05,
         -1.6177e-01,  7.1622e-03,  5.9526e-02, -5.0000e-06, -1.2444e-04,
         -1.4326e-03, -1.0949e+00, -2.1556e+00]], device='cuda:2'))])
end of epoch 27: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.3745e-06,  7.0691e-03, -5.7034e-05, -4.5002e-05, -1.2856e-04,
         -1.2610e-04,  8.2993e-07,  5.0398e-03, -1.2363e-04,  1.9289e-04,
         -1.4326e-03, -9.9899e-05, -1.8995e+00]], device='cuda:2'))])
end of epoch 28: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.9096e-05, -2.3190e-05, -2.8449e-05, -1.0701e-04, -3.3480e-04,
         -2.9499e-04,  1.8181e-06,  2.1135e-10, -1.6765e-04,  2.3641e-04,
         -1.4327e-03, -3.3648e-04, -1.2695e+00]], device='cuda:2'))])
end of epoch 29: val_loss 2.980231634808206e-09, val_acc 1.0
trigger times: 1
end of epoch 30: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-6.2836e-02,  1.0304e-01,  1.3509e-05, -1.7878e-01, -7.9239e-05,
         -6.3953e-05, -1.3711e-02,  9.5043e-03, -3.3652e-05,  6.0248e-05,
         -1.4327e-03, -1.1802e+00, -1.9767e+00]], device='cuda:2'))])
end of epoch 31: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.0542e-05, -1.9440e-05,  3.1664e-05, -1.3711e-02, -9.3251e-05,
         -3.9377e-05, -6.5765e-06, -4.6808e-06, -8.5144e-05,  1.4736e-04,
         -1.4328e-03,  2.2702e-04, -1.5999e+00]], device='cuda:2'))])
end of epoch 32: val_loss 4.544746226997632e-06, val_acc 1.0
trigger times: 1
end of epoch 33: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.7090e-02,  3.0850e-01,  4.5649e-01, -1.0405e-01,  3.0948e-02,
         -2.8513e-05,  8.8977e-03, -1.7080e-03,  1.8066e-05, -4.7127e-05,
         -1.4328e-03, -1.2988e+00, -2.2118e+00]], device='cuda:2'))])
end of epoch 34: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-6.0645e-06,  1.4928e-01,  3.0299e-01, -6.4652e-07,  4.2810e-05,
          6.0300e-05, -1.2163e-07, -3.5515e-06,  1.2443e-04, -1.0037e-04,
         -1.4329e-03, -5.0354e-01, -2.0172e+00]], device='cuda:2'))])
end of epoch 35: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.7162e-05, -1.0861e-06, -3.6111e-05, -8.3349e-06, -1.6393e-04,
          1.7649e-04,  2.7205e-06, -1.8765e-06, -1.2665e-04,  2.8498e-04,
         -1.4329e-03, -4.2096e-04, -1.5354e+00]], device='cuda:2'))])
end of epoch 36: val_loss 0.00032896459931137657, val_acc 1.0
trigger times: 1
end of epoch 37: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-4.1539e-02,  3.3396e-01,  2.2217e-01, -3.0362e-01, -2.3351e-05,
         -5.3524e-02, -2.5871e-02,  2.9489e-02,  8.7485e-05, -3.8211e-05,
         -1.4330e-03, -1.9144e+00, -2.5046e+00]], device='cuda:2'))])
end of epoch 38: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-7.2746e-05,  1.6992e-01,  1.8630e-02, -1.5649e-01, -5.1335e-05,
         -4.3636e-05, -1.6785e-02,  3.5824e-04, -2.3382e-05, -7.4996e-05,
         -1.4330e-03, -9.9398e-01, -2.2505e+00]], device='cuda:2'))])
end of epoch 39: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.7152e-04, -5.1600e-05,  1.0078e-04,  5.0593e-05, -1.1949e-04,
         -1.1652e-04,  3.3353e-07,  5.4034e-06, -1.0856e-04,  2.3932e-04,
         -1.4331e-03,  5.3904e-06, -1.6254e+00]], device='cuda:2'))])
end of epoch 40: val_loss 0.07365145653295706, val_acc 0.995
trigger times: 1
end of epoch 41: val_loss 6.393285467417797e-05, val_acc 1.0
trigger times: 2
end of epoch 42: val_loss 7.521540101151913e-07, val_acc 1.0
trigger times: 3
end of epoch 43: val_loss 1.9073481958287174e-08, val_acc 1.0
trigger times: 4
end of epoch 44: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.3938e-01,  2.5728e-01,  3.5163e-01, -3.1890e-01, -3.5800e-05,
          1.4606e-01, -1.9788e-02,  3.8017e-02,  1.1147e-02, -8.0716e-02,
         -1.4332e-03, -1.2993e+00, -2.0231e+00]], device='cuda:2'))])
end of epoch 45: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-5.3598e-02,  1.3930e-01,  2.5604e-01, -2.1270e-01, -8.8564e-05,
          2.0294e-05, -1.2937e-02,  1.5709e-02, -1.1187e-04, -3.7579e-05,
         -1.4333e-03, -6.3251e-01, -1.8685e+00]], device='cuda:2'))])
end of epoch 46: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.9348e-05, -7.7402e-06,  2.4817e-02,  4.3175e-07, -2.2679e-04,
          6.1645e-05, -2.3691e-06, -8.4516e-06, -2.6367e-04, -1.0176e-04,
         -1.4333e-03,  1.2174e-04, -1.4842e+00]], device='cuda:2'))])
end of epoch 47: val_loss 3.689655158030547e-05, val_acc 1.0
trigger times: 1
end of epoch 48: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-3.1035e-02,  4.9813e-01,  2.0386e-01, -2.6632e-01,  6.1758e-06,
         -1.4514e-05, -2.3101e-03,  1.5745e-02,  1.6843e-05,  1.2618e-05,
         -1.4334e-03, -1.3526e+00, -2.1889e+00]], device='cuda:2'))])
end of epoch 49: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.5048e-05,  2.8340e-01,  2.3073e-05, -8.9792e-02,  2.9466e-04,
         -1.1304e-04, -1.9849e-03, -8.9670e-07, -1.4206e-05, -9.5472e-05,
         -1.4334e-03, -2.3873e-01, -1.9588e+00]], device='cuda:2'))])
end of epoch 50: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-3.6950e-05,  3.0078e-06,  9.5919e-06, -1.0391e-04,  7.1934e-04,
         -2.5542e-04, -4.7538e-07, -2.9282e-06, -4.4002e-05, -5.5052e-04,
         -1.4334e-03, -3.8077e-04, -1.3599e+00]], device='cuda:2'))])
end of epoch 51: val_loss 2.384185471271394e-09, val_acc 1.0
trigger times: 1
end of epoch 52: val_loss 1.548361542376142e-06, val_acc 1.0
trigger times: 2
end of epoch 53: val_loss 1.561639731306741e-07, val_acc 1.0
trigger times: 3
end of epoch 54: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.8199e-01,  1.7399e-01,  2.5757e-01, -2.6256e-01,  2.6801e-01,
         -6.4251e-01, -7.5742e-03, -4.2701e-02, -8.0336e-02,  5.2578e-02,
         -1.4336e-03, -1.8690e+00, -2.4172e+00]], device='cuda:2'))])
end of epoch 55: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.5894e-01,  8.0488e-02,  1.6093e-01, -1.8530e-01, -9.7292e-06,
         -1.5876e-01, -9.2929e-04, -2.6520e-02,  6.0912e-05,  2.4869e-04,
         -1.4336e-03, -1.2342e+00, -2.2638e+00]], device='cuda:2'))])
end of epoch 56: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.7024e-05, -1.1522e-05,  3.9390e-06,  9.8241e-05,  8.9124e-05,
          2.1954e-04, -2.2030e-06, -2.7832e-06,  1.4454e-04,  5.9986e-04,
         -1.4336e-03, -6.1948e-04, -1.8865e+00]], device='cuda:2'))])
end of epoch 57: val_loss 5.9008564861073864e-08, val_acc 1.0
trigger times: 1
end of epoch 58: val_loss 2.5033921353667664e-08, val_acc 1.0
trigger times: 2
end of epoch 59: val_loss 2.831144199433311e-07, val_acc 1.0
trigger times: 3
end of epoch 60: val_loss 2.363888235201728e-06, val_acc 1.0
trigger times: 4
end of epoch 61: val_loss 2.3841852225814363e-09, val_acc 1.0
trigger times: 5
end of epoch 62: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.1480e-05,  2.6086e-01,  9.6198e-03,  4.9869e-06,  2.6166e-05,
         -9.7221e-05,  4.3192e-07,  2.0517e-02,  1.4320e-05, -2.2582e-05,
         -1.4339e-03, -4.6818e-01, -1.9854e+00]], device='cuda:2'))])
end of epoch 63: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 8.7769e-05,  3.0809e-06,  1.3944e-06, -8.6515e-06,  1.8218e-04,
         -2.2520e-04,  9.8939e-08, -2.6551e-07,  3.7794e-05,  5.9493e-04,
         -1.4339e-03, -2.9733e-04, -1.5193e+00]], device='cuda:2'))])
end of epoch 64: val_loss 0.00032936008205410874, val_acc 1.0
trigger times: 1
end of epoch 65: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.7969e-03,  4.6130e-01,  2.8035e-01, -2.9906e-01,  5.3278e-02,
         -3.7432e-01, -1.8583e-02,  7.2380e-02, -3.4266e-04, -1.9705e-01,
         -1.4340e-03, -2.1419e+00, -2.7945e+00]], device='cuda:2'))])
end of epoch 66: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.8650e-05,  3.5948e-01,  1.7779e-01, -2.1563e-01,  6.7821e-05,
          1.3097e-06, -1.0960e-02,  4.5924e-02, -1.8195e-05, -1.4946e-04,
         -1.4340e-03, -1.3739e+00, -2.6187e+00]], device='cuda:2'))])
end of epoch 67: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.2163e-05,  1.0896e-01,  9.2439e-06, -1.0337e-02,  1.4405e-04,
         -4.9796e-05,  4.9438e-06, -3.0275e-06, -4.8139e-05, -3.7293e-04,
         -1.4340e-03,  3.0687e-05, -2.1863e+00]], device='cuda:2'))])
end of epoch 68: val_loss 4.172324743478839e-09, val_acc 1.0
trigger times: 1
end of epoch 69: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.4803e-01,  4.0441e-01,  1.8457e-01, -1.4619e-01,  1.0131e-01,
         -1.0881e-01,  9.8982e-03,  5.5408e-02,  1.9777e-01, -1.2912e-04,
         -1.4341e-03, -1.3765e+00, -2.1642e+00]], device='cuda:2'))])
end of epoch 70: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.6490e-05,  2.6589e-01,  5.5647e-02, -4.8286e-02, -2.8870e-05,
         -1.0552e-04,  2.7494e-03,  1.9818e-02, -5.9052e-05,  1.4393e-04,
         -1.4341e-03, -5.5176e-01, -1.9737e+00]], device='cuda:2'))])
end of epoch 71: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-4.4620e-05,  3.7808e-05, -4.5370e-05, -7.5069e-06, -8.4128e-05,
         -2.6546e-04, -1.7058e-07, -2.9866e-05,  1.1396e-04,  3.6688e-04,
         -1.4342e-03,  5.3724e-05, -1.5052e+00]], device='cuda:2'))])
end of epoch 72: val_loss 0.00050413337897119, val_acc 1.0
trigger times: 1
end of epoch 73: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.0006e-01,  1.9999e-01,  2.8887e-01, -1.1147e-01,  8.2863e-02,
         -6.8345e-03, -4.1355e-07,  9.5543e-02, -3.2700e-05,  3.8828e-05,
         -1.4342e-03, -1.1594e+00, -2.2756e+00]], device='cuda:2'))])
end of epoch 74: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.1716e-05,  2.6172e-02,  1.2917e-01,  2.6561e-04, -1.1153e-04,
         -2.4259e-05,  1.7726e-06,  6.0174e-02,  5.1473e-05,  3.0325e-05,
         -1.4343e-03, -2.2096e-01, -2.0498e+00]], device='cuda:2'))])
end of epoch 75: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-5.4521e-05,  5.4561e-05, -1.3454e-05,  5.4254e-05, -2.0259e-04,
         -2.1270e-04,  4.9566e-06,  1.5278e-05, -1.0854e-04,  1.5403e-04,
         -1.4343e-03, -6.0593e-04, -1.4945e+00]], device='cuda:2'))])
end of epoch 76: val_loss 0.032420473069250874, val_acc 0.995
trigger times: 1
end of epoch 77: val_loss 6.630608811946104e-05, val_acc 1.0
trigger times: 2
end of epoch 78: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-8.7203e-06,  4.3280e-05,  4.1784e-05, -9.7756e-03,  2.4602e-04,
         -5.0775e-05,  3.1525e-05,  1.9645e-02, -2.5025e-04,  1.9567e-04,
         -1.4344e-03,  1.2373e-04, -1.4002e+00]], device='cuda:2'))])
end of epoch 79: val_loss 6.522920104039542e-06, val_acc 1.0
trigger times: 1
end of epoch 80: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 5.1718e-02,  6.7489e-02,  1.4998e-01, -7.6611e-02,  1.9899e-01,
         -1.6571e-01,  1.2026e-02,  3.5109e-02, -1.1660e-01, -9.9606e-08,
         -1.4345e-03, -9.7740e-01, -1.7130e+00]], device='cuda:2'))])
end of epoch 81: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-4.5480e-05, -2.1731e-05, -3.4623e-05,  4.9152e-06,  1.2906e-04,
          3.4057e-05,  2.8313e-03,  1.5330e-07,  4.9765e-05,  5.0450e-05,
         -1.4345e-03, -1.1820e-01, -1.4378e+00]], device='cuda:2'))])
end of epoch 82: val_loss 1.2010245332305657e-06, val_acc 1.0
trigger times: 1
end of epoch 83: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-9.9632e-02,  1.2662e-01,  2.2426e-01, -2.3476e-01,  8.5744e-02,
         -1.5402e-01,  9.1014e-03,  3.1723e-03,  4.6811e-06,  3.4187e-05,
         -1.4346e-03, -1.3882e+00, -2.1839e+00]], device='cuda:2'))])
end of epoch 84: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.9800e-05,  1.0532e-05,  7.5463e-02, -1.4149e-01, -1.1508e-05,
          3.2477e-05,  1.0152e-04, -3.3367e-06,  1.0130e-04,  8.0207e-05,
         -1.4346e-03, -6.4188e-01, -1.9847e+00]], device='cuda:2'))])
end of epoch 85: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 7.5655e-05,  2.8629e-05,  3.4414e-05, -3.1834e-05,  9.9583e-05,
          7.8979e-05, -2.2489e-06, -9.6358e-06,  2.6179e-04,  1.9395e-04,
         -1.4347e-03, -6.6099e-05, -1.4947e+00]], device='cuda:2'))])
end of epoch 86: val_loss 0.0006775853641363483, val_acc 1.0
trigger times: 1
end of epoch 87: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 6.0376e-02,  2.7486e-01,  1.0643e-01, -1.4974e-01, -2.1571e-05,
         -1.7724e-01, -4.8055e-03,  7.9571e-02,  4.1172e-05,  1.4130e-04,
         -1.4347e-03, -1.5777e+00, -2.1340e+00]], device='cuda:2'))])
end of epoch 88: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.7754e-05,  6.1754e-02, -2.9975e-06, -9.8338e-03,  3.4275e-05,
          6.8307e-05, -2.1534e-06,  4.5403e-02,  9.3265e-05,  3.6145e-04,
         -1.4348e-03, -5.0467e-01, -1.8441e+00]], device='cuda:2'))])
end of epoch 89: val_loss 3.5762784023063432e-09, val_acc 1.0
trigger times: 1
end of epoch 90: val_loss 3.711991594137487e-06, val_acc 1.0
trigger times: 2
end of epoch 91: val_loss 2.6562486307284417e-05, val_acc 1.0
trigger times: 3
end of epoch 92: val_loss 4.768370303054325e-09, val_acc 1.0
trigger times: 4
end of epoch 93: val_loss 1.575780175357977e-05, val_acc 1.0
trigger times: 5
end of epoch 94: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 6
end of epoch 95: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-5.3655e-05,  9.7043e-02,  4.6078e-02, -2.0339e-02, -3.5205e-05,
         -4.0750e-05, -2.3307e-07,  6.0981e-02,  9.3476e-05, -9.8908e-05,
         -1.4350e-03, -2.8057e-01, -1.7574e+00]], device='cuda:2'))])
end of epoch 96: val_loss 1.7881392366803084e-09, val_acc 1.0
trigger times: 1
end of epoch 97: val_loss 4.351124729851108e-08, val_acc 1.0
trigger times: 2
end of epoch 98: val_loss 8.582995178585406e-08, val_acc 1.0
trigger times: 3
end of epoch 99: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.7432e-06,  5.6407e-06,  1.3824e-05,  1.8354e-05, -4.8661e-05,
         -1.9633e-06, -3.3422e-06, -6.6003e-06,  1.8492e-04, -2.4217e-04,
         -1.4351e-03,  3.4545e-04, -1.2505e+00]], device='cuda:2'))])
Finished training.
0 -53.0764636695385 -54.98547503240923
1 -55.15623424947262 -50.492268601198035
2 -49.40962718427181 -50.03933801517046
3 -50.83596816658974 -49.75347184620696
4 -50.32339112460613 -49.72654640753777
5 -53.43691544234753 -46.98011874490918
6 -50.61932960152626 -45.7351542845057
7 -48.61457930132747 -45.670579884154705
8 -50.054469257593155 -44.99030608142343
9 -47.04277493059635 -44.14602409201361
10 -47.566616639494896 -43.81326882122305
11 -48.18287896737456 -43.18878399086166
12 -49.21919985115528 -42.29180714825394
13 -46.568613685667515 -42.00401746161006
14 -51.44096298515797 -41.6910044370425
15 -47.475565776228905 -41.68588229294918
16 -47.96501851081848 -41.281777102712205
17 -45.9403415620327 -40.44278203413966
18 -47.4214356392622 -40.34838365523108
19 -45.440143436193466 -39.599701153458774
20 -45.48545905947685 -39.57586365327889
21 -43.31669524312019 -39.31972693233231
22 -41.30452474951744 -39.024610555047154
23 -43.412224635481834 -38.45534493538269
24 -43.36334829777479 -38.41270390343083
25 -44.71854904294014 -38.35634328077039
26 -41.98456993326545 -37.79713616772368
27 -39.781483232975006 -37.741528994987384
28 -47.23952320218086 -37.66475323879293
29 -42.82094247639179 -37.513139380385574
30 -47.66283555328846 -37.1809993033689
31 -43.548558700829744 -37.100703136010694
32 -42.61035184562206 -37.00630588930485
33 -44.41511704027653 -36.821916772458344
34 -43.85357716679573 -36.48799015296732
35 -41.121094450354576 -36.20965269874363
36 -42.346282351762056 -36.19207561676116
37 -44.64912089705467 -36.114459029559086
38 -41.77223029732704 -35.78149902167743
39 -39.40145745128393 -35.394503873250635
40 -43.45932997763157 -35.26282499693737
41 -42.12348861992359 -35.24303541418371
42 -43.96486892551184 -35.209705244501436
43 -42.48581272363663 -35.0654408505187
44 -40.91974923759699 -34.80241747531743
45 -40.89705228805542 -34.64469044638467
46 -38.718960631638765 -33.84284985953318
47 -36.728313349187374 -32.70706485357069
48 -36.39448665082455 -31.969099402548657
49 -37.324812300503254 -31.7109134007892
50 -39.07830125838518 -31.64414355845032
51 -38.31266334652901 -31.392382758954444
52 -40.60338542610407 -31.223196019713853
53 -36.15236508846283 -31.12953085092458
54 -37.615687005221844 -29.39157139549552
55 -38.5397290289402 -29.340125609942326
56 -31.354052551090717 -29.106189988903285
57 -34.791595965623856 -27.41102349748205
58 -35.43122408539057 -27.343722362182305
59 -35.92849563807249 -27.196681629483837
60 -34.57581349462271 -27.07399028854534
61 -31.48311585187912 -26.7047217556024
62 -33.7406240105629 -26.244794902859052
63 -34.1134619936347 -25.548365085275513
64 -30.937451407313347 -25.45878528601009
65 -32.9078309237957 -24.879106999799365
66 -32.15972247347236 -24.828695359328833
67 -33.248647194355726 -24.592745144504722
68 -32.060850985348225 -23.978745577896312
69 -30.874953225255013 -23.57262108435893
70 -29.230673849582672 -23.44970807952351
71 -30.751762442290783 -22.745309160183492
72 -29.447848290205002 -22.60679894414887
73 -29.605728082358837 -22.19891031871716
74 -29.267777900211513 -20.656863763892378
75 -26.75248546153307 -20.444472560731253
76 -26.71227177232504 -20.19699010077007
77 -29.54901783540845 -20.13839114930498
78 -28.149599883705378 -19.63760343800059
79 -28.507568314671516 -19.515598718228343
80 -26.883009258657694 -18.92838809611677
81 -26.700492464005947 -17.994774057192853
82 -24.601127810776234 -17.55742370467821
83 -23.644560545682907 -16.823073927842348
84 -22.667003633454442 -14.855082803515382
85 -21.92830721847713 -14.531424598833084
86 -20.82232605665922 -14.442420089224363
87 -22.5599177852273 -13.596012850960644
88 -16.644553756341338 -12.68135972540495
89 -21.581074092537165 -12.66418205637357
90 -20.457154095638543 -12.30017947419658
91 -19.185343235731125 -12.151904772081672
92 -19.03657670877874 -11.788852141676486
93 -18.311843384057283 -10.869989101210326
94 -18.707994488067925 -10.327681503524177
95 -15.65916977263987 -9.8572159761571
96 -15.193261126521975 -8.330116995310416
97 -15.58238185569644 -8.133195842510668
98 -16.578657306730747 -8.108197691178031
99 -11.402796793729067 -7.57539849177145
100 -10.93649660423398 -7.362443126623615
101 -10.559857035055757 -7.108327355338034
102 -11.224894083105028 -6.959063561385431
103 -10.970202509313822 -6.776946485018116
104 -10.143446602392942 -6.7220638398623045
105 -11.247436236590147 -6.719970621583102
106 -15.641832765191793 -6.535447341844848
107 -12.922688653692603 -6.51820418055673
108 -12.579009180888534 -5.615796733870542
109 -10.717267822474241 -5.34720210027791
110 -10.42802393808961 -5.078485007852753
111 -10.74513372965157 -5.027957977402961
112 -9.782270665280521 -4.827572916892203
113 -10.205954233184457 -4.63049541560991
114 -9.88847067207098 -4.230832004686763
115 -10.152458502911031 -4.031048624093466
116 -9.342764401808381 -3.3844671463622564
117 -9.55371271353215 -3.3322555012187633
118 -9.909202240407467 -2.6416623314910934
119 -8.060785536654294 -1.9136196540088464
train accuracy: 1.0
validation accuracy: 1.0
[-54.98547503 -50.4922686  -50.03933802 -49.75347185 -49.72654641
 -46.98011874 -45.73515428 -45.67057988 -44.99030608 -44.14602409
 -43.81326882 -43.18878399 -42.29180715 -42.00401746 -41.69100444
 -41.68588229 -41.2817771  -40.44278203 -40.34838366 -39.59970115
 -39.57586365 -39.31972693 -39.02461056 -38.45534494 -38.4127039
 -38.35634328 -37.79713617 -37.74152899 -37.66475324 -37.51313938
 -37.1809993  -37.10070314 -37.00630589 -36.82191677 -36.48799015
 -36.2096527  -36.19207562 -36.11445903 -35.78149902 -35.39450387
 -35.262825   -35.24303541 -35.20970524 -35.06544085 -34.80241748
 -34.64469045 -33.84284986 -32.70706485 -31.9690994  -31.7109134
 -31.64414356 -31.39238276 -31.22319602 -31.12953085 -29.3915714
 -29.34012561 -29.10618999 -27.4110235  -27.34372236 -27.19668163
 -27.07399029 -26.70472176 -26.2447949  -25.54836509 -25.45878529
 -24.879107   -24.82869536 -24.59274514 -23.97874558 -23.57262108
 -23.44970808 -22.74530916 -22.60679894 -22.19891032 -20.65686376
 -20.44447256 -20.1969901  -20.13839115 -19.63760344 -19.63436396
 -19.51559872 -19.03868419 -19.01366146 -18.9283881  -18.40219305
 -18.13112681 -18.12524762 -17.99477406 -17.5574237  -17.50947559
 -17.45759595 -17.34359036 -17.22952416 -17.09235581 -16.82307393
 -16.72556391 -16.46524529 -16.44056833 -15.69844216 -15.62688785
 -15.54744861 -15.49021849 -15.42919215 -15.29797373 -15.20697481
 -15.12252306 -15.08728073 -15.08020331 -15.04626953 -14.98912762
 -14.97196392 -14.90387708 -14.8550828  -14.78622576 -14.63488148
 -14.5314246  -14.51735397 -14.44242009 -14.41583474 -14.37972793
 -14.26791204 -14.13660346 -13.68634927 -13.59601285 -13.53453212
 -13.46738201 -13.28824842 -13.11910909 -12.94042091 -12.88077847
 -12.87408383 -12.85344495 -12.68135973 -12.66418206 -12.64627127
 -12.63040428 -12.50725806 -12.5024721  -12.48743392 -12.30017947
 -12.29207041 -12.24407241 -12.15190477 -12.06189975 -11.98108374
 -11.97027503 -11.9042515  -11.88597412 -11.79872418 -11.78885214
 -11.74253045 -11.58584831 -11.54066985 -11.53480251 -11.4436213
 -11.42486018 -11.20813099 -11.01064843 -10.99611373 -10.95837823
 -10.92999647 -10.8699891  -10.59120474 -10.56227461 -10.55136287
 -10.47829501 -10.39312115 -10.36432725 -10.3276815  -10.31685999
 -10.05616271  -9.91813288  -9.89169983  -9.85740173  -9.85721598
  -9.73501692  -9.62007273  -9.55360725  -9.48252785  -9.3492285
  -9.3336688   -9.22561711  -9.1656006   -9.14765635  -9.13241564
  -9.03248048  -9.0098247   -9.00032931  -8.96382669  -8.65849607
  -8.65331888  -8.48445537  -8.48080646  -8.45579764  -8.44036508
  -8.44022089  -8.330117    -8.26243204  -8.16462536  -8.13319584
  -8.10819769  -8.02716962  -7.94379606  -7.90782955  -7.82133785
  -7.80716281  -7.79064574  -7.63951035  -7.57539849  -7.53264209
  -7.36278501  -7.36244313  -7.33727423  -7.27006135  -7.14127278
  -7.10832736  -6.95906356  -6.85677384  -6.77694649  -6.72206384
  -6.71997062  -6.66003536  -6.5904481   -6.53544734  -6.51820418
  -6.38767366  -6.25201696  -5.69407869  -5.61579673  -5.3472021
  -5.07848501  -5.02795798  -4.82757292  -4.63049542  -4.230832
  -4.03104862  -3.38446715  -3.3322555   -2.64166233  -1.91361965]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:0
end of epoch 0: val_loss 0.0029113959511921196, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 5.3211e-02,  4.2698e-05,  4.8022e-02, -1.7028e-02, -6.8618e-02,
          5.9366e-02, -2.9015e-03, -1.0414e-03, -2.7086e-04, -8.7543e-03,
         -1.4320e-03, -3.3696e-01, -2.9942e-01]], device='cuda:0'))])
end of epoch 1: val_loss 0.0015635438988168104, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.2262e-01,  1.3290e-02,  2.4349e-01, -1.1087e-01, -3.5054e-05,
         -9.9230e-04, -1.3952e-02,  6.6392e-03,  8.9334e-06, -9.3655e-02,
         -1.4320e-03, -1.0434e+00, -9.9922e-01]], device='cuda:0'))])
end of epoch 2: val_loss 0.0005049308140052844, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0270, -0.0127,  0.0598, -0.0009, -0.0016,  0.0020, -0.0171, -0.0093,
         -0.0009, -0.0052, -0.0014, -0.5662, -0.7315]], device='cuda:0'))])
end of epoch 3: val_loss 0.024787734634043906, val_acc 0.995
trigger times: 1
end of epoch 4: val_loss 0.0001555465469216699, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.3914e-01,  5.1467e-02,  3.0068e-01, -1.7652e-01, -6.5863e-02,
          8.7661e-02,  6.1262e-04,  1.2403e-01,  1.4613e-01, -3.3957e-01,
         -1.4320e-03, -1.4663e+00, -2.1229e+00]], device='cuda:0'))])
end of epoch 5: val_loss 4.834205837884298e-05, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.1920e-01, -1.9559e-02,  1.8828e-01, -1.1415e-01, -1.5142e-07,
          1.1633e-01,  1.1240e-02,  1.7164e-02,  6.9985e-05, -1.3268e-01,
         -1.4320e-03, -1.1960e+00, -1.8569e+00]], device='cuda:0'))])
end of epoch 6: val_loss 0.0001320954811490793, val_acc 1.0
trigger times: 1
end of epoch 7: val_loss 0.05096703403678592, val_acc 0.995
trigger times: 2
end of epoch 8: val_loss 2.784636691387379, val_acc 0.8
trigger times: 3
end of epoch 9: val_loss 0.0006719324095778845, val_acc 1.0
trigger times: 4
end of epoch 10: val_loss 3.862303158896907e-07, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.9772e-01, -3.9235e-02,  4.3603e-01, -1.6260e-01,  1.3085e-01,
          4.2108e-01, -7.6011e-02,  1.1582e-01,  1.4235e-05, -3.3163e-01,
         -1.4320e-03, -1.4699e+00, -2.0317e+00]], device='cuda:0'))])
end of epoch 11: val_loss 0.0016828509281860348, val_acc 1.0
trigger times: 1
end of epoch 12: val_loss 0.002686924247974609, val_acc 1.0
trigger times: 2
end of epoch 13: val_loss 0.0034716573343831314, val_acc 0.995
trigger times: 3
end of epoch 14: val_loss 0.007350333851421595, val_acc 0.995
trigger times: 4
end of epoch 15: val_loss 2.7449620777666438e-05, val_acc 1.0
trigger times: 5
end of epoch 16: val_loss 0.003532661753629327, val_acc 1.0
trigger times: 6
end of epoch 17: val_loss 0.0003986243169293857, val_acc 1.0
trigger times: 7
end of epoch 18: val_loss 0.00044705587678514294, val_acc 1.0
trigger times: 8
end of epoch 19: val_loss 2.1484761964494226e-05, val_acc 1.0
trigger times: 9
end of epoch 20: val_loss 0.001266688102465423, val_acc 1.0
trigger times: 10
Early stopping.
0 -113.61271274089813 -54.98547503240923
1 -84.34975184500217 -50.03933801517046
2 -83.53047513961792 -49.72654640753777
3 -89.47646820545197 -45.7351542845057
4 -88.44235062599182 -44.99030608142343
5 -95.0662599503994 -43.81326882122305
6 -75.13036096096039 -42.29180714825394
7 -69.8792732656002 -41.6910044370425
8 -61.83196730911732 -41.281777102712205
9 -89.89584589004517 -40.34838365523108
10 -77.57752214372158 -39.57586365327889
11 -76.91879332065582 -39.024610555047154
12 -68.56411135196686 -38.41270390343083
13 -75.7536545842886 -37.79713616772368
14 -55.42041766643524 -37.66475323879293
15 -84.09602651000023 -37.1809993033689
16 -67.18724370002747 -37.00630588930485
17 -75.1978988647461 -36.48799015296732
18 -53.6709386408329 -36.19207561676116
19 -69.37723425030708 -35.78149902167743
20 -90.35307288169861 -35.26282499693737
21 -60.25308972597122 -35.209705244501436
22 -57.8841912522912 -34.80241747531743
23 -57.8545942902565 -33.84284985953318
24 -70.84673070907593 -31.969099402548657
25 -55.61927245557308 -31.64414355845032
26 -52.94823336601257 -31.223196019713853
27 -67.76596510410309 -29.39157139549552
28 -89.54009622335434 -29.106189988903285
29 -36.37207928299904 -27.343722362182305
30 -55.52648268640041 -27.07399028854534
31 -35.251446068286896 -26.244794902859052
32 -79.5526037812233 -25.45878528601009
33 -45.01674510538578 -24.828695359328833
34 -51.37847155332565 -23.978745577896312
35 -78.35545274615288 -23.44970807952351
36 -61.41586822271347 -22.60679894414887
37 -76.28599748015404 -20.656863763892378
38 -41.25067029893398 -20.19699010077007
39 -59.113490611314774 -19.63760343800059
40 -32.068796530365944 -19.515598718228343
41 -33.128172516822815 -19.013661458547123
42 -28.55409276485443 -18.40219305308781
43 -28.54410570859909 -18.12524762224982
44 -21.060277372598648 -17.55742370467821
45 -18.160259146243334 -17.45759595071254
46 -32.84773914515972 -17.229524156575224
47 -46.73925095051527 -16.823073927842348
48 -26.58053646981716 -16.465245286323213
49 -24.362519904971123 -15.698442160753391
50 -23.260487601161003 -15.547448612110475
51 -27.858225777745247 -15.429192147495273
52 -27.908614069223404 -15.206974813006973
53 -22.370711714029312 -15.087280726906778
54 -37.91432777047157 -15.046269525186256
55 -30.84467613697052 -14.971963915263082
56 -13.087725937366486 -14.855082803515382
57 -19.269527185708284 -14.634881482764262
58 -25.619410172104836 -14.517353968866582
59 -17.84762267023325 -14.415834737533931
60 -23.426205694675446 -14.136603456622273
61 -9.825430482625961 -13.596012850960644
62 -19.06114400923252 -13.46738201284224
63 -20.809886714443564 -13.119109094760498
64 -12.439649533480406 -12.880778469177017
65 -11.153199829161167 -12.853444948014234
66 -24.44492755830288 -12.66418205637357
67 -16.80719570070505 -12.630404284954777
68 -19.242669377475977 -12.502472096276058
69 -12.193928882479668 -12.30017947419658
70 -18.396489152684808 -12.244072413557515
71 -11.904925771057606 -12.061899746555405
72 -19.089032121002674 -11.970275029169322
73 -24.79176864027977 -11.885974118704722
74 -17.211173869669437 -11.788852141676486
75 -23.687459364533424 -11.585848306718171
76 -21.738953862339258 -11.534802514798704
77 -23.591367974877357 -11.42486018393087
78 -13.92735931277275 -11.010648429740753
79 -17.89446686208248 -10.958378231523026
80 -23.34955097734928 -10.869989101210326
81 -10.044092036783695 -10.56227460567635
82 -9.389387279748917 -10.478295012926367
83 -16.085186704993248 -10.364327246341285
84 -22.12636785209179 -10.31685998918951
85 -19.469330601394176 -9.918132877383394
86 -17.05122921615839 -9.857401731102941
87 -15.88353744149208 -9.735016921371221
88 -2.7004157677292824 -9.553607251314032
89 -21.355414364486933 -9.349228502933956
90 -10.81363682821393 -9.22561711361344
91 -15.895830251276493 -9.147656351662803
92 -13.526365343481302 -9.032480480715858
93 -17.904256895184517 -9.000329314155312
94 -10.345343202352524 -8.658496065173749
95 -12.263296861201525 -8.484455365743758
96 -10.157024338841438 -8.455797636261352
97 -12.782509837299585 -8.44022089262088
98 -14.18681289255619 -8.262432035415433
99 -3.841711089015007 -8.133195842510668
100 -9.556457001715899 -8.027169616483599
101 -5.163661569356918 -7.9078295497745845
102 -5.110514998435974 -7.807162809000805
103 -5.788868609815836 -7.639510351200451
104 -9.730543479323387 -7.532642088692973
105 -23.00048479437828 -7.362443126623615
106 -5.360485348850489 -7.270061347491789
107 -16.916320614516735 -7.108327355338034
108 -3.625393033027649 -6.85677384072701
109 -18.27054336667061 -6.7220638398623045
110 0.027738988399505615 -6.660035363747956
111 2.7699208110570908 -6.535447341844848
112 -3.9479520469903946 -6.387673664752574
113 -1.6618620231747627 -5.694078692466705
114 -8.670122053474188 -5.34720210027791
115 -0.13257016241550446 -5.027957977402961
116 10.204600095748901 -4.63049541560991
117 -5.0653780698776245 -4.031048624093466
118 -3.157818615436554 -3.3322555012187633
119 2.0898908227682114 -1.9136196540088464
train accuracy: 0.9977777777777778
validation accuracy: 1.0
[-70.02437758 -69.84519803 -69.66914734 -69.22293128 -69.06514402
 -68.92597108 -68.91946169 -68.84832191 -68.70605984 -68.49448158
 -68.36549299 -68.36240257 -68.2633479  -68.07023934 -67.99098481
 -67.96217093 -67.88706403 -67.847765   -67.81443967 -67.71866943
 -67.57597012 -67.53661671 -67.48564781 -67.48225056 -67.46896131
 -67.24855841 -67.21563999 -67.08451606 -66.89166375 -66.75521955
 -66.7279203  -66.7155731  -66.61174271 -66.58703618 -66.56161148
 -66.55907926 -66.54641063 -66.54566613 -66.46407983 -66.45732572
 -66.45670142 -66.44624272 -66.13937792 -66.09018123 -66.07989104
 -66.07280262 -65.99732381 -65.95056286 -65.91596564 -65.72217307
 -65.66196757 -65.53002586 -65.50313625 -65.44672492 -65.31215608
 -65.30973874 -65.28143806 -65.23395913 -65.18650865 -65.08062664
 -64.92129177 -64.86829805 -64.70968772 -64.55791051 -64.52960809
 -64.50296145 -64.50292872 -64.39047086 -64.38888227 -64.25216681
 -64.19112389 -64.18988312 -64.04237035 -63.79982443 -63.76630157
 -63.73868218 -63.70646946 -63.6821681  -63.65198418 -63.54343205
 -63.45966792 -63.41220449 -63.40750842 -63.32379859 -63.29774043
 -63.28034273 -63.2355132  -63.22225564 -63.09862664 -63.01067311
 -62.91259595 -62.81122246 -62.79117203 -62.77841672 -62.76898501
 -62.67279431 -62.64051164 -62.57783713 -62.56967899 -62.44589019
 -62.38758784 -62.32952884 -62.24254122 -62.23310964 -62.18209193
 -62.13548877 -62.09275189 -62.07644115 -61.93848366 -61.74640362
 -61.65967907 -61.32814064 -61.17052504 -61.0441459  -60.77386348
 -60.39131992 -60.3329059  -59.64160815 -58.86517367 -58.53453108
 -54.98547503 -50.4922686  -50.03933802 -49.75347185 -49.72654641
 -46.98011874 -45.73515428 -45.67057988 -44.99030608 -44.14602409
 -43.81326882 -43.18878399 -42.29180715 -42.00401746 -41.69100444
 -41.68588229 -41.2817771  -40.44278203 -40.34838366 -39.59970115
 -39.57586365 -39.31972693 -39.02461056 -38.45534494 -38.4127039
 -38.35634328 -37.79713617 -37.74152899 -37.66475324 -37.51313938
 -37.1809993  -37.10070314 -37.00630589 -36.82191677 -36.48799015
 -36.2096527  -36.19207562 -36.11445903 -35.78149902 -35.39450387
 -35.262825   -35.24303541 -35.20970524 -35.06544085 -34.80241748
 -34.64469045 -33.84284986 -32.70706485 -31.9690994  -31.7109134
 -31.64414356 -31.39238276 -31.22319602 -31.12953085 -29.3915714
 -29.34012561 -29.10618999 -27.4110235  -27.34372236 -27.19668163
 -27.07399029 -26.70472176 -26.2447949  -25.54836509 -25.45878529
 -24.879107   -24.82869536 -24.59274514 -23.97874558 -23.57262108
 -23.44970808 -22.74530916 -22.60679894 -22.19891032 -20.65686376
 -20.44447256 -20.1969901  -20.13839115 -19.63760344 -19.63436396
 -19.51559872 -19.03868419 -19.01366146 -18.9283881  -18.40219305
 -18.13112681 -18.12524762 -17.99477406 -17.5574237  -17.50947559
 -17.45759595 -17.34359036 -17.22952416 -17.09235581 -16.82307393
 -16.72556391 -16.46524529 -16.44056833 -15.69844216 -15.62688785
 -15.54744861 -15.49021849 -15.42919215 -15.29797373 -15.20697481
 -15.12252306 -15.08728073 -15.08020331 -15.04626953 -14.98912762
 -14.97196392 -14.90387708 -14.8550828  -14.78622576 -14.63488148
 -14.5314246  -14.51735397 -14.44242009 -14.41583474 -14.37972793
 -14.26791204 -14.13660346 -13.68634927 -13.59601285 -13.53453212
 -13.46738201 -13.28824842 -13.11910909 -12.94042091 -12.88077847
 -12.87408383 -12.85344495 -12.68135973 -12.66418206 -12.64627127
 -12.63040428 -12.50725806 -12.5024721  -12.48743392 -12.30017947
 -12.29207041 -12.24407241 -12.15190477 -12.06189975 -11.98108374
 -11.97027503 -11.9042515  -11.88597412 -11.79872418 -11.78885214
 -11.74253045 -11.58584831 -11.54066985 -11.53480251 -11.4436213
 -11.42486018 -11.20813099 -11.01064843 -10.99611373 -10.95837823
 -10.92999647 -10.8699891  -10.59120474 -10.56227461 -10.55136287
 -10.47829501 -10.39312115 -10.36432725 -10.3276815  -10.31685999
 -10.05616271  -9.91813288  -9.89169983  -9.85740173  -9.85721598
  -9.73501692  -9.62007273  -9.55360725  -9.48252785  -9.3492285
  -9.3336688   -9.22561711  -9.1656006   -9.14765635  -9.13241564
  -9.03248048  -9.0098247   -9.00032931  -8.96382669  -8.65849607
  -8.65331888  -8.48445537  -8.48080646  -8.45579764  -8.44036508
  -8.44022089  -8.330117    -8.26243204  -8.16462536  -8.13319584
  -8.10819769  -8.02716962  -7.94379606  -7.90782955  -7.82133785
  -7.80716281  -7.79064574  -7.63951035  -7.57539849  -7.53264209
  -7.36278501  -7.36244313  -7.33727423  -7.27006135  -7.14127278
  -7.10832736  -6.95906356  -6.85677384  -6.77694649  -6.72206384
  -6.71997062  -6.66003536  -6.5904481   -6.53544734  -6.51820418
  -6.38767366  -6.25201696  -5.69407869  -5.61579673  -5.3472021
  -5.07848501  -5.02795798  -4.82757292  -4.63049542  -4.230832
  -4.03104862  -3.38446715  -3.3322555   -2.64166233  -1.91361965]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:0
end of epoch 0: val_loss 0.03958857410700048, val_acc 0.995
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-8.3057e-02,  3.6591e-02,  1.9474e-01, -2.6371e-01, -1.8848e-05,
          6.1298e-05,  5.1770e-02,  3.7067e-02,  1.9474e-05, -8.2015e-05,
         -1.4320e-03, -5.4152e-01, -5.1389e-01]], device='cuda:0'))])
end of epoch 1: val_loss 0.0015265786647781, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.1009,  0.1156,  0.1222, -0.0653, -0.0114,  0.2650,  0.0507, -0.0055,
          0.0041, -0.1394, -0.0014, -0.4124, -0.9245]], device='cuda:0'))])
end of epoch 2: val_loss 0.00020700075427267705, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.2455e-06, -1.3280e-06,  1.1079e-02,  7.5713e-06,  6.6387e-05,
          3.9551e-05,  4.3415e-02, -5.6700e-06,  1.9551e-04,  2.9057e-04,
         -1.4320e-03,  1.3950e-04, -7.5166e-01]], device='cuda:0'))])
end of epoch 3: val_loss 4.9683636503417005e-06, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.6361e-05, -6.8668e-05, -2.2236e-06,  4.9049e-05,  2.4143e-06,
          1.2888e-04, -5.4819e-07,  9.0925e-06, -3.0832e-04, -3.5543e-05,
         -1.4320e-03, -3.7250e-04, -3.7748e-01]], device='cuda:0'))])
end of epoch 4: val_loss 0.16538605063684372, val_acc 0.995
trigger times: 1
end of epoch 5: val_loss 0.049714250564575194, val_acc 0.995
trigger times: 2
end of epoch 6: val_loss 0.026620169281959496, val_acc 0.995
trigger times: 3
end of epoch 7: val_loss 0.02419752180576321, val_acc 0.995
trigger times: 4
end of epoch 8: val_loss 0.04121721267700195, val_acc 0.995
trigger times: 5
end of epoch 9: val_loss 0.040418905965875634, val_acc 0.99
trigger times: 6
end of epoch 10: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-8.5213e-05,  4.4464e-05,  1.5855e-01, -2.1041e-01, -6.6301e-04,
         -6.0253e-05, -1.0328e-06, -3.5134e-02,  1.4412e-04,  1.8143e-04,
         -1.4320e-03,  3.1475e-04, -1.5870e+00]], device='cuda:0'))])
end of epoch 11: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.2012e-04,  8.5604e-05, -6.1164e-05,  8.1613e-06, -1.4446e-03,
          2.1546e-05,  4.6660e-07, -4.9741e-06,  3.6282e-04, -3.4045e-04,
         -1.4321e-03,  6.9916e-04, -9.1017e-01]], device='cuda:0'))])
end of epoch 12: val_loss 0.38654230744718004, val_acc 0.99
trigger times: 1
end of epoch 13: val_loss 7.59936450049281e-05, val_acc 1.0
trigger times: 2
end of epoch 14: val_loss 4.6398458071053025e-05, val_acc 1.0
trigger times: 3
end of epoch 15: val_loss 0.0011207459990598778, val_acc 1.0
trigger times: 4
end of epoch 16: val_loss 0.00865588366985321, val_acc 0.995
trigger times: 5
end of epoch 17: val_loss 0.0013261470198631287, val_acc 1.0
trigger times: 6
end of epoch 18: val_loss 0.025644099712371825, val_acc 0.995
trigger times: 7
end of epoch 19: val_loss 0.21309318352294213, val_acc 0.995
trigger times: 8
end of epoch 20: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 9
end of epoch 21: val_loss 1.7401637614611332e-06, val_acc 1.0
trigger times: 10
Early stopping.
0 -491.45788383483887 -70.02437758354124
1 -486.480845451355 -69.22293128139457
2 -488.649614572525 -68.91946169090464
3 -483.2496919631958 -68.49448157814682
4 -485.8197433948517 -68.26334789627366
5 -484.0324959754944 -67.96217093419735
6 -483.53679394721985 -67.81443967035496
7 -486.9719166755676 -67.53661670589112
8 -486.681679725647 -67.468961314271
9 -489.8949601650238 -67.08451606100085
10 -485.9551351070404 -66.72792030035001
11 -474.8050332069397 -66.58703618076294
12 -477.3567612171173 -66.54641062659476
13 -492.745623588562 -66.45732572025315
14 -488.13652515411377 -66.13937792390927
15 -489.24388551712036 -66.07280261942869
16 -488.22093439102173 -65.91596564229344
17 -477.70156502723694 -65.53002586214863
18 -492.17323780059814 -65.31215608217713
19 -486.24224948883057 -65.23395912841217
20 -484.14253544807434 -64.92129176893178
21 -474.38430309295654 -64.55791051277296
22 -479.86651587486267 -64.50292872232112
23 -471.71550369262695 -64.25216681388612
24 -479.5836136341095 -64.04237034687793
25 -489.6378164291382 -63.73868218304008
26 -485.2933428287506 -63.65198417780727
27 -483.4479811191559 -63.41220449143389
28 -483.8079516887665 -63.29774042867055
29 -481.86429238319397 -63.22225563671035
30 -477.4560685157776 -62.81122246134827
31 -477.1360054016113 -62.76898501092357
32 -485.75186014175415 -62.57783712641824
33 -473.85732197761536 -62.387587844604646
34 -485.7939383983612 -62.23310964379467
35 -483.3005299568176 -62.09275189171944
36 -483.3487410545349 -61.746403615685615
37 -480.5286819934845 -61.17052504276673
38 -478.2864074707031 -60.39131992075664
39 -485.69201135635376 -58.865173674914324
40 -38.81870937347412 -50.492268601198035
41 -59.82260477542877 -49.72654640753777
42 -80.40545383095741 -45.670579884154705
43 -90.09851634502411 -43.81326882122305
44 -80.60247454047203 -42.00401746161006
45 -79.97263398766518 -41.281777102712205
46 -123.03359526395798 -39.599701153458774
47 -42.53875470161438 -39.024610555047154
48 -93.13423237204552 -38.35634328077039
49 -62.411904871463776 -37.66475323879293
50 -85.37823033332825 -37.100703136010694
51 -112.59853342175484 -36.48799015296732
52 -52.300906002521515 -36.114459029559086
53 -49.23633795976639 -35.26282499693737
54 -57.06344813108444 -35.0654408505187
55 -15.147825241088867 -33.84284985953318
56 -43.47243593633175 -31.7109134007892
57 -62.32770100235939 -31.223196019713853
58 -54.6611018627882 -29.340125609942326
59 -43.93760011345148 -27.343722362182305
60 -32.77062380313873 -26.7047217556024
61 -66.84060522913933 -25.45878528601009
62 -26.707901656627655 -24.592745144504722
63 -53.218793738633394 -23.44970807952351
64 -35.28438951075077 -22.19891031871716
65 -40.82451272010803 -20.19699010077007
66 2.24408171325922 -19.634363962764166
67 3.318074371665716 -19.013661458547123
68 5.205646306276321 -18.131126814449324
69 -22.304137989878654 -17.55742370467821
70 4.19830521568656 -17.343590362219476
71 -26.60686206817627 -16.823073927842348
72 2.920902244746685 -16.440568326848314
73 1.831223912537098 -15.547448612110475
74 3.1275380551815033 -15.29797373472319
75 1.7880428321659565 -15.087280726906778
76 1.0396004617214203 -14.98912761511048
77 -21.42698583006859 -14.855082803515382
78 -34.70227560400963 -14.531424598833084
79 3.393437072634697 -14.415834737533931
80 0.4096115306019783 -14.136603456622273
81 2.384418036788702 -13.534532124095186
82 1.4539838545024395 -13.119109094760498
83 4.215109139680862 -12.87408382585279
84 -33.786201886832714 -12.66418205637357
85 1.0317889340221882 -12.507258057903355
86 -20.23328340984881 -12.30017947419658
87 -23.29564045369625 -12.151904772081672
88 4.220146343111992 -11.970275029169322
89 6.6115777567029 -11.798724175673653
90 4.899352237582207 -11.540669845266835
91 7.144561488181353 -11.42486018393087
92 2.54504930973053 -10.996113732217184
93 -25.415261536836624 -10.869989101210326
94 8.068964842706919 -10.551362869855023
95 1.1233657337725163 -10.364327246341285
96 4.177795447409153 -10.056162705994502
97 3.178625874221325 -9.857401731102941
98 0.9147813953459263 -9.620072730709573
99 4.011788792908192 -9.349228502933956
100 1.8776151947677135 -9.165600597219733
101 2.5586522854864597 -9.032480480715858
102 0.7598904147744179 -8.963826694643434
103 3.0179383158683777 -8.484455365743758
104 2.8071803748607635 -8.440365078847586
105 4.780303202569485 -8.262432035415433
106 -18.700088400393724 -8.108197691178031
107 0.494638055562973 -7.9078295497745845
108 0.9023287668824196 -7.790645742734256
109 2.9645911306142807 -7.532642088692973
110 1.279452096670866 -7.3372742345819955
111 -7.974169695749879 -7.108327355338034
112 -34.55702555924654 -6.776946485018116
113 1.6333037205040455 -6.660035363747956
114 -7.018104672431946 -6.51820418055673
115 1.3680341988801956 -5.694078692466705
116 -3.181488648056984 -5.078485007852753
117 -3.654790848493576 -4.63049541560991
118 -6.181998763233423 -3.3844671463622564
119 -9.086321137845516 -1.9136196540088464
train accuracy: 1.0
validation accuracy: 1.0
[-70.02437758 -69.84519803 -69.66914734 -69.22293128 -69.06514402
 -68.92597108 -68.91946169 -68.84832191 -68.70605984 -68.49448158
 -68.36549299 -68.36240257 -68.2633479  -68.07023934 -67.99098481
 -67.96217093 -67.88706403 -67.847765   -67.81443967 -67.71866943
 -67.57597012 -67.53661671 -67.48564781 -67.48225056 -67.46896131
 -67.24855841 -67.21563999 -67.08451606 -66.89166375 -66.75521955
 -66.7279203  -66.7155731  -66.61174271 -66.58703618 -66.56161148
 -66.55907926 -66.54641063 -66.54566613 -66.46407983 -66.45732572
 -66.45670142 -66.44624272 -66.13937792 -66.09018123 -66.07989104
 -66.07280262 -65.99732381 -65.95056286 -65.91596564 -65.72217307
 -65.66196757 -65.53002586 -65.50313625 -65.44672492 -65.31215608
 -65.30973874 -65.28143806 -65.23395913 -65.18650865 -65.08062664
 -64.92129177 -64.86829805 -64.70968772 -64.55791051 -64.52960809
 -64.50296145 -64.50292872 -64.39047086 -64.38888227 -64.25216681
 -64.19112389 -64.18988312 -64.04237035 -63.79982443 -63.76630157
 -63.73868218 -63.70646946 -63.6821681  -63.65198418 -63.54343205
 -63.45966792 -63.41220449 -63.40750842 -63.32379859 -63.29774043
 -63.28034273 -63.2355132  -63.22225564 -63.09862664 -63.01067311
 -62.91259595 -62.81122246 -62.79117203 -62.77841672 -62.76898501
 -62.67279431 -62.64051164 -62.57783713 -62.56967899 -62.44589019
 -62.38758784 -62.32952884 -62.24254122 -62.23310964 -62.18209193
 -62.13548877 -62.09275189 -62.07644115 -61.93848366 -61.74640362
 -61.65967907 -61.32814064 -61.17052504 -61.0441459  -60.77386348
 -60.39131992 -60.3329059  -59.64160815 -58.86517367 -58.53453108
 -54.98547503 -50.4922686  -50.03933802 -49.75347185 -49.72654641
 -46.98011874 -45.73515428 -45.67057988 -44.99030608 -44.14602409
 -43.81326882 -43.18878399 -42.29180715 -42.00401746 -41.69100444
 -41.68588229 -41.2817771  -40.44278203 -40.34838366 -39.59970115
 -39.57586365 -39.31972693 -39.02461056 -38.45534494 -38.4127039
 -38.35634328 -37.79713617 -37.74152899 -37.66475324 -37.51313938
 -37.1809993  -37.10070314 -37.00630589 -36.82191677 -36.48799015
 -36.2096527  -36.19207562 -36.11445903 -35.78149902 -35.39450387
 -35.262825   -35.24303541 -35.20970524 -35.06544085 -34.80241748
 -34.64469045 -33.84284986 -32.70706485 -31.9690994  -31.7109134
 -31.64414356 -31.39238276 -31.22319602 -31.12953085 -29.3915714
 -29.34012561 -29.10618999 -27.4110235  -27.34372236 -27.19668163
 -27.07399029 -26.70472176 -26.2447949  -25.54836509 -25.45878529
 -24.879107   -24.82869536 -24.59274514 -23.97874558 -23.57262108
 -23.44970808 -22.74530916 -22.60679894 -22.19891032 -20.65686376
 -20.44447256 -20.1969901  -20.13839115 -19.63760344 -19.63436396
 -19.51559872 -19.12310322 -19.03868419 -19.01366146 -18.9283881
 -18.40219305 -18.13112681 -18.12524762 -17.99477406 -17.92234129
 -17.5574237  -17.50947559 -17.45759595 -17.34359036 -17.22952416
 -17.17757645 -17.09235581 -16.93408769 -16.82307393 -16.72556391
 -16.64420594 -16.58300081 -16.46524529 -16.44056833 -16.43912857
 -16.35001782 -16.3025938  -16.02435993 -15.76323944 -15.71191307
 -15.69844216 -15.62688785 -15.54744861 -15.49021849 -15.44524324
 -15.42919215 -15.29797373 -15.20697481 -15.12252306 -15.08728073
 -15.08020331 -15.04626953 -15.00306645 -14.98912762 -14.97196392
 -14.90387708 -14.89699861 -14.8550828  -14.78622576 -14.7718506
 -14.66967038 -14.63488148 -14.56494753 -14.5314246  -14.51735397
 -14.44242009 -14.41895357 -14.41583474 -14.37972793 -14.36571785
 -14.26791204 -14.23511078 -14.23487762 -14.13660346 -14.07418631
 -13.90136462 -13.68634927 -13.59601285 -13.53453212 -13.53331925
 -13.478197   -13.46738201 -13.39063064 -13.28824842 -13.28203865
 -13.11910909 -12.94042091 -12.88077847 -12.87731044 -12.87408383
 -12.85344495 -12.83471659 -12.76514887 -12.73217899 -12.68135973
 -12.66418206 -12.64627127 -12.63040428 -12.5347541  -12.53436099
 -12.50725806 -12.5024721  -12.49682747 -12.48743392 -12.4026627
 -12.30017947 -12.29207041 -12.24407241 -12.22711767 -12.16557428
 -12.15190477 -12.06189975 -11.98145628 -11.98108374 -11.97562281
 -11.97027503 -11.96415664 -11.93806882 -11.9042515  -11.88597412
 -11.86072034 -11.82292724 -11.79872418 -11.78885214 -11.74253045
 -11.7346916  -11.62352291 -11.61946733 -11.58584831 -11.57713554
 -11.54066985 -11.53480251 -11.5152788  -11.4436213  -11.42486018
 -11.2750863  -11.2502218  -11.24303432 -11.20813099 -11.17912376
 -11.09213431 -11.08359889 -11.01064843 -10.99611373 -10.96917495
 -10.95837823 -10.92999647 -10.89707236 -10.8699891  -10.84987851
 -10.82877971 -10.80098324 -10.74814979 -10.69671285 -10.6616839
 -10.60706065 -10.59120474 -10.57148789 -10.56227461 -10.55136287
 -10.47829501 -10.44866874 -10.39312115 -10.36432725 -10.3294588
 -10.3276815  -10.32598645 -10.31685999 -10.30222586 -10.2515667
 -10.06180269 -10.05616271 -10.04256065 -10.03515384  -9.93790918
  -9.91813288  -9.91282047  -9.89524828  -9.89430622  -9.89169983
  -9.87583446  -9.85958624  -9.85740173  -9.85721598  -9.8559419
  -9.79053708  -9.73501692  -9.71783519  -9.70673964  -9.6965766
  -9.6610764   -9.62007273  -9.59982074  -9.55360725  -9.53649186
  -9.48252785  -9.43124362  -9.41642606  -9.37720577  -9.3492285
  -9.34914586  -9.34497763  -9.3336688   -9.27490238  -9.23194004
  -9.22561711  -9.21621713  -9.19492935  -9.1656006   -9.14765635
  -9.13241564  -9.04021626  -9.03248048  -9.0098247   -9.00032931
  -8.98917669  -8.96382669  -8.93633365  -8.89152428  -8.88582952
  -8.82313476  -8.81964329  -8.79491308  -8.77318925  -8.70892142
  -8.65849607  -8.65331888  -8.63569928  -8.62263876  -8.61198794
  -8.48445537  -8.48080646  -8.45579764  -8.44036508  -8.44022089
  -8.37283463  -8.330117    -8.32937339  -8.26243204  -8.25728726
  -8.24511599  -8.23779071  -8.16606994  -8.16462536  -8.13319584
  -8.13225237  -8.10819769  -8.02716962  -7.94379606  -7.90782955
  -7.86704751  -7.82133785  -7.80716281  -7.79064574  -7.63951035
  -7.57539849  -7.53264209  -7.36278501  -7.36244313  -7.33727423
  -7.27006135  -7.14127278  -7.10832736  -7.00169191  -6.95906356
  -6.90518534  -6.85677384  -6.77694649  -6.72206384  -6.71997062
  -6.66003536  -6.5904481   -6.53544734  -6.52671874  -6.51820418
  -6.38767366  -6.25201696  -5.69407869  -5.61579673  -5.3472021
  -5.07848501  -5.02795798  -4.82757292  -4.63049542  -4.230832
  -4.03104862  -3.38446715  -3.3322555   -2.64166233  -1.91361965]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:1
end of epoch 0: val_loss 0.00043618173682421715, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.9796e-04,  1.5557e-01, -8.2139e-02, -6.1895e-03,  5.7991e-05,
          6.8244e-02,  6.5736e-03,  1.2174e-02, -4.8176e-06, -1.0799e-01,
         -1.4320e-03, -5.2246e-01, -3.6883e-01]], device='cuda:1'))])
end of epoch 1: val_loss 0.0025827439644217874, val_acc 1.0
trigger times: 1
end of epoch 2: val_loss 0.00038086536800108206, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 8.2089e-07,  7.1779e-01, -3.0782e-01, -1.0496e-02,  3.4183e-01,
         -1.0310e-05,  3.4358e-02, -2.6474e-02, -3.5548e-01, -1.3288e-01,
         -1.4320e-03, -9.3974e-01, -1.2752e+00]], device='cuda:1'))])
end of epoch 3: val_loss 1.654478141936977e-06, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-7.6918e-02,  9.3197e-01, -4.3772e-01,  2.2520e-01,  5.4858e-01,
          1.7095e-01,  1.5408e-02, -2.5667e-02, -5.3409e-01, -3.3145e-01,
         -1.4320e-03, -1.6049e+00, -1.8418e+00]], device='cuda:1'))])
end of epoch 4: val_loss 1.2443214545996284e-05, val_acc 1.0
trigger times: 1
end of epoch 5: val_loss 0.000655623157912828, val_acc 1.0
trigger times: 2
end of epoch 6: val_loss 2.395887786263984e-06, val_acc 1.0
trigger times: 3
end of epoch 7: val_loss 1.7344788201256732e-07, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 8.4853e-02,  5.4708e-01, -6.3633e-01,  2.6975e-02,  6.4258e-01,
         -2.4795e-03,  1.6009e-01,  5.7504e-02, -5.8459e-01, -7.1690e-01,
         -1.4320e-03, -1.4295e+00, -2.4410e+00]], device='cuda:1'))])
end of epoch 8: val_loss 1.9073124345680982e-07, val_acc 1.0
trigger times: 1
end of epoch 9: val_loss 1.3947704572672138e-05, val_acc 1.0
trigger times: 2
end of epoch 10: val_loss 0.08879361389697352, val_acc 0.995
trigger times: 3
end of epoch 11: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.6292e-01,  3.5956e-01, -5.4537e-01,  1.0395e-01,  4.0448e-01,
         -7.5599e-05,  2.7381e-02, -1.0533e-01, -6.4389e-01, -2.3317e-01,
         -1.4321e-03, -1.2955e+00, -2.2417e+00]], device='cuda:1'))])
end of epoch 12: val_loss 0.004593643258546898, val_acc 0.995
trigger times: 1
end of epoch 13: val_loss 7.914870366221293e-07, val_acc 1.0
trigger times: 2
end of epoch 14: val_loss 0.00940249724345449, val_acc 0.995
trigger times: 3
end of epoch 15: val_loss 0.7294534239521862, val_acc 0.96
trigger times: 4
end of epoch 16: val_loss 6.961415987458253e-05, val_acc 1.0
trigger times: 5
end of epoch 17: val_loss 5.215136840419632e-07, val_acc 1.0
trigger times: 6
end of epoch 18: val_loss 0.003441900325997267, val_acc 1.0
trigger times: 7
end of epoch 19: val_loss 3.927453418782534e-05, val_acc 1.0
trigger times: 8
end of epoch 20: val_loss 0.0001650464304253063, val_acc 1.0
trigger times: 9
end of epoch 21: val_loss 0.002810730040072258, val_acc 1.0
trigger times: 10
Early stopping.
0 -592.6348831653595 -70.02437758354124
1 -583.2300882339478 -69.06514402420994
2 -578.9302636384964 -68.70605983665877
3 -584.5941896438599 -68.26334789627366
4 -589.9905009269714 -67.88706403206893
5 -581.9132807254791 -67.57597012403065
6 -571.891214966774 -67.468961314271
7 -571.8874204158783 -66.89166375352565
8 -588.9049167633057 -66.6117427080782
9 -577.1282088756561 -66.54641062659476
10 -566.7496755123138 -66.45670141949869
11 -553.9231182336807 -66.07989104225499
12 -586.5820708274841 -65.91596564229344
13 -578.3811585903168 -65.50313624737767
14 -576.2740828990936 -65.28143805539828
15 -560.9078184366226 -64.92129176893178
16 -570.7251191139221 -64.52960808642393
17 -575.5168347358704 -64.38888226545579
18 -579.2768266201019 -64.04237034687793
19 -565.8713614940643 -63.70646946231605
20 -579.5327167510986 -63.41220449143389
21 -575.3774049282074 -63.280342734337076
22 -564.9196257591248 -63.01067310805819
23 -563.1209051609039 -62.77841671708813
24 -572.2394299507141 -62.57783712641824
25 -569.4223915338516 -62.3295288437319
26 -549.7078747749329 -62.135488768509596
27 -561.636078119278 -61.746403615685615
28 -565.7809336185455 -61.04414589634305
29 -563.5166802406311 -59.64160814525277
30 -69.68606847524643 -50.492268601198035
31 -219.65928208827972 -46.98011874490918
32 -31.929199814796448 -44.14602409201361
33 -78.37182027101517 -42.00401746161006
34 -107.39891564846039 -40.44278203413966
35 -44.874124348163605 -39.31972693233231
36 -131.41277170181274 -38.35634328077039
37 -127.60347932577133 -37.513139380385574
38 -88.02542623877525 -36.821916772458344
39 -69.49908185005188 -36.114459029559086
40 -123.79238599538803 -35.24303541418371
41 -45.13921898603439 -34.64469044638467
42 -66.95171558856964 -31.7109134007892
43 -68.15880516171455 -31.12953085092458
44 -32.08122920244932 -27.41102349748205
45 -53.05392813682556 -26.7047217556024
46 -38.67893901467323 -24.879106999799365
47 -63.03518985211849 -23.57262108435893
48 -40.58069954812527 -22.19891031871716
49 -32.92356975376606 -20.13839114930498
50 -38.15152056515217 -19.123103219946703
51 -31.737243697047234 -18.40219305308781
52 -24.66560234129429 -17.922341287369633
53 -32.10549786686897 -17.343590362219476
54 -46.012833923101425 -16.93408768540679
55 -26.62772911414504 -16.58300081433467
56 -28.307335674762726 -16.350017815279713
57 -24.924130722880363 -15.711913070805013
58 -23.780979856848717 -15.490218487341382
59 -20.339691199362278 -15.206974813006973
60 -28.63843461871147 -15.003066446238579
61 -29.226713553071022 -14.896998614540767
62 6.5426395907998085 -14.669670382136477
63 -16.90274780243635 -14.517353968866582
64 -27.01619590073824 -14.379727929402803
65 -13.900002684444189 -14.234877622902621
66 -26.57935956120491 -13.686349266389305
67 -27.173784337937832 -13.478197003787718
68 -17.174412474036217 -13.282038650760315
69 -15.163937412202358 -12.877310438021263
70 -5.0978837832808495 -12.765148870708396
71 4.250899590551853 -12.646271270327462
72 -8.360738195478916 -12.507258057903355
73 -9.076683171093464 -12.402662695420005
74 5.618866063654423 -12.227117665314724
75 -8.857478823512793 -11.981456282382652
76 -5.640364412218332 -11.96415663708999
77 -6.291951984167099 -11.860720343974997
78 -9.786043100059032 -11.742530452836307
79 -13.481862738728523 -11.585848306718171
80 -9.70022551715374 -11.5152787953626
81 -15.9175576120615 -11.25022179763156
82 -21.9096851721406 -11.092134306341087
83 -9.30341937020421 -10.969174948333906
84 -47.78451496362686 -10.869989101210326
85 -9.366700246930122 -10.748149785714
86 -4.976415760815144 -10.59120473963286
87 -20.196424916386604 -10.478295012926367
88 -6.4680498242378235 -10.329458802727405
89 15.687440201640129 -10.30222586137941
90 13.678668186068535 -10.04256065142963
91 -13.962681002914906 -9.912820468646165
92 -8.32006100565195 -9.875834462593172
93 7.658257275819778 -9.855941903850479
94 -7.154724480584264 -9.706739635827205
95 -0.9813205227255821 -9.599820741479471
96 2.7092187106609344 -9.431243621809212
97 0.10948556661605835 -9.349145855897213
98 6.173712804913521 -9.231940042743117
99 -6.4585878401994705 -9.165600597219733
100 -13.089699424803257 -9.00982469640954
101 5.402640596032143 -8.936333651187548
102 10.983254462480545 -8.819643292498888
103 -7.443976014852524 -8.658496065173749
104 -3.4021983444690704 -8.61198794419007
105 3.603013500571251 -8.440365078847586
106 -14.4754230491817 -8.329373394740154
107 8.015304833650589 -8.237790707393113
108 7.632901631295681 -8.132252369673209
109 -11.753130793571472 -7.9078295497745845
110 -5.381144605576992 -7.790645742734256
111 -3.209748037159443 -7.36278501235848
112 2.96955643594265 -7.141272781594934
113 -13.473192572593689 -6.90518534137812
114 -24.383810579776764 -6.719970621583102
115 17.997295707464218 -6.526718738335009
116 5.931937865912914 -5.694078692466705
117 -18.776673197746277 -5.027957977402961
118 -2.1977344751358032 -4.031048624093466
119 17.806684643030167 -1.9136196540088464
train accuracy: 1.0
validation accuracy: 1.0
[-70.02437758 -69.84519803 -69.66914734 -69.22293128 -69.06514402
 -68.92597108 -68.91946169 -68.84832191 -68.70605984 -68.49448158
 -68.36549299 -68.36240257 -68.2633479  -68.07023934 -67.99098481
 -67.96217093 -67.88706403 -67.847765   -67.81443967 -67.71866943
 -67.57597012 -67.53661671 -67.48564781 -67.48225056 -67.46896131
 -67.24855841 -67.21563999 -67.08451606 -66.89166375 -66.75521955
 -66.7279203  -66.7155731  -66.61174271 -66.58703618 -66.56161148
 -66.55907926 -66.54641063 -66.54566613 -66.46407983 -66.45732572
 -66.45670142 -66.44624272 -66.13937792 -66.09018123 -66.07989104
 -66.07280262 -65.99732381 -65.95056286 -65.91596564 -65.72217307
 -65.66196757 -65.53002586 -65.50313625 -65.44672492 -65.31215608
 -65.30973874 -65.28143806 -65.23395913 -65.18650865 -65.08062664
 -64.92129177 -64.86829805 -64.70968772 -64.55791051 -64.52960809
 -64.50296145 -64.50292872 -64.39047086 -64.38888227 -64.25216681
 -64.19112389 -64.18988312 -64.04237035 -63.79982443 -63.76630157
 -63.73868218 -63.70646946 -63.6821681  -63.65198418 -63.54343205
 -63.45966792 -63.41220449 -63.40750842 -63.32379859 -63.29774043
 -63.28034273 -63.2355132  -63.22225564 -63.09862664 -63.01067311
 -62.91259595 -62.81122246 -62.79117203 -62.77841672 -62.76898501
 -62.67279431 -62.64051164 -62.57783713 -62.56967899 -62.44589019
 -62.38758784 -62.32952884 -62.24254122 -62.23310964 -62.18209193
 -62.13548877 -62.09275189 -62.07644115 -61.93848366 -61.74640362
 -61.65967907 -61.32814064 -61.17052504 -61.0441459  -60.77386348
 -60.39131992 -60.3329059  -59.64160815 -58.86517367 -58.53453108
 -54.98547503 -50.4922686  -50.03933802 -49.75347185 -49.72654641
 -46.98011874 -45.73515428 -45.67057988 -44.99030608 -44.14602409
 -43.81326882 -43.18878399 -42.29180715 -42.00401746 -41.69100444
 -41.68588229 -41.2817771  -40.44278203 -40.34838366 -39.59970115
 -39.57586365 -39.31972693 -39.02461056 -38.45534494 -38.4127039
 -38.35634328 -37.79713617 -37.74152899 -37.66475324 -37.51313938
 -37.1809993  -37.10070314 -37.00630589 -36.82191677 -36.48799015
 -36.2096527  -36.19207562 -36.11445903 -35.78149902 -35.39450387
 -35.262825   -35.24303541 -35.20970524 -35.06544085 -34.80241748
 -34.64469045 -33.84284986 -32.70706485 -31.9690994  -31.7109134
 -31.64414356 -31.39238276 -31.22319602 -31.12953085 -29.3915714
 -29.34012561 -29.10618999 -27.4110235  -27.34372236 -27.19668163
 -27.07399029 -26.70472176 -26.2447949  -25.54836509 -25.45878529
 -24.879107   -24.82869536 -24.59274514 -23.97874558 -23.57262108
 -23.44970808 -22.74530916 -22.60679894 -22.19891032 -20.65686376
 -20.44447256 -20.1969901  -20.1814153  -20.17959602 -20.13839115
 -19.92624243 -19.63760344 -19.63436396 -19.51559872 -19.39756409
 -19.34447885 -19.23593207 -19.12310322 -19.03868419 -19.01366146
 -18.95170124 -18.92864293 -18.9283881  -18.59616826 -18.40219305
 -18.26397084 -18.13112681 -18.12524762 -18.00326352 -17.99477406
 -17.92234129 -17.90998836 -17.75923117 -17.5574237  -17.50947559
 -17.45759595 -17.39960006 -17.34359036 -17.23421418 -17.22952416
 -17.17757645 -17.12268398 -17.09235581 -16.93719112 -16.93408769
 -16.82307393 -16.72556391 -16.69606948 -16.64420594 -16.58300081
 -16.46524529 -16.44056833 -16.43912857 -16.35001782 -16.3025938
 -16.20525991 -16.19672667 -16.17622393 -16.02435993 -15.99985529
 -15.93479371 -15.88968647 -15.78422113 -15.76323944 -15.71191307
 -15.69844216 -15.67416693 -15.635793   -15.62688785 -15.54744861
 -15.49021849 -15.45210689 -15.44524324 -15.42919215 -15.32494513
 -15.29797373 -15.24305514 -15.22860131 -15.20697481 -15.16485985
 -15.12252306 -15.08728073 -15.08020331 -15.04626953 -15.01396048
 -15.00306645 -14.98912762 -14.97705763 -14.97196392 -14.91216678
 -14.90387708 -14.89699861 -14.8550828  -14.81404643 -14.78622576
 -14.7718506  -14.74401033 -14.70913254 -14.69128996 -14.66967038
 -14.63488148 -14.59596186 -14.56494753 -14.5314246  -14.51735397
 -14.44242009 -14.41895357 -14.41583474 -14.37972793 -14.36571785
 -14.35424825 -14.30204939 -14.26791204 -14.23511078 -14.23487762
 -14.15121867 -14.13660346 -14.07418631 -13.90136462 -13.85738623
 -13.765325   -13.68634927 -13.59601285 -13.53453212 -13.53331925
 -13.478197   -13.46738201 -13.39063064 -13.32715153 -13.32106729
 -13.28824842 -13.28203865 -13.20886919 -13.11910909 -13.01149556
 -12.94042091 -12.88523587 -12.88077847 -12.87731044 -12.87628438
 -12.87408383 -12.85344495 -12.83471659 -12.83228066 -12.76514887
 -12.73217899 -12.68135973 -12.66418206 -12.64745202 -12.64627127
 -12.63040428 -12.57534526 -12.5347541  -12.53436099 -12.50725806
 -12.5024721  -12.49682747 -12.48866592 -12.48743392 -12.4164314
 -12.4026627  -12.31337623 -12.30017947 -12.29207041 -12.26426289
 -12.24407241 -12.23955807 -12.22711767 -12.21657299 -12.16557428
 -12.15190477 -12.09460199 -12.06189975 -12.05853498 -11.98145628
 -11.98108374 -11.97562281 -11.97027503 -11.96415664 -11.93806882
 -11.9042515  -11.88597412 -11.86072034 -11.82292724 -11.79872418
 -11.78885214 -11.77833202 -11.74253045 -11.7346916  -11.62352291
 -11.61946733 -11.59966107 -11.58584831 -11.57785081 -11.57713554
 -11.54066985 -11.53480251 -11.5152788  -11.46421273 -11.45692174
 -11.4436213  -11.42486018 -11.37040241 -11.31829582 -11.28221787
 -11.2750863  -11.26573977 -11.2502218  -11.24303432 -11.22312905
 -11.21889858 -11.20813099 -11.20024646 -11.17912376 -11.09213431
 -11.08359889 -11.01064843 -10.99611373 -10.97093044 -10.96917495
 -10.95837823 -10.94697681 -10.92999647 -10.91494096 -10.8974297
 -10.89707236 -10.87316999 -10.8699891  -10.84987851 -10.82877971
 -10.80098324 -10.76593874 -10.74814979 -10.72771815 -10.69671285
 -10.6616839  -10.6529369  -10.60706065 -10.59120474 -10.57148789
 -10.56227461 -10.55136287 -10.5325345  -10.50038676 -10.47829501
 -10.47073846 -10.44866874 -10.44676532 -10.39794369 -10.39312115
 -10.38356728 -10.37711194 -10.36432725 -10.3294588  -10.3276815
 -10.32598645 -10.31685999 -10.30222586 -10.2515667  -10.14354684
 -10.06985002 -10.06316834 -10.06180269 -10.05616271 -10.04256065
 -10.03515384  -9.95955814  -9.95675631  -9.93790918  -9.91813288
  -9.91282047  -9.89524828  -9.89430622  -9.89169983  -9.87583446
  -9.85958624  -9.85740173  -9.85721598  -9.8559419   -9.79604807
  -9.79053708  -9.73501692  -9.71783519  -9.70673964  -9.6965766
  -9.6610764   -9.65999581  -9.62007273  -9.59982074  -9.59452006
  -9.55360725  -9.53649186  -9.48252785  -9.47409877  -9.4370424
  -9.43124362  -9.41642606  -9.37720577  -9.3492285   -9.34914586
  -9.34497763  -9.3336688   -9.27490238  -9.23194004  -9.22561711
  -9.21621713  -9.21546888  -9.19829123  -9.19492935  -9.1656006
  -9.14765635  -9.13241564  -9.10142691  -9.04021626  -9.03248048
  -9.0098247   -9.00032931  -8.98917669  -8.96382669  -8.93633365
  -8.89152428  -8.88582952  -8.8391866   -8.82313476  -8.81964329
  -8.79491308  -8.77318925  -8.70892142  -8.66463661  -8.66416507
  -8.65849607  -8.65331888  -8.63569928  -8.62263876  -8.62034767
  -8.61198794  -8.48445537  -8.48080646  -8.45579764  -8.44036508
  -8.44022089  -8.37283463  -8.330117    -8.32937339  -8.26243204
  -8.25728726  -8.24511599  -8.23779071  -8.16606994  -8.16462536
  -8.16143504  -8.13319584  -8.13225237  -8.10819769  -8.05013334
  -8.02716962  -7.94379606  -7.90782955  -7.89665196  -7.89619757
  -7.86704751  -7.82133785  -7.80716281  -7.79064574  -7.77952325
  -7.71040759  -7.63951035  -7.57539849  -7.53264209  -7.52565259
  -7.40319483  -7.37892782  -7.37666527  -7.36278501  -7.36244313
  -7.35486686  -7.33727423  -7.29132104  -7.27515967  -7.27006135
  -7.14127278  -7.12836571  -7.10832736  -7.00169191  -6.95906356
  -6.90518534  -6.85677384  -6.77694649  -6.72206384  -6.71997062
  -6.66003536  -6.5904481   -6.53544734  -6.52671874  -6.51820418
  -6.38767366  -6.25201696  -5.69407869  -5.61579673  -5.3472021
  -5.07848501  -5.02795798  -4.82757292  -4.63049542  -4.230832
  -4.03104862  -3.38446715  -3.3322555   -2.64166233  -1.91361965]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:3
end of epoch 0: val_loss 0.000909111340637665, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-7.5695e-03, -5.4896e-03, -2.4900e-02, -1.6112e-02, -2.5986e-04,
          1.7200e-05,  1.3097e-02,  1.1244e-02, -7.8214e-05,  8.1816e-04,
         -1.4320e-03, -6.2768e-01, -4.2886e-01]], device='cuda:3'))])
end of epoch 1: val_loss 0.04751750952412433, val_acc 0.985
trigger times: 1
end of epoch 2: val_loss 6.976538385252695e-06, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 9.6857e-06,  7.7016e-03,  3.5375e-07, -5.7995e-06,  1.1293e-05,
          1.6203e-05,  8.0863e-03,  1.5260e-03, -4.8169e-05,  7.6765e-05,
         -1.4320e-03, -1.2338e+00, -8.9074e-01]], device='cuda:3'))])
end of epoch 3: val_loss 0.11866643209250466, val_acc 0.975
trigger times: 1
end of epoch 4: val_loss 2.8713600118592807e-05, val_acc 1.0
trigger times: 2
end of epoch 5: val_loss 8.843918990386612e-06, val_acc 1.0
trigger times: 3
end of epoch 6: val_loss 0.009934149009993015, val_acc 0.995
trigger times: 4
end of epoch 7: val_loss 4.768370800434241e-09, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.1409e-02, -3.3913e-02, -1.0938e-01,  5.1014e-02,  5.4250e-02,
         -9.4426e-06,  5.6032e-02,  1.3548e-02, -8.0525e-02, -8.9069e-02,
         -1.4320e-03, -2.1982e+00, -2.3053e+00]], device='cuda:3'))])
end of epoch 8: val_loss 1.1795493843891336e-06, val_acc 1.0
trigger times: 1
end of epoch 9: val_loss 0.009176873752976817, val_acc 0.995
trigger times: 2
end of epoch 10: val_loss 0.004224486959292868, val_acc 0.995
trigger times: 3
end of epoch 11: val_loss 0.008982601270208015, val_acc 0.995
trigger times: 4
end of epoch 12: val_loss 0.0014043064414751073, val_acc 1.0
trigger times: 5
end of epoch 13: val_loss 1.4901151352830766e-08, val_acc 1.0
trigger times: 6
end of epoch 14: val_loss 0.000726895428069625, val_acc 1.0
trigger times: 7
end of epoch 15: val_loss 2.1151010011521974e-06, val_acc 1.0
trigger times: 8
end of epoch 16: val_loss 5.006592057910097e-07, val_acc 1.0
trigger times: 9
end of epoch 17: val_loss 0.02896023169043417, val_acc 0.99
trigger times: 10
Early stopping.
0 -628.89253282547 -70.02437758354124
1 -616.8014550209045 -68.92597108070859
2 -608.2870192527771 -68.36549298631815
3 -617.9849185943604 -67.96217093419735
4 -611.4279131889343 -67.57597012403065
5 -597.5116672515869 -67.2485584088034
6 -611.0969977378845 -66.72792030035001
7 -620.6739168167114 -66.55907925618051
8 -604.03049659729 -66.45670141949869
9 -599.1271953582764 -66.07280261942869
10 -608.2960948944092 -65.66196757455543
11 -596.3089101314545 -65.30973874386889
12 -594.4712529182434 -64.92129176893178
13 -593.4123656749725 -64.50296145342024
14 -593.3401103019714 -64.1911238898472
15 -589.2304892539978 -63.70646946231605
16 -603.8195323944092 -63.41220449143389
17 -593.5260498523712 -63.23551320371064
18 -583.8287160396576 -62.81122246134827
19 -581.6872124671936 -62.64051164305419
20 -599.8920164108276 -62.3295288437319
21 -590.5123596191406 -62.09275189171944
22 -578.4060618877411 -61.328140642820685
23 -590.0570349693298 -60.33290589876112
24 -70.60478103160858 -50.492268601198035
25 -112.13360741734505 -45.7351542845057
26 -78.47374391555786 -43.18878399086166
27 -129.99522578716278 -41.281777102712205
28 -38.21166783571243 -39.31972693233231
29 -60.23865157365799 -37.79713616772368
30 -117.68289087712765 -37.100703136010694
31 -91.97939944267273 -36.19207561676116
32 -147.20064628124237 -35.24303541418371
33 -41.66564843058586 -33.84284985953318
34 -82.54799155890942 -31.392382758954444
35 -91.51993560791016 -29.106189988903285
36 -67.64232894778252 -26.7047217556024
37 -68.72016532719135 -24.828695359328833
38 -70.52185444533825 -22.745309160183492
39 -82.72290521860123 -20.19699010077007
40 -57.68074831366539 -19.63760343800059
41 -64.88705521821976 -19.235932072225243
42 -62.74418652057648 -18.92864293192921
43 -55.963274121284485 -18.131126814449324
44 -65.0141954421997 -17.909988361694168
45 -62.00351107120514 -17.343590362219476
46 -62.00693720579147 -17.09235580700411
47 -62.800012320280075 -16.696069476664405
48 -66.11012804508209 -16.439128565935984
49 -54.06261324882507 -16.176223925558837
50 -61.27570828795433 -15.784221125597993
51 -54.34445232152939 -15.635792996100953
52 -61.02532696723938 -15.445243244588788
53 -60.80824747681618 -15.228601310000212
54 -62.21401596069336 -15.080203312079139
55 -51.79363936185837 -14.977057634814416
56 -51.77231069654226 -14.855082803515382
57 -57.17669557034969 -14.709132541411762
58 -39.16407585144043 -14.564947527554397
59 -61.062475502491 -14.415834737533931
60 -48.11688530445099 -14.267912042938836
61 -59.47868233919144 -14.074186313273858
62 -53.488031566143036 -13.596012850960644
63 -52.875520050525665 -13.39063064219855
64 -37.7092921435833 -13.208869186529649
65 -50.22151106595993 -12.880778469177017
66 -54.32270973920822 -12.834716589218248
67 -47.852479577064514 -12.66418205637357
68 -41.873633958399296 -12.534754102132148
69 -40.29289473593235 -12.488665919882303
70 -53.868188098073006 -12.30017947419658
71 -46.44584971666336 -12.227117665314724
72 -48.606737554073334 -12.061899746555405
73 -41.17471706867218 -11.970275029169322
74 -48.03495490550995 -11.860720343974997
75 -51.27754187583923 -11.734691595351148
76 -39.06277818977833 -11.5778508139014
77 -37.681539721786976 -11.464212727359632
78 -30.08781246840954 -11.31829581912316
79 -34.597626298666 -11.243034323020916
80 -41.71118205785751 -11.179123759426064
81 -38.653452064841986 -10.970930437099456
82 -26.82867367938161 -10.91494095688773
83 -43.57716119289398 -10.849878510712346
84 -35.70398413017392 -10.727718150401003
85 -39.441438268870115 -10.59120473963286
86 -42.71817933022976 -10.50038676003908
87 -26.661748692393303 -10.397943689802995
88 -41.84124982357025 -10.329458802727405
89 -32.60103192180395 -10.251566700997724
90 -42.73990881443024 -10.056162705994502
91 -28.290097698569298 -9.937909181874549
92 -31.235317200422287 -9.891699828961956
93 -36.92864705622196 -9.855941903850479
94 -45.43634957075119 -9.706739635827205
95 -33.000357270240784 -9.599820741479471
96 -30.14883015304804 -9.47409877434449
97 -35.625242471694946 -9.349228502933956
98 -34.012571170926094 -9.231940042743117
99 -42.345048904418945 -9.194929345979661
100 -37.55466067790985 -9.040216260966693
101 -40.21942090988159 -8.963826694643434
102 -38.823939859867096 -8.823134759835558
103 -33.42361396551132 -8.664636606170474
104 -24.65819526463747 -8.622638763249515
105 -43.80037930607796 -8.440365078847586
106 -33.99531018733978 -8.262432035415433
107 -32.231159798800945 -8.164625358693467
108 -31.774729400873184 -8.050133343529204
109 -23.69478804245591 -7.896197566956192
110 -23.174247235059738 -7.779523248332896
111 -29.94711795542389 -7.52565258667013
112 -40.96428921818733 -7.362443126623615
113 -37.296245604753494 -7.270061347491789
114 -32.33153539896011 -6.959063561385431
115 -32.32001967728138 -6.719970621583102
116 -33.13038447499275 -6.51820418055673
117 -30.721553023904562 -5.34720210027791
118 -16.605029329657555 -4.230832004686763
119 -22.54924106411636 -1.9136196540088464
train accuracy: 0.995
validation accuracy: 0.99
[-70.02437758 -69.84519803 -69.66914734 -69.22293128 -69.06514402
 -68.92597108 -68.91946169 -68.84832191 -68.70605984 -68.49448158
 -68.36549299 -68.36240257 -68.2633479  -68.07023934 -67.99098481
 -67.96217093 -67.88706403 -67.847765   -67.81443967 -67.71866943
 -67.57597012 -67.53661671 -67.48564781 -67.48225056 -67.46896131
 -67.24855841 -67.21563999 -67.08451606 -66.89166375 -66.83305073
 -66.75521955 -66.7279203  -66.7155731  -66.61174271 -66.58703618
 -66.56161148 -66.55907926 -66.54641063 -66.54566613 -66.46407983
 -66.45732572 -66.45670142 -66.44624272 -66.13937792 -66.09018123
 -66.07989104 -66.07280262 -65.99732381 -65.95056286 -65.91596564
 -65.72217307 -65.66196757 -65.60080372 -65.53002586 -65.50313625
 -65.44672492 -65.43239888 -65.31215608 -65.30973874 -65.28143806
 -65.23395913 -65.18650865 -65.1730687  -65.08062664 -64.92129177
 -64.86829805 -64.799475   -64.78027845 -64.76146415 -64.70968772
 -64.6741648  -64.65600673 -64.55791051 -64.52960809 -64.52767339
 -64.50296145 -64.50292872 -64.39047086 -64.38888227 -64.25216681
 -64.19112389 -64.18988312 -64.16215177 -64.15699107 -64.14001284
 -64.04237035 -64.01682464 -63.95269109 -63.93007699 -63.86603087
 -63.83165117 -63.79982443 -63.76630157 -63.76079531 -63.73868218
 -63.70646946 -63.69509013 -63.6821681  -63.65198418 -63.58299753
 -63.55465215 -63.54343205 -63.47965676 -63.45966792 -63.45901735
 -63.41220449 -63.40750842 -63.36963959 -63.32379859 -63.30725722
 -63.29774043 -63.28034273 -63.2355132  -63.22225564 -63.21600665
 -63.10255242 -63.09862664 -63.08959598 -63.03905618 -63.01067311
 -63.00741668 -62.91259595 -62.86445104 -62.81122246 -62.79117203
 -62.77841672 -62.77053899 -62.76898501 -62.67491264 -62.67279431
 -62.64237479 -62.64051164 -62.63105025 -62.62485897 -62.6030107
 -62.57783713 -62.56967899 -62.49945841 -62.49664426 -62.49354983
 -62.45707761 -62.44589019 -62.39051353 -62.38758784 -62.32952884
 -62.25932324 -62.24254122 -62.23310964 -62.18209193 -62.13548877
 -62.09275189 -62.07644115 -62.07201078 -62.00305901 -61.93848366
 -61.91199905 -61.87747231 -61.82854372 -61.74640362 -61.65967907
 -61.63408403 -61.62418245 -61.49774789 -61.45368129 -61.44030118
 -61.32814064 -61.24495235 -61.19813369 -61.18363271 -61.17052504
 -61.0441459  -61.01718103 -60.97165699 -60.95326454 -60.93834881
 -60.77386348 -60.69351422 -60.62988892 -60.60889824 -60.57531288
 -60.55274516 -60.45992788 -60.44294027 -60.43735503 -60.43279948
 -60.41742488 -60.39131992 -60.35378677 -60.3329059  -60.2520207
 -60.11782794 -60.11770151 -60.0851582  -60.05077762 -59.99631821
 -59.98720584 -59.94956198 -59.94408863 -59.90479316 -59.68903026
 -59.6636883  -59.65535831 -59.64160815 -59.53093583 -59.52599959
 -59.50143897 -59.28726243 -59.25938333 -58.9477371  -58.9289216
 -58.92467868 -58.91563865 -58.86517367 -58.86261772 -58.84618662
 -58.82987544 -58.78651363 -58.76188385 -58.65218112 -58.60527017
 -58.57686281 -58.53453108 -58.50078104 -58.39990767 -58.16670795
 -58.15307168 -58.13839838 -58.11154093 -58.10664633 -58.08259059
 -58.02687392 -57.60680687 -57.54878785 -56.98440106 -56.88307798
 -56.8697953  -56.67423213 -56.60215288 -56.41956065 -55.70538663
 -54.98547503 -50.4922686  -50.03933802 -49.75347185 -49.72654641
 -46.98011874 -45.73515428 -45.67057988 -44.99030608 -44.14602409
 -43.81326882 -43.18878399 -42.29180715 -42.00401746 -41.69100444
 -41.68588229 -41.2817771  -40.44278203 -40.34838366 -39.59970115
 -39.57586365 -39.31972693 -39.02461056 -38.45534494 -38.4127039
 -38.35634328 -37.79713617 -37.74152899 -37.66475324 -37.51313938
 -37.1809993  -37.10070314 -37.00630589 -36.82191677 -36.48799015
 -36.2096527  -36.19207562 -36.11445903 -35.78149902 -35.39450387
 -35.262825   -35.24303541 -35.20970524 -35.06544085 -34.80241748
 -34.64469045 -33.84284986 -32.70706485 -31.9690994  -31.7109134
 -31.64414356 -31.39238276 -31.22319602 -31.12953085 -29.3915714
 -29.34012561 -29.10618999 -27.4110235  -27.34372236 -27.19668163
 -27.07399029 -26.70472176 -26.2447949  -25.54836509 -25.45878529
 -24.879107   -24.82869536 -24.59274514 -23.97874558 -23.57262108
 -23.44970808 -22.74530916 -22.60679894 -22.19891032 -20.65686376
 -20.44447256 -20.1969901  -20.1814153  -20.17959602 -20.13839115
 -19.92624243 -19.63760344 -19.63436396 -19.51559872 -19.39756409
 -19.34447885 -19.23593207 -19.12310322 -19.03868419 -19.01366146
 -18.95170124 -18.92864293 -18.9283881  -18.59616826 -18.40219305
 -18.26397084 -18.13112681 -18.12524762 -18.00326352 -17.99477406
 -17.92234129 -17.90998836 -17.75923117 -17.5574237  -17.50947559
 -17.45759595 -17.39960006 -17.34359036 -17.23421418 -17.22952416
 -17.17757645 -17.12268398 -17.09235581 -16.93719112 -16.93408769
 -16.82307393 -16.72556391 -16.69606948 -16.64420594 -16.58300081
 -16.46524529 -16.44056833 -16.43912857 -16.35001782 -16.3025938
 -16.20525991 -16.19672667 -16.17622393 -16.02435993 -15.99985529
 -15.93479371 -15.88968647 -15.78422113 -15.76323944 -15.71191307
 -15.69844216 -15.67416693 -15.635793   -15.62688785 -15.54744861
 -15.49021849 -15.45210689 -15.44524324 -15.42919215 -15.32494513
 -15.29797373 -15.24305514 -15.22860131 -15.20697481 -15.16485985
 -15.12252306 -15.08728073 -15.08020331 -15.04626953 -15.01396048
 -15.00306645 -14.98912762 -14.97705763 -14.97196392 -14.91216678
 -14.90387708 -14.89699861 -14.8550828  -14.81404643 -14.78622576
 -14.7718506  -14.74401033 -14.70913254 -14.69128996 -14.66967038
 -14.63488148 -14.59596186 -14.56494753 -14.5314246  -14.51735397
 -14.44242009 -14.41895357 -14.41583474 -14.37972793 -14.36571785
 -14.35424825 -14.30204939 -14.26791204 -14.23511078 -14.23487762
 -14.15121867 -14.13660346 -14.07418631 -13.90136462 -13.85738623
 -13.765325   -13.68634927 -13.59601285 -13.53453212 -13.53331925
 -13.478197   -13.46738201 -13.39063064 -13.32715153 -13.32106729
 -13.28824842 -13.28203865 -13.20886919 -13.11910909 -13.01149556
 -12.94042091 -12.88523587 -12.88077847 -12.87731044 -12.87628438
 -12.87408383 -12.85344495 -12.83471659 -12.83228066 -12.76514887
 -12.73217899 -12.68135973 -12.66418206 -12.64745202 -12.64627127
 -12.63040428 -12.57534526 -12.5347541  -12.53436099 -12.50725806
 -12.5024721  -12.49682747 -12.48866592 -12.48743392 -12.4164314
 -12.4026627  -12.31337623 -12.30017947 -12.29207041 -12.26426289
 -12.24407241 -12.23955807 -12.22711767 -12.21657299 -12.16557428
 -12.15190477 -12.09460199 -12.06189975 -12.05853498 -11.98145628
 -11.98108374 -11.97562281 -11.97027503 -11.96415664 -11.93806882
 -11.9042515  -11.88597412 -11.86072034 -11.82292724 -11.79872418
 -11.78885214 -11.77833202 -11.74253045 -11.7346916  -11.62352291
 -11.61946733 -11.59966107 -11.58584831 -11.57785081 -11.57713554
 -11.54066985 -11.53480251 -11.5152788  -11.46421273 -11.45692174
 -11.4436213  -11.42486018 -11.37040241 -11.31829582 -11.28221787
 -11.2750863  -11.26573977 -11.2502218  -11.24303432 -11.22312905
 -11.21889858 -11.20813099 -11.20024646 -11.17912376 -11.09213431
 -11.08359889 -11.01064843 -10.99611373 -10.97093044 -10.96917495
 -10.95837823 -10.94697681 -10.92999647 -10.91494096 -10.8974297
 -10.89707236 -10.87316999 -10.8699891  -10.84987851 -10.82877971
 -10.80098324 -10.76593874 -10.74814979 -10.72771815 -10.69671285
 -10.6616839  -10.6529369  -10.60706065 -10.59120474 -10.57148789
 -10.56227461 -10.55136287 -10.5325345  -10.50038676 -10.47829501
 -10.47073846 -10.44866874 -10.44676532 -10.39794369 -10.39312115
 -10.38356728 -10.37711194 -10.36432725 -10.3294588  -10.3276815
 -10.32598645 -10.31685999 -10.30222586 -10.2515667  -10.14354684
 -10.06985002 -10.06316834 -10.06180269 -10.05616271 -10.04256065
 -10.03515384  -9.95955814  -9.95675631  -9.93790918  -9.91813288
  -9.91282047  -9.89524828  -9.89430622  -9.89169983  -9.87583446
  -9.85958624  -9.85740173  -9.85721598  -9.8559419   -9.79604807
  -9.79053708  -9.73501692  -9.71783519  -9.70673964  -9.6965766
  -9.6610764   -9.65999581  -9.62007273  -9.59982074  -9.59452006
  -9.55360725  -9.53649186  -9.48252785  -9.47409877  -9.4370424
  -9.43124362  -9.41642606  -9.37720577  -9.3492285   -9.34914586
  -9.34497763  -9.3336688   -9.27490238  -9.23194004  -9.22561711
  -9.21621713  -9.21546888  -9.19829123  -9.19492935  -9.1656006
  -9.14765635  -9.13241564  -9.10142691  -9.04021626  -9.03248048
  -9.0098247   -9.00032931  -8.98917669  -8.96382669  -8.93633365
  -8.89152428  -8.88582952  -8.8391866   -8.82313476  -8.81964329
  -8.79491308  -8.77318925  -8.70892142  -8.66463661  -8.66416507
  -8.65849607  -8.65331888  -8.63569928  -8.62263876  -8.62034767
  -8.61198794  -8.48445537  -8.48080646  -8.45579764  -8.44036508
  -8.44022089  -8.37283463  -8.330117    -8.32937339  -8.26243204
  -8.25728726  -8.24511599  -8.23779071  -8.16606994  -8.16462536
  -8.16143504  -8.13319584  -8.13225237  -8.10819769  -8.05013334
  -8.02716962  -7.94379606  -7.90782955  -7.89665196  -7.89619757
  -7.86704751  -7.82133785  -7.80716281  -7.79064574  -7.77952325
  -7.71040759  -7.63951035  -7.57539849  -7.53264209  -7.52565259
  -7.40319483  -7.37892782  -7.37666527  -7.36278501  -7.36244313
  -7.35486686  -7.33727423  -7.29132104  -7.27515967  -7.27006135
  -7.14127278  -7.12836571  -7.10832736  -7.00169191  -6.95906356
  -6.90518534  -6.85677384  -6.77694649  -6.72206384  -6.71997062
  -6.66003536  -6.5904481   -6.53544734  -6.52671874  -6.51820418
  -6.38767366  -6.25201696  -5.69407869  -5.61579673  -5.3472021
  -5.07848501  -5.02795798  -4.82757292  -4.63049542  -4.230832
  -4.03104862  -3.38446715  -3.3322555   -2.64166233  -1.91361965]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:3
end of epoch 0: val_loss 0.007365525062817682, val_acc 0.995
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 8.5426e-03,  2.1220e-01,  1.0806e-01, -6.6246e-02, -2.3425e-01,
         -5.7295e-03,  4.6568e-03, -2.3983e-02, -3.5467e-05,  2.6214e-02,
         -1.4320e-03, -1.9995e-01, -4.5202e-01]], device='cuda:3'))])
end of epoch 1: val_loss 0.12824039578437776, val_acc 0.99
trigger times: 1
end of epoch 2: val_loss 0.08630128256976605, val_acc 0.995
trigger times: 2
end of epoch 3: val_loss 0.17352888107299805, val_acc 0.995
trigger times: 3
end of epoch 4: val_loss 0.0009609030524734408, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.1825e-05,  1.6170e+00,  2.9683e-01,  5.8523e-02, -2.9862e-01,
         -6.4161e-02, -1.7590e-02, -5.6481e-01,  9.5969e-05,  1.3743e-01,
         -1.4320e-03, -1.6614e+00, -3.1326e+00]], device='cuda:3'))])
end of epoch 5: val_loss 0.013229046631604433, val_acc 0.995
trigger times: 1
end of epoch 6: val_loss 2.2704441508381024e-06, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.3014e-01,  1.0374e+00,  4.9806e-01,  1.9148e-01, -1.1105e-01,
          1.9830e-05, -3.6994e-02, -3.1234e-01,  3.9371e-05,  4.0840e-02,
         -1.4320e-03, -1.3967e+00, -2.8077e+00]], device='cuda:3'))])
end of epoch 7: val_loss 0.1880351023375988, val_acc 0.995
trigger times: 1
end of epoch 8: val_loss 9.944080375134945e-06, val_acc 1.0
trigger times: 2
end of epoch 9: val_loss 6.55650637781946e-09, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.7784e-05,  1.3694e+00,  6.6870e-01,  2.4590e-02,  1.0285e-06,
          3.1461e-05, -1.2749e-07, -5.7412e-01, -3.5542e-05, -4.8754e-04,
         -1.4320e-03, -1.2005e+00, -3.6459e+00]], device='cuda:3'))])
end of epoch 10: val_loss 0.0021245290338993074, val_acc 1.0
trigger times: 1
end of epoch 11: val_loss 0.6474399646232496, val_acc 0.975
trigger times: 2
end of epoch 12: val_loss 1.430509428246296e-08, val_acc 1.0
trigger times: 3
end of epoch 13: val_loss 2.1099598598084413e-07, val_acc 1.0
trigger times: 4
end of epoch 14: val_loss 1.484134815754601e-07, val_acc 1.0
trigger times: 5
end of epoch 15: val_loss 0.1938052165135423, val_acc 0.995
trigger times: 6
end of epoch 16: val_loss 0.000619348416221328, val_acc 1.0
trigger times: 7
end of epoch 17: val_loss 5.423995361297784e-08, val_acc 1.0
trigger times: 8
end of epoch 18: val_loss 0.00017757899902619555, val_acc 1.0
trigger times: 9
end of epoch 19: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 9.5734e-05,  6.9073e-01,  3.3606e-01,  3.6903e-02,  1.6462e-05,
          7.0662e-04, -1.0577e-03, -3.9128e-01, -4.7309e-04,  5.0685e-02,
         -1.4324e-03, -6.0779e-01, -3.6453e+00]], device='cuda:3'))])
end of epoch 20: val_loss 3.3536498085595667e-06, val_acc 1.0
trigger times: 1
end of epoch 21: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 2
end of epoch 22: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-6.4896e-03,  7.0073e-01,  3.8051e-01, -2.2482e-01, -2.6288e-02,
         -3.4191e-01, -3.8790e-05, -3.7972e-01, -4.1620e-02,  2.7713e-01,
         -1.4325e-03, -6.6827e-01, -3.6272e+00]], device='cuda:3'))])
end of epoch 23: val_loss 1.370905231112829e-08, val_acc 1.0
trigger times: 1
end of epoch 24: val_loss 0.33377455921843646, val_acc 0.995
trigger times: 2
end of epoch 25: val_loss 1.1503566369697183e-07, val_acc 1.0
trigger times: 3
end of epoch 26: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.4019e-02,  9.5958e-01,  4.9814e-01,  1.4876e-01, -5.3318e-02,
         -9.9032e-02,  3.6102e-02, -4.3270e-01,  1.9066e-01,  2.4569e-01,
         -1.4326e-03, -4.2729e-01, -4.0033e+00]], device='cuda:3'))])
end of epoch 27: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.5218e-01,  7.3829e-01,  3.8101e-01, -1.2243e-05,  6.9236e-05,
         -1.1750e-04, -1.9904e-02, -4.2950e-01,  4.5603e-05, -2.7495e-06,
         -1.4326e-03, -3.3703e-01, -3.5115e+00]], device='cuda:3'))])
end of epoch 28: val_loss 0.062202625674108274, val_acc 0.995
trigger times: 1
end of epoch 29: val_loss 3.5701908927876504e-07, val_acc 1.0
trigger times: 2
end of epoch 30: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.4618e-05,  1.0622e+00,  5.9932e-01, -2.6082e-05,  3.8683e-05,
         -7.6198e-06, -1.3485e-02, -4.6659e-01,  8.3210e-05, -1.7388e-05,
         -1.4327e-03, -5.4633e-01, -4.0963e+00]], device='cuda:3'))])
end of epoch 31: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.9052e-05,  5.0323e-01,  4.8164e-01,  1.0830e-02,  9.9430e-02,
          2.2031e-02, -6.6337e-02, -4.6841e-01, -9.2969e-02, -4.5196e-02,
         -1.4328e-03, -1.7224e-01, -3.5101e+00]], device='cuda:3'))])
end of epoch 32: val_loss 6.460725853685289e-07, val_acc 1.0
trigger times: 1
end of epoch 33: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.1762e-05,  7.4989e-01,  4.9592e-01,  1.5162e-01,  8.3680e-05,
         -8.5289e-05, -3.5564e-02, -4.6127e-01,  3.8054e-05, -3.8846e-05,
         -1.4328e-03, -5.4237e-01, -3.5114e+00]], device='cuda:3'))])
end of epoch 34: val_loss 4.240437294356525e-05, val_acc 1.0
trigger times: 1
end of epoch 35: val_loss 0.08700728416442871, val_acc 0.995
trigger times: 2
end of epoch 36: val_loss 5.9604610669339305e-09, val_acc 1.0
trigger times: 3
end of epoch 37: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.7015e-02,  8.3349e-01,  3.3119e-01, -6.7075e-03,  1.0329e-05,
          1.8267e-03,  2.3662e-02, -4.5288e-01,  8.7534e-05,  3.5367e-03,
         -1.4330e-03, -1.0493e-01, -3.3230e+00]], device='cuda:3'))])
end of epoch 38: val_loss 0.06443513989382608, val_acc 0.995
trigger times: 1
end of epoch 39: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.7985e-01,  1.4394e+00,  7.3932e-01,  3.4980e-01,  3.1268e-02,
         -1.4916e-01, -1.6490e-03, -6.6983e-01, -9.2676e-02,  1.8008e-01,
         -1.4331e-03, -9.0369e-01, -4.0421e+00]], device='cuda:3'))])
end of epoch 40: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 1
end of epoch 41: val_loss 4.124865401536226e-05, val_acc 1.0
trigger times: 2
end of epoch 42: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-5.0173e-05,  5.6317e-01,  3.9066e-01, -7.7139e-05,  7.9179e-05,
         -1.6360e-03, -4.4139e-05, -3.3038e-01, -6.4062e-05,  1.7476e-03,
         -1.4332e-03, -5.2440e-04, -2.7038e+00]], device='cuda:3'))])
end of epoch 43: val_loss 0.01229356306954287, val_acc 0.995
trigger times: 1
end of epoch 44: val_loss 2.384180106673739e-08, val_acc 1.0
trigger times: 2
end of epoch 45: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.6224e-01,  5.0433e-01,  5.0601e-01,  3.1116e-02, -3.0208e-01,
         -2.0033e-01, -1.6945e-02, -3.5096e-01,  2.1927e-01,  2.5344e-01,
         -1.4333e-03, -9.1476e-01, -2.8798e+00]], device='cuda:3'))])
end of epoch 46: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 1
end of epoch 47: val_loss 0.04091141700744629, val_acc 0.995
trigger times: 2
end of epoch 48: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.8575e-01,  8.6669e-01,  5.9576e-01, -1.5954e-05, -2.5749e-05,
          1.0803e-04, -2.7816e-02, -4.2974e-01, -7.7721e-06, -4.1094e-06,
         -1.4334e-03, -6.6717e-01, -3.3749e+00]], device='cuda:3'))])
end of epoch 49: val_loss 3.138567876703746e-06, val_acc 1.0
trigger times: 1
end of epoch 50: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 2
end of epoch 51: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.7512e-02,  4.8386e-01,  1.6470e-01,  9.2540e-03, -1.3415e-01,
         -1.3701e-01,  2.7395e-02, -3.2177e-01,  9.8144e-02,  1.8008e-01,
         -1.4335e-03, -6.4235e-01, -2.8818e+00]], device='cuda:3'))])
end of epoch 52: val_loss 5.999319720757512e-05, val_acc 1.0
trigger times: 1
end of epoch 53: val_loss 0.014742261767387355, val_acc 0.995
trigger times: 2
end of epoch 54: val_loss 6.737691321177408e-05, val_acc 1.0
trigger times: 3
end of epoch 55: val_loss 1.0847928024304565e-07, val_acc 1.0
trigger times: 4
end of epoch 56: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.8696e-06,  3.6652e-01,  3.4582e-01,  2.3830e-05, -1.1686e-04,
         -1.7984e-04, -3.7798e-06, -2.1379e-01,  1.4683e-04,  5.4565e-05,
         -1.4336e-03, -2.2408e-01, -2.7075e+00]], device='cuda:3'))])
end of epoch 57: val_loss 3.7948365115880734e-06, val_acc 1.0
trigger times: 1
end of epoch 58: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 9.2408e-03,  5.0478e-01,  3.5781e-01, -1.1530e-05, -3.7325e-05,
          1.0354e-04, -2.0026e-02, -3.1740e-01, -6.8560e-05, -4.2159e-05,
         -1.4337e-03,  1.0582e-04, -2.8228e+00]], device='cuda:3'))])
end of epoch 59: val_loss 5.9604610669339305e-09, val_acc 1.0
trigger times: 1
end of epoch 60: val_loss 0.6092057675123198, val_acc 0.98
trigger times: 2
end of epoch 61: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-3.2500e-02,  1.0267e+00,  5.4900e-01, -7.2646e-02, -1.7916e-01,
         -1.0326e-01, -3.8778e-02, -3.4355e-01,  5.8455e-02,  1.8025e-01,
         -1.4338e-03, -8.5235e-01, -3.4513e+00]], device='cuda:3'))])
end of epoch 62: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 5.0787e-02,  7.6989e-01,  3.6081e-01, -5.0987e-02,  4.7305e-05,
         -5.1874e-05, -3.0302e-02, -3.8959e-01, -9.6214e-05,  2.7733e-03,
         -1.4339e-03, -5.9071e-01, -3.2681e+00]], device='cuda:3'))])
end of epoch 63: val_loss 0.003407372236251831, val_acc 1.0
trigger times: 1
end of epoch 64: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-7.3818e-02,  1.1130e+00,  6.4132e-01,  6.5077e-04,  1.6080e-05,
         -1.6943e-02, -5.6580e-03, -5.3721e-01, -1.9051e-05,  3.3953e-01,
         -1.4339e-03, -5.7689e-01, -4.0030e+00]], device='cuda:3'))])
end of epoch 65: val_loss 0.03219940017908698, val_acc 0.99
trigger times: 1
end of epoch 66: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.5008e-01,  6.2178e-01,  4.8128e-01,  9.8017e-02,  2.4361e-04,
         -3.4355e-02,  2.3174e-02, -3.4753e-01,  5.5606e-03,  1.2757e-01,
         -1.4340e-03, -5.7169e-01, -3.7848e+00]], device='cuda:3'))])
end of epoch 67: val_loss 0.5753231412011155, val_acc 0.99
trigger times: 1
end of epoch 68: val_loss 1.4602925148210487e-07, val_acc 1.0
trigger times: 2
end of epoch 69: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.0805e-02,  1.0311e+00,  3.7476e-01, -6.6198e-06,  7.7936e-06,
          1.8143e-05, -1.3026e-03, -5.4517e-01, -7.1906e-02,  8.6664e-05,
         -1.4341e-03, -6.4958e-01, -3.9689e+00]], device='cuda:3'))])
end of epoch 70: val_loss 0.01879775892775797, val_acc 0.995
trigger times: 1
end of epoch 71: val_loss 5.364415720521265e-09, val_acc 1.0
trigger times: 2
end of epoch 72: val_loss 9.480333892497583e-06, val_acc 1.0
trigger times: 3
end of epoch 73: val_loss 0.3754543262716743, val_acc 0.985
trigger times: 4
end of epoch 74: val_loss 2.3841852225814363e-09, val_acc 1.0
trigger times: 5
end of epoch 75: val_loss 0.018911456627829466, val_acc 0.995
trigger times: 6
end of epoch 76: val_loss 0.14042694091796876, val_acc 0.995
trigger times: 7
end of epoch 77: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 6.3250e-02,  8.4369e-01,  5.4123e-01,  1.8589e-01, -1.0894e-01,
         -2.7446e-02,  2.8427e-02, -5.0622e-01, -1.4575e-02,  2.0784e-01,
         -1.4344e-03, -9.3888e-01, -4.1518e+00]], device='cuda:3'))])
end of epoch 78: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 7.6418e-02,  7.2230e-01,  3.6379e-01,  6.1276e-02,  6.6928e-05,
         -1.5607e-04, -5.7743e-07, -4.5299e-01, -1.0999e-04, -5.2832e-07,
         -1.4344e-03, -6.5021e-01, -3.7717e+00]], device='cuda:3'))])
end of epoch 79: val_loss 0.0015134897822736094, val_acc 1.0
trigger times: 1
end of epoch 80: val_loss 8.724464569240809e-06, val_acc 1.0
trigger times: 2
end of epoch 81: val_loss 2.3841852225814363e-09, val_acc 1.0
trigger times: 3
end of epoch 82: val_loss 1.404776754498016e-05, val_acc 1.0
trigger times: 4
end of epoch 83: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-3.0479e-07,  8.6555e-01,  3.8306e-01, -8.6348e-06,  3.9806e-05,
          3.6736e-05,  1.7463e-02, -4.5248e-01,  1.2725e-04,  1.7273e-05,
         -1.4346e-03, -5.1667e-01, -3.8474e+00]], device='cuda:3'))])
end of epoch 84: val_loss 1.9669494122354082e-08, val_acc 1.0
trigger times: 1
end of epoch 85: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.5175e-02,  2.8394e-01,  2.7483e-01,  2.4602e-05,  5.9384e-03,
         -9.7903e-03,  3.4453e-02, -3.4021e-01,  4.3276e-03,  1.2038e-01,
         -1.4347e-03, -2.4223e-01, -3.4227e+00]], device='cuda:3'))])
end of epoch 86: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 1
end of epoch 87: val_loss 0.023162630675348055, val_acc 0.995
trigger times: 2
end of epoch 88: val_loss 0.00012034916318953037, val_acc 1.0
trigger times: 3
end of epoch 89: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.8183e-01,  6.8286e-01,  3.7682e-01, -1.8547e-05,  1.1947e-05,
          6.9938e-05,  2.3322e-02, -4.4991e-01,  1.7579e-04, -3.1038e-05,
         -1.4348e-03, -5.2588e-01, -3.9361e+00]], device='cuda:3'))])
end of epoch 90: val_loss 0.05300180494779397, val_acc 0.99
trigger times: 1
end of epoch 91: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.4637e-01,  5.2572e-02,  3.9023e-01,  2.4532e-05,  6.3352e-05,
          1.1966e-04,  3.0927e-03, -2.2780e-01,  1.0092e-05, -2.4786e-05,
         -1.4349e-03, -4.1436e-01, -3.2633e+00]], device='cuda:3'))])
end of epoch 92: val_loss 4.17232396188183e-09, val_acc 1.0
trigger times: 1
end of epoch 93: val_loss 4.1723157835349414e-08, val_acc 1.0
trigger times: 2
end of epoch 94: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.5049e-01,  4.3349e-02,  2.5592e-01, -2.0593e-02, -1.2332e-04,
          7.5771e-02,  2.5818e-02, -2.8442e-01, -4.4960e-05, -3.6527e-02,
         -1.4350e-03, -3.5029e-01, -2.6915e+00]], device='cuda:3'))])
end of epoch 95: val_loss 0.5802821715720438, val_acc 0.99
trigger times: 1
end of epoch 96: val_loss 3.099431978625944e-08, val_acc 1.0
trigger times: 2
end of epoch 97: val_loss 1.0132783039296101e-08, val_acc 1.0
trigger times: 3
end of epoch 98: val_loss 0.02493313372135159, val_acc 0.995
trigger times: 4
end of epoch 99: val_loss 0.00013973322696983815, val_acc 1.0
trigger times: 5
Finished training.
0 -88.48635375499725 -70.02437758354124
1 -80.63008785247803 -68.91946169090464
2 -83.48282766342163 -68.26334789627366
3 -87.31623268127441 -67.81443967035496
4 -84.61493170261383 -67.468961314271
5 -78.98739111423492 -66.75521955032598
6 -76.50100314617157 -66.55907925618051
7 -84.24812984466553 -66.44624272192608
8 -83.26727020740509 -65.95056286291832
9 -87.51116633415222 -65.50313624737767
10 -83.74368822574615 -65.23395912841217
11 -405.6836402416229 -64.79947499756878
12 -85.82635796070099 -64.52960808642393
13 -87.6260746717453 -64.25216681388612
14 -82.38506281375885 -64.04237034687793
15 -84.94257867336273 -63.799824431323586
16 -87.03680157661438 -63.68216810247448
17 -82.68974423408508 -63.459667922542614
18 -418.94485092163086 -63.30725722005412
19 -415.4503538608551 -63.10255242205952
20 -85.24597907066345 -62.912595947961414
21 -87.76310539245605 -62.76898501092357
22 -394.79225969314575 -62.624858974583894
23 -401.8994333744049 -62.493549828901195
24 -399.21609902381897 -62.25932324004642
25 -81.67017352581024 -62.07644115384551
26 -417.75292921066284 -61.82854372456997
27 -411.9283995628357 -61.45368129244922
28 -85.43033611774445 -61.17052504276673
29 -78.57169044017792 -60.773863476289286
30 -406.25617814064026 -60.45992788273156
31 -403.46138310432434 -60.353786771153636
32 -410.00194358825684 -60.0507776155215
33 -413.2147637605667 -59.68903026437862
34 -405.5310924053192 -59.501438966848866
35 -408.9734756946564 -58.915638654720226
36 -406.0469937324524 -58.652181120459346
37 -411.8779444694519 -58.16670794795547
38 -408.7626144886017 -58.026873916480284
39 -408.5893256664276 -56.67423213114131
40 -48.72186475992203 -50.03933801517046
41 -97.18267500400543 -44.99030608142343
42 -82.48337513208389 -41.6910044370425
43 -109.49473762512207 -39.57586365327889
44 -42.541028410196304 -37.79713616772368
45 -29.18411672115326 -37.00630588930485
46 -60.638684928417206 -35.78149902167743
47 -7.5916344821453094 -34.80241747531743
48 -166.89284721016884 -31.64414355845032
49 -128.43484744429588 -29.106189988903285
50 2.3352336287498474 -26.244794902859052
51 -42.130187690258026 -23.978745577896312
52 -161.53447711467743 -20.656863763892378
53 0.9460535421967506 -19.926242431263915
54 3.6029079779982567 -19.235932072225243
55 2.419224478304386 -18.92838809611677
56 5.626460243016481 -18.003263520499647
57 43.90597718954086 -17.509475594184124
58 31.218246430158615 -17.177576450763027
59 46.445304185152054 -16.725563907250084
60 38.44121852517128 -16.350017815279713
61 2.6582531109452248 -15.999855288473436
62 45.239169269800186 -15.698442160753391
63 3.827550023794174 -15.452106892533626
64 11.29191105812788 -15.228601310000212
65 3.155687741935253 -15.046269525186256
66 7.114988997578621 -14.912166784565946
67 39.55755802989006 -14.771850604017443
68 5.392058350145817 -14.595961855586516
69 51.9862477183342 -14.415834737533931
70 33.082962952554226 -14.235110782179001
71 7.425144486129284 -13.857386232948453
72 32.80287781357765 -13.478197003787718
73 36.794630870223045 -13.282038650760315
74 49.6965770944953 -12.880778469177017
75 12.539255820214748 -12.832280663105164
76 38.210547387599945 -12.646271270327462
77 34.931031972169876 -12.502472096276058
78 8.62830276042223 -12.31337623223133
79 8.535073325037956 -12.227117665314724
80 16.48949360847473 -12.058534980034162
81 30.328984811902046 -11.938068820271281
82 2.177872598171234 -11.788852141676486
83 9.592238560318947 -11.59966106685851
84 10.697147466242313 -11.464212727359632
85 15.501997146755457 -11.282217868458462
86 11.556256726384163 -11.218898581625728
87 40.6984029263258 -11.010648429740753
88 45.423983216285706 -10.92999647335951
89 10.784225553274155 -10.849878510712346
90 16.27657350152731 -10.696712850329469
91 49.71572324633598 -10.56227460567635
92 23.82888363301754 -10.448668735832262
93 44.33245566487312 -10.364327246341285
94 26.63634169101715 -10.251566700997724
95 18.115558743476868 -10.04256065142963
96 31.228606432676315 -9.912820468646165
97 38.87700417637825 -9.857401731102941
98 32.29986022412777 -9.717835193156986
99 35.08443668484688 -9.599820741479471
100 18.43676097691059 -9.4370424029771
101 29.085247859358788 -9.344977632953821
102 15.075327634811401 -9.215468878533203
103 12.994126431643963 -9.101426912313467
104 44.69487223029137 -8.963826694643434
105 21.770167529582977 -8.819643292498888
106 44.33528649806976 -8.658496065173749
107 43.89543059468269 -8.484455365743758
108 13.007813796401024 -8.329373394740154
109 52.619863986968994 -8.164625358693467
110 35.94198599457741 -8.027169616483599
111 50.235776752233505 -7.821337852994627
112 -4.028184294700623 -7.57539849177145
113 45.52794027328491 -7.36278501235848
114 43.56661023199558 -7.270061347491789
115 25.868179082870483 -6.90518534137812
116 45.7792931497097 -6.5904480954069875
117 44.323333382606506 -5.694078692466705
118 41.113067738711834 -4.63049541560991
119 39.58403082191944 -1.9136196540088464
train accuracy: 0.9988888888888889
validation accuracy: 1.0
