[-50.0022206  -48.82373914 -47.15605336 -46.19619105 -45.59422709
 -45.36842966 -45.19068756 -44.1649084  -44.07830313 -43.99355529
 -43.86306534 -43.84874807 -43.84199129 -43.80638567 -43.80581986
 -42.75947674 -42.66316469 -42.33177225 -41.77496339 -41.41006807
 -41.17786296 -40.72352042 -40.52718976 -40.49595848 -40.42938988
 -40.05653451 -39.59232358 -39.54162101 -39.19523747 -39.17238958
 -38.51095963 -38.44726577 -38.39210704 -38.0074535  -37.46482489
 -37.10988161 -34.27116724 -34.14139118 -33.26307273 -33.13344797
 -33.07825234 -33.03213148 -32.44934973 -32.40079781 -32.40063926
 -30.73440379 -30.57151372 -30.1312365  -29.99326723 -29.66908259
 -29.29723351 -29.28889042 -29.14587835 -28.49601894 -28.49202366
 -28.31596147 -27.12111057 -26.0645326  -25.52052428 -25.27101421
 -25.06664428 -24.92584938 -24.18810567 -23.48479966 -23.15394356
 -22.9547303  -22.74124885 -22.73927354 -22.26494505 -22.15569724
 -21.05592093 -20.54335656 -20.33499634 -20.18157658 -19.5814441
 -19.37722575 -19.24313562 -19.06062023 -18.96412452 -18.44896231
 -17.74072202 -16.8588937  -16.33811941 -14.53589256 -14.44367057
 -14.20041301 -13.93697618 -13.86225304 -13.48309853 -13.45589275
 -13.35586828 -12.27851524 -12.22738746 -12.02071783 -11.9100948
 -11.40028402 -11.13461816 -10.85916692  -9.59513796  -9.28992161
  -8.23087707  -7.88236324  -7.64789842  -7.45962324  -7.12435731
  -7.05379066  -6.8530911   -6.62113845  -6.49455522  -6.11735418
  -6.0870551   -5.43500832  -5.10529174  -4.62864941  -4.47103119
  -4.45550478  -4.28054982  -3.79447357  -2.95124385  -2.54161816]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=12, out_features=1, bias=False)
)
Total number of parameters: 12
Number of trainable paramters: 12
device: cuda:1
end of epoch 0: val_loss 0.005281174800187322, val_acc 0.995
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.3945e-02,  2.5593e-02,  9.4761e-02, -1.6148e-02, -5.6977e-01,
         -7.7077e-02, -4.9714e-03,  1.1732e-02,  1.9050e-05, -1.0125e-01,
          1.3673e-03, -2.4510e+00]], device='cuda:1'))])
end of epoch 1: val_loss 0.2496783908396077, val_acc 0.96
trigger times: 1
end of epoch 2: val_loss 0.006170970271707894, val_acc 0.995
trigger times: 2
end of epoch 3: val_loss 0.009579320390864154, val_acc 0.995
trigger times: 3
end of epoch 4: val_loss 9.214696931611143e-05, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 5.1506e-03, -1.3355e-02, -6.9013e-02, -2.1833e-02, -1.0594e+00,
          2.2925e-01, -1.3973e-02,  1.6767e-02,  5.0956e-05, -6.2386e-01,
          1.3656e-03, -6.3732e+00]], device='cuda:1'))])
end of epoch 5: val_loss 0.0005329716441129406, val_acc 1.0
trigger times: 1
end of epoch 6: val_loss 0.0022246728399017714, val_acc 1.0
trigger times: 2
end of epoch 7: val_loss 0.0009934063852069031, val_acc 1.0
trigger times: 3
end of epoch 8: val_loss 0.05514921838453283, val_acc 0.99
trigger times: 4
end of epoch 9: val_loss 0.0006317349051763444, val_acc 1.0
trigger times: 5
end of epoch 10: val_loss 0.08967543134494488, val_acc 0.985
trigger times: 6
end of epoch 11: val_loss 0.3040885647253074, val_acc 0.96
trigger times: 7
end of epoch 12: val_loss 6.941390019601812e-05, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-3.9518e-02, -1.2702e-02,  3.7756e-02, -7.1302e-02, -7.3064e-01,
         -6.1668e-05,  1.0811e-03,  1.3716e-02,  9.2190e-05,  2.4063e-05,
          1.3624e-03, -7.4479e+00]], device='cuda:1'))])
end of epoch 13: val_loss 0.04292404861253189, val_acc 0.99
trigger times: 1
end of epoch 14: val_loss 0.0011058529817949392, val_acc 1.0
trigger times: 2
end of epoch 15: val_loss 0.08150711024501056, val_acc 0.985
trigger times: 3
end of epoch 16: val_loss 0.000529429424627601, val_acc 1.0
trigger times: 4
end of epoch 17: val_loss 0.2083839697987457, val_acc 0.985
trigger times: 5
end of epoch 18: val_loss 0.004142053030421984, val_acc 1.0
trigger times: 6
end of epoch 19: val_loss 2.403831428416936e-05, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.4703e-01,  4.3713e-02,  1.1593e-01,  1.6890e-01, -9.2145e-01,
          1.3766e-01, -2.2355e-02, -6.6469e-02,  8.4575e-02, -3.8703e-01,
          1.3595e-03, -9.1483e+00]], device='cuda:1'))])
end of epoch 20: val_loss 2.2567711384162694e-05, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.7460e-01, -1.4848e-01,  1.7971e-01,  4.9457e-02, -9.2549e-01,
          1.8185e-01, -3.1354e-02, -9.1660e-03,  7.1104e-01, -3.0022e-01,
          1.3591e-03, -9.3936e+00]], device='cuda:1'))])
end of epoch 21: val_loss 2.6497074240836583e-05, val_acc 1.0
trigger times: 1
end of epoch 22: val_loss 0.003486678858750025, val_acc 1.0
trigger times: 2
end of epoch 23: val_loss 0.00014540820413913024, val_acc 1.0
trigger times: 3
end of epoch 24: val_loss 0.06753278734500726, val_acc 0.995
trigger times: 4
end of epoch 25: val_loss 9.935125086713015e-07, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-3.7221e-02, -7.0417e-02, -3.1873e-07, -3.3205e-02, -1.1618e+00,
         -3.3155e-05, -8.2789e-03,  2.7618e-02, -2.0161e-05, -8.4361e-05,
          1.3570e-03, -9.2082e+00]], device='cuda:1'))])
end of epoch 26: val_loss 0.03056888781390381, val_acc 0.985
trigger times: 1
end of epoch 27: val_loss 0.005466431600507242, val_acc 0.995
trigger times: 2
end of epoch 28: val_loss 0.004315834892731729, val_acc 0.995
trigger times: 3
end of epoch 29: val_loss 0.023439090661704468, val_acc 0.995
trigger times: 4
end of epoch 30: val_loss 2.253022219633749e-07, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.4052e-01,  8.4144e-06, -1.2926e-06,  4.5004e-06, -8.5430e-01,
          3.2379e-05, -2.1201e-02,  3.2833e-06, -1.0631e-06, -8.5742e-02,
          1.3549e-03, -9.5337e+00]], device='cuda:1'))])
end of epoch 31: val_loss 0.02443684527533975, val_acc 0.99
trigger times: 1
end of epoch 32: val_loss 0.0414640222212201, val_acc 0.99
trigger times: 2
end of epoch 33: val_loss 0.054024232838346294, val_acc 0.99
trigger times: 3
end of epoch 34: val_loss 0.012018839567899526, val_acc 0.995
trigger times: 4
end of epoch 35: val_loss 1.3739899085543073e-05, val_acc 1.0
trigger times: 5
end of epoch 36: val_loss 0.13963599339082036, val_acc 0.985
trigger times: 6
end of epoch 37: val_loss 4.318788087626757e-05, val_acc 1.0
trigger times: 7
end of epoch 38: val_loss 0.0014898042026826985, val_acc 1.0
trigger times: 8
end of epoch 39: val_loss 7.181766521533462e-06, val_acc 1.0
trigger times: 9
end of epoch 40: val_loss 0.020107148367418618, val_acc 0.99
trigger times: 10
Early stopping.
0 -147.60875046253204 -50.00222059884506
1 -88.36511451005936 -48.823739140882175
2 -65.50278860330582 -47.15605336419176
3 -91.03698921203613 -46.19619104961985
4 -141.5207201242447 -45.594227093057754
5 -114.84518527984619 -45.36842966452394
6 -141.44112479686737 -45.19068756322445
7 -102.84424132108688 -44.16490839583478
8 -57.53950570523739 -44.078303125872196
9 -89.52365240454674 -43.993555290419714
10 -77.30476592481136 -43.86306534422809
11 -111.47992126643658 -43.84874807044028
12 -127.39123940467834 -43.84199129025074
13 -73.4769979417324 -43.806385671938365
14 -68.35749314725399 -43.80581985978556
15 -103.69154715538025 -42.7594767358323
16 -63.96784320473671 -42.66316468983175
17 -120.85503363609314 -42.33177224591743
18 -107.29481327533722 -41.774963389485094
19 -112.56807029247284 -41.410068073767725
20 -146.5086793899536 -41.17786296442943
21 -95.79702626168728 -40.723520424948155
22 -85.3537917137146 -40.527189756101116
23 -106.26412642002106 -40.49595848244517
24 -111.88568133115768 -40.429389880911344
25 -125.30972909927368 -40.05653450521898
26 -123.34809696674347 -39.59232357792555
27 -125.84269213676453 -39.54162101198148
28 -98.07997101545334 -39.195237471709476
29 -119.12314295768738 -39.172389579378766
30 -85.56460598111153 -38.51095963496708
31 -59.983418866992 -38.447265769744824
32 -88.97044512629509 -38.392107037026264
33 -95.4563502073288 -38.00745349944469
34 -74.10276183485985 -37.46482488602393
35 -109.89306569099426 -37.10988160586883
36 -98.16237819194794 -34.27116723637227
37 -84.8699244260788 -34.14139118114101
38 -60.128007382154465 -33.263072731706835
39 -107.34898322820663 -33.13344797200536
40 -65.74794322252274 -33.07825234291984
41 -95.9433491230011 -33.0321314765637
42 -107.86028406023979 -32.44934973065406
43 -46.83901059627533 -32.4007978120153
44 -95.84112960100174 -32.40063925734975
45 -61.34904909133911 -30.734403792103194
46 -62.18960505723953 -30.57151371770873
47 -92.3173235654831 -30.131236504472803
48 -54.14862239360809 -29.99326722619033
49 -89.53028464317322 -29.66908258985071
50 -99.85202068090439 -29.297233511513635
51 -70.15659266710281 -29.288890423975797
52 -60.22379571199417 -29.145878352769948
53 -36.8127516657114 -28.49601894351319
54 -85.60312885046005 -28.492023661124072
55 -78.92095535807312 -28.315961465855167
56 -64.49879449605942 -27.121110566589827
57 -60.054379403591156 -26.064532595535336
58 -56.21780362725258 -25.520524278341334
59 -36.38726933300495 -25.27101421179229
60 -70.32212617993355 -25.066644278800943
61 -48.39041371643543 -24.925849381327673
62 -73.13593319058418 -24.188105669766596
63 -35.875713378190994 -23.48479966198816
64 -37.97752223908901 -23.153943559703283
65 -28.17333471775055 -22.954730295117237
66 -45.79148951172829 -22.74124885266394
67 -47.2793989777565 -22.739273544503753
68 -54.80129623413086 -22.264945050603636
69 -57.26186418533325 -22.15569724300287
70 -52.380187809467316 -21.055920928583344
71 -57.825106739997864 -20.543356562348553
72 -59.881885796785355 -20.33499633836848
73 -45.92628634721041 -20.18157658281111
74 -44.119564801454544 -19.58144410477429
75 -53.264842607080936 -19.377225745334304
76 -31.899080231785774 -19.243135617403095
77 -54.260615825653076 -19.060620225371707
78 -67.92500752210617 -18.964124524696246
79 -50.7649702578783 -18.448962308005108
80 -54.400866225361824 -17.740722019993825
81 -46.87313497066498 -16.85889369985028
82 -49.31897474825382 -16.3381194095591
83 -36.132281720638275 -14.535892564189266
84 -59.06551265716553 -14.443670567499144
85 -51.31417167186737 -14.200413010108107
86 -44.47460696101189 -13.936976181618805
87 -44.62533551454544 -13.862253042167257
88 -38.929417569190264 -13.483098530680483
89 -56.5211134403944 -13.455892754889845
90 -51.0780775398016 -13.355868275096913
91 -33.386576771736145 -12.278515244993585
92 -43.454467475414276 -12.227387460046547
93 -49.64029824733734 -12.020717825467683
94 -57.26038634777069 -11.910094799877324
95 -42.58685752749443 -11.400284019256157
96 -31.55585054308176 -11.134618158086587
97 -41.93382579088211 -10.859166921158222
98 -44.99922227859497 -9.595137958067907
99 -53.67074030637741 -9.289921608799773
100 -21.734284728765488 -8.230877068641124
101 -37.54278936982155 -7.882363241796725
102 -39.42807015776634 -7.6478984168416355
103 -36.490855142474174 -7.459623237418707
104 -36.90980842709541 -7.124357312750265
105 -45.01574087142944 -7.05379065585803
106 -32.0520142018795 -6.853091098326624
107 -31.40224500000477 -6.6211384471641495
108 -48.69994521141052 -6.494555224953677
109 -31.060166895389557 -6.117354180737655
110 -47.40978267788887 -6.087055095509873
111 -29.58531904965639 -5.43500831968483
112 -42.401184126734734 -5.105291741614599
113 -51.959894716739655 -4.628649413275992
114 -43.81981506943703 -4.471031187897325
115 -21.552071012556553 -4.455504779070034
116 -44.314458817243576 -4.2805498188182405
117 -44.99383211135864 -3.7944735717969627
118 -36.09062743186951 -2.9512438456190186
119 -37.13622432947159 -2.541618164765197
train accuracy: 0.9922222222222222
validation accuracy: 0.99
[-86.91338399 -83.73144705 -82.84260503 -81.37897356 -81.22309245
 -80.02405688 -79.22486155 -78.29476705 -78.27380603 -77.83353943
 -77.35811446 -77.04193138 -76.29322251 -76.2660723  -76.21832787
 -76.01874642 -75.80871969 -75.7790183  -75.20723639 -75.20586954
 -75.07013099 -75.06928062 -74.5685953  -74.34582999 -74.34501992
 -74.25214116 -73.84264419 -73.56956586 -73.49676029 -73.4570759
 -72.35992622 -72.146965   -72.05073585 -71.98912262 -71.92052497
 -71.9121905  -71.59704609 -71.45601634 -71.44046475 -71.25245533
 -71.08219378 -70.72181447 -70.60428712 -70.16227679 -70.07926884
 -69.91665206 -69.57063564 -69.44024773 -69.40166876 -69.38984568
 -69.38370827 -69.33497455 -69.17411004 -69.16888927 -69.00016027
 -68.76905739 -68.73583502 -68.50445309 -68.25661754 -65.82254733
 -47.15605336 -46.19619105 -44.07830313 -43.99355529 -43.86306534
 -43.84199129 -43.80638567 -42.75947674 -42.33177225 -41.77496339
 -41.41006807 -40.42938988 -39.54162101 -38.44726577 -38.39210704
 -38.0074535  -37.46482489 -37.10988161 -34.27116724 -33.26307273
 -33.03213148 -32.40063926 -30.1312365  -29.29723351 -29.28889042
 -28.49601894 -26.0645326  -25.27101421 -25.06664428 -24.92584938
 -24.18810567 -23.48479966 -23.15394356 -22.73927354 -19.5814441
 -19.37722575 -19.24313562 -18.44896231 -16.8588937  -14.44367057
 -12.27851524 -12.22738746 -12.02071783 -11.9100948  -11.13461816
 -10.85916692  -9.59513796  -9.28992161  -8.23087707  -7.45962324
  -7.12435731  -7.05379066  -6.62113845  -6.49455522  -6.11735418
  -4.62864941  -4.45550478  -4.28054982  -3.79447357  -2.54161816]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=12, out_features=1, bias=False)
)
Found existing model weights! Loading state dict...
Total number of parameters: 12
Number of trainable paramters: 12
device: cuda:2
end of epoch 0: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.6991e-05,  2.0085e-05, -2.5208e-06,  2.1908e-05, -2.4185e-01,
          5.9355e-05,  6.1890e-02, -1.7352e-02, -2.5902e-05,  1.3031e-04,
          2.8493e-04, -8.5960e+00]], device='cuda:2'))])
end of epoch 1: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 7.3818e-05,  4.9360e-05,  7.8774e-05, -2.2506e-05, -4.4778e-04,
          1.3835e-04,  5.7310e-02, -3.1917e-05, -7.6874e-05,  3.4904e-04,
          2.8506e-04, -5.5570e+00]], device='cuda:2'))])
end of epoch 2: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.9734e-04,  1.1910e-04,  1.9158e-04, -4.6009e-06, -1.0133e-03,
          3.1253e-04,  4.5707e-02,  4.5901e-05,  9.5592e-04,  7.9828e-04,
          2.8519e-04, -1.2310e-03]], device='cuda:2'))])
end of epoch 3: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.6999e-04,  2.8719e-04,  4.5386e-04,  6.5091e-05, -1.9517e-03,
          6.0274e-04,  1.7022e-02, -8.3061e-06,  1.7065e-03,  1.3843e-03,
          2.8532e-04, -7.7840e-04]], device='cuda:2'))])
end of epoch 4: val_loss 3.8140744977965826e-06, val_acc 1.0
trigger times: 1
end of epoch 5: val_loss 9.14503958995283e-06, val_acc 1.0
trigger times: 2
end of epoch 6: val_loss 4.973962897736328e-06, val_acc 1.0
trigger times: 3
end of epoch 7: val_loss 1.7195870282549209e-06, val_acc 1.0
trigger times: 4
end of epoch 8: val_loss 1.8298608381428494e-07, val_acc 1.0
trigger times: 5
end of epoch 9: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0001, -0.0022, -0.0007,  0.0008, -0.0009,  0.0032,  0.0087,  0.0023,
          0.0023,  0.0003,  0.0003, -0.0008]], device='cuda:2'))])
end of epoch 10: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.1721e-03,  8.7036e-05,  1.5368e-03, -4.3640e-04, -1.6802e-03,
         -2.1518e-03,  3.2248e-02,  1.4392e-03,  1.3673e-03,  5.0095e-04,
          2.8623e-04, -1.9355e-03]], device='cuda:2'))])
end of epoch 11: val_loss 1.8829042690882148e-06, val_acc 1.0
trigger times: 1
end of epoch 12: val_loss 4.6473099510180305e-06, val_acc 1.0
trigger times: 2
end of epoch 13: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.4115e-03,  2.3608e-03, -1.8320e-04,  7.3242e-04, -8.9753e-05,
          1.4016e-04,  1.3374e-02, -2.0629e-04,  5.4613e-05, -1.3579e-03,
          2.8658e-04, -2.3252e-03]], device='cuda:2'))])
end of epoch 14: val_loss 1.25169719922269e-08, val_acc 1.0
trigger times: 1
end of epoch 15: val_loss 5.5556666045504246e-05, val_acc 1.0
trigger times: 2
end of epoch 16: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.4470e-03, -1.7297e-04,  4.0334e-04,  4.0594e-04, -7.6438e-04,
         -7.8131e-04,  5.1206e-02, -1.7210e-04,  3.4857e-04,  6.9963e-05,
          2.8692e-04,  2.5259e-03]], device='cuda:2'))])
end of epoch 17: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.7975e-05,  7.2681e-04,  1.7439e-04, -2.2872e-03,  6.9677e-04,
         -2.0261e-03,  2.2177e-01, -7.8045e-03,  1.3582e-03, -9.4532e-04,
          2.8704e-04,  1.1375e-03]], device='cuda:2'))])
end of epoch 18: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-3.8366e-03,  7.7654e-04,  5.0765e-04, -1.2366e-03, -1.3340e-05,
         -9.8094e-04,  9.3273e-03, -3.7429e-03,  9.1278e-04, -7.2795e-04,
          2.8716e-04,  2.6841e-04]], device='cuda:2'))])
end of epoch 19: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.0007,  0.0023, -0.0019, -0.0006,  0.0002,  0.0012,  0.0083, -0.0002,
          0.0007, -0.0014,  0.0003,  0.0010]], device='cuda:2'))])
end of epoch 20: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 7.4433e-04,  8.6894e-04, -1.6840e-03, -2.0621e-03,  4.8261e-04,
          5.8297e-04,  3.7404e-02, -1.7033e-03,  9.8239e-04, -2.7901e-06,
          2.8739e-04,  9.8360e-04]], device='cuda:2'))])
end of epoch 21: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 1
end of epoch 22: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0001,  0.0021,  0.0009,  0.0014,  0.0006, -0.0004,  0.0617,  0.0048,
          0.0013,  0.0023,  0.0003,  0.0008]], device='cuda:2'))])
end of epoch 23: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.3024e-03, -6.8796e-05,  8.7158e-04, -1.6850e-03,  1.2130e-03,
         -1.1429e-03,  2.0503e-01, -2.3257e-04,  2.7704e-05,  1.1831e-04,
          2.8774e-04,  3.5900e-04]], device='cuda:2'))])
end of epoch 24: val_loss 8.392316274097311e-07, val_acc 1.0
trigger times: 1
end of epoch 25: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0006,  0.0017,  0.0011, -0.0014, -0.0017, -0.0021,  0.0090,  0.0005,
         -0.0005,  0.0025,  0.0003,  0.0023]], device='cuda:2'))])
end of epoch 26: val_loss 2.384185577852804e-09, val_acc 1.0
trigger times: 1
end of epoch 27: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0014, -0.0008, -0.0015, -0.0023,  0.0024, -0.0008,  0.0807,  0.0007,
          0.0009,  0.0003,  0.0003,  0.0022]], device='cuda:2'))])
end of epoch 28: val_loss 1.25169719922269e-08, val_acc 1.0
trigger times: 1
end of epoch 29: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.2069e-04,  1.3088e-03, -6.9436e-04,  1.6903e-03,  3.0179e-05,
          4.3822e-04,  2.5423e-02,  1.7542e-03, -1.5345e-03, -7.7330e-06,
          2.8844e-04, -3.0305e-04]], device='cuda:2'))])
end of epoch 30: val_loss 3.337858693441831e-08, val_acc 1.0
trigger times: 1
end of epoch 31: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 9.0646e-05, -4.3939e-04,  3.3844e-04, -1.5490e-03, -6.1398e-04,
         -1.5794e-03,  1.4399e-01, -2.2701e-03,  8.2236e-04, -3.0644e-04,
          2.8867e-04, -1.8898e-04]], device='cuda:2'))])
end of epoch 32: val_loss 8.71418016359371e-07, val_acc 1.0
trigger times: 1
end of epoch 33: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0030,  0.0010, -0.0010,  0.0017,  0.0009,  0.0025,  0.0314, -0.0021,
          0.0041,  0.0017,  0.0003, -0.0014]], device='cuda:2'))])
end of epoch 34: val_loss 8.622921260439398e-06, val_acc 1.0
trigger times: 1
end of epoch 35: val_loss 9.877494406396181e-06, val_acc 1.0
trigger times: 2
end of epoch 36: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.0019, -0.0006, -0.0025,  0.0036, -0.0001,  0.0013,  0.0097,  0.0003,
         -0.0027,  0.0002,  0.0003,  0.0003]], device='cuda:2'))])
end of epoch 37: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.0012,  0.0004, -0.0020, -0.0010,  0.0003,  0.0001,  0.0223, -0.0012,
          0.0008, -0.0016,  0.0003, -0.0007]], device='cuda:2'))])
end of epoch 38: val_loss 1.6570077722377617e-07, val_acc 1.0
trigger times: 1
end of epoch 39: val_loss 2.2238374774374846e-06, val_acc 1.0
trigger times: 2
end of epoch 40: val_loss 3.7812887889288048e-06, val_acc 1.0
trigger times: 3
end of epoch 41: val_loss 8.20747004183886e-06, val_acc 1.0
trigger times: 4
end of epoch 42: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.0310e-04, -3.1391e-04, -2.6325e-04, -1.3413e-03,  5.9245e-05,
         -2.6306e-04,  2.9751e-02,  1.8109e-03,  3.9583e-04,  1.6970e-03,
          2.8995e-04, -1.1862e-05]], device='cuda:2'))])
end of epoch 43: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0005,  0.0013, -0.0021, -0.0010, -0.0008,  0.0023,  0.0066,  0.0018,
         -0.0001, -0.0007,  0.0003,  0.0001]], device='cuda:2'))])
end of epoch 44: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.0007,  0.0017,  0.0004,  0.0020,  0.0005,  0.0002,  0.0553,  0.0012,
          0.0013, -0.0008,  0.0003, -0.0005]], device='cuda:2'))])
end of epoch 45: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0021,  0.0017, -0.0008, -0.0002, -0.0027, -0.0008,  0.0120, -0.0016,
         -0.0003,  0.0012,  0.0003,  0.0009]], device='cuda:2'))])
end of epoch 46: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0034, -0.0013,  0.0002, -0.0005, -0.0011,  0.0027,  0.0604, -0.0011,
         -0.0010, -0.0007,  0.0003, -0.0020]], device='cuda:2'))])
end of epoch 47: val_loss 8.290931595524854e-06, val_acc 1.0
trigger times: 1
end of epoch 48: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0019,  0.0023, -0.0006, -0.0002, -0.0019, -0.0002,  0.0366, -0.0127,
          0.0004, -0.0013,  0.0003,  0.0006]], device='cuda:2'))])
end of epoch 49: val_loss 3.2322478266451074e-05, val_acc 1.0
trigger times: 1
end of epoch 50: val_loss 1.6462740703104829e-06, val_acc 1.0
trigger times: 2
end of epoch 51: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.7640e-03,  8.6870e-04,  2.8224e-03, -8.2907e-04, -9.1981e-04,
         -1.6270e-03,  1.0519e-02, -9.1299e-04, -1.3697e-03, -8.8577e-05,
          2.9100e-04,  1.4534e-03]], device='cuda:2'))])
end of epoch 52: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.0360e-04, -2.6096e-03,  1.3574e-05, -4.3223e-05,  1.1899e-03,
         -6.0149e-04,  4.2688e-02, -1.3472e-03,  1.3448e-04, -1.1586e-03,
          2.9112e-04,  1.6100e-03]], device='cuda:2'))])
end of epoch 53: val_loss 8.940695011006028e-09, val_acc 1.0
trigger times: 1
end of epoch 54: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.0019,  0.0020, -0.0006, -0.0005,  0.0015, -0.0006,  0.1190,  0.0006,
          0.0013, -0.0009,  0.0003, -0.0021]], device='cuda:2'))])
end of epoch 55: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.0002, -0.0012, -0.0031, -0.0006, -0.0012,  0.0014,  0.0194, -0.0028,
          0.0007, -0.0006,  0.0003, -0.0001]], device='cuda:2'))])
end of epoch 56: val_loss 1.639126962516002e-07, val_acc 1.0
trigger times: 1
end of epoch 57: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 8.5230e-05,  2.4047e-04, -1.5948e-03, -1.3518e-03,  6.8147e-04,
          2.1727e-03,  3.2394e-02, -4.2686e-04, -8.2112e-04,  1.4465e-03,
          2.9170e-04, -4.0959e-04]], device='cuda:2'))])
end of epoch 58: val_loss 2.544506617674358e-06, val_acc 1.0
trigger times: 1
end of epoch 59: val_loss 1.5026268156859146e-06, val_acc 1.0
trigger times: 2
end of epoch 60: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-5.1892e-05,  1.5012e-03, -1.0464e-03, -5.6115e-04,  6.2816e-04,
         -8.1960e-05,  1.4906e-02,  8.0941e-04, -1.2709e-03,  9.7665e-04,
          2.9205e-04, -9.8927e-04]], device='cuda:2'))])
end of epoch 61: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.0010,  0.0009,  0.0003,  0.0010,  0.0008, -0.0007,  0.0120,  0.0018,
         -0.0012,  0.0005,  0.0003,  0.0003]], device='cuda:2'))])
end of epoch 62: val_loss 1.6826332428721003e-06, val_acc 1.0
trigger times: 1
end of epoch 63: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.5500e-03, -1.8590e-03,  6.8003e-05, -5.4622e-05, -1.2780e-03,
          2.5163e-03,  1.1022e-01,  6.9858e-04, -1.1694e-03, -5.9083e-04,
          2.9240e-04, -2.2255e-04]], device='cuda:2'))])
end of epoch 64: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0014,  0.0013, -0.0022,  0.0016,  0.0019,  0.0005,  0.1627, -0.0002,
         -0.0023,  0.0012,  0.0003, -0.0030]], device='cuda:2'))])
end of epoch 65: val_loss 2.0986712610593374e-06, val_acc 1.0
trigger times: 1
end of epoch 66: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.6081e-03,  1.8740e-03, -1.0689e-04, -4.5629e-04,  1.7902e-03,
          8.5413e-04,  3.5458e-02,  2.9566e-04,  1.8841e-06, -3.9939e-04,
          2.9275e-04, -7.1213e-04]], device='cuda:2'))])
end of epoch 67: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0005, -0.0009,  0.0014, -0.0021,  0.0002, -0.0028,  0.1612, -0.0014,
          0.0008,  0.0019,  0.0003,  0.0033]], device='cuda:2'))])
end of epoch 68: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.8082e-03,  3.5555e-03,  2.5078e-03,  1.8291e-03,  1.1105e-04,
         -1.3034e-03,  7.5052e-03, -1.7597e-04,  9.7788e-05, -7.6733e-04,
          2.9298e-04, -1.2762e-03]], device='cuda:2'))])
end of epoch 69: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-5.7193e-04,  5.1714e-04, -2.9463e-04,  8.5010e-05,  1.3639e-03,
          1.1612e-03,  3.4887e-02,  2.1696e-03,  9.9511e-04, -9.3376e-04,
          2.9309e-04, -1.6052e-03]], device='cuda:2'))])
end of epoch 70: val_loss 1.2284485951852276e-06, val_acc 1.0
trigger times: 1
end of epoch 71: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.0010, -0.0030,  0.0011,  0.0021,  0.0007, -0.0007,  0.0070, -0.0004,
         -0.0014,  0.0007,  0.0003,  0.0029]], device='cuda:2'))])
end of epoch 72: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 5.5146e-05, -1.3633e-03, -1.0957e-03, -1.5253e-03, -1.6452e-03,
         -1.7440e-04,  8.9033e-03,  5.1552e-04,  9.3686e-04,  2.4095e-03,
          2.9344e-04, -1.6427e-03]], device='cuda:2'))])
end of epoch 73: val_loss 6.121380897639028e-07, val_acc 1.0
trigger times: 1
end of epoch 74: val_loss 1.4656727189432673e-06, val_acc 1.0
trigger times: 2
end of epoch 75: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.0010, -0.0006,  0.0002, -0.0018,  0.0019,  0.0012,  0.0643, -0.0015,
          0.0008, -0.0015,  0.0003, -0.0005]], device='cuda:2'))])
end of epoch 76: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-3.3939e-05, -4.1389e-04, -1.4714e-03,  2.5981e-04,  1.3790e-03,
         -8.1638e-04,  1.5532e-02,  1.3880e-03,  9.2438e-04, -4.5727e-04,
          2.9391e-04,  9.6878e-04]], device='cuda:2'))])
end of epoch 77: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0013,  0.0011,  0.0004, -0.0026,  0.0006,  0.0023,  0.0183, -0.0049,
          0.0010,  0.0015,  0.0003, -0.0005]], device='cuda:2'))])
end of epoch 78: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 6.2430e-04,  1.7470e-03,  2.2722e-03,  3.1631e-04, -1.0660e-03,
         -2.2121e-05,  3.3292e-02,  5.9738e-04,  6.6265e-05,  1.6546e-04,
          2.9414e-04,  1.3634e-04]], device='cuda:2'))])
end of epoch 79: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.3462e-03, -9.3357e-04,  1.3486e-03, -2.8894e-03,  9.8821e-05,
          1.7414e-04,  5.7241e-02,  4.6261e-04, -1.2952e-03, -6.0135e-04,
          2.9426e-04,  9.4403e-04]], device='cuda:2'))])
end of epoch 80: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0011,  0.0004,  0.0011,  0.0006, -0.0012, -0.0003,  0.0157, -0.0028,
         -0.0007,  0.0020,  0.0003, -0.0023]], device='cuda:2'))])
end of epoch 81: val_loss 1.2748045309649569e-05, val_acc 1.0
trigger times: 1
end of epoch 82: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 5.2453e-03,  5.6206e-04, -8.2068e-04, -8.9957e-04,  1.0402e-03,
          1.6390e-03,  4.4702e-02, -1.5586e-04,  2.8859e-04, -1.8932e-04,
          2.9461e-04, -9.3203e-05]], device='cuda:2'))])
end of epoch 83: val_loss 6.854468444430495e-06, val_acc 1.0
trigger times: 1
end of epoch 84: val_loss 7.5488101990117686e-06, val_acc 1.0
trigger times: 2
end of epoch 85: val_loss 5.125998232102802e-08, val_acc 1.0
trigger times: 3
end of epoch 86: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.3085e-03,  3.0699e-05, -3.7515e-04,  5.2119e-04, -2.8056e-03,
         -5.4189e-05,  1.7779e-01, -3.6854e-04,  1.1676e-03, -9.1495e-04,
          2.9507e-04, -1.8367e-04]], device='cuda:2'))])
end of epoch 87: val_loss 2.460470629870315e-06, val_acc 1.0
trigger times: 1
end of epoch 88: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.5595e-03, -7.0927e-04,  2.9929e-04, -1.2158e-03, -7.5649e-04,
         -1.1694e-03,  3.4565e-02, -4.1176e-03,  1.5590e-03,  6.8784e-05,
          2.9531e-04, -2.3329e-04]], device='cuda:2'))])
end of epoch 89: val_loss 1.1921848127087742e-05, val_acc 1.0
trigger times: 1
end of epoch 90: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 8.2638e-04, -7.7926e-04,  1.9617e-03,  1.3735e-03,  3.2716e-05,
         -7.4784e-04,  2.9338e-02, -1.8690e-03,  1.3709e-03,  1.8424e-03,
          2.9554e-04, -1.3401e-04]], device='cuda:2'))])
end of epoch 91: val_loss 2.1934479008223207e-07, val_acc 1.0
trigger times: 1
end of epoch 92: val_loss 2.3424607075384075e-07, val_acc 1.0
trigger times: 2
end of epoch 93: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.0007, -0.0013, -0.0007,  0.0001, -0.0005, -0.0013,  0.0273, -0.0017,
         -0.0012,  0.0003,  0.0003,  0.0004]], device='cuda:2'))])
end of epoch 94: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.1404e-03,  1.0413e-03,  8.2013e-06, -1.6040e-03, -4.1573e-04,
         -1.8074e-03,  1.1984e-02,  1.5988e-03,  1.7224e-03,  1.6730e-03,
          2.9601e-04,  1.5327e-04]], device='cuda:2'))])
end of epoch 95: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.1270e-03, -2.7401e-03,  2.3866e-03, -6.4532e-04,  4.6877e-04,
          2.5008e-06,  9.4503e-02, -1.1478e-03, -4.2897e-04, -3.7825e-03,
          2.9612e-04, -1.0378e-03]], device='cuda:2'))])
end of epoch 96: val_loss 2.1791365000822794e-06, val_acc 1.0
trigger times: 1
end of epoch 97: val_loss 8.219457776093009e-07, val_acc 1.0
trigger times: 2
end of epoch 98: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.0484e-04,  3.6605e-05,  2.7745e-03, -1.1813e-03, -2.2698e-05,
          8.2659e-04,  1.3193e-01,  9.5873e-03,  1.5566e-03, -2.0028e-03,
          2.9647e-04, -1.3656e-04]], device='cuda:2'))])
end of epoch 99: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.3021e-03,  3.1202e-04,  1.7231e-04,  2.3797e-03,  1.4905e-03,
         -6.0893e-05,  5.9253e-02, -5.7479e-04, -3.3021e-03,  1.9027e-04,
          2.9659e-04,  5.3362e-04]], device='cuda:2'))])
Finished training.
0 -205.1865559874568 -86.91338399433552
1 -207.8896707878448 -83.73144705004965
2 -206.967571613146 -82.8426050318675
3 -204.68015878740698 -81.37897355989648
4 -205.92851324996445 -81.22309245429243
5 -205.30884424969554 -80.02405687972622
6 -203.27773511735722 -79.22486155121096
7 -205.61699966713786 -78.29476705076013
8 -207.44641131930985 -78.2738060281537
9 -204.35993779543787 -77.83353943064219
10 -207.46032025059685 -77.3581144557719
11 -206.38942067802418 -77.04193137564523
12 -206.3169668953633 -76.29322251465294
13 -205.13590428675525 -76.2660722967455
14 -206.40561065333895 -76.21832786900973
15 -205.71964375209063 -76.01874641792017
16 -206.53649968258105 -75.80871968582433
17 -190.55289907671977 -75.77901829704301
18 -207.29900649981573 -75.20723638903908
19 -206.284890251467 -75.20586953652035
20 -205.38347144552972 -75.07013098613223
21 -208.31923244369682 -75.06928062054426
22 -205.28594006877393 -74.56859530291729
23 -206.38771908381023 -74.34582998958717
24 -206.55002605053596 -74.34501992038129
25 -207.98086041701026 -74.25214115555151
26 -204.69481911952607 -73.8426441930754
27 -206.75302348216064 -73.56956586482053
28 -187.8301212823717 -73.49676028508203
29 -206.25673398864456 -73.45707589714108
30 -205.41119419736788 -72.35992622049811
31 -208.06575953541324 -72.14696499944588
32 -203.85324113734532 -72.05073584765728
33 -151.71107280731667 -71.98912261672817
34 -188.37572237168206 -71.9205249725425
35 -203.89472315600142 -71.91219049988875
36 -203.3253444901202 -71.59704608611555
37 -192.8820618254831 -71.4560163350558
38 -203.75956490909448 -71.44046475054458
39 -205.900536688976 -71.25245533466205
40 -204.66823381278664 -71.08219377739607
41 -202.31433509720955 -70.7218144675834
42 -204.5527944600908 -70.60428711769023
43 -203.60575179429725 -70.16227679075955
44 -205.03638632199727 -70.07926884474585
45 -193.4871438416303 -69.91665206357293
46 -207.0551263350062 -69.5706356373092
47 -164.90374467463698 -69.44024773348045
48 -205.74228722939733 -69.40166876452572
49 -195.10204146179603 -69.38984567969896
50 -172.97751405159943 -69.38370826635217
51 -201.88680866721552 -69.33497455303188
52 -206.64416891359724 -69.17411003849203
53 -198.4131730197114 -69.16888927396366
54 -203.37160526879597 -69.0001602698317
55 -203.22995404351968 -68.76905739407297
56 -201.2613807534799 -68.73583502323959
57 -206.12472022906877 -68.50445309194002
58 -204.56832829024643 -68.25661754075512
59 -204.27988818334416 -65.8225473265898
60 -25.53906693099998 -47.15605336419176
61 -14.000578311854042 -46.19619104961985
62 -26.217514970572665 -44.078303125872196
63 -37.021880828076974 -43.993555290419714
64 -0.5163233519997448 -43.86306534422809
65 20.359655124600977 -43.84199129025074
66 0.06101706111803651 -43.806385671938365
67 25.605653218459338 -42.7594767358323
68 33.614068806055 -42.33177224591743
69 -1.8853051819605753 -41.774963389485094
70 15.58099492173642 -41.410068073767725
71 -5.912153104552999 -40.429389880911344
72 -13.84434344060719 -39.54162101198148
73 -15.864009756420273 -38.447265769744824
74 -13.800938197295181 -38.392107037026264
75 24.301580870407633 -38.00745349944469
76 -0.08524222625419497 -37.46482488602393
77 7.2593794907443225 -37.10988160586883
78 -0.6396500614937395 -34.27116723637227
79 6.367967519676313 -33.263072731706835
80 4.6182431895285845 -33.0321314765637
81 7.061347550712526 -32.40063925734975
82 11.828046897426248 -30.131236504472803
83 4.682081459206529 -29.297233511513635
84 17.93043158366345 -29.288890423975797
85 -10.37044546729885 -28.49601894351319
86 3.485568331700051 -26.064532595535336
87 -8.161461453186348 -25.27101421179229
88 1.4717395235784352 -25.066644278800943
89 -8.336366554198321 -24.925849381327673
90 -0.023756266047712415 -24.188105669766596
91 -11.278904599952511 -23.48479966198816
92 5.941748366225511 -23.153943559703283
93 2.8708253640215844 -22.739273544503753
94 9.027698278303433 -19.58144410477429
95 7.674554156139493 -19.377225745334304
96 -5.076364086125977 -19.243135617403095
97 11.196850358275697 -18.448962308005108
98 0.827268784516491 -16.85889369985028
99 3.860631378251128 -14.443670567499144
100 4.024791592382826 -12.278515244993585
101 2.5523447216837667 -12.227387460046547
102 2.420402653864585 -12.020717825467683
103 2.895964650437236 -11.910094799877324
104 4.582636656152317 -11.134618158086587
105 -0.9208225253678393 -10.859166921158222
106 1.492154831881635 -9.595137958067907
107 5.241494680405594 -9.289921608799773
108 -9.941573264251929 -8.230877068641124
109 6.5243922725494485 -7.459623237418707
110 5.826394892879762 -7.124357312750265
111 -4.763034077943303 -7.05379065585803
112 4.412318297661841 -6.6211384471641495
113 -4.9158691591146635 -6.494555224953677
114 5.011441954644397 -6.117354180737655
115 5.801449877093546 -4.628649413275992
116 2.1954390901955776 -4.455504779070034
117 -0.2929055349668488 -4.2805498188182405
118 0.08125833602389321 -3.7944735717969627
119 2.866431022528559 -2.541618164765197
train accuracy: 1.0
validation accuracy: 1.0
[-83.73144705 -82.84260503 -80.02405688 -79.22486155 -77.56970359
 -77.35811446 -77.31242231 -76.92526317 -76.28172228 -76.2660723
 -76.19993471 -76.01874642 -75.95390494 -75.89067159 -75.80871969
 -75.78377846 -75.72348929 -75.64742963 -75.48885914 -75.36825129
 -75.23491223 -75.20586954 -75.14557354 -74.88869266 -74.83947744
 -74.83301814 -74.83190676 -74.79501846 -74.75129512 -74.73935787
 -74.73135224 -74.68166225 -74.60612547 -74.57488576 -74.5685953
 -74.47039407 -74.42749515 -74.34582999 -74.34501992 -74.27873276
 -74.24044932 -74.12750645 -73.90468572 -73.89376747 -73.84264419
 -73.58088827 -73.5149839  -73.49676029 -73.4671554  -73.4545496
 -73.39957698 -72.80725053 -72.74192679 -72.72359235 -72.61734819
 -72.55910327 -72.55779284 -72.44322581 -72.43763358 -72.35992622
 -72.32045668 -72.29821105 -72.20772236 -72.07889211 -72.05073585
 -71.98912262 -71.92052497 -71.9121905  -71.70313921 -71.68791199
 -71.66901429 -71.59704609 -71.46168724 -71.44046475 -71.33972131
 -71.28242353 -71.27918849 -71.10258051 -70.72181447 -70.60428712
 -70.36076638 -70.16227679 -70.07926884 -69.83914057 -69.44024773
 -69.33497455 -69.22055811 -69.17411004 -69.16888927 -65.82254733
 -47.15605336 -43.86306534 -43.80638567 -42.75947674 -41.77496339
 -41.41006807 -40.42938988 -38.39210704 -38.0074535  -33.03213148
 -29.29723351 -28.49601894 -25.27101421 -25.06664428 -24.92584938
 -24.18810567 -23.48479966 -19.5814441  -18.44896231 -14.44367057
 -12.22738746 -12.02071783 -11.9100948  -11.13461816 -10.85916692
  -9.28992161  -8.23087707  -6.49455522  -4.62864941  -3.79447357]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=12, out_features=1, bias=False)
)
Found existing model weights! Loading state dict...
Total number of parameters: 12
Number of trainable paramters: 12
device: cuda:1
end of epoch 0: val_loss 5.949546395519926, val_acc 0.775
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 7.8861e-01,  5.0175e-01,  3.2441e-01, -1.7735e-01, -5.2013e-02,
         -5.2446e-01, -1.6952e-02,  1.1115e-01,  2.9302e-01,  2.0420e-01,
         -1.6307e-03, -4.5995e+00]], device='cuda:1'))])
end of epoch 1: val_loss 3.514430892436583, val_acc 0.875
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 9.4020e-01,  8.7428e-01,  7.1206e-01, -9.9309e-02,  1.1023e-02,
         -6.0252e-01, -1.4909e-02, -8.5309e-02,  3.6786e-01,  7.3387e-02,
         -1.6306e-03, -8.5161e+00]], device='cuda:1'))])
end of epoch 2: val_loss 0.6811996793826477, val_acc 0.945
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.2474e+00,  9.8429e-01,  6.5810e-01,  6.0607e-02, -1.8568e-01,
         -7.0017e-01, -3.1413e-03,  7.3020e-03,  7.0785e-01,  1.1407e-01,
         -1.6304e-03, -1.0803e+01]], device='cuda:1'))])
end of epoch 3: val_loss 0.7967104026299776, val_acc 0.96
trigger times: 1
end of epoch 4: val_loss 25.366293724915632, val_acc 0.745
trigger times: 2
end of epoch 5: val_loss 5.400086259004249, val_acc 0.89
trigger times: 3
end of epoch 6: val_loss 9.101009384761912, val_acc 0.815
trigger times: 4
end of epoch 7: val_loss 0.8778930505824972, val_acc 0.95
trigger times: 5
end of epoch 8: val_loss 4.0875323075800845, val_acc 0.88
trigger times: 6
end of epoch 9: val_loss 1.3011669729550954, val_acc 0.96
trigger times: 7
end of epoch 10: val_loss 1.0347727243141858, val_acc 0.96
trigger times: 8
end of epoch 11: val_loss 1.6403375128057087, val_acc 0.96
trigger times: 9
end of epoch 12: val_loss 1.1893710719666706, val_acc 0.955
trigger times: 10
Early stopping.
0 -353.05591106414795 -83.73144705004965
1 -292.1351010799408 -82.8426050318675
2 -199.66072171926498 -80.02405687972622
3 -226.48281741142273 -79.22486155121096
4 -240.3788390159607 -77.56970359061481
5 -279.6137331724167 -77.3581144557719
6 -231.85353875160217 -77.31242231128952
7 -220.9825539290905 -76.92526316852114
8 -223.78221201896667 -76.28172228079553
9 -299.8202407360077 -76.2660722967455
10 -228.46837198734283 -76.19993470709022
11 -285.23478174209595 -76.01874641792017
12 -262.2133067250252 -75.95390494100478
13 -239.76414036750793 -75.89067158905105
14 -196.08579689264297 -75.80871968582433
15 -205.43874597549438 -75.78377845742408
16 -250.15407931804657 -75.72348928513276
17 -237.06631922721863 -75.64742962812143
18 -217.95567125082016 -75.48885913876587
19 -257.9640573859215 -75.36825128912793
20 -191.55521368980408 -75.2349122341165
21 -214.8231041431427 -75.20586953652035
22 -208.20339941978455 -75.14557354359802
23 -192.10908389091492 -74.88869265969203
24 -200.09099531173706 -74.83947744073161
25 -211.96396589279175 -74.83301813700467
26 -216.15974962711334 -74.8319067606844
27 -191.47325611114502 -74.79501845988233
28 -237.2644258737564 -74.75129512142802
29 -263.252168238163 -74.73935786725762
30 -234.68177485466003 -74.731352241768
31 -214.11460161209106 -74.68166224518423
32 -209.76126146316528 -74.60612546849954
33 -214.33630084991455 -74.57488575925572
34 -236.25718092918396 -74.56859530291729
35 -216.46638345718384 -74.47039407195963
36 -247.38469195365906 -74.42749514991493
37 -194.68084478378296 -74.34582998958717
38 -191.9119115769863 -74.34501992038129
39 -209.47530150413513 -74.27873275780367
40 -182.11999607086182 -74.24044932191849
41 -209.6984829902649 -74.12750645370208
42 -190.71652698516846 -73.90468572433612
43 -200.23131906986237 -73.89376746900379
44 -170.62184339761734 -73.8426441930754
45 -226.09724962711334 -73.58088826770992
46 -262.9189908504486 -73.51498389678083
47 -247.40611028671265 -73.49676028508203
48 -193.37705516815186 -73.46715539537216
49 -212.1459118127823 -73.45454960386748
50 -234.19350612163544 -73.3995769798173
51 -229.86160254478455 -72.80725053362633
52 -212.3228212594986 -72.74192679349568
53 -199.9246060848236 -72.72359235326576
54 -201.8644301891327 -72.61734819264782
55 -205.80829191207886 -72.55910326967994
56 -193.7649426460266 -72.55779284224927
57 -201.9921042919159 -72.44322580896966
58 -184.72677445411682 -72.43763358084409
59 -212.5589061975479 -72.35992622049811
60 -214.38927686214447 -72.32045667857052
61 -182.15503692626953 -72.29821104824131
62 -193.685311794281 -72.20772235500118
63 -184.02338767051697 -72.07889210639917
64 -174.68682825565338 -72.05073584765728
65 -218.48903489112854 -71.98912261672817
66 -204.63194024562836 -71.9205249725425
67 -185.51107221841812 -71.91219049988875
68 -190.9087266921997 -71.70313920534355
69 -213.34146463871002 -71.68791199217152
70 -211.05385780334473 -71.66901428755553
71 -303.3238699436188 -71.59704608611555
72 -199.53137111663818 -71.4616872425094
73 -155.85853564739227 -71.44046475054458
74 -185.8781762123108 -71.3397213057249
75 -199.24376237392426 -71.28242352844205
76 -183.7987024784088 -71.27918848872807
77 -196.5598804950714 -71.1025805146788
78 -170.90080857276917 -70.7218144675834
79 -174.68520593643188 -70.60428711769023
80 -187.4087998867035 -70.36076638030563
81 -184.1544884443283 -70.16227679075955
82 -144.40937185287476 -70.07926884474585
83 -204.16820812225342 -69.83914057311914
84 -205.501256108284 -69.44024773348045
85 -112.46176868677139 -69.33497455303188
86 -182.32910585403442 -69.22055811318926
87 -141.0084786117077 -69.17411003849203
88 -172.04557484388351 -69.16888927396366
89 -99.02683866024017 -65.8225473265898
90 -160.80134984850883 -47.15605336419176
91 -113.79787480831146 -43.86306534422809
92 -92.34958410263062 -43.806385671938365
93 -124.55719268321991 -42.7594767358323
94 -118.53773260116577 -41.774963389485094
95 -244.86583185195923 -41.410068073767725
96 -196.21065425872803 -40.429389880911344
97 -226.45922660827637 -38.392107037026264
98 -129.73425936698914 -38.00745349944469
99 -40.21061110496521 -33.0321314765637
100 -86.48271524906158 -29.297233511513635
101 -156.58558654785156 -28.49601894351319
102 -130.68820905685425 -25.27101421179229
103 -134.94579458236694 -25.066644278800943
104 -111.08004468679428 -24.925849381327673
105 -38.30067229270935 -24.188105669766596
106 -143.56771063804626 -23.48479966198816
107 -137.0974624156952 -19.58144410477429
108 -171.54096654057503 -18.448962308005108
109 -53.838650584220886 -14.443670567499144
110 58.22386333346367 -12.227387460046547
111 49.46274691820145 -12.020717825467683
112 -84.25715565681458 -11.910094799877324
113 19.872729063034058 -11.134618158086587
114 89.01476049423218 -10.859166921158222
115 -125.17916476726532 -9.289921608799773
116 -109.36015552282333 -8.230877068641124
117 -119.07400798797607 -6.494555224953677
118 -25.147670298814774 -4.628649413275992
119 80.0983395576477 -3.7944735717969627
train accuracy: 0.9594444444444444
validation accuracy: 0.955
