[-54.98547503 -50.4922686  -50.03933802 -49.75347185 -49.72654641
 -46.98011874 -45.73515428 -45.67057988 -44.99030608 -44.14602409
 -43.81326882 -43.18878399 -42.29180715 -42.00401746 -41.69100444
 -41.68588229 -41.2817771  -40.44278203 -40.34838366 -39.59970115
 -39.57586365 -39.31972693 -39.02461056 -38.45534494 -38.4127039
 -38.35634328 -37.79713617 -37.74152899 -37.66475324 -37.51313938
 -37.1809993  -37.10070314 -37.00630589 -36.82191677 -36.48799015
 -36.2096527  -36.19207562 -36.11445903 -35.78149902 -35.39450387
 -35.262825   -35.24303541 -35.20970524 -35.06544085 -34.80241748
 -34.64469045 -33.84284986 -32.70706485 -31.9690994  -31.7109134
 -31.64414356 -31.39238276 -31.22319602 -31.12953085 -29.3915714
 -29.34012561 -29.10618999 -27.4110235  -27.34372236 -27.19668163
 -27.07399029 -26.70472176 -26.2447949  -25.54836509 -25.45878529
 -24.879107   -24.82869536 -24.59274514 -23.97874558 -23.57262108
 -23.44970808 -22.74530916 -22.60679894 -22.19891032 -20.65686376
 -20.44447256 -20.1969901  -20.13839115 -19.63760344 -19.51559872
 -18.9283881  -17.99477406 -17.5574237  -16.82307393 -14.8550828
 -14.5314246  -14.44242009 -13.59601285 -12.68135973 -12.66418206
 -12.30017947 -12.15190477 -11.78885214 -10.8699891  -10.3276815
  -9.85721598  -8.330117    -8.13319584  -8.10819769  -7.57539849
  -7.36244313  -7.10832736  -6.95906356  -6.77694649  -6.72206384
  -6.71997062  -6.53544734  -6.51820418  -5.61579673  -5.3472021
  -5.07848501  -5.02795798  -4.82757292  -4.63049542  -4.230832
  -4.03104862  -3.38446715  -3.3322555   -2.64166233  -1.91361965]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:3
end of epoch 0: val_loss 3.5636665076630435e-05, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.0477e-06,  1.4328e-05, -1.0680e-06, -6.5258e-02, -7.5586e-05,
          6.2181e-05,  4.4854e-06,  1.3492e-02,  1.5943e-05,  1.3542e-05,
         -3.7692e-04, -5.0678e-02, -5.6661e-01]], device='cuda:3'))])
end of epoch 1: val_loss 0.6591772069539209, val_acc 0.95
trigger times: 1
end of epoch 2: val_loss 1.1920927533992654e-09, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-9.3092e-02, -1.4001e-05,  1.6502e-01, -3.1578e-01, -7.3259e-05,
         -7.5433e-06, -2.9934e-02,  8.6553e-02, -3.0089e-05, -2.3572e-05,
         -3.7710e-04, -1.2173e+00, -2.0179e+00]], device='cuda:3'))])
end of epoch 3: val_loss 3.7191915907897055e-07, val_acc 1.0
trigger times: 1
end of epoch 4: val_loss 1.3470634151246942e-07, val_acc 1.0
trigger times: 2
end of epoch 5: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-5.3111e-02,  4.0890e-01,  1.9498e-01, -5.6042e-02,  6.1577e-01,
         -2.4259e-01, -9.2777e-03, -1.0620e-06, -4.5260e-01, -9.4125e-06,
         -3.7736e-04, -1.4981e+00, -2.1023e+00]], device='cuda:3'))])
end of epoch 6: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.1330e-05,  2.7114e-01,  2.3798e-02,  2.8623e-05,  4.2150e-02,
          1.2694e-04, -5.4873e-07, -3.0349e-06, -6.1604e-05, -1.2909e-04,
         -3.7745e-04, -7.5538e-01, -1.8880e+00]], device='cuda:3'))])
end of epoch 7: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.7104e-05,  2.6789e-05,  1.1986e-04,  6.7604e-05,  1.3547e-04,
          2.9960e-04, -2.6485e-06, -5.1490e-06, -1.4316e-04, -6.8393e-06,
         -3.7754e-04, -4.7600e-04, -1.3609e+00]], device='cuda:3'))])
end of epoch 8: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.1307e-03,  2.3884e-01,  8.7949e-02, -3.0895e-02,  3.9427e-01,
         -2.6829e-05, -2.6513e-02, -1.3152e-02, -1.8050e-02, -2.7153e-01,
         -3.7761e-04, -1.2851e+00, -1.7497e+00]], device='cuda:3'))])
end of epoch 9: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 5.7473e-06,  1.0849e-01,  1.8883e-05,  1.2375e-05,  6.2552e-05,
         -2.3804e-05, -1.5759e-02, -4.7602e-06,  3.4329e-05,  5.7172e-05,
         -3.7770e-04, -8.3360e-01, -1.6029e+00]], device='cuda:3'))])
end of epoch 10: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 5.2075e-06,  6.1259e-06,  1.0362e-05,  3.3258e-05,  8.3645e-05,
          1.1596e-04, -1.3741e-06,  4.7614e-06,  1.0645e-04,  1.3907e-04,
         -3.7781e-04, -3.7826e-05, -1.2402e+00]], device='cuda:3'))])
end of epoch 11: val_loss 0.3295271054115599, val_acc 0.895
trigger times: 1
end of epoch 12: val_loss 7.748598669365947e-09, val_acc 1.0
trigger times: 2
end of epoch 13: val_loss 4.9471779632881406e-08, val_acc 1.0
trigger times: 3
end of epoch 14: val_loss 5.900847810380583e-08, val_acc 1.0
trigger times: 4
end of epoch 15: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.4564e-05, -1.3028e-06,  1.6510e-01,  9.2841e-02,  1.4807e-05,
          7.1735e-05, -1.0550e-02,  3.7182e-04,  2.7848e-05,  1.3558e-04,
         -3.7833e-04, -4.3123e-01, -1.6585e+00]], device='cuda:3'))])
end of epoch 16: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-4.1930e-05, -5.2520e-07, -4.0404e-06, -7.5814e-05,  3.0061e-05,
         -2.8237e-05,  4.7216e-07, -1.1677e-06,  6.5992e-05,  2.2092e-04,
         -3.7844e-04, -1.3504e-04, -1.2504e+00]], device='cuda:3'))])
end of epoch 17: val_loss 0.014741877248628122, val_acc 0.995
trigger times: 1
end of epoch 18: val_loss 1.1920917444285806e-08, val_acc 1.0
trigger times: 2
end of epoch 19: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.2311e-05,  1.3175e-01,  3.4996e-01, -4.5391e-02,  1.0129e-04,
          1.0793e-05, -3.2152e-02,  4.5154e-02,  1.3947e-04,  1.1484e-04,
         -3.7875e-04, -4.0884e-01, -2.2595e+00]], device='cuda:3'))])
end of epoch 20: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.7917e-05, -1.9438e-04,  8.8721e-06, -2.7245e-05,  7.2042e-05,
         -8.2706e-05, -9.3478e-03, -1.3380e-05, -1.0924e-04,  3.4433e-04,
         -3.7886e-04,  4.5533e-04, -1.7015e+00]], device='cuda:3'))])
end of epoch 21: val_loss 0.052847623663755595, val_acc 0.985
trigger times: 1
end of epoch 22: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.5345e-02,  2.2360e-02,  1.0482e-01, -1.2067e-01,  2.2912e-05,
         -1.2241e-01,  1.3743e-02,  1.7085e-02, -4.2942e-05, -4.0536e-05,
         -3.7907e-04, -1.2790e+00, -2.1419e+00]], device='cuda:3'))])
end of epoch 23: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.2709e-05, -3.8070e-05,  1.8376e-05, -2.1223e-05,  5.6655e-05,
          4.6535e-05,  4.3263e-04,  3.9198e-06,  1.0932e-04,  1.3048e-04,
         -3.7917e-04, -4.6741e-03, -1.8539e+00]], device='cuda:3'))])
end of epoch 24: val_loss 1.1920928244535389e-09, val_acc 1.0
trigger times: 1
end of epoch 25: val_loss 1.1861183338623959e-07, val_acc 1.0
trigger times: 2
end of epoch 26: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.8817e-05,  7.6640e-02, -1.9621e-02, -2.3916e-01,  1.7095e-06,
         -7.7364e-02, -1.2499e-02,  4.8180e-02,  7.2381e-05, -1.1803e-04,
         -3.7948e-04, -9.7687e-01, -2.1670e+00]], device='cuda:3'))])
end of epoch 27: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-4.4521e-05,  6.5071e-06, -8.3441e-06, -8.1713e-02,  1.6745e-05,
         -1.2281e-04,  1.6884e-06,  3.6702e-03,  1.6281e-04, -2.8854e-04,
         -3.7959e-04,  1.3663e-04, -1.8124e+00]], device='cuda:3'))])
end of epoch 28: val_loss 5.304810663631088e-08, val_acc 1.0
trigger times: 1
end of epoch 29: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.2284e-01,  5.2796e-02,  8.2639e-02, -9.9029e-02, -9.1180e-06,
          5.2196e-08,  6.4348e-07,  4.6229e-03, -2.4744e-01,  3.2925e-02,
         -3.7980e-04, -1.4018e+00, -2.1531e+00]], device='cuda:3'))])
end of epoch 30: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-3.0584e-06, -1.8431e-05, -2.5257e-08, -1.8921e-02, -6.5092e-05,
         -1.0694e-04, -3.8659e-07, -1.5363e-06, -6.9093e-05, -6.0548e-05,
         -3.7990e-04, -6.7836e-01, -1.9536e+00]], device='cuda:3'))])
end of epoch 31: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-5.0879e-07, -4.3563e-05,  1.5358e-05,  3.9077e-06, -1.1878e-04,
         -1.5247e-04, -1.4480e-06,  2.3131e-06, -1.3214e-04,  5.4982e-05,
         -3.8001e-04, -8.1125e-06, -1.4627e+00]], device='cuda:3'))])
end of epoch 32: val_loss 0.097852963445591, val_acc 0.99
trigger times: 1
end of epoch 33: val_loss 3.5762775496550603e-09, val_acc 1.0
trigger times: 2
end of epoch 34: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.1164e-05,  2.1588e-02,  3.3052e-01,  1.3524e-05, -6.4076e-05,
         -5.6161e-05, -9.7317e-07,  2.3447e-02,  6.4575e-05, -2.0163e-04,
         -3.8032e-04, -2.5801e-01, -2.0820e+00]], device='cuda:3'))])
end of epoch 35: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.0406e-04,  3.0467e-05, -6.7814e-05,  1.4847e-05, -2.1841e-04,
         -7.1255e-05, -3.0382e-06,  9.5078e-06, -4.2954e-04, -5.0790e-04,
         -3.8043e-04,  1.7613e-04, -1.4750e+00]], device='cuda:3'))])
end of epoch 36: val_loss 0.03592102155398834, val_acc 0.99
trigger times: 1
end of epoch 37: val_loss 0.021598437426218878, val_acc 0.99
trigger times: 2
end of epoch 38: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 6.4072e-06,  1.2510e-05,  7.2037e-02, -2.5414e-01,  8.7328e-06,
          1.4266e-03, -2.3164e-02, -1.1532e-06,  1.4796e-04,  7.4485e-05,
         -3.8074e-04, -5.2633e-01, -2.5401e+00]], device='cuda:3'))])
end of epoch 39: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.6955e-05,  2.9639e-05,  5.0823e-05,  1.4236e-05, -1.8957e-04,
          2.8891e-04, -5.1018e-03,  2.5565e-06,  7.7195e-05,  1.7353e-04,
         -3.8085e-04,  2.7023e-04, -2.0671e+00]], device='cuda:3'))])
end of epoch 40: val_loss 8.761875481155812e-08, val_acc 1.0
trigger times: 1
end of epoch 41: val_loss 7.271713911904953e-08, val_acc 1.0
trigger times: 2
end of epoch 42: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.7419e-05,  1.5292e-01, -9.5977e-07, -7.6681e-03, -9.0031e-05,
          5.1422e-05, -3.0864e-04,  1.7421e-02, -1.8373e-04,  1.9518e-05,
         -3.8116e-04, -3.6703e-01, -1.8621e+00]], device='cuda:3'))])
end of epoch 43: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.4857e-05,  9.6318e-05, -2.7993e-05,  1.7070e-05, -2.5840e-04,
         -3.2238e-05, -7.5203e-08, -2.9265e-05, -4.5909e-04,  2.8771e-04,
         -3.8127e-04, -1.8399e-04, -1.3324e+00]], device='cuda:3'))])
end of epoch 44: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 1
end of epoch 45: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-4.1613e-05,  4.2373e-06,  1.4225e-01, -1.8466e-01, -2.7865e-05,
         -1.4060e-05, -3.0020e-06,  3.5071e-02, -1.7664e-04,  2.5632e-05,
         -3.8148e-04, -7.2335e-01, -1.5458e+00]], device='cuda:3'))])
end of epoch 46: val_loss 2.9802319190253e-09, val_acc 1.0
trigger times: 1
end of epoch 47: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 9.0156e-02, -2.6568e-02,  2.4401e-01, -2.4858e-01,  1.3168e-01,
         -1.6580e-01, -1.1044e-02,  4.7683e-02,  2.7239e-01, -4.0843e-01,
         -3.8168e-04, -1.5884e+00, -2.0649e+00]], device='cuda:3'))])
end of epoch 48: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.9714e-05,  3.8527e-06,  1.5952e-01, -1.4914e-01,  2.7496e-05,
          3.3688e-05, -4.3210e-03,  2.9441e-02,  4.7777e-05,  1.0193e-04,
         -3.8179e-04, -9.8272e-01, -1.9162e+00]], device='cuda:3'))])
end of epoch 49: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-5.3672e-05,  1.1187e-05, -1.0943e-05,  1.9557e-05,  1.0031e-04,
          9.1970e-05, -4.4884e-06,  8.0229e-06, -3.0453e-05,  2.0991e-05,
         -3.8189e-04, -1.3108e-04, -1.5503e+00]], device='cuda:3'))])
end of epoch 50: val_loss 4.615663247875546e-06, val_acc 1.0
trigger times: 1
end of epoch 51: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-3.0493e-02,  7.1670e-03,  5.3473e-01, -2.0535e-01,  5.6868e-05,
         -3.7681e-01,  2.5186e-02,  8.9188e-02, -2.9644e-05, -1.2413e-05,
         -3.8210e-04, -1.8163e+00, -2.6938e+00]], device='cuda:3'))])
end of epoch 52: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.5418e-06, -4.7558e-06,  3.9909e-01, -1.1861e-01,  4.2458e-05,
          1.1438e-05,  1.4899e-02,  6.3267e-02,  1.2878e-04, -6.9062e-05,
         -3.8221e-04, -1.0427e+00, -2.4990e+00]], device='cuda:3'))])
end of epoch 53: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 7.6446e-06, -1.4179e-05,  7.2001e-02,  3.7289e-06,  9.9053e-05,
          4.5397e-05, -2.1529e-07,  3.2431e-03,  3.0917e-04, -7.0791e-06,
         -3.8231e-04, -3.7283e-05, -2.0165e+00]], device='cuda:3'))])
end of epoch 54: val_loss 2.8192932390425083e-07, val_acc 1.0
trigger times: 1
end of epoch 55: val_loss 0.010263987183560346, val_acc 0.995
trigger times: 2
end of epoch 56: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 7.3310e-02, -4.8074e-05,  1.2213e-01, -2.3820e-06,  1.7265e-07,
          4.0111e-05,  1.1376e-02,  8.8633e-02,  2.4311e-05,  4.2472e-05,
         -3.8263e-04, -1.3130e+00, -2.4708e+00]], device='cuda:3'))])
end of epoch 57: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.4243e-05, -3.8426e-05,  1.0870e-05, -2.2783e-06,  1.4855e-04,
         -6.0112e-06, -1.6691e-06,  3.2846e-02, -1.0014e-04, -5.9243e-05,
         -3.8273e-04, -2.7360e-06, -2.0225e+00]], device='cuda:3'))])
end of epoch 58: val_loss 7.21215716481538e-08, val_acc 1.0
trigger times: 1
end of epoch 59: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.3361e-01,  2.6383e-01,  1.8907e-01, -1.0860e-01,  2.2595e-05,
         -3.0516e-01,  7.4070e-07,  4.6864e-02, -1.3349e-05,  4.4039e-05,
         -3.8294e-04, -1.4460e+00, -2.1539e+00]], device='cuda:3'))])
end of epoch 60: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 7.5317e-02,  7.3777e-02,  2.5653e-02,  1.4178e-06,  1.6048e-04,
         -1.8727e-04,  1.9489e-06,  2.1650e-02, -3.9567e-05,  2.5432e-05,
         -3.8305e-04, -5.6564e-01, -1.9303e+00]], device='cuda:3'))])
end of epoch 61: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 8.2753e-06, -2.5117e-05,  5.3699e-05, -4.6685e-05,  3.7888e-04,
          1.0431e-04, -4.8407e-07, -6.6876e-06, -1.0306e-04,  2.0597e-04,
         -3.8315e-04, -3.8108e-04, -1.3802e+00]], device='cuda:3'))])
end of epoch 62: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.3251e-01,  3.1068e-01,  5.4994e-02, -2.2445e-01,  3.2288e-01,
         -2.0060e-01, -2.2977e-02, -9.4802e-03,  1.2749e-01, -4.4111e-01,
         -3.8326e-04, -1.6461e+00, -1.9528e+00]], device='cuda:3'))])
end of epoch 63: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.6322e-02,  1.7670e-01,  3.0494e-06, -1.5529e-01, -1.7776e-06,
         -6.5639e-05, -1.6982e-02,  2.6744e-06,  2.6630e-05,  1.0609e-05,
         -3.8336e-04, -1.0460e+00, -1.8129e+00]], device='cuda:3'))])
end of epoch 64: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-4.0225e-05, -6.4755e-05,  2.0793e-05,  6.4318e-07, -7.9044e-05,
         -1.3056e-04, -2.4367e-03, -5.7643e-06,  7.3099e-05,  1.9977e-04,
         -3.8347e-04,  4.0287e-04, -1.4685e+00]], device='cuda:3'))])
end of epoch 65: val_loss 7.353733179691346e-06, val_acc 1.0
trigger times: 1
end of epoch 66: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.3739e-01,  2.3245e-01,  2.2360e-01, -2.5478e-01, -8.3669e-06,
         -7.8033e-05, -3.1671e-02,  3.7738e-06,  2.2577e-05,  8.1965e-07,
         -3.8368e-04, -1.2859e+00, -1.8860e+00]], device='cuda:3'))])
end of epoch 67: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.0159e-01,  1.2134e-01, -1.1549e-01, -1.6784e-01,  2.2627e-08,
         -2.6173e-01, -1.4327e-02,  1.0650e-05, -1.2719e-05,  3.8170e-05,
         -3.8378e-04, -1.2404e+00, -2.6179e+00]], device='cuda:3'))])
end of epoch 68: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.5977e-05,  3.0464e-05,  2.5362e-05, -3.5291e-02,  7.2670e-06,
         -8.3754e-05, -4.9259e-03, -1.4848e-05, -1.3153e-04, -1.3990e-05,
         -3.8388e-04,  4.9207e-05, -2.2900e+00]], device='cuda:3'))])
end of epoch 69: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-4.0387e-05,  7.2678e-05, -7.0727e-07,  3.1978e-05, -1.4640e-04,
          2.1639e-04, -1.8685e-06, -3.6987e-05, -1.5696e-04, -1.3699e-04,
         -3.8399e-04,  5.5304e-04, -1.4839e+00]], device='cuda:3'))])
end of epoch 70: val_loss 4.353415570221841e-06, val_acc 1.0
trigger times: 1
end of epoch 71: val_loss 7.748597568024706e-09, val_acc 1.0
trigger times: 2
end of epoch 72: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 7.3134e-05, -3.1144e-05,  2.2176e-06, -3.5957e-02, -6.8303e-05,
         -3.3719e-05, -7.7241e-08,  2.2851e-02,  6.2294e-05, -1.4231e-04,
         -3.8430e-04, -1.8641e-05, -1.4785e+00]], device='cuda:3'))])
end of epoch 73: val_loss 2.511992159650589e-05, val_acc 1.0
trigger times: 1
end of epoch 74: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.5434e-02,  1.8840e-01,  3.2607e-01, -2.2054e-01,  6.1538e-03,
         -3.9545e-01, -5.4536e-03, -3.7662e-02, -1.1940e-01,  2.8698e-01,
         -3.8451e-04, -1.7062e+00, -2.3112e+00]], device='cuda:3'))])
end of epoch 75: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 7.2006e-05,  6.7879e-02,  2.1969e-01, -1.1770e-01,  1.8044e-05,
         -1.1458e-06, -2.7952e-06, -1.2113e-02,  1.2986e-04,  5.1185e-05,
         -3.8462e-04, -9.4368e-01, -2.1221e+00]], device='cuda:3'))])
end of epoch 76: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 7.3077e-05,  4.4024e-06, -1.8197e-05, -5.6946e-05,  5.7951e-05,
         -1.5081e-05, -6.0610e-06,  4.6768e-06,  3.1098e-04,  9.2741e-05,
         -3.8472e-04,  5.1624e-04, -1.6570e+00]], device='cuda:3'))])
end of epoch 77: val_loss 3.867780453763459e-05, val_acc 1.0
trigger times: 1
end of epoch 78: val_loss 1.1920928244535389e-09, val_acc 1.0
trigger times: 2
end of epoch 79: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-7.6581e-02, -4.0507e-06,  1.5293e-05, -9.3691e-02, -3.1361e-05,
         -4.5327e-01,  2.2968e-03,  2.1876e-06,  2.1148e-05, -2.6888e-05,
         -3.8504e-04, -1.0979e+00, -2.5122e+00]], device='cuda:3'))])
end of epoch 80: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.7578e-05, -1.2307e-05, -1.6869e-05,  1.6406e-05,  9.0826e-05,
          2.7855e-04, -1.3623e-06,  5.1102e-06,  6.9439e-05, -8.6569e-05,
         -3.8514e-04,  1.8018e-06, -2.1061e+00]], device='cuda:3'))])
end of epoch 81: val_loss 2.9802319190253e-09, val_acc 1.0
trigger times: 1
end of epoch 82: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.2858e-01,  5.2052e-06,  1.7224e-01,  1.7408e-02,  2.0118e-01,
         -2.6374e-01, -8.0965e-07,  1.7256e-02, -1.6278e-02,  2.8824e-01,
         -3.8535e-04, -1.4065e+00, -2.0173e+00]], device='cuda:3'))])
end of epoch 83: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-3.1342e-06,  1.0977e-05,  1.9968e-02,  1.5694e-07, -2.4317e-05,
          3.3966e-06, -1.9955e-06, -6.4270e-06,  2.0783e-04, -1.0650e-04,
         -3.8546e-04, -6.2032e-01, -1.8331e+00]], device='cuda:3'))])
end of epoch 84: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.7379e-05,  2.9024e-05,  2.0303e-05,  1.3522e-05,  4.2172e-05,
          7.6640e-05, -4.9280e-06, -1.6963e-05,  5.2030e-04, -2.5180e-04,
         -3.8556e-04,  7.8389e-06, -1.3800e+00]], device='cuda:3'))])
end of epoch 85: val_loss 0.022913955450047718, val_acc 0.995
trigger times: 1
end of epoch 86: val_loss 1.7881390590446245e-09, val_acc 1.0
trigger times: 2
end of epoch 87: val_loss 5.310497340005326e-07, val_acc 1.0
trigger times: 3
end of epoch 88: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-3.7616e-05,  1.4806e-05, -8.1758e-06, -1.9815e-05, -2.3907e-04,
          9.5109e-05,  2.8512e-06,  6.7379e-05,  6.5521e-04, -8.2785e-05,
         -3.8598e-04,  9.9589e-04, -1.4107e+00]], device='cuda:3'))])
end of epoch 89: val_loss 0.1261395758389648, val_acc 0.98
trigger times: 1
end of epoch 90: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.5669e-01,  1.9592e-01,  2.3911e-01, -1.4340e-01,  1.7060e-01,
          2.1735e-05, -2.3211e-03,  2.9332e-02, -2.0884e-01,  1.0446e-04,
         -3.8619e-04, -1.1491e+00, -1.9962e+00]], device='cuda:3'))])
end of epoch 91: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-5.9649e-05, -1.4380e-05,  6.8135e-02,  1.9975e-04,  6.8665e-06,
          2.9010e-05, -3.2189e-06,  2.0193e-06, -3.1508e-04,  2.7238e-04,
         -3.8629e-04, -8.0996e-03, -1.6973e+00]], device='cuda:3'))])
end of epoch 92: val_loss 3.874300336548231e-08, val_acc 1.0
trigger times: 1
end of epoch 93: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.1856e-01,  7.2641e-02,  3.4898e-01, -1.2652e-01,  3.3280e-01,
         -2.2367e-01,  5.4019e-03,  9.9850e-02,  8.1688e-06,  3.9615e-02,
         -3.8650e-04, -1.5841e+00, -2.5796e+00]], device='cuda:3'))])
end of epoch 94: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.6129e-04, -3.2842e-06,  2.6645e-01, -5.1730e-02, -6.9207e-05,
         -1.6497e-05,  2.8510e-07,  7.9894e-02,  4.4439e-06, -6.3823e-05,
         -3.8661e-04, -9.7352e-01, -2.4348e+00]], device='cuda:3'))])
end of epoch 95: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 7.0115e-05, -1.5096e-05,  6.3622e-02, -3.0271e-05,  4.6503e-05,
         -1.4387e-04, -1.8268e-06,  3.1123e-02,  2.4184e-05, -1.9471e-04,
         -3.8671e-04,  4.2236e-04, -2.0783e+00]], device='cuda:3'))])
end of epoch 96: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-5.4162e-05, -4.5176e-05, -6.7280e-05, -7.4804e-05, -5.9665e-04,
          3.1947e-04, -4.1305e-06,  2.6779e-06,  8.2385e-05,  3.8160e-04,
         -3.8682e-04,  9.6204e-04, -1.2022e+00]], device='cuda:3'))])
end of epoch 97: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 6.1246e-02,  2.4257e-01,  3.2761e-01, -9.1226e-02,  9.9081e-06,
         -2.8414e-01,  7.8536e-03, -9.6405e-04,  2.6591e-04, -9.7870e-06,
         -3.8692e-04, -1.1795e+00, -1.9277e+00]], device='cuda:3'))])
end of epoch 98: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.1817e-05,  9.9447e-02,  2.1634e-01, -6.5928e-03, -4.0166e-05,
          4.6830e-05, -7.5413e-07, -1.0828e-06,  1.4051e-05,  7.3959e-05,
         -3.8703e-04, -3.9581e-01, -1.7521e+00]], device='cuda:3'))])
end of epoch 99: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-4.5277e-05,  5.1332e-07,  3.8053e-05, -1.5940e-05, -8.1585e-05,
          9.7057e-05,  3.3484e-06, -3.1925e-06, -4.1885e-05,  1.6631e-04,
         -3.8713e-04, -2.6601e-04, -1.3197e+00]], device='cuda:3'))])
Finished training.
0 -56.03523708879948 -54.98547503240923
1 -58.21387097239494 -50.492268601198035
2 -52.153269842267036 -50.03933801517046
3 -53.66539765894413 -49.75347184620696
4 -53.11478444933891 -49.72654640753777
5 -56.40573704242706 -46.98011874490918
6 -53.433283776044846 -45.7351542845057
7 -51.31369100883603 -45.670579884154705
8 -52.84088343381882 -44.99030608142343
9 -49.65523149073124 -44.14602409201361
10 -50.206363171339035 -43.81326882122305
11 -50.85345236212015 -43.18878399086166
12 -51.947405472397804 -42.29180714825394
13 -49.158679470419884 -42.00401746161006
14 -54.2904414832592 -41.6910044370425
15 -50.10668022930622 -41.68588229294918
16 -50.62578195333481 -41.281777102712205
17 -48.48709315061569 -40.44278203413966
18 -50.050656683743 -40.34838365523108
19 -47.970622539520264 -39.599701153458774
20 -48.00928843021393 -39.57586365327889
21 -45.71808597445488 -39.31972693233231
22 -43.60363917052746 -39.024610555047154
23 -45.823014095425606 -38.45534493538269
24 -45.76930493861437 -38.41270390343083
25 -47.20597942173481 -38.35634328077039
26 -44.31778363138437 -37.79713616772368
27 -41.99668484926224 -37.741528994987384
28 -49.85700748860836 -37.66475323879293
29 -45.20427577197552 -37.513139380385574
30 -50.30329683423042 -37.1809993033689
31 -45.96431338042021 -37.100703136010694
32 -44.97710608690977 -37.00630588930485
33 -46.88176919519901 -36.821916772458344
34 -46.29117967188358 -36.48799015296732
35 -43.40638455748558 -36.20965269874363
36 -44.699835911393166 -36.19207561676116
37 -47.12656119465828 -36.114459029559086
38 -44.09221550822258 -35.78149902167743
39 -41.591256357729435 -35.394503873250635
40 -45.869116857647896 -35.26282499693737
41 -44.466659262776375 -35.24303541418371
42 -46.403391152620316 -35.209705244501436
43 -44.84598061442375 -35.0654408505187
44 -43.19053877145052 -34.80241747531743
45 -43.16873662173748 -34.64469044638467
46 -40.86514716036618 -33.84284985953318
47 -38.769200034439564 -32.70706485357069
48 -38.41987860202789 -31.969099402548657
49 -39.39215353876352 -31.7109134007892
50 -41.246468625962734 -31.64414355845032
51 -40.440119452774525 -31.392382758954444
52 -42.856770895421505 -31.223196019713853
53 -38.16128668934107 -31.12953085092458
54 -39.70249982178211 -29.39157139549552
55 -40.679763451218605 -29.340125609942326
56 -33.10386819392443 -29.106189988903285
57 -36.720756731927395 -27.41102349748205
58 -37.3970012627542 -27.343722362182305
59 -37.92112413048744 -27.196681629483837
60 -36.49323630705476 -27.07399028854534
61 -33.23389558494091 -26.7047217556024
62 -35.61257876455784 -26.244794902859052
63 -36.004777796566486 -25.548365085275513
64 -32.65972499549389 -25.45878528601009
65 -34.73437272757292 -24.879106999799365
66 -33.946598161011934 -24.828695359328833
67 -35.09307271242142 -24.592745144504722
68 -33.84164883196354 -23.978745577896312
69 -32.58853954076767 -23.57262108435893
70 -30.85540011525154 -23.44970807952351
71 -32.46186511963606 -22.745309160183492
72 -31.0833094753325 -22.60679894414887
73 -31.252630412578583 -22.19891031871716
74 -30.893713915720582 -20.656863763892378
75 -28.24158614873886 -20.444472560731253
76 -28.194924101233482 -20.19699010077007
77 -31.1907875277102 -20.13839114930498
78 -29.714907716959715 -19.63760343800059
79 -30.088138960301876 -19.515598718228343
80 -28.37067585065961 -18.92838809611677
81 -28.185104489326477 -17.994774057192853
82 -25.965001847594976 -17.55742370467821
83 -24.956558596342802 -16.823073927842348
84 -23.922836074605584 -14.855082803515382
85 -23.148566372692585 -14.531424598833084
86 -21.98166126012802 -14.442420089224363
87 -23.808924697339535 -13.596012850960644
88 -17.568710044026375 -12.68135972540495
89 -22.779545590281487 -12.66418205637357
90 -21.59033339796588 -12.30017947419658
91 -20.251015581190586 -12.151904772081672
92 -20.09164304099977 -11.788852141676486
93 -19.32941609621048 -10.869989101210326
94 -19.743883506860584 -10.327681503524177
95 -16.53122885338962 -9.8572159761571
96 -16.034882260486484 -8.330116995310416
97 -16.447712812572718 -8.133195842510668
98 -17.4980203025043 -8.108197691178031
99 -12.036622561514378 -7.57539849177145
100 -11.544102773070335 -7.362443126623615
101 -11.145891843363643 -7.108327355338034
102 -11.84631902584806 -6.959063561385431
103 -11.584120225161314 -6.776946485018116
104 -10.707172444090247 -6.7220638398623045
105 -11.87685340642929 -6.719970621583102
106 -16.50871078670025 -6.535447341844848
107 -13.639250222593546 -6.51820418055673
108 -13.276143610477448 -5.615796733870542
109 -11.315619909204543 -5.34720210027791
110 -11.005299899727106 -5.078485007852753
111 -11.339568826369941 -5.027957977402961
112 -10.328825796954334 -4.827572916892203
113 -10.770846583880484 -4.63049541560991
114 -10.440520515665412 -4.230832004686763
115 -10.718471679836512 -4.031048624093466
116 -9.861406866461039 -3.3844671463622564
117 -10.086062205955386 -3.3322555012187633
118 -10.45841484889388 -2.6416623314910934
119 -8.50921068014577 -1.9136196540088464
train accuracy: 1.0
validation accuracy: 1.0
[-54.98547503 -50.4922686  -50.03933802 -49.75347185 -49.72654641
 -46.98011874 -45.73515428 -45.67057988 -44.99030608 -44.14602409
 -43.81326882 -43.18878399 -42.29180715 -42.00401746 -41.69100444
 -41.68588229 -41.2817771  -40.44278203 -40.34838366 -39.59970115
 -39.57586365 -39.31972693 -39.02461056 -38.45534494 -38.4127039
 -38.35634328 -37.79713617 -37.74152899 -37.66475324 -37.51313938
 -37.1809993  -37.10070314 -37.00630589 -36.82191677 -36.48799015
 -36.2096527  -36.19207562 -36.11445903 -35.78149902 -35.39450387
 -35.262825   -35.24303541 -35.20970524 -35.06544085 -34.80241748
 -34.64469045 -33.84284986 -32.70706485 -31.9690994  -31.7109134
 -31.64414356 -31.39238276 -31.22319602 -31.12953085 -29.3915714
 -29.34012561 -29.10618999 -27.4110235  -27.34372236 -27.19668163
 -27.07399029 -26.70472176 -26.2447949  -25.54836509 -25.45878529
 -24.879107   -24.82869536 -24.59274514 -23.97874558 -23.57262108
 -23.44970808 -22.74530916 -22.60679894 -22.19891032 -20.65686376
 -20.44447256 -20.1969901  -20.13839115 -19.63760344 -19.51559872
 -18.95826739 -18.9283881  -18.87905758 -18.7063571  -18.54530077
 -18.13131256 -17.99477406 -17.5574237  -17.40134513 -17.09350147
 -17.01473387 -16.9804259  -16.91589062 -16.82307393 -16.59067732
 -16.49040418 -16.48669442 -16.34426663 -16.33360514 -15.99002393
 -15.92560211 -15.92481331 -15.92378128 -15.50853283 -15.45216084
 -15.3078339  -15.19607379 -15.15037833 -15.13097011 -14.90448261
 -14.8550828  -14.77725123 -14.56039097 -14.5314246  -14.52058071
 -14.46756371 -14.44242009 -14.37936197 -14.37201643 -14.32766052
 -14.3132018  -14.28066982 -14.01199748 -13.95611382 -13.94274459
 -13.87737941 -13.67405283 -13.66567776 -13.59601285 -13.52842465
 -13.39367838 -13.3738228  -13.18927336 -13.05267593 -13.01572624
 -12.96689133 -12.84064929 -12.76269483 -12.68135973 -12.66418206
 -12.63380648 -12.63264281 -12.46913248 -12.30017947 -12.23147123
 -12.15896926 -12.15190477 -12.13724316 -12.12247272 -12.10575018
 -11.92156759 -11.86688047 -11.80121495 -11.78885214 -11.74353867
 -11.6317191  -11.59156179 -11.58343034 -11.39414499 -11.32823243
 -11.3208311  -11.29899183 -11.00100398 -10.8699891  -10.7891748
 -10.66078229 -10.53172231 -10.52922211 -10.43670194 -10.38926265
 -10.35820774 -10.3438193  -10.33581168 -10.3276815  -10.15906067
 -10.11556218  -9.94969155  -9.88199546  -9.85721598  -9.85617682
  -9.68427725  -9.63753286  -9.38310153  -9.30919238  -9.30649506
  -9.24176854  -9.12002976  -9.0744544   -8.84362927  -8.70664425
  -8.57936795  -8.57934762  -8.5452769   -8.50115887  -8.49500087
  -8.39796704  -8.330117    -8.32987796  -8.29795764  -8.23038631
  -8.19204998  -8.14296637  -8.13319584  -8.10819769  -7.85400235
  -7.60251679  -7.57539849  -7.46138035  -7.36244313  -7.35497938
  -7.10832736  -7.05002985  -6.95906356  -6.77694649  -6.72206384
  -6.71997062  -6.66285306  -6.53544734  -6.51820418  -6.49459235
  -6.49403511  -6.35182029  -6.34053654  -5.6890279   -5.61579673
  -5.42493771  -5.3472021   -5.3385794   -5.33820923  -5.07848501
  -5.02795798  -4.82757292  -4.63049542  -4.60294814  -4.230832
  -4.03104862  -3.38446715  -3.3322555   -2.64166233  -1.91361965]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:3
end of epoch 0: val_loss 0.0007738264926052807, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-6.7612e-02,  2.5992e-01, -3.3457e-02, -1.5349e-01,  5.1253e-01,
         -1.8127e-01,  3.2827e-02,  7.6366e-03, -3.9323e-01,  1.0552e-04,
         -3.7692e-04, -1.0479e+00, -1.2172e+00]], device='cuda:3'))])
end of epoch 1: val_loss 8.239266218488694e-05, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.7176e-02,  1.0755e-02, -5.1805e-03, -3.6300e-02,  7.1752e-02,
         -5.0404e-04, -4.1260e-03,  2.8338e-02,  6.9484e-07, -5.5086e-05,
         -3.7700e-04, -7.9093e-01, -1.0688e+00]], device='cuda:3'))])
end of epoch 2: val_loss 0.02920698141102715, val_acc 0.99
trigger times: 1
end of epoch 3: val_loss 2.045481594379339e-06, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.8037e-06,  8.0181e-02,  4.8178e-06, -1.6690e-01,  2.3788e-01,
         -1.7536e-04, -3.3456e-02,  7.1484e-03,  1.2688e-05,  2.0036e-05,
         -3.7719e-04, -1.3302e+00, -1.4697e+00]], device='cuda:3'))])
end of epoch 4: val_loss 0.20107238610893546, val_acc 0.985
trigger times: 1
end of epoch 5: val_loss 8.22541585421277e-08, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.5922e-02,  1.9719e-01,  3.0003e-05, -1.1069e-01,  1.0478e-01,
          9.6465e-06,  4.3641e-03,  3.9907e-04, -8.1872e-02, -4.6220e-02,
         -3.7736e-04, -1.9576e+00, -1.9799e+00]], device='cuda:3'))])
end of epoch 6: val_loss 3.871499277288138e-06, val_acc 1.0
trigger times: 1
end of epoch 7: val_loss 3.416479264842565e-05, val_acc 1.0
trigger times: 2
end of epoch 8: val_loss 4.7889478769356234e-05, val_acc 1.0
trigger times: 3
end of epoch 9: val_loss 3.017791284136706e-05, val_acc 1.0
trigger times: 4
end of epoch 10: val_loss 8.47639570558556e-06, val_acc 1.0
trigger times: 5
end of epoch 11: val_loss 2.8967505308230554e-07, val_acc 1.0
trigger times: 6
end of epoch 12: val_loss 6.338811061823435e-06, val_acc 1.0
trigger times: 7
end of epoch 13: val_loss 2.838093219907023e-05, val_acc 1.0
trigger times: 8
end of epoch 14: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-3.6517e-07,  1.6862e-05,  1.1140e-01, -2.1731e-01,  4.7653e-01,
         -1.2116e-06, -6.0412e-03,  1.1827e-01, -3.4278e-01,  2.3833e-05,
         -3.7823e-04, -1.9598e+00, -1.7997e+00]], device='cuda:3'))])
end of epoch 15: val_loss 9.393295308512961e-07, val_acc 1.0
trigger times: 1
end of epoch 16: val_loss 0.0006788686344374639, val_acc 1.0
trigger times: 2
end of epoch 17: val_loss 8.564926553233932e-07, val_acc 1.0
trigger times: 3
end of epoch 18: val_loss 0.0005176422570233186, val_acc 1.0
trigger times: 4
end of epoch 19: val_loss 6.448833823213818e-07, val_acc 1.0
trigger times: 5
end of epoch 20: val_loss 2.7418081529617667e-08, val_acc 1.0
trigger times: 6
end of epoch 21: val_loss 0.00029762190383255673, val_acc 1.0
trigger times: 7
end of epoch 22: val_loss 5.333509659863011e-05, val_acc 1.0
trigger times: 8
end of epoch 23: val_loss 0.12753808654742152, val_acc 0.985
trigger times: 9
end of epoch 24: val_loss 4.778691813278612e-06, val_acc 1.0
trigger times: 10
Early stopping.
0 -110.7820919752121 -54.98547503240923
1 -108.43034332990646 -50.03933801517046
2 -102.76249131560326 -49.72654640753777
3 -90.11651211977005 -45.7351542845057
4 -95.34807914495468 -44.99030608142343
5 -95.45896118879318 -43.81326882122305
6 -98.76303219795227 -42.29180714825394
7 -99.2961385846138 -41.6910044370425
8 -89.38405814766884 -41.281777102712205
9 -81.43192601203918 -40.34838365523108
10 -88.80616426467896 -39.57586365327889
11 -83.76795671880245 -39.024610555047154
12 -94.22155696153641 -38.41270390343083
13 -89.41015231609344 -37.79713616772368
14 -91.28362309932709 -37.66475323879293
15 -78.11293119192123 -37.1809993033689
16 -85.84675151109695 -37.00630588930485
17 -93.75075936317444 -36.48799015296732
18 -85.49614769220352 -36.19207561676116
19 -86.85133299231529 -35.78149902167743
20 -81.2615755200386 -35.26282499693737
21 -79.814981803298 -35.209705244501436
22 -74.8347129970789 -34.80241747531743
23 -85.61779674887657 -33.84284985953318
24 -73.58312579989433 -31.969099402548657
25 -64.19602636992931 -31.64414355845032
26 -68.93161200731993 -31.223196019713853
27 -85.51922249794006 -29.39157139549552
28 -67.36814832687378 -29.106189988903285
29 -71.18014147877693 -27.343722362182305
30 -75.73222871869802 -27.07399028854534
31 -70.7827798128128 -26.244794902859052
32 -56.99804663658142 -25.45878528601009
33 -64.17435478419065 -24.828695359328833
34 -73.67102980613708 -23.978745577896312
35 -54.790997356176376 -23.44970807952351
36 -57.32805445790291 -22.60679894414887
37 -51.147403448820114 -20.656863763892378
38 -39.89650521799922 -20.19699010077007
39 -39.877434477210045 -19.63760343800059
40 -42.82006597518921 -18.95826739196259
41 -41.815100848674774 -18.87905758287616
42 -40.830011427402496 -18.54530077322492
43 -42.693968042731285 -17.994774057192853
44 -37.725415110588074 -17.401345128610057
45 -36.80005341768265 -17.014733874139218
46 -36.68569231033325 -16.915890622226563
47 -37.4227300286293 -16.59067732130881
48 -34.84976688027382 -16.48669441686549
49 -36.075480580329895 -16.333605142059007
50 -35.81328445672989 -15.925602106854877
51 -33.27121230959892 -15.923781284507067
52 -30.9354906976223 -15.45216083515835
53 -37.03661501407623 -15.196073786180163
54 -34.37591248750687 -15.130970110729379
55 -51.525457203388214 -14.855082803515382
56 -34.26865282654762 -14.560390965461536
57 -35.006729423999786 -14.52058070590298
58 -38.15544219315052 -14.442420089224363
59 -33.81019625067711 -14.372016427085182
60 -33.29962819814682 -14.280669824338958
61 -31.2128763794899 -13.956113818182269
62 -32.41040760278702 -13.877379407016798
63 -31.00861093401909 -13.6656777590252
64 -33.042170107364655 -13.528424645708483
65 -29.037712007761 -13.373822800522767
66 -27.880427807569504 -13.052675933905098
67 -27.526504039764404 -12.966891330133944
68 -31.929028868675232 -12.762694828821783
69 -34.585632756352425 -12.66418205637357
70 -28.313515573740005 -12.632642813105404
71 -37.48554155230522 -12.30017947419658
72 -27.381169110536575 -12.158969262874024
73 -26.403206080198288 -12.13724315976819
74 -33.45148220658302 -12.105750180114182
75 -29.39688202738762 -11.866880471017074
76 -49.88997603952885 -11.788852141676486
77 -28.498449593782425 -11.631719103567702
78 -30.039769619703293 -11.58343034356252
79 -20.791737899184227 -11.328232433230076
80 -28.99637670814991 -11.298991830252898
81 -25.99658965319395 -10.869989101210326
82 -23.856545478105545 -10.660782288857632
83 -26.192845553159714 -10.52922210813378
84 -27.56118991971016 -10.389262650750606
85 -25.833435773849487 -10.343819298590391
86 -35.328768737614155 -10.327681503524177
87 -18.583499886095524 -10.115562180638529
88 -24.425221025943756 -9.881995461906246
89 -16.16371475160122 -9.856176822145105
90 -21.556071996688843 -9.63753285840073
91 -21.161502316594124 -9.309192380086348
92 -16.062891706824303 -9.241768536707228
93 -15.66615479439497 -9.074454396568065
94 -17.07703783735633 -8.70664425465433
95 -19.587147682905197 -8.57934761599037
96 -20.637581631541252 -8.501158865322148
97 -15.273113757371902 -8.397967037001104
98 -15.82649333961308 -8.329877957545065
99 -19.96451099216938 -8.230386311846033
100 -19.449765488505363 -8.14296637047142
101 -24.171885907649994 -8.108197691178031
102 -14.498436123132706 -7.602516785576057
103 -16.85903763771057 -7.461380354533785
104 -15.801507925614715 -7.354979383611287
105 -15.518425300717354 -7.050029845978645
106 -21.668637678027153 -6.776946485018116
107 -22.6453797519207 -6.719970621583102
108 -27.156316071748734 -6.535447341844848
109 -16.001122437417507 -6.494592345417679
110 -19.643660113215446 -6.351820292503013
111 -12.515932193025947 -5.689027904495626
112 -15.357214279472828 -5.4249377103205845
113 -15.861823193728924 -5.338579395002669
114 -26.299024745821953 -5.078485007852753
115 -18.328516464680433 -4.827572916892203
116 -8.78091998398304 -4.602948144906834
117 -19.01816490292549 -4.031048624093466
118 -14.41711874306202 -3.3322555012187633
119 -7.006430793553591 -1.9136196540088464
train accuracy: 1.0
validation accuracy: 1.0
[-54.98547503 -50.4922686  -50.03933802 -49.75347185 -49.72654641
 -46.98011874 -45.73515428 -45.67057988 -44.99030608 -44.14602409
 -43.81326882 -43.18878399 -42.29180715 -42.00401746 -41.69100444
 -41.68588229 -41.2817771  -40.44278203 -40.34838366 -39.59970115
 -39.57586365 -39.31972693 -39.02461056 -38.45534494 -38.4127039
 -38.35634328 -37.79713617 -37.74152899 -37.66475324 -37.51313938
 -37.1809993  -37.10070314 -37.00630589 -36.82191677 -36.48799015
 -36.2096527  -36.19207562 -36.11445903 -35.78149902 -35.39450387
 -35.262825   -35.24303541 -35.20970524 -35.06544085 -34.80241748
 -34.64469045 -33.84284986 -32.70706485 -31.9690994  -31.7109134
 -31.64414356 -31.39238276 -31.22319602 -31.12953085 -29.3915714
 -29.34012561 -29.10618999 -27.4110235  -27.34372236 -27.19668163
 -27.07399029 -26.70472176 -26.2447949  -25.54836509 -25.45878529
 -24.879107   -24.82869536 -24.59274514 -23.97874558 -23.57262108
 -23.44970808 -22.74530916 -22.60679894 -22.19891032 -20.65686376
 -20.44447256 -20.1969901  -20.13839115 -19.63760344 -19.51559872
 -18.95826739 -18.9283881  -18.87905758 -18.7063571  -18.54530077
 -18.13131256 -17.99477406 -17.5574237  -17.40134513 -17.09350147
 -17.01473387 -16.9804259  -16.91589062 -16.82307393 -16.59067732
 -16.49040418 -16.48669442 -16.34426663 -16.33360514 -15.99002393
 -15.92560211 -15.92481331 -15.92378128 -15.50853283 -15.45216084
 -15.3078339  -15.19607379 -15.15037833 -15.13097011 -14.90448261
 -14.8550828  -14.77725123 -14.58138984 -14.56039097 -14.5314246
 -14.52058071 -14.46756371 -14.44242009 -14.37936197 -14.37201643
 -14.32766052 -14.3132018  -14.28066982 -14.19861518 -14.10024812
 -14.01199748 -13.95611382 -13.94274459 -13.87737941 -13.69184427
 -13.67405283 -13.66567776 -13.59601285 -13.52842465 -13.39367838
 -13.3738228  -13.18927336 -13.05267593 -13.01572624 -12.96689133
 -12.90426226 -12.86529864 -12.84064929 -12.76269483 -12.68135973
 -12.66418206 -12.63380648 -12.63264281 -12.46913248 -12.30017947
 -12.27208401 -12.25981587 -12.2351833  -12.23147123 -12.15896926
 -12.15190477 -12.13724316 -12.12247272 -12.11081048 -12.10575018
 -11.93810862 -11.92156759 -11.86688047 -11.80121495 -11.78885214
 -11.7543625  -11.74353867 -11.6317191  -11.59156179 -11.58343034
 -11.56534539 -11.5270303  -11.45861252 -11.39414499 -11.32823243
 -11.3208311  -11.29899183 -11.28918302 -11.26031571 -11.19038699
 -11.14616918 -11.12139973 -11.00100398 -10.99547072 -10.94167627
 -10.8699891  -10.866048   -10.8054964  -10.80253887 -10.7891748
 -10.68001643 -10.66078229 -10.53172231 -10.52922211 -10.50969241
 -10.49464447 -10.48068288 -10.45746496 -10.43670194 -10.38926265
 -10.38796419 -10.36589281 -10.35820774 -10.35155306 -10.3438193
 -10.33581168 -10.3276815  -10.30149061 -10.15906067 -10.11556218
 -10.06246895 -10.03721915  -9.99893971  -9.96903965  -9.96427374
  -9.94969155  -9.90109121  -9.88199546  -9.87787986  -9.85721598
  -9.85617682  -9.84130889  -9.82804734  -9.78843396  -9.68666716
  -9.68427725  -9.63753286  -9.63098169  -9.47759802  -9.4019298
  -9.38310153  -9.38200198  -9.36887733  -9.30919238  -9.30649506
  -9.27230868  -9.24176854  -9.23331784  -9.23083416  -9.17253092
  -9.12514882  -9.12002976  -9.11900252  -9.08136258  -9.0744544
  -9.03533012  -9.01539794  -8.98121386  -8.96615773  -8.96406066
  -8.91926507  -8.90040861  -8.84362927  -8.83554155  -8.83121015
  -8.82765866  -8.78362228  -8.70664425  -8.66076515  -8.65090717
  -8.61414944  -8.57936795  -8.57934762  -8.55272917  -8.5452769
  -8.50667687  -8.50115887  -8.49891995  -8.49500087  -8.39796704
  -8.38159771  -8.35138026  -8.330117    -8.32987796  -8.29795764
  -8.25777932  -8.23038631  -8.19204998  -8.1879492   -8.18156857
  -8.14296637  -8.13319584  -8.10819769  -8.06327093  -7.94856102
  -7.92763923  -7.9258916   -7.89196127  -7.86695292  -7.86647498
  -7.85400235  -7.81067418  -7.77133022  -7.75059405  -7.74872277
  -7.70343103  -7.6947421   -7.69300785  -7.69222111  -7.64204348
  -7.60251679  -7.57539849  -7.5367211   -7.52733959  -7.51537456
  -7.50355076  -7.46138035  -7.39304499  -7.38496157  -7.36244313
  -7.35910942  -7.35497938  -7.28652427  -7.26109967  -7.2130292
  -7.10893803  -7.10832736  -7.05002985  -6.95906356  -6.90235505
  -6.83665358  -6.83342605  -6.78946603  -6.77694649  -6.76080576
  -6.75186293  -6.72649057  -6.72206384  -6.71997062  -6.66285306
  -6.55290116  -6.54660316  -6.53544734  -6.51820418  -6.49459235
  -6.49403511  -6.47363627  -6.45693355  -6.35182029  -6.34053654
  -6.16321453  -6.15212877  -5.6890279   -5.61579673  -5.51691844
  -5.42493771  -5.3472021   -5.3385794   -5.33820923  -5.07848501
  -5.02795798  -4.82757292  -4.63049542  -4.60294814  -4.230832
  -4.03104862  -3.38446715  -3.3322555   -2.64166233  -1.91361965]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:3
end of epoch 0: val_loss 0.0003216733081912082, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.1130e-02, -3.3344e-02, -3.1573e-05, -1.0478e-01,  1.4396e-01,
          1.7414e-01, -7.9020e-04,  1.9671e-02,  1.4460e-02, -5.5905e-02,
         -3.7692e-04, -1.2147e+00, -8.1247e-01]], device='cuda:3'))])
end of epoch 1: val_loss 4.837259124993665e-05, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 8.9389e-02,  7.2897e-02,  1.5027e-01, -8.8402e-02,  1.2938e-01,
          1.3826e-01, -6.1696e-02,  2.2667e-02, -1.3191e-06,  6.4512e-05,
         -3.7700e-04, -1.6414e+00, -1.0800e+00]], device='cuda:3'))])
end of epoch 2: val_loss 0.0005534280633983002, val_acc 1.0
trigger times: 1
end of epoch 3: val_loss 9.536739682403095e-09, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.2277e-01, -1.6716e-02,  4.3272e-01,  1.2547e-01,  1.1993e+00,
          2.3594e-01, -8.4409e-02,  4.1988e-02, -3.1723e-01, -2.4461e-01,
         -3.7719e-04, -2.8722e+00, -1.6284e+00]], device='cuda:3'))])
end of epoch 4: val_loss 3.915953561062224e-07, val_acc 1.0
trigger times: 1
end of epoch 5: val_loss 5.496022984321058e-05, val_acc 1.0
trigger times: 2
end of epoch 6: val_loss 2.5868149680974286e-07, val_acc 1.0
trigger times: 3
end of epoch 7: val_loss 4.930652076922115e-06, val_acc 1.0
trigger times: 4
end of epoch 8: val_loss 0.0004439672687586693, val_acc 1.0
trigger times: 5
end of epoch 9: val_loss 0.058869924170974454, val_acc 0.985
trigger times: 6
end of epoch 10: val_loss 1.449778279830838e-05, val_acc 1.0
trigger times: 7
end of epoch 11: val_loss 1.4615905908293643, val_acc 0.865
trigger times: 8
end of epoch 12: val_loss 0.0010180046409218946, val_acc 1.0
trigger times: 9
end of epoch 13: val_loss 0.0001358371654372803, val_acc 1.0
trigger times: 10
Early stopping.
0 -116.09242141246796 -54.98547503240923
1 -107.6986757516861 -49.75347184620696
2 -93.53742116689682 -45.7351542845057
3 -92.95925360918045 -44.14602409201361
4 -96.79267030954361 -42.29180714825394
5 -85.77285307645798 -41.68588229294918
6 -76.39215004444122 -40.34838365523108
7 -99.67108678817749 -39.31972693233231
8 -82.90127623081207 -38.41270390343083
9 -84.36919644474983 -37.741528994987384
10 -76.72630649805069 -37.1809993033689
11 -71.5194208920002 -36.821916772458344
12 -83.13559660315514 -36.19207561676116
13 -70.56833317875862 -35.394503873250635
14 -75.7293352484703 -35.209705244501436
15 -76.35876259207726 -34.64469044638467
16 -69.87612074613571 -31.969099402548657
17 -70.1681736856699 -31.392382758954444
18 -84.04379153251648 -29.39157139549552
19 -70.04014274477959 -27.41102349748205
20 -75.80302986502647 -27.07399028854534
21 -57.88473479449749 -25.548365085275513
22 -67.78861184418201 -24.828695359328833
23 -42.883034974336624 -23.57262108435893
24 -56.801282584667206 -22.60679894414887
25 -54.121817886829376 -20.444472560731253
26 -46.806130178272724 -19.63760343800059
27 -39.900338262319565 -18.92838809611677
28 -43.01559853553772 -18.54530077322492
29 -48.38851986825466 -17.55742370467821
30 -35.805679857730865 -16.980425898254765
31 -38.57785540819168 -16.59067732130881
32 -37.251765072345734 -16.344266629445098
33 -35.69472575187683 -15.925602106854877
34 -42.626682698726654 -15.508532834040299
35 -37.077944576740265 -15.196073786180163
36 -33.18688639998436 -14.904482610357418
37 -31.19439324736595 -14.5813898350114
38 -42.68086764216423 -14.52058070590298
39 -33.26310774683952 -14.37936197194177
40 -34.87139755487442 -14.313201802940128
41 -29.949568912386894 -14.10024812370176
42 -30.57209923863411 -13.942744593566932
43 -32.34959760308266 -13.67405282962576
44 -31.079112499952316 -13.528424645708483
45 -29.207216948270798 -13.189273357354436
46 -26.18790929019451 -12.966891330133944
47 -28.6050985455513 -12.840649288269582
48 -38.46810183301568 -12.66418205637357
49 -25.01987487077713 -12.469132478750263
50 -24.759856827557087 -12.25981586696299
51 -25.547834917902946 -12.158969262874024
52 -24.09600865840912 -12.122472722957268
53 -25.77274949848652 -11.938108617468604
54 -39.25804305076599 -11.801214951705882
55 -21.286874920129776 -11.743538667886787
56 -26.85527265071869 -11.58343034356252
57 -23.09459511190653 -11.45861252061011
58 -24.83139631152153 -11.320831097589815
59 -22.72509168088436 -11.260315708541759
60 -28.807839930057526 -11.121399734299642
61 -25.094522073864937 -10.941676269692449
62 -26.887127555906773 -10.805496395720702
63 -20.34604486823082 -10.680016434355997
64 -22.148257479071617 -10.52922210813378
65 -22.134802378714085 -10.480682884622757
66 -22.65370860695839 -10.389262650750606
67 -23.543838664889336 -10.358207740128002
68 -18.925158441066742 -10.335811677130739
69 -14.744161732494831 -10.159060666643725
70 -18.169240280985832 -10.037219146146185
71 -17.666316501796246 -9.964273742726046
72 -22.43976029753685 -9.881995461906246
73 -15.18771187029779 -9.856176822145105
74 -20.762590169906616 -9.788433955884193
75 -17.89625507965684 -9.63753285840073
76 -22.925016567111015 -9.40192979700846
77 -18.69698977470398 -9.368877330089191
78 -19.188160561025143 -9.272308683423732
79 -18.1970369592309 -9.230834156022215
80 -14.888048738241196 -9.120029762323945
81 -14.19340755790472 -9.074454396568065
82 -23.42987221479416 -8.981213859766973
83 -23.87181581929326 -8.919265070330715
84 -17.706186957657337 -8.835541545242977
85 -18.47745931893587 -8.783622284874431
86 -16.531333774328232 -8.650907165207073
87 -13.6220509596169 -8.57934761599037
88 -21.38139410316944 -8.506676869924311
89 -15.234498865902424 -8.495000865396662
90 -22.952435471117496 -8.330116995310416
91 -19.855211444199085 -8.257779320001426
92 -16.104687124490738 -8.187949197711195
93 -22.152937553822994 -8.133195842510668
94 -20.904646150767803 -7.948561022791138
95 -12.997303403913975 -7.891961268035399
96 -11.933032255619764 -7.854002347678565
97 -15.705425918102264 -7.7505940516414515
98 -15.186564582400024 -7.694742103423024
99 -13.624180018901825 -7.64204348129513
100 -22.774587847292423 -7.536721101543098
101 -22.295597344636917 -7.50355076209545
102 -12.806087255477905 -7.384961571563285
103 -11.561924416571856 -7.354979383611287
104 -13.052020654082298 -7.213029198554223
105 -10.719319190829992 -7.050029845978645
106 -11.270981453359127 -6.836653578302678
107 -25.977351412177086 -6.776946485018116
108 -20.85287430509925 -6.726490571697894
109 -7.443792127072811 -6.662853064341674
110 -20.098006881773472 -6.535447341844848
111 -11.527763616293669 -6.4940351064209345
112 -15.203716404736042 -6.351820292503013
113 -19.0190674290061 -6.152128773523117
114 -9.668320201337337 -5.5169184390887445
115 -11.904482886195183 -5.338579395002669
116 -13.501565903425217 -5.027957977402961
117 -2.921451650559902 -4.602948144906834
118 -14.372009932994843 -3.3844671463622564
119 -9.03603371605277 -1.9136196540088464
train accuracy: 1.0
validation accuracy: 1.0
[-74.17211785 -73.95782727 -73.26805818 -73.0186223  -72.71649503
 -72.53240426 -72.10762886 -71.31091253 -71.15257801 -71.06127544
 -70.899451   -70.80441266 -70.63515468 -70.62043016 -70.53269566
 -70.39681369 -70.35740546 -70.24539955 -70.17239217 -70.14769102
 -70.1139844  -69.97393649 -69.71058218 -69.68963454 -69.65328467
 -69.46999863 -69.41251292 -69.34855695 -69.31050315 -69.27065534
 -69.1350947  -69.08815837 -68.92907957 -68.89156511 -68.80237261
 -68.63219386 -68.61024866 -68.6068239  -68.60480039 -68.59498466
 -68.59342596 -68.5847388  -68.48500696 -68.46187963 -68.42673896
 -68.40256333 -68.05136636 -67.97875363 -67.96222764 -67.89072549
 -67.83054511 -67.7144862  -67.49051681 -67.47438541 -67.32750834
 -67.26714336 -67.25386762 -67.19962639 -67.14581154 -67.09124055
 -67.06251734 -67.00862004 -67.00637773 -66.98688062 -66.92540899
 -66.90335156 -66.8831681  -66.75857022 -66.67964391 -66.60163304
 -66.49461673 -66.39849672 -66.39360876 -66.29969197 -66.16764842
 -66.16472136 -66.00377018 -65.99300774 -65.96752013 -65.91634725
 -65.91354766 -65.78478981 -65.52872527 -65.50911485 -65.44338807
 -65.30439264 -65.28773769 -65.25277927 -65.25043604 -65.20473009
 -65.17397157 -65.09248013 -65.07355266 -65.04372698 -64.94248071
 -64.92267824 -64.86924824 -64.85665614 -64.79311473 -64.76596878
 -64.63676646 -64.19615668 -64.17049706 -64.02627761 -64.00194249
 -63.94691813 -63.87619084 -63.82346273 -63.41033423 -63.33300159
 -63.08645804 -62.957309   -62.90163285 -62.86266992 -62.73402621
 -62.7214969  -62.23780065 -62.08382901 -61.36034637 -60.84862878
 -54.98547503 -50.4922686  -50.03933802 -49.75347185 -49.72654641
 -46.98011874 -45.73515428 -45.67057988 -44.99030608 -44.14602409
 -43.81326882 -43.18878399 -42.29180715 -42.00401746 -41.69100444
 -41.68588229 -41.2817771  -40.44278203 -40.34838366 -39.59970115
 -39.57586365 -39.31972693 -39.02461056 -38.45534494 -38.4127039
 -38.35634328 -37.79713617 -37.74152899 -37.66475324 -37.51313938
 -37.1809993  -37.10070314 -37.00630589 -36.82191677 -36.48799015
 -36.2096527  -36.19207562 -36.11445903 -35.78149902 -35.39450387
 -35.262825   -35.24303541 -35.20970524 -35.06544085 -34.80241748
 -34.64469045 -33.84284986 -32.70706485 -31.9690994  -31.7109134
 -31.64414356 -31.39238276 -31.22319602 -31.12953085 -29.3915714
 -29.34012561 -29.10618999 -27.4110235  -27.34372236 -27.19668163
 -27.07399029 -26.70472176 -26.2447949  -25.54836509 -25.45878529
 -24.879107   -24.82869536 -24.59274514 -23.97874558 -23.57262108
 -23.44970808 -22.74530916 -22.60679894 -22.19891032 -20.65686376
 -20.44447256 -20.1969901  -20.13839115 -19.63760344 -19.51559872
 -18.95826739 -18.9283881  -18.87905758 -18.7063571  -18.54530077
 -18.13131256 -17.99477406 -17.5574237  -17.40134513 -17.09350147
 -17.01473387 -16.9804259  -16.91589062 -16.82307393 -16.59067732
 -16.49040418 -16.48669442 -16.34426663 -16.33360514 -15.99002393
 -15.92560211 -15.92481331 -15.92378128 -15.50853283 -15.45216084
 -15.3078339  -15.19607379 -15.15037833 -15.13097011 -14.90448261
 -14.8550828  -14.77725123 -14.58138984 -14.56039097 -14.5314246
 -14.52058071 -14.46756371 -14.44242009 -14.37936197 -14.37201643
 -14.32766052 -14.3132018  -14.28066982 -14.19861518 -14.10024812
 -14.01199748 -13.95611382 -13.94274459 -13.87737941 -13.69184427
 -13.67405283 -13.66567776 -13.59601285 -13.52842465 -13.39367838
 -13.3738228  -13.18927336 -13.05267593 -13.01572624 -12.96689133
 -12.90426226 -12.86529864 -12.84064929 -12.76269483 -12.68135973
 -12.66418206 -12.63380648 -12.63264281 -12.46913248 -12.30017947
 -12.27208401 -12.25981587 -12.2351833  -12.23147123 -12.15896926
 -12.15190477 -12.13724316 -12.12247272 -12.11081048 -12.10575018
 -11.93810862 -11.92156759 -11.86688047 -11.80121495 -11.78885214
 -11.7543625  -11.74353867 -11.6317191  -11.59156179 -11.58343034
 -11.56534539 -11.5270303  -11.45861252 -11.39414499 -11.32823243
 -11.3208311  -11.29899183 -11.28918302 -11.26031571 -11.19038699
 -11.14616918 -11.12139973 -11.00100398 -10.99547072 -10.94167627
 -10.8699891  -10.866048   -10.8054964  -10.80253887 -10.7891748
 -10.68001643 -10.66078229 -10.53172231 -10.52922211 -10.50969241
 -10.49464447 -10.48068288 -10.45746496 -10.43670194 -10.38926265
 -10.38796419 -10.36589281 -10.35820774 -10.35155306 -10.3438193
 -10.33581168 -10.3276815  -10.30149061 -10.15906067 -10.11556218
 -10.06246895 -10.03721915  -9.99893971  -9.96903965  -9.96427374
  -9.94969155  -9.90109121  -9.88199546  -9.87787986  -9.85721598
  -9.85617682  -9.84130889  -9.82804734  -9.78843396  -9.68666716
  -9.68427725  -9.63753286  -9.63098169  -9.47759802  -9.4019298
  -9.38310153  -9.38200198  -9.36887733  -9.30919238  -9.30649506
  -9.27230868  -9.24176854  -9.23331784  -9.23083416  -9.17253092
  -9.12514882  -9.12002976  -9.11900252  -9.08136258  -9.0744544
  -9.03533012  -9.01539794  -8.98121386  -8.96615773  -8.96406066
  -8.91926507  -8.90040861  -8.84362927  -8.83554155  -8.83121015
  -8.82765866  -8.78362228  -8.70664425  -8.66076515  -8.65090717
  -8.61414944  -8.57936795  -8.57934762  -8.55272917  -8.5452769
  -8.50667687  -8.50115887  -8.49891995  -8.49500087  -8.39796704
  -8.38159771  -8.35138026  -8.330117    -8.32987796  -8.29795764
  -8.25777932  -8.23038631  -8.19204998  -8.1879492   -8.18156857
  -8.14296637  -8.13319584  -8.10819769  -8.06327093  -7.94856102
  -7.92763923  -7.9258916   -7.89196127  -7.86695292  -7.86647498
  -7.85400235  -7.81067418  -7.77133022  -7.75059405  -7.74872277
  -7.70343103  -7.6947421   -7.69300785  -7.69222111  -7.64204348
  -7.60251679  -7.57539849  -7.5367211   -7.52733959  -7.51537456
  -7.50355076  -7.46138035  -7.39304499  -7.38496157  -7.36244313
  -7.35910942  -7.35497938  -7.28652427  -7.26109967  -7.2130292
  -7.10893803  -7.10832736  -7.05002985  -6.95906356  -6.90235505
  -6.83665358  -6.83342605  -6.78946603  -6.77694649  -6.76080576
  -6.75186293  -6.72649057  -6.72206384  -6.71997062  -6.66285306
  -6.55290116  -6.54660316  -6.53544734  -6.51820418  -6.49459235
  -6.49403511  -6.47363627  -6.45693355  -6.35182029  -6.34053654
  -6.16321453  -6.15212877  -5.6890279   -5.61579673  -5.51691844
  -5.42493771  -5.3472021   -5.3385794   -5.33820923  -5.07848501
  -5.02795798  -4.82757292  -4.63049542  -4.60294814  -4.230832
  -4.03104862  -3.38446715  -3.3322555   -2.64166233  -1.91361965]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:1
end of epoch 0: val_loss 4.421308505691002e-05, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-8.9807e-03, -3.6149e-02,  8.6152e-06, -1.2373e-01,  1.0096e-05,
          1.1144e-04, -6.7037e-07,  6.2971e-02, -4.1112e-06, -3.1897e-05,
         -3.7692e-04, -4.6456e-01, -6.6609e-01]], device='cuda:1'))])
end of epoch 1: val_loss 8.702209754574141e-08, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.6759e-01,  6.8224e-02,  2.5338e-01, -5.5058e-02,  2.6943e-01,
          3.5793e-03,  7.1853e-02,  1.9687e-02, -1.5668e-01, -5.0159e-01,
         -3.7700e-04, -1.7237e+00, -2.1297e+00]], device='cuda:1'))])
end of epoch 2: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.1627e-06,  1.1716e-05,  6.0681e-06, -3.6026e-02,  4.8632e-02,
         -1.0457e-05,  3.2579e-02, -1.0145e-07,  6.3859e-05, -1.5726e-01,
         -3.7710e-04, -1.4124e+00, -2.1183e+00]], device='cuda:1'))])
end of epoch 3: val_loss 5.292508180900768e-06, val_acc 1.0
trigger times: 1
end of epoch 4: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.0710e-01, -1.7254e-01, -2.4413e-02,  4.0879e-03,  8.1781e-02,
         -2.8959e-01,  4.0449e-02, -3.0377e-02, -3.3833e-06,  3.4047e-05,
         -3.7728e-04, -1.2830e+00, -2.7101e+00]], device='cuda:1'))])
end of epoch 5: val_loss 7.1525522571391775e-09, val_acc 1.0
trigger times: 1
end of epoch 6: val_loss 4.702585283666849e-07, val_acc 1.0
trigger times: 2
end of epoch 7: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.1801e-06, -1.8227e-01,  4.1011e-07,  9.9286e-07,  8.8649e-05,
          4.5373e-05,  9.7461e-02,  6.5974e-02,  3.8659e-06, -2.3070e-01,
         -3.7754e-04, -1.5563e+00, -3.3695e+00]], device='cuda:1'))])
end of epoch 8: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 1
end of epoch 9: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.0888e-01, -3.6277e-01, -1.2840e-01,  1.8698e-06,  2.2883e-02,
          1.0737e-01,  1.1400e-01,  7.1894e-02, -2.7050e-01, -6.1363e-01,
         -3.7770e-04, -1.4749e+00, -3.6941e+00]], device='cuda:1'))])
end of epoch 10: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.0697e-01, -2.2187e-02, -8.9314e-02,  1.0896e-04,  4.0315e-02,
          4.9921e-02,  1.0451e-01,  6.3394e-02, -1.5704e-02, -1.1368e-01,
         -3.7781e-04, -9.0851e-01, -3.4502e+00]], device='cuda:1'))])
end of epoch 11: val_loss 4.828028613701462e-06, val_acc 1.0
trigger times: 1
end of epoch 12: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 2
end of epoch 13: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 5.3060e-01, -1.7822e-01,  8.6657e-02, -8.1353e-04,  6.2198e-01,
          2.0717e-03,  4.0771e-02,  6.0183e-02, -3.1838e-01, -3.2902e-01,
         -3.7812e-04, -1.8866e+00, -3.9510e+00]], device='cuda:1'))])
end of epoch 14: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.8216e-01, -1.8864e-02, -8.0927e-06,  1.1518e-05, -2.6131e-06,
         -1.1359e-04,  3.1442e-02,  4.3494e-02,  3.0798e-05,  3.7430e-05,
         -3.7823e-04, -1.4239e+00, -3.7446e+00]], device='cuda:1'))])
end of epoch 15: val_loss 1.8357894077780656e-07, val_acc 1.0
trigger times: 1
end of epoch 16: val_loss 0.0039375512674438085, val_acc 0.995
trigger times: 2
end of epoch 17: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 3
end of epoch 18: val_loss 2.801410346364719e-08, val_acc 1.0
trigger times: 4
end of epoch 19: val_loss 0.002761750817298889, val_acc 1.0
trigger times: 5
end of epoch 20: val_loss 1.1920927533992654e-09, val_acc 1.0
trigger times: 6
end of epoch 21: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.9627e-01, -7.3876e-02,  1.2556e-01, -3.6092e-07,  5.3948e-01,
         -5.0479e-01,  8.6442e-02,  6.2221e-02, -1.9833e-01,  4.8976e-05,
         -3.7896e-04, -1.8617e+00, -3.6051e+00]], device='cuda:1'))])
end of epoch 22: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.1596e-01, -3.5475e-02, -3.1444e-02, -1.4172e-05,  1.2088e-02,
          1.8950e-04,  6.8595e-02,  3.9994e-02, -9.3577e-05,  3.9690e-05,
         -3.7907e-04, -1.6815e+00, -3.4228e+00]], device='cuda:1'))])
end of epoch 23: val_loss 5.600911404386243, val_acc 0.935
trigger times: 1
end of epoch 24: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.2109e-01, -2.4693e-01, -1.2607e-01, -1.0948e-01,  6.0019e-02,
         -5.8538e-05,  8.6590e-02,  7.6067e-02, -1.2303e-01, -1.5274e-01,
         -3.7927e-04, -1.8890e+00, -3.6388e+00]], device='cuda:1'))])
end of epoch 25: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 5.6326e-05, -6.4810e-02, -3.3039e-02,  8.9762e-05,  1.2470e-05,
         -7.3860e-05,  7.7416e-02,  2.6181e-02, -5.4776e-05,  4.0109e-05,
         -3.7938e-04, -1.1979e+00, -3.3203e+00]], device='cuda:1'))])
end of epoch 26: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.0186e-01, -3.9641e-01, -7.8986e-02,  1.3454e-05,  2.9830e-02,
         -5.3987e-01,  9.8698e-02, -8.3235e-02, -4.2397e-02, -2.1981e-06,
         -3.7948e-04, -1.7787e+00, -3.6874e+00]], device='cuda:1'))])
end of epoch 27: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.0312e-01, -1.8843e-01, -2.3945e-01,  1.5032e-05,  6.1048e-05,
          9.5938e-05,  6.8077e-02, -4.2088e-06, -1.0372e-04, -2.1801e-05,
         -3.7959e-04, -1.4475e+00, -3.3953e+00]], device='cuda:1'))])
end of epoch 28: val_loss 2.9802313861182485e-09, val_acc 1.0
trigger times: 1
end of epoch 29: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.8121e-01, -3.8635e-01, -8.5115e-03,  1.7280e-01,  5.2603e-01,
         -9.9885e-02,  2.0051e-02,  6.6177e-02, -1.6586e-01, -2.9483e-06,
         -3.7980e-04, -1.6712e+00, -3.6502e+00]], device='cuda:1'))])
end of epoch 30: val_loss 2.0563214206958946e-07, val_acc 1.0
trigger times: 1
end of epoch 31: val_loss 0.03683322429656982, val_acc 0.995
trigger times: 2
end of epoch 32: val_loss 8.360841311514378e-05, val_acc 1.0
trigger times: 3
end of epoch 33: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-7.2335e-02, -1.8411e-01, -1.9273e-01, -9.8425e-06,  5.3074e-01,
         -3.1877e-01,  1.1357e-01,  1.1999e-01, -3.2164e-01,  2.2784e-05,
         -3.8022e-04, -1.6960e+00, -4.0749e+00]], device='cuda:1'))])
end of epoch 34: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-4.4281e-05, -1.3076e-01, -2.5983e-01, -2.0525e-05, -1.9615e-05,
          6.9065e-05,  9.9665e-02,  6.7669e-02, -3.9834e-05, -1.1716e-04,
         -3.8032e-04, -1.3338e+00, -3.7911e+00]], device='cuda:1'))])
end of epoch 35: val_loss 1.1920927533992654e-09, val_acc 1.0
trigger times: 1
end of epoch 36: val_loss 6.55650836733912e-09, val_acc 1.0
trigger times: 2
end of epoch 37: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.1156e-05, -2.7741e-01, -1.1356e-01,  6.4391e-02,  1.8520e-01,
         -1.8679e-05,  1.0226e-01,  8.3849e-02, -1.1700e-01, -1.5429e-01,
         -3.8064e-04, -1.7257e+00, -4.5209e+00]], device='cuda:1'))])
end of epoch 38: val_loss 7.802503183484078e-05, val_acc 1.0
trigger times: 1
end of epoch 39: val_loss 0.031621270179748535, val_acc 0.995
trigger times: 2
end of epoch 40: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.2592e-02, -3.7961e-01, -4.0679e-02,  7.5600e-02,  1.7879e-05,
         -1.7989e-04,  3.5579e-02,  1.2759e-01,  1.8348e-05, -3.3223e-05,
         -3.8095e-04, -1.4631e+00, -3.8767e+00]], device='cuda:1'))])
end of epoch 41: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.5652e-01, -5.2144e-01, -1.7128e-01, -1.4821e-02,  2.3243e-01,
         -1.7318e-01,  1.1473e-01,  7.5570e-02, -3.4069e-01, -2.4775e-01,
         -3.8106e-04, -1.4958e+00, -4.0509e+00]], device='cuda:1'))])
end of epoch 42: val_loss 1.907344994833693e-08, val_acc 1.0
trigger times: 1
end of epoch 43: val_loss 1.7881390590446245e-09, val_acc 1.0
trigger times: 2
end of epoch 44: val_loss 6.0059078969025846e-05, val_acc 1.0
trigger times: 3
end of epoch 45: val_loss 8.702203555088772e-08, val_acc 1.0
trigger times: 4
end of epoch 46: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 9.9248e-02, -2.8545e-01,  2.4046e-01,  4.7236e-02,  1.9287e-01,
         -1.2582e-01,  6.0219e-02,  1.1980e-01, -6.7075e-02, -1.4037e-01,
         -3.8158e-04, -1.2273e+00, -3.8772e+00]], device='cuda:1'))])
end of epoch 47: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.2360e-01, -1.9815e-01, -1.3994e-02, -4.6992e-06, -4.8603e-05,
         -6.9783e-06,  3.5179e-02,  1.1529e-01,  4.2458e-05, -5.8148e-05,
         -3.8168e-04, -1.1511e+00, -3.7178e+00]], device='cuda:1'))])
end of epoch 48: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 1
end of epoch 49: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.1842e-01, -7.5564e-02, -2.9741e-05,  1.4646e-05, -1.2012e-04,
          1.4136e-04,  2.4524e-02, -1.0040e-06,  1.4965e-04, -2.1786e-05,
         -3.8189e-04, -7.8315e-01, -2.4644e+00]], device='cuda:1'))])
end of epoch 50: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.6490e-02, -1.6322e-01, -1.3248e-01, -1.1816e-02,  3.2772e-01,
         -1.5616e-01,  7.3610e-02,  3.2918e-06, -3.1094e-01, -2.0486e-01,
         -3.8200e-04, -1.5279e+00, -2.7595e+00]], device='cuda:1'))])
end of epoch 51: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 1
end of epoch 52: val_loss 1.251695948667475e-08, val_acc 1.0
trigger times: 2
end of epoch 53: val_loss 0.04746506403898735, val_acc 0.985
trigger times: 3
end of epoch 54: val_loss 0.024565351009368897, val_acc 0.995
trigger times: 4
end of epoch 55: val_loss 2.3245756892720237e-08, val_acc 1.0
trigger times: 5
end of epoch 56: val_loss 0.00027636012808670787, val_acc 1.0
trigger times: 6
end of epoch 57: val_loss 2.7418061563366792e-08, val_acc 1.0
trigger times: 7
end of epoch 58: val_loss 1.430491010978585e-07, val_acc 1.0
trigger times: 8
end of epoch 59: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.0702e-01, -1.1096e-01, -8.3505e-02, -6.6566e-02,  1.3395e-04,
          1.3861e-04,  6.8382e-02, -8.6209e-02,  6.8637e-05, -1.0726e-04,
         -3.8294e-04, -1.1073e+00, -3.2479e+00]], device='cuda:1'))])
end of epoch 60: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 1
end of epoch 61: val_loss 8.344643447344424e-09, val_acc 1.0
trigger times: 2
end of epoch 62: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 9.1527e-02, -3.8906e-01, -1.9958e-02,  3.2926e-06,  3.5906e-01,
         -4.5015e-01,  6.6477e-02,  1.6060e-01, -3.2196e-01,  7.6107e-05,
         -3.8326e-04, -1.3626e+00, -4.1561e+00]], device='cuda:1'))])
end of epoch 63: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.0498e-01, -5.0105e-01, -5.1886e-02, -5.7484e-07, -6.8145e-06,
          1.7022e-05,  8.8648e-02,  3.4797e-03, -9.1767e-05, -6.7373e-07,
         -3.8336e-04, -1.4232e+00, -3.8541e+00]], device='cuda:1'))])
end of epoch 64: val_loss 5.364415187614213e-09, val_acc 1.0
trigger times: 1
end of epoch 65: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.4597e-01, -1.5490e-01, -3.4940e-02, -8.0025e-02,  7.6987e-01,
         -4.7954e-01,  9.4133e-02,  1.1386e-01, -5.9503e-01, -5.0975e-02,
         -3.8357e-04, -1.5340e+00, -3.5973e+00]], device='cuda:1'))])
end of epoch 66: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 9.3942e-02, -6.8381e-02,  2.5466e-05, -1.4465e-05,  4.5920e-01,
         -6.2166e-02,  9.1442e-02,  9.4094e-02, -2.6828e-01, -7.4147e-06,
         -3.8368e-04, -1.1254e+00, -3.4854e+00]], device='cuda:1'))])
end of epoch 67: val_loss 7.152555525635762e-09, val_acc 1.0
trigger times: 1
end of epoch 68: val_loss 0.7252110214524146, val_acc 0.975
trigger times: 2
end of epoch 69: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.5351e-01, -2.5343e-01, -7.1090e-03,  4.9272e-02,  2.2366e-01,
         -3.1625e-01,  9.0752e-02, -8.5834e-02, -2.3950e-01, -8.6277e-02,
         -3.8399e-04, -1.3841e+00, -3.5192e+00]], device='cuda:1'))])
end of epoch 70: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.1184e-02, -9.9909e-02, -1.7343e-01,  3.3683e-05, -1.0128e-04,
          6.5526e-05,  5.6744e-02,  2.4449e-06,  4.6809e-05,  1.5628e-04,
         -3.8409e-04, -1.0988e+00, -3.2036e+00]], device='cuda:1'))])
end of epoch 71: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.7936e-02, -1.6790e-01, -2.6982e-02,  5.2531e-02,  4.8681e-01,
         -6.0411e-01,  8.0272e-02, -1.0460e-01, -4.4435e-01,  2.5260e-02,
         -3.8420e-04, -1.5021e+00, -3.5331e+00]], device='cuda:1'))])
end of epoch 72: val_loss 4.1723234289747776e-09, val_acc 1.0
trigger times: 1
end of epoch 73: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.1327e-01, -4.1619e-01, -1.4959e-01, -1.1095e-01,  2.2127e-01,
         -4.3811e-01,  1.3247e-01,  1.2136e-01, -1.7642e-01, -1.7270e-05,
         -3.8441e-04, -1.5666e+00, -3.7995e+00]], device='cuda:1'))])
end of epoch 74: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 6.9220e-06, -2.8956e-01, -2.7789e-01,  6.2102e-06, -8.2659e-05,
         -6.4978e-05,  1.1730e-01,  1.2165e-01,  1.8333e-06,  7.9842e-05,
         -3.8451e-04, -1.2812e+00, -3.6121e+00]], device='cuda:1'))])
end of epoch 75: val_loss 6.675675649603363e-08, val_acc 1.0
trigger times: 1
end of epoch 76: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 5.4492e-02, -3.4627e-01, -1.5223e-02, -3.3462e-06,  1.0725e-01,
         -1.8754e-05,  5.1029e-02,  7.5036e-02,  5.4387e-03,  9.3388e-02,
         -3.8472e-04, -1.0600e+00, -3.3045e+00]], device='cuda:1'))])
end of epoch 77: val_loss 2.5927677597792355e-07, val_acc 1.0
trigger times: 1
end of epoch 78: val_loss 1.7761869457899593e-07, val_acc 1.0
trigger times: 2
end of epoch 79: val_loss 0.20522752347920686, val_acc 0.985
trigger times: 3
end of epoch 80: val_loss 1.7881392366803084e-09, val_acc 1.0
trigger times: 4
end of epoch 81: val_loss 0.0915012276172618, val_acc 0.99
trigger times: 5
end of epoch 82: val_loss 2.562993131505209e-08, val_acc 1.0
trigger times: 6
end of epoch 83: val_loss 1.877525437521399e-07, val_acc 1.0
trigger times: 7
end of epoch 84: val_loss 3.1590392381986024e-08, val_acc 1.0
trigger times: 8
end of epoch 85: val_loss 0.0001268735062330606, val_acc 1.0
trigger times: 9
end of epoch 86: val_loss 3.0317765413201415e-06, val_acc 1.0
trigger times: 10
Early stopping.
0 -345.7877881526947 -74.1721178479907
1 -343.4900996685028 -72.71649503498074
2 -340.42242097854614 -71.1525780094121
3 -341.94126415252686 -70.6351546777058
4 -343.358957529068 -70.35740546141608
5 -340.4715449810028 -70.11398439797705
6 -345.04054284095764 -69.65328467349545
7 -339.7379879951477 -69.31050315164319
8 -336.20862102508545 -68.92907956994428
9 -341.2006151676178 -68.61024866348654
10 -341.14354515075684 -68.5934259629071
11 -342.566858291626 -68.42673895715825
12 -337.09952044487 -67.96222763686896
13 -338.4024293422699 -67.49051680506614
14 -338.2669725418091 -67.25386761804988
15 -339.501592874527 -67.06251733755995
16 -336.9672508239746 -66.9254089942571
17 -336.1580345630646 -66.67964391448251
18 -341.51905822753906 -66.39360875590565
19 -332.84372639656067 -66.00377018313415
20 -327.4183576107025 -65.78478981041695
21 -338.6522762775421 -65.30439263979832
22 -331.5554895401001 -65.20473008643418
23 -335.2132408618927 -65.04372698099213
24 -331.3625741004944 -64.8566561370319
25 -337.91278982162476 -64.19615667823099
26 -331.68701791763306 -63.946918129474476
27 -333.13159441947937 -63.33300158711638
28 -336.0766615867615 -62.862669919490095
29 -328.3783688545227 -62.083829012609364
30 -114.80337846279144 -50.492268601198035
31 -171.43862748146057 -46.98011874490918
32 -78.224191904068 -44.14602409201361
33 -110.85640543699265 -42.00401746161006
34 -108.18668758869171 -40.44278203413966
35 -84.84718576073647 -39.31972693233231
36 -123.50151544809341 -38.35634328077039
37 -115.60749614238739 -37.513139380385574
38 -107.98046436905861 -36.821916772458344
39 -98.37616991996765 -36.114459029559086
40 -113.82499468326569 -35.24303541418371
41 -103.7676297724247 -34.64469044638467
42 -102.55727368593216 -31.7109134007892
43 -85.90696524083614 -31.12953085092458
44 -68.86376211047173 -27.41102349748205
45 -78.92193534970284 -26.7047217556024
46 -69.91941380500793 -24.879106999799365
47 -72.25469642877579 -23.57262108435893
48 -72.23070402443409 -22.19891031871716
49 -72.66189409792423 -20.13839114930498
50 -74.51863464713097 -18.92838809611677
51 -35.57897016406059 -18.131312560073106
52 -35.58155882358551 -17.09350146890714
53 -62.833580389618874 -16.823073927842348
54 -36.5075027346611 -16.344266629445098
55 -34.61680218577385 -15.924813306536285
56 -35.20542997121811 -15.307833897061936
57 -35.035677045583725 -14.904482610357418
58 -35.518320351839066 -14.560390965461536
59 -64.2666340470314 -14.442420089224363
60 -36.54816475510597 -14.280669824338958
61 -31.13650117814541 -13.956113818182269
62 -34.73684096336365 -13.67405282962576
63 -33.413785964250565 -13.393678381917208
64 -33.65203958749771 -13.015726239087478
65 -30.802615374326706 -12.840649288269582
66 -31.72004147619009 -12.633806480141791
67 -23.76354306936264 -12.272084008794856
68 -33.17069661617279 -12.158969262874024
69 -21.14127253741026 -12.110810484439153
70 -35.68405741453171 -11.866880471017074
71 -31.459611639380455 -11.743538667886787
72 -20.809250965714455 -11.565345387673993
73 -19.825506016612053 -11.328232433230076
74 -18.811928883194923 -11.260315708541759
75 -25.39732800424099 -11.001003977864357
76 -22.284254789352417 -10.866047997251195
77 -23.421566739678383 -10.680016434355997
78 -41.697419852018356 -10.509692405085175
79 -30.003641605377197 -10.436701940411714
80 -29.91369739174843 -10.358207740128002
81 -54.00654447078705 -10.327681503524177
82 -18.771834425628185 -10.062468951839561
83 -15.699132047593594 -9.964273742726046
84 -17.291233494877815 -9.877879861822818
85 -18.10098221153021 -9.828047339644366
86 -30.712985455989838 -9.63753285840073
87 -29.017603367567062 -9.383101526029112
88 -33.29150350391865 -9.306495056458639
89 -22.93008963763714 -9.230834156022215
90 -18.008550070226192 -9.119002520581768
91 -15.935561068356037 -9.015397940224625
92 -34.04615817219019 -8.919265070330715
93 -35.09381330758333 -8.831210153312487
94 -16.71300780773163 -8.660765147495423
95 -32.165462870150805 -8.57934761599037
96 -31.563402011990547 -8.501158865322148
97 -16.69012713432312 -8.381597705343829
98 -30.26427713036537 -8.297957641021425
99 -17.254824116826057 -8.187949197711195
100 -16.75523492693901 -8.063270933680341
101 -13.916265696287155 -7.891961268035399
102 -17.895588278770447 -7.810674179763153
103 -18.6560540497303 -7.703431034670109
104 -16.385780410841107 -7.64204348129513
105 -33.5630849301815 -7.5273395904846705
106 -33.320937253534794 -7.3930449885939264
107 -27.758576579391956 -7.354979383611287
108 -31.70071153342724 -7.108938032985654
109 -16.98728660494089 -6.902355047160277
110 -35.00465968251228 -6.776946485018116
111 -32.05813975632191 -6.7220638398623045
112 -16.20546320080757 -6.546603156403991
113 -25.416551291942596 -6.4940351064209345
114 -28.1648630797863 -6.340536540052647
115 -36.35023579001427 -5.615796733870542
116 -25.225530683994293 -5.338579395002669
117 -22.34214147925377 -4.827572916892203
118 -23.09723511338234 -4.031048624093466
119 -20.63771867007017 -1.9136196540088464
train accuracy: 0.9977777777777778
validation accuracy: 1.0
[-74.17211785 -73.95782727 -73.26805818 -73.0186223  -72.71649503
 -72.53240426 -72.10762886 -71.31091253 -71.15257801 -71.06127544
 -70.899451   -70.80441266 -70.63515468 -70.62043016 -70.53269566
 -70.39681369 -70.35740546 -70.24539955 -70.17239217 -70.14769102
 -70.1139844  -69.97393649 -69.71058218 -69.68963454 -69.65328467
 -69.46999863 -69.41251292 -69.34855695 -69.31050315 -69.27065534
 -69.1350947  -69.08815837 -68.92907957 -68.89156511 -68.80237261
 -68.63219386 -68.61024866 -68.6068239  -68.60480039 -68.59498466
 -68.59342596 -68.5847388  -68.48500696 -68.46187963 -68.42673896
 -68.40256333 -68.05136636 -67.97875363 -67.96222764 -67.89072549
 -67.83054511 -67.7144862  -67.49051681 -67.47438541 -67.32750834
 -67.26714336 -67.25386762 -67.19962639 -67.14581154 -67.09124055
 -67.06251734 -67.00862004 -67.00637773 -66.98688062 -66.92540899
 -66.90335156 -66.8831681  -66.75857022 -66.67964391 -66.60163304
 -66.49461673 -66.39849672 -66.39360876 -66.29969197 -66.16764842
 -66.16472136 -66.00377018 -65.99300774 -65.96752013 -65.91634725
 -65.91354766 -65.78478981 -65.52872527 -65.50911485 -65.44338807
 -65.30439264 -65.28773769 -65.25277927 -65.25043604 -65.20473009
 -65.17397157 -65.09248013 -65.07355266 -65.04372698 -64.94248071
 -64.92267824 -64.86924824 -64.85665614 -64.79311473 -64.76596878
 -64.63676646 -64.19615668 -64.17049706 -64.02627761 -64.00194249
 -63.94691813 -63.87619084 -63.82346273 -63.41033423 -63.33300159
 -63.08645804 -62.957309   -62.90163285 -62.86266992 -62.76327897
 -62.73402621 -62.7214969  -62.23780065 -62.10576235 -62.08382901
 -61.80421912 -61.77633144 -61.36034637 -61.16005103 -61.13866388
 -61.04998096 -60.84862878 -60.6943887  -60.5875466  -60.51836728
 -60.46065756 -60.38718537 -60.38357794 -60.23840017 -60.04421813
 -60.02638645 -59.83403273 -59.81087215 -59.80758008 -59.79936937
 -59.72978889 -59.67377247 -59.67324583 -59.63573057 -59.479519
 -59.35183559 -59.3331544  -59.15376326 -59.11328063 -59.11108948
 -59.01375074 -59.0017195  -58.91020179 -58.90049235 -58.86177554
 -58.78056699 -58.76791277 -58.75873216 -58.73702192 -58.71874372
 -58.66878745 -58.52511233 -58.50468902 -58.43682135 -58.38369275
 -58.35114862 -58.32056422 -58.31876101 -58.21309823 -58.16259958
 -57.97295989 -57.95252047 -57.95121516 -57.88783722 -57.87472892
 -57.80603645 -57.79232597 -57.76792801 -57.73825517 -57.66311437
 -57.49003961 -57.44614089 -57.43534564 -57.3358511  -57.25402972
 -57.24021776 -57.17404009 -57.10705863 -57.02083028 -57.01031751
 -57.00777649 -56.93392957 -56.88941122 -56.87261742 -56.87019318
 -56.81723664 -56.76272566 -56.74396349 -56.66165036 -56.63445322
 -56.55228584 -56.48413654 -56.45964356 -56.43839989 -56.43035673
 -56.29921443 -56.26727436 -55.9921034  -55.94868324 -55.84721514
 -55.77551486 -55.72514104 -55.67181192 -55.64890947 -55.5140687
 -55.49655349 -55.4349547  -55.41620162 -55.21782741 -55.19969659
 -55.15334161 -54.98547503 -54.95774248 -54.84101147 -54.79798252
 -54.73427941 -54.37610836 -53.97452655 -53.88679139 -53.60251365
 -53.563251   -53.08471312 -53.05236476 -52.94548208 -52.77509559
 -52.75224363 -52.21075633 -52.18252397 -52.160559   -52.06238467
 -52.00276372 -50.4922686  -50.03933802 -49.75347185 -49.72654641
 -46.98011874 -45.73515428 -45.67057988 -44.99030608 -44.14602409
 -43.81326882 -43.18878399 -42.29180715 -42.00401746 -41.69100444
 -41.68588229 -41.2817771  -40.44278203 -40.34838366 -39.59970115
 -39.57586365 -39.31972693 -39.02461056 -38.45534494 -38.4127039
 -38.35634328 -37.79713617 -37.74152899 -37.66475324 -37.51313938
 -37.1809993  -37.10070314 -37.00630589 -36.82191677 -36.48799015
 -36.2096527  -36.19207562 -36.11445903 -35.78149902 -35.39450387
 -35.262825   -35.24303541 -35.20970524 -35.06544085 -34.80241748
 -34.64469045 -33.84284986 -32.70706485 -31.9690994  -31.7109134
 -31.64414356 -31.39238276 -31.22319602 -31.12953085 -29.3915714
 -29.34012561 -29.10618999 -27.4110235  -27.34372236 -27.19668163
 -27.07399029 -26.70472176 -26.2447949  -25.54836509 -25.45878529
 -24.879107   -24.82869536 -24.59274514 -23.97874558 -23.57262108
 -23.44970808 -22.74530916 -22.60679894 -22.19891032 -20.65686376
 -20.44447256 -20.1969901  -20.13839115 -19.63760344 -19.51559872
 -18.95826739 -18.9283881  -18.87905758 -18.7063571  -18.54530077
 -18.13131256 -17.99477406 -17.5574237  -17.40134513 -17.09350147
 -17.01473387 -16.9804259  -16.91589062 -16.82307393 -16.59067732
 -16.49040418 -16.48669442 -16.34426663 -16.33360514 -15.99002393
 -15.92560211 -15.92481331 -15.92378128 -15.50853283 -15.45216084
 -15.3078339  -15.19607379 -15.15037833 -15.13097011 -14.90448261
 -14.8550828  -14.77725123 -14.58138984 -14.56039097 -14.5314246
 -14.52058071 -14.46756371 -14.44242009 -14.37936197 -14.37201643
 -14.32766052 -14.3132018  -14.28066982 -14.19861518 -14.10024812
 -14.01199748 -13.95611382 -13.94274459 -13.87737941 -13.69184427
 -13.67405283 -13.66567776 -13.59601285 -13.52842465 -13.39367838
 -13.3738228  -13.18927336 -13.05267593 -13.01572624 -12.96689133
 -12.90426226 -12.86529864 -12.84064929 -12.76269483 -12.68135973
 -12.66418206 -12.63380648 -12.63264281 -12.46913248 -12.30017947
 -12.27208401 -12.25981587 -12.2351833  -12.23147123 -12.15896926
 -12.15190477 -12.13724316 -12.12247272 -12.11081048 -12.10575018
 -11.93810862 -11.92156759 -11.86688047 -11.80121495 -11.78885214
 -11.7543625  -11.74353867 -11.6317191  -11.59156179 -11.58343034
 -11.56534539 -11.5270303  -11.45861252 -11.39414499 -11.32823243
 -11.3208311  -11.29899183 -11.28918302 -11.26031571 -11.19038699
 -11.14616918 -11.12139973 -11.00100398 -10.99547072 -10.94167627
 -10.8699891  -10.866048   -10.8054964  -10.80253887 -10.7891748
 -10.68001643 -10.66078229 -10.53172231 -10.52922211 -10.50969241
 -10.49464447 -10.48068288 -10.45746496 -10.43670194 -10.38926265
 -10.38796419 -10.36589281 -10.35820774 -10.35155306 -10.3438193
 -10.33581168 -10.3276815  -10.30149061 -10.15906067 -10.11556218
 -10.06246895 -10.03721915  -9.99893971  -9.96903965  -9.96427374
  -9.94969155  -9.90109121  -9.88199546  -9.87787986  -9.85721598
  -9.85617682  -9.84130889  -9.82804734  -9.78843396  -9.68666716
  -9.68427725  -9.63753286  -9.63098169  -9.47759802  -9.4019298
  -9.38310153  -9.38200198  -9.36887733  -9.30919238  -9.30649506
  -9.27230868  -9.24176854  -9.23331784  -9.23083416  -9.17253092
  -9.12514882  -9.12002976  -9.11900252  -9.08136258  -9.0744544
  -9.03533012  -9.01539794  -8.98121386  -8.96615773  -8.96406066
  -8.91926507  -8.90040861  -8.84362927  -8.83554155  -8.83121015
  -8.82765866  -8.78362228  -8.70664425  -8.66076515  -8.65090717
  -8.61414944  -8.57936795  -8.57934762  -8.55272917  -8.5452769
  -8.50667687  -8.50115887  -8.49891995  -8.49500087  -8.39796704
  -8.38159771  -8.35138026  -8.330117    -8.32987796  -8.29795764
  -8.25777932  -8.23038631  -8.19204998  -8.1879492   -8.18156857
  -8.14296637  -8.13319584  -8.10819769  -8.06327093  -7.94856102
  -7.92763923  -7.9258916   -7.89196127  -7.86695292  -7.86647498
  -7.85400235  -7.81067418  -7.77133022  -7.75059405  -7.74872277
  -7.70343103  -7.6947421   -7.69300785  -7.69222111  -7.64204348
  -7.60251679  -7.57539849  -7.5367211   -7.52733959  -7.51537456
  -7.50355076  -7.46138035  -7.39304499  -7.38496157  -7.36244313
  -7.35910942  -7.35497938  -7.28652427  -7.26109967  -7.2130292
  -7.10893803  -7.10832736  -7.05002985  -6.95906356  -6.90235505
  -6.83665358  -6.83342605  -6.78946603  -6.77694649  -6.76080576
  -6.75186293  -6.72649057  -6.72206384  -6.71997062  -6.66285306
  -6.55290116  -6.54660316  -6.53544734  -6.51820418  -6.49459235
  -6.49403511  -6.47363627  -6.45693355  -6.35182029  -6.34053654
  -6.16321453  -6.15212877  -5.6890279   -5.61579673  -5.51691844
  -5.42493771  -5.3472021   -5.3385794   -5.33820923  -5.07848501
  -5.02795798  -4.82757292  -4.63049542  -4.60294814  -4.230832
  -4.03104862  -3.38446715  -3.3322555   -2.64166233  -1.91361965]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:2
end of epoch 0: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.5605e-01,  3.1418e-01,  4.6474e-01, -2.7688e-01,  2.0810e-05,
          2.1961e-05, -5.4845e-03,  2.8098e-06,  2.4343e-05,  1.6697e-01,
         -3.7692e-04, -2.9663e-01, -9.9962e-01]], device='cuda:2'))])
end of epoch 1: val_loss 3.5762775496550603e-09, val_acc 1.0
trigger times: 1
end of epoch 2: val_loss 2.98023181244389e-09, val_acc 1.0
trigger times: 2
end of epoch 3: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.6162e-01,  6.0657e-01,  1.3157e+00,  2.4569e-01,  2.8182e-01,
         -2.0691e-01, -1.3408e-02,  2.2134e-02, -3.5512e-01,  5.0125e-01,
         -3.7719e-04, -1.6486e+00, -2.0850e+00]], device='cuda:2'))])
end of epoch 4: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.1022e-01,  5.3479e-01,  1.2354e+00,  1.1779e-01,  2.7213e-06,
         -3.2580e-05, -1.2514e-02,  2.1548e-03,  5.5658e-05,  4.8339e-02,
         -3.7728e-04, -1.0910e+00, -2.0190e+00]], device='cuda:2'))])
end of epoch 5: val_loss 1.847740577431978e-08, val_acc 1.0
trigger times: 1
end of epoch 6: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.1689e-04,  5.4738e-05,  5.3202e-01, -1.1213e-04,  5.2873e-05,
          1.1290e-04, -5.2936e-03,  3.5344e-05,  4.2056e-04,  3.1578e-04,
         -3.7745e-04, -3.9615e-04, -1.4615e+00]], device='cuda:2'))])
end of epoch 7: val_loss 6.437284937987898e-08, val_acc 1.0
trigger times: 1
end of epoch 8: val_loss 1.883488948806189e-07, val_acc 1.0
trigger times: 2
end of epoch 9: val_loss 1.0788386049398469e-07, val_acc 1.0
trigger times: 3
end of epoch 10: val_loss 3.218640358682023e-08, val_acc 1.0
trigger times: 4
end of epoch 11: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.3426e-04, -2.1164e-04,  5.8738e-02,  3.9029e-05, -3.3565e-04,
         -1.8021e-04,  1.0337e-02, -1.0403e-05, -5.7158e-05, -1.9167e-04,
         -3.7791e-04,  3.1682e-04, -1.5926e+00]], device='cuda:2'))])
end of epoch 12: val_loss 0.0003289994410124564, val_acc 1.0
trigger times: 1
end of epoch 13: val_loss 4.501104413066059e-06, val_acc 1.0
trigger times: 2
end of epoch 14: val_loss 1.26360246213153e-07, val_acc 1.0
trigger times: 3
end of epoch 15: val_loss 1.3117260823491961e-06, val_acc 1.0
trigger times: 4
end of epoch 16: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.1561e-04, -1.2101e-04,  4.4725e-01, -1.0701e-04,  1.6444e-04,
         -3.9902e-04,  8.5007e-04, -4.7510e-07, -4.0862e-05,  6.1369e-04,
         -3.7844e-04, -1.0774e-03, -1.4953e+00]], device='cuda:2'))])
end of epoch 17: val_loss 2.8540070354938507, val_acc 0.97
trigger times: 1
end of epoch 18: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.0914e-01,  7.0357e-01,  1.7830e+00, -4.9895e-01,  9.3020e-06,
          1.3800e-04, -5.4345e-03, -1.2721e-01,  7.8182e-02,  4.5102e-01,
         -3.7865e-04, -1.0620e+00, -2.3881e+00]], device='cuda:2'))])
end of epoch 19: val_loss 3.1914061401039363e-06, val_acc 1.0
trigger times: 1
end of epoch 20: val_loss 1.40664978971472e-07, val_acc 1.0
trigger times: 2
end of epoch 21: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.9264e-01,  5.1579e-01,  1.4773e+00, -6.6127e-02,  2.5938e-02,
          1.8736e-01,  1.0940e-02, -3.3424e-01, -2.6874e-01, -6.8474e-05,
         -3.7896e-04, -8.8136e-01, -2.9954e+00]], device='cuda:2'))])
end of epoch 22: val_loss 2.3841852225814363e-09, val_acc 1.0
trigger times: 1
end of epoch 23: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.3341e-05,  2.3109e-01,  1.0558e+00,  6.4945e-05, -9.4486e-05,
         -1.1641e-04,  4.7864e-03, -2.1781e-01,  6.6612e-05, -4.4346e-04,
         -3.7917e-04, -2.1398e-04, -2.5651e+00]], device='cuda:2'))])
end of epoch 24: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 8.4857e-05,  3.0165e-06,  3.1910e-01,  8.8087e-05, -2.1992e-04,
         -3.8132e-04,  7.4004e-07, -1.4120e-02, -5.4718e-04, -1.0175e-03,
         -3.7927e-04, -1.1720e-05, -1.8129e+00]], device='cuda:2'))])
end of epoch 25: val_loss 1.7290893306775206, val_acc 0.935
trigger times: 1
end of epoch 26: val_loss 2.3841852225814363e-09, val_acc 1.0
trigger times: 2
end of epoch 27: val_loss 4.244558978825808e-05, val_acc 1.0
trigger times: 3
end of epoch 28: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.9672e-01,  8.4922e-01,  1.4887e+00, -9.0954e-02,  5.9997e-01,
         -6.7370e-01, -2.3488e-02, -1.0011e-01, -3.8129e-01,  3.4351e-01,
         -3.7969e-04, -7.7397e-01, -3.6978e+00]], device='cuda:2'))])
end of epoch 29: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.7570e-01,  7.1502e-01,  1.3402e+00,  3.3842e-05, -9.8221e-05,
         -5.8029e-02, -2.1880e-02, -6.0096e-02,  5.8428e-05,  8.2892e-05,
         -3.7980e-04, -1.0992e-05, -3.5809e+00]], device='cuda:2'))])
end of epoch 30: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.2384e-04,  3.8487e-01,  9.7483e-01, -2.2142e-05, -8.0701e-05,
         -1.6620e-04, -1.7924e-02,  7.0845e-06,  3.3283e-04,  1.9351e-04,
         -3.7990e-04, -4.4049e-06, -3.2935e+00]], device='cuda:2'))])
end of epoch 31: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-3.1478e-04, -8.6322e-05,  7.6840e-02, -6.3842e-05, -2.2505e-04,
         -5.0582e-04, -8.1883e-03,  1.7454e-05, -2.6853e-04,  4.3912e-04,
         -3.8001e-04,  5.0513e-04, -2.5868e+00]], device='cuda:2'))])
end of epoch 32: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-7.6230e-04, -4.5095e-06, -5.3935e-05,  3.1656e-04, -4.5326e-04,
         -1.1177e-03,  7.2013e-07,  4.2926e-05, -4.1820e-04,  8.1661e-04,
         -3.8011e-04,  3.4231e-04, -8.5582e-01]], device='cuda:2'))])
end of epoch 33: val_loss 2.783358213491738e-06, val_acc 1.0
trigger times: 1
end of epoch 34: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 6.3865e-01,  9.1770e-01,  1.4721e+00, -5.9085e-02, -1.8864e-01,
         -2.2100e-01, -3.8542e-03, -6.4445e-02,  1.4473e-01,  6.2005e-02,
         -3.8032e-04, -3.8835e-01, -2.6182e+00]], device='cuda:2'))])
end of epoch 35: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.9931e-01,  6.7902e-01,  1.2848e+00, -6.3648e-05, -4.0525e-05,
         -1.0727e-04, -1.1697e-03, -8.5327e-06, -2.2225e-04,  3.6435e-05,
         -3.8043e-04, -8.9339e-05, -2.4373e+00]], device='cuda:2'))])
end of epoch 36: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.0336e-05,  8.8275e-02,  8.2953e-01, -9.7022e-06,  1.1791e-04,
         -2.2519e-04, -9.1597e-07,  9.5818e-06,  2.6657e-04, -6.6288e-04,
         -3.8053e-04, -5.0999e-04, -1.9887e+00]], device='cuda:2'))])
end of epoch 37: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.9929e-04, -2.0784e-04,  1.1886e-04, -1.6926e-04,  8.0698e-05,
          2.0216e-04,  8.2589e-07, -4.6091e-05, -5.5343e-05,  5.5809e-04,
         -3.8064e-04, -4.8019e-04, -8.9707e-01]], device='cuda:2'))])
end of epoch 38: val_loss 2.747396647464484e-06, val_acc 1.0
trigger times: 1
end of epoch 39: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 7.0329e-01,  3.9842e-01,  1.5571e+00, -2.4665e-01, -2.2939e-01,
          1.1066e-03, -1.1052e-02,  6.6531e-02,  1.1632e-01,  1.1959e-01,
         -3.8085e-04, -8.5910e-01, -2.2641e+00]], device='cuda:2'))])
end of epoch 40: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.1326e-01,  3.2364e-01,  1.2285e+00, -1.0463e-01, -8.1575e-05,
         -1.0118e-04, -1.2610e-02, -4.6851e-04, -4.7347e-06,  6.1760e-06,
         -3.8095e-04, -2.7331e-04, -2.1209e+00]], device='cuda:2'))])
end of epoch 41: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.6251e-05,  2.0041e-02,  6.4517e-01, -3.1582e-05,  1.5749e-04,
          4.2200e-04, -9.2603e-03, -8.3257e-06,  6.6470e-04,  1.9795e-04,
         -3.8106e-04, -2.9600e-04, -1.7012e+00]], device='cuda:2'))])
end of epoch 42: val_loss 5.364416608699685e-09, val_acc 1.0
trigger times: 1
end of epoch 43: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.1670e-01,  5.9041e-01,  1.2658e+00, -3.7100e-01,  4.3839e-01,
         -6.2928e-01,  1.1380e-02, -1.6200e-01, -1.1552e-01,  7.2029e-01,
         -3.8127e-04, -6.3883e-01, -2.3697e+00]], device='cuda:2'))])
end of epoch 44: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.3759e-01,  4.9082e-01,  1.1332e+00, -2.1283e-01, -2.6580e-05,
         -9.1702e-02,  1.0129e-02, -1.3323e-01, -4.3962e-05,  1.4573e-01,
         -3.8137e-04,  3.9310e-05, -2.2772e+00]], device='cuda:2'))])
end of epoch 45: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.9260e-06,  2.4576e-01,  8.0701e-01,  7.0101e-05,  3.7655e-05,
          1.0218e-04,  7.0490e-03, -6.2451e-02, -1.0901e-04,  1.4404e-04,
         -3.8148e-04, -1.0199e-04, -2.0496e+00]], device='cuda:2'))])
end of epoch 46: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.8618e-04,  1.9649e-05,  5.1017e-03, -1.5076e-04,  2.9269e-04,
          1.7869e-04,  3.8131e-07, -7.9944e-06, -2.6261e-04,  2.8987e-04,
         -3.8158e-04,  9.0042e-04, -1.4899e+00]], device='cuda:2'))])
end of epoch 47: val_loss 0.475847463607665, val_acc 0.955
trigger times: 1
end of epoch 48: val_loss 2.240814734250307e-05, val_acc 1.0
trigger times: 2
end of epoch 49: val_loss 1.013277938000101e-08, val_acc 1.0
trigger times: 3
end of epoch 50: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.0041e-05,  3.9466e-05,  1.6892e-01,  9.6362e-05, -2.3217e-04,
          4.8701e-04, -7.3708e-04,  9.3031e-06, -1.4624e-04, -2.2083e-04,
         -3.8200e-04, -8.3587e-05, -9.5886e-01]], device='cuda:2'))])
end of epoch 51: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 1
end of epoch 52: val_loss 2.3304872229346074e-07, val_acc 1.0
trigger times: 2
end of epoch 53: val_loss 3.516661763569573e-08, val_acc 1.0
trigger times: 3
end of epoch 54: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 8.8409e-01,  6.5885e-01,  1.6049e+00, -3.0916e-01, -8.5606e-02,
         -4.6069e-01,  9.7847e-03, -2.6105e-01,  3.3964e-01,  4.5328e-01,
         -3.8242e-04, -1.0251e+00, -3.1550e+00]], device='cuda:2'))])
end of epoch 55: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 6.7391e-01,  5.5772e-01,  1.4921e+00, -1.6260e-01, -3.8015e-05,
         -1.5273e-04,  8.5448e-03, -2.3528e-01, -6.8944e-05, -8.9853e-06,
         -3.8252e-04, -6.2325e-05, -3.0654e+00]], device='cuda:2'))])
end of epoch 56: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.5693e-01,  3.0890e-01,  1.2146e+00,  7.3763e-05,  6.8069e-06,
         -2.2104e-04,  5.4938e-03, -1.7187e-01, -1.6621e-04, -1.3721e-05,
         -3.8263e-04, -1.4431e-04, -2.8448e+00]], device='cuda:2'))])
end of epoch 57: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.6497e-05,  2.5313e-04,  5.3229e-01,  1.8407e-04, -8.0934e-08,
          2.8923e-06,  9.3230e-07, -1.5842e-02, -4.2107e-04, -3.0592e-05,
         -3.8273e-04, -3.0801e-04, -2.3024e+00]], device='cuda:2'))])
end of epoch 58: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.7293e-04,  6.1010e-04, -3.8373e-04,  4.4965e-04,  1.6900e-04,
         -2.0869e-05,  2.0881e-06,  4.1865e-05, -9.1284e-04, -6.4043e-05,
         -3.8284e-04, -5.0273e-04, -9.7127e-01]], device='cuda:2'))])
end of epoch 59: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 8.4263e-01,  5.3894e-01,  1.2843e+00, -1.5430e-01,  8.6529e-02,
         -7.6301e-05,  2.2272e-03, -7.1938e-02, -7.1965e-06, -6.9998e-06,
         -3.8294e-04, -8.9710e-01, -2.6765e+00]], device='cuda:2'))])
end of epoch 60: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 6.5819e-01,  4.3305e-01,  1.1864e+00,  6.0471e-07,  2.3993e-05,
         -1.9509e-04,  1.1807e-03, -4.2595e-02, -1.7145e-05, -2.9394e-05,
         -3.8305e-04, -1.2477e-01, -2.5979e+00]], device='cuda:2'))])
end of epoch 61: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.0448e-01,  1.7250e-01,  9.4578e-01, -2.1149e-05,  6.5879e-05,
         -4.8492e-04,  4.0705e-07,  1.3980e-06, -4.1429e-05, -8.7305e-05,
         -3.8315e-04, -1.9967e-04, -2.4045e+00]], device='cuda:2'))])
end of epoch 62: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.4241e-04, -1.1897e-04,  3.5392e-01, -5.7374e-05,  1.6532e-04,
         -1.1633e-03,  1.0446e-06,  2.8860e-05, -9.8449e-05, -2.2332e-04,
         -3.8326e-04,  8.3949e-05, -1.9287e+00]], device='cuda:2'))])
end of epoch 63: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.4278e-04,  5.1442e-04, -1.7604e-04, -1.4429e-04,  3.6774e-04,
         -2.4508e-03,  2.2978e-06,  5.7361e-05, -2.0822e-04, -4.8544e-04,
         -3.8336e-04,  1.1122e-04, -7.6035e-01]], device='cuda:2'))])
end of epoch 64: val_loss 1.1920927533992654e-09, val_acc 1.0
trigger times: 1
end of epoch 65: val_loss 0.0002336135506629944, val_acc 1.0
trigger times: 2
end of epoch 66: val_loss 1.3029273832216859e-05, val_acc 1.0
trigger times: 3
end of epoch 67: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.5025e-01,  6.6006e-01,  1.5814e+00, -2.1338e-01,  5.6554e-01,
         -7.2262e-02, -1.6600e-02, -1.5413e-01, -2.1964e-01, -1.7561e-02,
         -3.8378e-04, -1.3024e+00, -3.7569e+00]], device='cuda:2'))])
end of epoch 68: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.7158e-02,  5.9201e-01,  1.4731e+00, -2.5491e-02,  2.6201e-01,
         -3.1768e-05,  3.1644e-02, -1.2656e-01, -4.1899e-05, -6.5579e-05,
         -3.8388e-04, -7.3260e-01, -3.7492e+00]], device='cuda:2'))])
end of epoch 69: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.6820e-05,  3.8933e-01,  1.2150e+00,  4.4822e-05,  1.0077e-04,
         -1.0210e-04,  2.9469e-02, -6.1203e-02, -1.0006e-04, -1.6807e-04,
         -3.8399e-04, -3.0239e-04, -3.5859e+00]], device='cuda:2'))])
end of epoch 70: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-6.1847e-05, -1.1734e-04,  5.8041e-01, -2.1078e-04,  1.7432e-04,
         -2.6965e-04,  2.4115e-02, -1.7815e-06, -2.3981e-04,  2.8434e-04,
         -3.8409e-04, -7.1014e-04, -3.1843e+00]], device='cuda:2'))])
end of epoch 71: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.4605e-04, -2.6923e-04, -4.2933e-05, -5.2809e-04,  3.3337e-04,
         -6.1511e-04,  1.0941e-02,  1.5472e-05, -5.4068e-04,  5.5105e-04,
         -3.8420e-04, -1.4693e-03, -2.1974e+00]], device='cuda:2'))])
end of epoch 72: val_loss 0.0007903982389370867, val_acc 1.0
trigger times: 1
end of epoch 73: val_loss 2.3841852225814363e-09, val_acc 1.0
trigger times: 2
end of epoch 74: val_loss 8.894633501768113e-06, val_acc 1.0
trigger times: 3
end of epoch 75: val_loss 4.559547596727498e-07, val_acc 1.0
trigger times: 4
end of epoch 76: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-7.0767e-05,  2.8193e-05,  4.2801e-01, -2.3760e-04, -1.6565e-04,
          1.2378e-04, -3.9773e-03, -2.4474e-05,  4.9572e-04,  2.0346e-04,
         -3.8472e-04,  4.1840e-04, -1.6669e+00]], device='cuda:2'))])
end of epoch 77: val_loss 0.6513037109375, val_acc 0.99
trigger times: 1
end of epoch 78: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 6.3912e-01,  7.4553e-01,  1.1046e+00,  1.9412e-04,  9.5215e-02,
          1.8731e-05, -1.4322e-02, -1.0422e-01, -8.8705e-06,  1.6151e-01,
         -3.8493e-04, -1.0294e+00, -2.0559e+00]], device='cuda:2'))])
end of epoch 79: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.5155e-01,  6.1107e-01,  9.3515e-01,  1.6088e-05,  4.7341e-05,
         -9.8592e-05, -1.2612e-02, -6.7985e-02, -4.1329e-05,  1.1479e-04,
         -3.8504e-04,  1.5011e-04, -1.9240e+00]], device='cuda:2'))])
end of epoch 80: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-4.7494e-05,  2.8027e-01,  5.1821e-01, -4.0578e-05, -2.3251e-04,
         -2.1800e-04, -8.4051e-03, -1.3833e-06,  1.9523e-04, -4.8868e-04,
         -3.8514e-04,  1.0569e-04, -1.5995e+00]], device='cuda:2'))])
end of epoch 81: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.5991e-04, -1.4672e-04, -1.1842e-04, -1.0082e-04, -6.2921e-04,
         -4.8952e-04, -1.2572e-07, -1.1689e-05,  3.7948e-04,  9.1590e-04,
         -3.8525e-04, -2.0060e-04, -8.0188e-01]], device='cuda:2'))])
end of epoch 82: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 7.2590e-01,  4.7858e-01,  8.7469e-01, -9.2419e-02,  3.4659e-01,
          1.9798e-05, -9.7278e-03,  5.2044e-02, -3.9161e-01,  2.9754e-01,
         -3.8535e-04, -6.5654e-01, -1.5527e+00]], device='cuda:2'))])
end of epoch 83: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 1
end of epoch 84: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-5.1638e-05,  5.7914e-05,  3.6471e-01, -4.8862e-05, -3.0751e-04,
          1.8935e-04, -4.1070e-03,  2.0289e-05, -6.5478e-05,  2.2160e-04,
         -3.8556e-04, -6.2773e-05, -1.1481e+00]], device='cuda:2'))])
end of epoch 85: val_loss 1.71064215486183e-07, val_acc 1.0
trigger times: 1
end of epoch 86: val_loss 7.1525522571391775e-09, val_acc 1.0
trigger times: 2
end of epoch 87: val_loss 6.13890151726082e-07, val_acc 1.0
trigger times: 3
end of epoch 88: val_loss 3.218640358682023e-08, val_acc 1.0
trigger times: 4
end of epoch 89: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.0009e-06,  5.5780e-05, -4.3174e-05, -1.6929e-04, -6.6727e-04,
          1.0691e-04,  7.1271e-07,  7.1446e-06,  3.7208e-04, -3.4164e-05,
         -3.8609e-04, -1.6461e-03, -8.0911e-01]], device='cuda:2'))])
end of epoch 90: val_loss 3.635875913232667e-08, val_acc 1.0
trigger times: 1
end of epoch 91: val_loss 3.814687730141486e-08, val_acc 1.0
trigger times: 2
end of epoch 92: val_loss 7.569732588308397e-08, val_acc 1.0
trigger times: 3
end of epoch 93: val_loss 4.47034013362213e-08, val_acc 1.0
trigger times: 4
end of epoch 94: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 8.6127e-01,  7.1951e-01,  1.3594e+00,  3.7268e-01,  7.0011e-02,
         -6.4050e-02,  1.1646e-02, -1.3521e-01, -2.8735e-02,  8.4030e-02,
         -3.8661e-04, -1.4736e+00, -2.7158e+00]], device='cuda:2'))])
end of epoch 95: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 7.1346e-01,  5.9023e-01,  1.2461e+00,  8.7690e-02, -1.2176e-06,
          1.0164e-04,  1.0631e-02, -9.4249e-02, -2.4188e-05,  6.0324e-05,
         -3.8671e-04, -5.9547e-01, -2.6393e+00]], device='cuda:2'))])
end of epoch 96: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.4980e-01,  2.7215e-01,  9.6750e-01, -6.2821e-05, -5.2234e-05,
          2.4739e-04,  8.1313e-03,  1.7153e-06, -6.4014e-05,  2.9129e-05,
         -3.8682e-04, -3.6839e-04, -2.4511e+00]], device='cuda:2'))])
end of epoch 97: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.8315e-06,  2.9485e-05,  2.8241e-01, -1.2000e-04,  7.3447e-05,
          5.9265e-04,  1.9811e-03,  9.8468e-06, -1.5809e-04,  8.7397e-04,
         -3.8692e-04, -7.4092e-04, -1.9880e+00]], device='cuda:2'))])
end of epoch 98: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.5445e-05,  2.0796e-04,  3.6305e-04, -2.4998e-04,  2.0712e-04,
          1.2853e-03, -9.8911e-07,  3.0357e-05, -3.4439e-04, -2.0475e-03,
         -3.8703e-04, -1.3020e-03, -8.5094e-01]], device='cuda:2'))])
end of epoch 99: val_loss 5.817074998049066e-07, val_acc 1.0
trigger times: 1
Finished training.
0 -99.80436086654663 -74.1721178479907
1 -100.17091035842896 -72.53240425614226
2 -86.61724424362183 -70.8994510047542
3 -91.30652713775635 -70.39681369496377
4 -85.54979622364044 -70.11398439797705
5 -100.01089251041412 -69.46999863324044
6 -95.46115285158157 -69.13509469721924
7 -100.19673717021942 -68.63219385965232
8 -84.12089967727661 -68.5934259629071
9 -98.74793589115143 -68.40256332590795
10 -95.56833040714264 -67.83054510718824
11 -95.08337903022766 -67.26714336425908
12 -95.68075335025787 -67.06251733755995
13 -86.02474403381348 -66.90335156316253
14 -83.38778030872345 -66.49461672695084
15 -84.16675734519958 -66.00377018313415
16 -92.6943724155426 -65.78478981041695
17 -93.67725038528442 -65.28773768816716
18 -88.75366270542145 -65.09248013366215
19 -90.73323726654053 -64.8692482426243
20 -82.77407538890839 -64.19615667823099
21 -81.3232057094574 -63.87619083665447
22 -83.86824345588684 -62.957308997795835
23 -88.75707018375397 -62.72149690379113
24 -195.61346852779388 -61.776331442264365
25 -83.85684657096863 -60.848628782598574
26 -206.3248289823532 -60.38718536542509
27 -212.4551910161972 -59.83403272829647
28 -208.15459871292114 -59.673772474088956
29 -202.0409119129181 -59.333154400945965
30 -191.33099734783173 -59.001719499099124
31 -207.357661485672 -58.76791276501542
32 -202.45818984508514 -58.525112330336405
33 -202.0169038772583 -58.320564222040005
34 -207.1153109073639 -57.95252047370761
35 -192.13893067836761 -57.79232597100083
36 -189.4852979183197 -57.4461408949042
37 -193.68340229988098 -57.1740400851804
38 -196.49558651447296 -56.93392956513718
39 -203.2924132347107 -56.76272565813944
40 -201.28015673160553 -56.484136535549545
41 -202.18859660625458 -56.267274364894455
42 -200.19156289100647 -55.72514103936067
43 -190.65224397182465 -55.43495470216553
44 -116.34730327129364 -54.98547503240923
45 -199.11976552009583 -53.97452655055861
46 -192.78174948692322 -53.052364763466606
47 -188.4299157857895 -52.18252396613792
48 -51.06710132956505 -50.03933801517046
49 -79.54838466644287 -45.670579884154705
50 -77.41575455665588 -42.29180714825394
51 -61.292328387498856 -40.44278203413966
52 -37.74613565206528 -39.024610555047154
53 -57.60739266872406 -37.741528994987384
54 -51.98057273030281 -37.00630588930485
55 -60.25481218099594 -36.114459029559086
56 -39.81468769907951 -35.209705244501436
57 -24.738758265972137 -32.70706485357069
58 -29.609934955835342 -31.223196019713853
59 -67.28215003013611 -27.41102349748205
60 20.650070071220398 -26.244794902859052
61 -51.203282192349434 -24.592745144504722
62 -77.98290690779686 -22.60679894414887
63 -19.885637164115906 -20.13839114930498
64 77.06448572874069 -18.87905758287616
65 -3.3477068692445755 -17.55742370467821
66 81.9123272895813 -16.915890622226563
67 71.68663695454597 -16.344266629445098
68 83.51645070314407 -15.923781284507067
69 75.6888116300106 -15.150378332064733
70 11.2132468521595 -14.5813898350114
71 -39.55643077194691 -14.442420089224363
72 70.96589398384094 -14.280669824338958
73 59.21126139163971 -13.942744593566932
74 31.45703211426735 -13.596012850960644
75 75.04174762964249 -13.015726239087478
76 73.06290888786316 -12.762694828821783
77 73.71181380748749 -12.469132478750263
78 69.16193091869354 -12.231471230015076
79 16.032242998480797 -12.110810484439153
80 -24.416979379951954 -11.801214951705882
81 75.3330528140068 -11.591561793686814
82 67.91078341007233 -11.394144985793808
83 16.066726252436638 -11.260315708541759
84 -27.8839730322361 -10.995470723246697
85 12.899708360433578 -10.80253887494433
86 70.4810471534729 -10.52922210813378
87 75.81129711866379 -10.436701940411714
88 10.551096051931381 -10.351553064761587
89 54.75435620546341 -10.159060666643725
90 -41.801043348386884 -9.96903964512557
91 9.341384701430798 -9.877879861822818
92 11.416758105158806 -9.788433955884193
93 -1.9853484518826008 -9.477598024956635
94 73.05753335356712 -9.309192380086348
95 12.569048672914505 -9.230834156022215
96 10.282051965594292 -9.08136258399302
97 -0.6854487843811512 -8.966157734696775
98 13.6509994789958 -8.835541545242977
99 14.9152487590909 -8.660765147495423
100 7.036278277635574 -8.552729172085996
101 64.87899005413055 -8.495000865396662
102 75.26685282588005 -8.329877957545065
103 1.6038811206817627 -8.187949197711195
104 15.867268741130829 -8.063270933680341
105 -63.13443674147129 -7.866474981674106
106 -58.88238491117954 -7.748722774635732
107 10.461931481957436 -7.64204348129513
108 10.707030475139618 -7.515374561238876
109 54.31831356883049 -7.362443126623615
110 9.967789687216282 -7.213029198554223
111 9.302347138524055 -6.902355047160277
112 10.003050744533539 -6.760805759962728
113 80.6183013021946 -6.662853064341674
114 75.62213981151581 -6.494592345417679
115 73.87873309850693 -6.340536540052647
116 14.067481108009815 -5.5169184390887445
117 52.73591595888138 -5.078485007852753
118 -28.68707464635372 -4.230832004686763
119 40.47136980295181 -1.9136196540088464
train accuracy: 1.0
validation accuracy: 1.0
[-74.17211785 -73.95782727 -73.26805818 -73.0186223  -72.71649503
 -72.53240426 -72.10762886 -71.31091253 -71.15257801 -71.06127544
 -70.899451   -70.80441266 -70.63515468 -70.62043016 -70.53269566
 -70.39681369 -70.35740546 -70.24539955 -70.17239217 -70.14769102
 -70.1139844  -69.97393649 -69.71058218 -69.68963454 -69.65328467
 -69.46999863 -69.41251292 -69.34855695 -69.31050315 -69.27065534
 -69.1350947  -69.08815837 -68.92907957 -68.89156511 -68.80237261
 -68.63219386 -68.61024866 -68.6068239  -68.60480039 -68.59498466
 -68.59342596 -68.5847388  -68.48500696 -68.46187963 -68.42673896
 -68.40256333 -68.05136636 -67.97875363 -67.96222764 -67.89072549
 -67.83054511 -67.7144862  -67.49051681 -67.47438541 -67.32750834
 -67.26714336 -67.25386762 -67.19962639 -67.14581154 -67.09124055
 -67.06251734 -67.00862004 -67.00637773 -66.98688062 -66.92540899
 -66.90335156 -66.8831681  -66.75857022 -66.67964391 -66.60163304
 -66.49461673 -66.39849672 -66.39360876 -66.29969197 -66.16764842
 -66.16472136 -66.00377018 -65.99300774 -65.96752013 -65.91634725
 -65.91354766 -65.78478981 -65.52872527 -65.50911485 -65.44338807
 -65.30439264 -65.28773769 -65.25277927 -65.25043604 -65.20473009
 -65.17397157 -65.09248013 -65.07355266 -65.04372698 -64.94248071
 -64.92267824 -64.86924824 -64.85665614 -64.79311473 -64.76596878
 -64.63676646 -64.19615668 -64.17049706 -64.02627761 -64.00194249
 -63.94691813 -63.87619084 -63.82346273 -63.41033423 -63.33300159
 -63.08645804 -62.957309   -62.90163285 -62.86266992 -62.76327897
 -62.73402621 -62.7214969  -62.23780065 -62.10576235 -62.08382901
 -61.80421912 -61.77633144 -61.36034637 -61.16005103 -61.13866388
 -61.04998096 -60.84862878 -60.6943887  -60.5875466  -60.51836728
 -60.46065756 -60.38718537 -60.38357794 -60.23840017 -60.04421813
 -60.02638645 -59.83403273 -59.81087215 -59.80758008 -59.79936937
 -59.72978889 -59.67377247 -59.67324583 -59.63573057 -59.479519
 -59.35183559 -59.3331544  -59.15376326 -59.11328063 -59.11108948
 -59.01375074 -59.0017195  -58.91020179 -58.90049235 -58.86177554
 -58.78056699 -58.76791277 -58.75873216 -58.73702192 -58.71874372
 -58.66878745 -58.52511233 -58.50468902 -58.43682135 -58.38369275
 -58.35114862 -58.32056422 -58.31876101 -58.21309823 -58.16259958
 -57.97295989 -57.95252047 -57.95121516 -57.88783722 -57.87472892
 -57.80603645 -57.79232597 -57.76792801 -57.73825517 -57.66311437
 -57.49003961 -57.44614089 -57.43534564 -57.3358511  -57.25402972
 -57.24021776 -57.17404009 -57.10705863 -57.02083028 -57.01031751
 -57.00777649 -56.93392957 -56.88941122 -56.87261742 -56.87019318
 -56.81723664 -56.76272566 -56.74396349 -56.66165036 -56.63445322
 -56.55228584 -56.48413654 -56.45964356 -56.43839989 -56.43035673
 -56.29921443 -56.26727436 -55.9921034  -55.94868324 -55.84721514
 -55.77551486 -55.72514104 -55.67181192 -55.64890947 -55.5140687
 -55.49655349 -55.4349547  -55.41620162 -55.21782741 -55.19969659
 -55.15334161 -54.98547503 -54.95774248 -54.84101147 -54.79798252
 -54.73427941 -54.37610836 -53.97452655 -53.88679139 -53.60251365
 -53.563251   -53.08471312 -53.05236476 -52.94548208 -52.77509559
 -52.75224363 -52.21075633 -52.18252397 -52.160559   -52.06238467
 -52.00276372 -50.4922686  -50.03933802 -49.75347185 -49.72654641
 -46.98011874 -45.73515428 -45.67057988 -44.99030608 -44.14602409
 -43.81326882 -43.18878399 -42.29180715 -42.00401746 -41.69100444
 -41.68588229 -41.2817771  -40.44278203 -40.34838366 -39.59970115
 -39.57586365 -39.31972693 -39.02461056 -38.45534494 -38.4127039
 -38.35634328 -37.79713617 -37.74152899 -37.66475324 -37.51313938
 -37.1809993  -37.10070314 -37.00630589 -36.82191677 -36.48799015
 -36.2096527  -36.19207562 -36.11445903 -35.78149902 -35.39450387
 -35.262825   -35.24303541 -35.20970524 -35.06544085 -34.80241748
 -34.64469045 -33.84284986 -32.70706485 -31.9690994  -31.7109134
 -31.64414356 -31.39238276 -31.22319602 -31.12953085 -29.3915714
 -29.34012561 -29.10618999 -27.4110235  -27.34372236 -27.19668163
 -27.07399029 -26.70472176 -26.2447949  -25.54836509 -25.45878529
 -24.879107   -24.82869536 -24.59274514 -23.97874558 -23.57262108
 -23.44970808 -22.74530916 -22.60679894 -22.19891032 -20.65686376
 -20.44447256 -20.1969901  -20.13839115 -19.63760344 -19.51559872
 -18.95826739 -18.9283881  -18.87905758 -18.7063571  -18.54530077
 -18.13131256 -17.99477406 -17.5574237  -17.40134513 -17.09350147
 -17.01473387 -16.9804259  -16.91589062 -16.82307393 -16.59067732
 -16.49040418 -16.48669442 -16.34426663 -16.33360514 -15.99002393
 -15.92560211 -15.92481331 -15.92378128 -15.62905519 -15.58859275
 -15.50853283 -15.45216084 -15.3078339  -15.24846554 -15.19607379
 -15.15037833 -15.13097011 -14.95993861 -14.90448261 -14.8550828
 -14.77725123 -14.70803207 -14.60367065 -14.58138984 -14.56039097
 -14.53457164 -14.5314246  -14.52058071 -14.51805728 -14.46756371
 -14.44242009 -14.37936197 -14.37201643 -14.32766052 -14.31590308
 -14.3132018  -14.28066982 -14.26585911 -14.19861518 -14.1672544
 -14.10024812 -14.01199748 -13.95611382 -13.94274459 -13.87737941
 -13.81728443 -13.78494613 -13.77729914 -13.69184427 -13.67405283
 -13.66567776 -13.65289981 -13.63531017 -13.62102107 -13.59601285
 -13.59577016 -13.52842465 -13.52065533 -13.41432468 -13.41323139
 -13.3989988  -13.39367838 -13.3738228  -13.35777352 -13.32482296
 -13.26277885 -13.19749602 -13.18927336 -13.18685989 -13.11366442
 -13.05267593 -13.02745666 -13.01572624 -12.96689133 -12.94365623
 -12.90426226 -12.8745753  -12.87193036 -12.86529864 -12.84064929
 -12.76269483 -12.75458949 -12.68135973 -12.67038963 -12.66418206
 -12.63380648 -12.63264281 -12.5549764  -12.52574124 -12.46913248
 -12.30017947 -12.27208401 -12.25981587 -12.2351833  -12.23147123
 -12.19240693 -12.15896926 -12.15190477 -12.13724316 -12.12247272
 -12.11081048 -12.10575018 -11.93810862 -11.92156759 -11.86688047
 -11.83332939 -11.82025112 -11.80121495 -11.78885214 -11.7636485
 -11.7543625  -11.74353867 -11.6317191  -11.62556278 -11.62395156
 -11.59156179 -11.58343034 -11.56534539 -11.5270303  -11.45861252
 -11.39414499 -11.35353684 -11.32823243 -11.3208311  -11.29899183
 -11.28918302 -11.26031571 -11.19038699 -11.14616918 -11.12139973
 -11.11318052 -11.00100398 -10.99547072 -10.94167627 -10.93738171
 -10.90474105 -10.8863843  -10.8699891  -10.86698825 -10.866048
 -10.86572163 -10.8054964  -10.80253887 -10.7891748  -10.6995802
 -10.68001643 -10.66960816 -10.66078229 -10.62762616 -10.55216091
 -10.53172231 -10.52922211 -10.52602619 -10.50969241 -10.49500771
 -10.49464447 -10.49136356 -10.48068288 -10.45746496 -10.43670194
 -10.41709345 -10.38926265 -10.38796419 -10.37500487 -10.37029065
 -10.36589281 -10.35820774 -10.35155306 -10.3438193  -10.33581168
 -10.3276815  -10.30149061 -10.24868148 -10.15906067 -10.12580413
 -10.11556218 -10.06246895 -10.03971305 -10.03721915 -10.01958495
  -9.99893971  -9.96903965  -9.96427374  -9.94969155  -9.90109121
  -9.88199546  -9.87787986  -9.87386875  -9.86044406  -9.85721598
  -9.85617682  -9.84130889  -9.82804734  -9.78843396  -9.73483575
  -9.68666716  -9.68427725  -9.6518249   -9.63753286  -9.63098169
  -9.60984242  -9.60601768  -9.47759802  -9.4019298   -9.38310153
  -9.38200198  -9.36887733  -9.30919238  -9.30649506  -9.27230868
  -9.24176854  -9.23331784  -9.23083416  -9.17253092  -9.12514882
  -9.12002976  -9.11900252  -9.08136258  -9.07904889  -9.0776691
  -9.0744544   -9.03533012  -9.01539794  -8.98121386  -8.98029062
  -8.96615773  -8.96406066  -8.91926507  -8.90040861  -8.84362927
  -8.83554155  -8.83121015  -8.82765866  -8.78362228  -8.7571979
  -8.72777815  -8.70664425  -8.69402853  -8.69124989  -8.66076515
  -8.65090717  -8.61414944  -8.61275301  -8.57936795  -8.57934762
  -8.55272917  -8.5452769   -8.51333535  -8.50667687  -8.50115887
  -8.49891995  -8.49500087  -8.49266397  -8.47787963  -8.39796704
  -8.38159771  -8.35138026  -8.34346506  -8.330117    -8.32987796
  -8.32055374  -8.29795764  -8.29448914  -8.26011664  -8.25777932
  -8.23038631  -8.19204998  -8.1879492   -8.18156857  -8.14296637
  -8.13319584  -8.10819769  -8.06327093  -7.94856102  -7.92763923
  -7.9258916   -7.89196127  -7.88490149  -7.86695292  -7.86647498
  -7.85400235  -7.85250167  -7.81605426  -7.81067418  -7.77133022
  -7.75059405  -7.74872277  -7.70613771  -7.70343103  -7.6947421
  -7.69300785  -7.69222111  -7.69029852  -7.68789883  -7.64204348
  -7.60251679  -7.57539849  -7.55244816  -7.5367211   -7.52733959
  -7.51942891  -7.51537456  -7.50355076  -7.48087993  -7.46138035
  -7.39304499  -7.38496157  -7.36244313  -7.35910942  -7.35497938
  -7.28652427  -7.2666446   -7.26109967  -7.25591005  -7.2130292
  -7.18318261  -7.10893803  -7.10832736  -7.05002985  -6.95906356
  -6.90235505  -6.86794907  -6.85015128  -6.83665358  -6.83342605
  -6.78946603  -6.77694649  -6.76080576  -6.75186293  -6.72901939
  -6.72649057  -6.72206384  -6.71997062  -6.66285306  -6.55290116
  -6.54660316  -6.53544734  -6.53011624  -6.51820418  -6.51256876
  -6.51118511  -6.49489396  -6.49459235  -6.49403511  -6.49362284
  -6.48533749  -6.47363627  -6.45693355  -6.35182029  -6.34053654
  -6.16321453  -6.15212877  -6.13697036  -6.11567384  -6.07423677
  -6.0338868   -6.0006728   -5.97277828  -5.89689111  -5.69449155
  -5.6890279   -5.64333094  -5.61579673  -5.51691844  -5.42493771
  -5.4129837   -5.39229224  -5.3472021   -5.3385794   -5.33820923
  -5.2835736   -5.08890325  -5.07848501  -5.05371294  -5.02795798
  -4.82757292  -4.72492103  -4.63049542  -4.60294814  -4.230832
  -4.03104862  -3.38446715  -3.3322555   -2.64166233  -1.91361965]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:1
end of epoch 0: val_loss 8.642623672727722e-08, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.0928e-01,  8.6944e-03, -1.4518e-01, -2.7696e-01,  8.1711e-02,
          8.0561e-02, -2.2560e-03,  3.9098e-02, -1.4394e-01, -1.4590e-01,
         -3.7692e-04, -8.6195e-01, -6.7798e-01]], device='cuda:1'))])
end of epoch 1: val_loss 8.872696135000524e-06, val_acc 1.0
trigger times: 1
end of epoch 2: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-4.2901e-02,  3.9205e-01,  6.4184e-01, -3.0528e-01,  1.0868e+00,
         -3.4781e-01,  1.0227e-03, -7.2253e-02, -5.4747e-01,  2.9592e-02,
         -3.7710e-04, -2.0870e+00, -2.4730e+00]], device='cuda:1'))])
end of epoch 3: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.0929e-04,  1.5150e-01,  3.3524e-01, -1.4621e-01,  7.5466e-01,
         -6.3259e-05, -4.6962e-03, -3.0672e-02, -3.0053e-01, -8.5718e-05,
         -3.7719e-04, -1.8637e+00, -2.4098e+00]], device='cuda:1'))])
end of epoch 4: val_loss 2.9205422833911145e-07, val_acc 1.0
trigger times: 1
end of epoch 5: val_loss 1.7881390590446245e-09, val_acc 1.0
trigger times: 2
end of epoch 6: val_loss 0.8336248207092152, val_acc 0.985
trigger times: 3
end of epoch 7: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 4
end of epoch 8: val_loss 0.0001200075913220644, val_acc 1.0
trigger times: 5
end of epoch 9: val_loss 2.8609643322852206e-07, val_acc 1.0
trigger times: 6
end of epoch 10: val_loss 7.783760520396754e-07, val_acc 1.0
trigger times: 7
end of epoch 11: val_loss 1.1920927533992654e-09, val_acc 1.0
trigger times: 8
end of epoch 12: val_loss 1.4982362336013465e-06, val_acc 1.0
trigger times: 9
end of epoch 13: val_loss 5.960464122267694e-10, val_acc 1.0
trigger times: 10
Early stopping.
0 -141.63315844535828 -74.1721178479907
1 -137.5456441640854 -72.10762885780905
2 -139.9210788011551 -70.6351546777058
3 -133.4127801656723 -70.17239217269297
4 -132.88921439647675 -69.65328467349545
5 -134.97891056537628 -69.13509469721924
6 -130.03976202011108 -68.61024866348654
7 -133.47262573242188 -68.48500695888033
8 -133.51278614997864 -67.96222763686896
9 -133.41482198238373 -67.3275083366685
10 -127.11374306678772 -67.06251733755995
11 -129.56440675258636 -66.88316809945694
12 -128.11475944519043 -66.29969196938822
13 -129.2782496213913 -65.91634724850468
14 -126.85230481624603 -65.30439263979832
15 -127.65694189071655 -65.09248013366215
16 -131.48402643203735 -64.8566561370319
17 -127.41524696350098 -64.02627760776319
18 -125.44236993789673 -63.33300158711638
19 -127.139719247818 -62.73402620707767
20 -323.68180799484253 -61.776331442264365
21 -316.0865111351013 -60.694388703708505
22 -315.71019744873047 -60.238400168101776
23 -316.0178961753845 -59.79936937169079
24 -321.2595477104187 -59.35183558827016
25 -320.00186824798584 -59.001719499099124
26 -313.91759872436523 -58.75873215557551
27 -311.36426877975464 -58.43682135095009
28 -309.6225299835205 -58.16259957619627
29 -315.52018117904663 -57.80603644732433
30 -312.0887804031372 -57.4461408949042
31 -315.0271382331848 -57.107058627162424
32 -306.4356245994568 -56.8726174229368
33 -311.618040561676 -56.6344532223106
34 -312.74051094055176 -56.29921443434797
35 -304.824590921402 -55.72514103936067
36 -308.2560086250305 -55.21782740977726
37 -310.57481384277344 -54.79798252140884
38 -302.10533595085144 -53.56325099518672
39 -303.9048185348511 -52.21075632533168
40 -134.6437200307846 -50.03933801517046
41 -145.69011008739471 -44.99030608142343
42 -127.33974295854568 -41.6910044370425
43 -133.6982443332672 -39.57586365327889
44 -119.26461058855057 -37.79713616772368
45 -104.17856788635254 -37.00630588930485
46 -111.52971893548965 -35.78149902167743
47 -81.53265145421028 -34.80241747531743
48 -134.94036127626896 -31.64414355845032
49 -140.58835756778717 -29.106189988903285
50 -61.08769929409027 -26.244794902859052
51 -78.4221783876419 -23.978745577896312
52 -132.71416169404984 -20.656863763892378
53 -4.606073267757893 -18.95826739196259
54 -86.81199496984482 -17.994774057192853
55 2.965084917843342 -16.915890622226563
56 -4.729896582663059 -16.333605142059007
57 -19.17064955830574 -15.588592753621883
58 2.9012345671653748 -15.150378332064733
59 -12.198413714766502 -14.708032068741046
60 -16.974434405565262 -14.518057278178569
61 -8.954441919922829 -14.315903078780284
62 -60.835779186338186 -14.10024812370176
63 -10.165027260780334 -13.784946125305416
64 -17.4684377014637 -13.635310174325618
65 -10.14846034348011 -13.414324676903227
66 -35.480220541357994 -13.324822962029103
67 4.003202974796295 -13.052675933905098
68 -11.287118017673492 -12.87457530057317
69 -68.77250741422176 -12.68135972540495
70 -4.135253809392452 -12.52574123985455
71 13.161715179681778 -12.231471230015076
72 -59.391170086339116 -12.110810484439153
73 -12.756112981587648 -11.820251116409686
74 8.30926638841629 -11.631719103567702
75 -57.32635296136141 -11.52703030325326
76 -3.773886017501354 -11.298991830252898
77 -28.89304757118225 -11.113180516558366
78 -5.72533143311739 -10.886384301991674
79 -58.29219032637775 -10.80253887494433
80 -7.628687232732773 -10.627626155051956
81 -5.956567361950874 -10.49500770909082
82 -37.277831971645355 -10.417093453846016
83 11.299255967140198 -10.358207740128002
84 -16.26451136916876 -10.159060666643725
85 -4.645856410264969 -10.019584945567843
86 10.480221271514893 -9.881995461906246
87 -52.59557785093784 -9.841308887481414
88 -4.841731667518616 -9.651824897550707
89 -60.5168322622776 -9.40192979700846
90 -53.90736638754606 -9.272308683423732
91 2.971518650650978 -9.120029762323945
92 -54.91274702548981 -9.03533011695653
93 -62.67950655519962 -8.919265070330715
94 -53.83774435520172 -8.783622284874431
95 -51.00398524850607 -8.660765147495423
96 -49.90295112505555 -8.552729172085996
97 -8.202214628458023 -8.495000865396662
98 -1.8788729906082153 -8.343465061206691
99 -10.255797117948532 -8.260116635625264
100 6.268538132309914 -8.14296637047142
101 -61.1307720169425 -7.925891602525946
102 -4.950699955224991 -7.852501671313691
103 -8.66981890797615 -7.706137713108701
104 -1.2717359811067581 -7.687898825337681
105 -64.94607529044151 -7.5273395904846705
106 -58.82003325223923 -7.3930449885939264
107 -0.18854370713233948 -7.2666446009698165
108 7.6832883059978485 -7.050029845978645
109 -46.14607360959053 -6.8334260471568555
110 -63.74917362630367 -6.726490571697894
111 -1.5390467047691345 -6.535447341844848
112 9.082245886325836 -6.494592345417679
113 16.306359872221947 -6.351820292503013
114 -0.7284926027059555 -6.074236771592862
115 13.122717663645744 -5.689027904495626
116 7.180436573922634 -5.392292244890788
117 5.974568590521812 -5.078485007852753
118 14.593310885131359 -4.602948144906834
119 11.464497417211533 -1.9136196540088464
train accuracy: 0.9994444444444445
validation accuracy: 1.0
[-74.17211785 -73.95782727 -73.26805818 -73.0186223  -72.71649503
 -72.53240426 -72.10762886 -71.31091253 -71.15257801 -71.06127544
 -70.899451   -70.80441266 -70.63515468 -70.62043016 -70.53269566
 -70.39681369 -70.35740546 -70.24539955 -70.17239217 -70.14769102
 -70.1139844  -69.97393649 -69.71058218 -69.68963454 -69.65328467
 -69.46999863 -69.41251292 -69.34855695 -69.31050315 -69.27065534
 -69.1350947  -69.08815837 -68.92907957 -68.89156511 -68.80237261
 -68.63219386 -68.61024866 -68.6068239  -68.60480039 -68.59498466
 -68.59342596 -68.5847388  -68.48500696 -68.46187963 -68.42673896
 -68.40256333 -68.05136636 -67.97875363 -67.96222764 -67.89072549
 -67.83054511 -67.7144862  -67.49051681 -67.47438541 -67.32750834
 -67.26714336 -67.25386762 -67.19962639 -67.14581154 -67.09124055
 -67.06251734 -67.00862004 -67.00637773 -66.98688062 -66.92540899
 -66.90335156 -66.8831681  -66.75857022 -66.67964391 -66.60163304
 -66.49461673 -66.39849672 -66.39360876 -66.29969197 -66.16764842
 -66.16472136 -66.00377018 -65.99300774 -65.96752013 -65.91634725
 -65.91354766 -65.78478981 -65.52872527 -65.50911485 -65.44338807
 -65.30439264 -65.28773769 -65.25277927 -65.25043604 -65.20473009
 -65.17397157 -65.09248013 -65.07355266 -65.04372698 -64.94248071
 -64.92267824 -64.86924824 -64.85665614 -64.79311473 -64.76596878
 -64.63676646 -64.19615668 -64.17049706 -64.02627761 -64.00194249
 -63.94691813 -63.87619084 -63.82346273 -63.41033423 -63.33300159
 -63.08645804 -62.957309   -62.90163285 -62.86266992 -62.76327897
 -62.73402621 -62.7214969  -62.23780065 -62.10576235 -62.08382901
 -61.80421912 -61.77633144 -61.36034637 -61.16005103 -61.13866388
 -61.04998096 -60.84862878 -60.6943887  -60.5875466  -60.51836728
 -60.46065756 -60.38718537 -60.38357794 -60.23840017 -60.04421813
 -60.02638645 -59.83403273 -59.81087215 -59.80758008 -59.79936937
 -59.72978889 -59.67377247 -59.67324583 -59.63573057 -59.479519
 -59.35183559 -59.3331544  -59.15376326 -59.11328063 -59.11108948
 -59.01375074 -59.0017195  -58.91020179 -58.90049235 -58.86177554
 -58.78056699 -58.76791277 -58.75873216 -58.73702192 -58.71874372
 -58.66878745 -58.52511233 -58.50468902 -58.43682135 -58.38369275
 -58.35114862 -58.32056422 -58.31876101 -58.21309823 -58.16259958
 -57.97295989 -57.95252047 -57.95121516 -57.88783722 -57.87472892
 -57.80603645 -57.79232597 -57.76792801 -57.73825517 -57.66311437
 -57.49003961 -57.44614089 -57.43534564 -57.3358511  -57.25402972
 -57.24021776 -57.17404009 -57.10705863 -57.02083028 -57.01031751
 -57.00777649 -56.93392957 -56.88941122 -56.87261742 -56.87019318
 -56.81723664 -56.76272566 -56.74396349 -56.66165036 -56.63445322
 -56.55228584 -56.48413654 -56.45964356 -56.43839989 -56.43035673
 -56.29921443 -56.26727436 -55.9921034  -55.94868324 -55.84721514
 -55.77551486 -55.72514104 -55.67181192 -55.64890947 -55.5140687
 -55.49655349 -55.4349547  -55.41620162 -55.21782741 -55.19969659
 -55.15334161 -54.98547503 -54.95774248 -54.84101147 -54.79798252
 -54.73427941 -54.37610836 -53.97452655 -53.88679139 -53.60251365
 -53.563251   -53.08471312 -53.05236476 -52.94548208 -52.77509559
 -52.75224363 -52.21075633 -52.18252397 -52.160559   -52.06238467
 -52.00276372 -50.4922686  -50.03933802 -49.75347185 -49.72654641
 -46.98011874 -45.73515428 -45.67057988 -44.99030608 -44.14602409
 -43.81326882 -43.18878399 -42.29180715 -42.00401746 -41.69100444
 -41.68588229 -41.2817771  -40.44278203 -40.34838366 -39.59970115
 -39.57586365 -39.31972693 -39.02461056 -38.45534494 -38.4127039
 -38.35634328 -37.79713617 -37.74152899 -37.66475324 -37.51313938
 -37.1809993  -37.10070314 -37.00630589 -36.82191677 -36.48799015
 -36.2096527  -36.19207562 -36.11445903 -35.78149902 -35.39450387
 -35.262825   -35.24303541 -35.20970524 -35.06544085 -34.80241748
 -34.64469045 -33.84284986 -32.70706485 -31.9690994  -31.7109134
 -31.64414356 -31.39238276 -31.22319602 -31.12953085 -29.3915714
 -29.34012561 -29.10618999 -27.4110235  -27.34372236 -27.19668163
 -27.07399029 -26.70472176 -26.2447949  -25.54836509 -25.45878529
 -24.879107   -24.82869536 -24.59274514 -23.97874558 -23.57262108
 -23.44970808 -22.74530916 -22.60679894 -22.19891032 -20.65686376
 -20.44447256 -20.1969901  -20.13839115 -19.63760344 -19.51559872
 -18.95826739 -18.9283881  -18.87905758 -18.7063571  -18.54530077
 -18.13131256 -17.99477406 -17.5574237  -17.40134513 -17.09350147
 -17.01473387 -16.9804259  -16.91589062 -16.82307393 -16.59067732
 -16.49040418 -16.48669442 -16.34426663 -16.33360514 -15.99002393
 -15.92560211 -15.92481331 -15.92378128 -15.62905519 -15.58859275
 -15.50853283 -15.45216084 -15.3078339  -15.24846554 -15.19607379
 -15.15037833 -15.13097011 -14.96017772 -14.95993861 -14.90448261
 -14.8550828  -14.77725123 -14.74577722 -14.70803207 -14.65867411
 -14.60367065 -14.58138984 -14.56039097 -14.55183569 -14.53457164
 -14.5314246  -14.52058071 -14.51805728 -14.46756371 -14.44242009
 -14.37936197 -14.37201643 -14.34438737 -14.32766052 -14.31590308
 -14.3132018  -14.28066982 -14.26585911 -14.19861518 -14.1672544
 -14.10024812 -14.01199748 -13.95611382 -13.94274459 -13.87737941
 -13.81728443 -13.78494613 -13.77729914 -13.69184427 -13.67405283
 -13.66567776 -13.65289981 -13.64817052 -13.63531017 -13.62102107
 -13.59601285 -13.59577016 -13.56167202 -13.52842465 -13.52065533
 -13.41432468 -13.41323139 -13.3989988  -13.39367838 -13.3738228
 -13.35777352 -13.32482296 -13.26277885 -13.19749602 -13.18927336
 -13.18685989 -13.11366442 -13.05267593 -13.02745666 -13.01572624
 -12.96689133 -12.94365623 -12.90426226 -12.8745753  -12.87193036
 -12.86529864 -12.84064929 -12.80567857 -12.76269483 -12.75458949
 -12.68135973 -12.67038963 -12.66418206 -12.63380648 -12.63264281
 -12.59805506 -12.5917843  -12.5549764  -12.52574124 -12.46913248
 -12.30017947 -12.27208401 -12.25981587 -12.2351833  -12.23147123
 -12.19240693 -12.15896926 -12.15190477 -12.13724316 -12.12247272
 -12.11081048 -12.106932   -12.10575018 -11.93810862 -11.92156759
 -11.86688047 -11.84952765 -11.83332939 -11.82025112 -11.80121495
 -11.78885214 -11.7636485  -11.76081759 -11.7543625  -11.74353867
 -11.6317191  -11.62556278 -11.62395156 -11.59156179 -11.58343034
 -11.56534539 -11.5270303  -11.45861252 -11.39414499 -11.37516395
 -11.35353684 -11.32823243 -11.3208311  -11.29899183 -11.29205729
 -11.28918302 -11.28697946 -11.26031571 -11.23719758 -11.19038699
 -11.14616918 -11.12139973 -11.11318052 -11.00100398 -10.99547072
 -10.97994804 -10.94167627 -10.93738171 -10.92726598 -10.91038437
 -10.90474105 -10.8863843  -10.8699891  -10.86698825 -10.866048
 -10.86572163 -10.8054964  -10.80253887 -10.7891748  -10.71111387
 -10.6995802  -10.68001643 -10.66960816 -10.66078229 -10.62762616
 -10.62118709 -10.5874562  -10.55216091 -10.53172231 -10.52922211
 -10.52602619 -10.50969241 -10.50851478 -10.49500771 -10.49464447
 -10.49136356 -10.48068288 -10.45746496 -10.43670194 -10.41709345
 -10.38926265 -10.38796419 -10.37500487 -10.37029065 -10.36589281
 -10.35820774 -10.35155306 -10.3438193  -10.34355436 -10.33581168
 -10.33412559 -10.3276815  -10.31788619 -10.30149061 -10.24868148
 -10.15906067 -10.12580413 -10.11556218 -10.08428645 -10.07581589
 -10.06246895 -10.03971305 -10.03721915 -10.01958495  -9.99893971
  -9.96903965  -9.96427374  -9.94969155  -9.90109121  -9.88669646
  -9.88199546  -9.87787986  -9.87386875  -9.86044406  -9.85721598
  -9.85617682  -9.84130889  -9.82804734  -9.78843396  -9.76917041
  -9.73483575  -9.68666716  -9.68427725  -9.66866953  -9.6518249
  -9.6415599   -9.63753286  -9.63098169  -9.60984242  -9.60601768
  -9.60215729  -9.58087005  -9.47759802  -9.4019298   -9.38310153
  -9.38200198  -9.36887733  -9.30919238  -9.30649506  -9.27230868
  -9.24176854  -9.24174388  -9.23331784  -9.23083416  -9.20968069
  -9.17253092  -9.15876561  -9.14868716  -9.12514882  -9.12002976
  -9.11900252  -9.08136258  -9.07904889  -9.0776691   -9.0744544
  -9.03533012  -9.01539794  -8.98121386  -8.98029062  -8.96615773
  -8.96406066  -8.93705159  -8.91926507  -8.90040861  -8.89310364
  -8.88126156  -8.84362927  -8.83554155  -8.83121015  -8.82765866
  -8.80771463  -8.78362228  -8.7571979   -8.72777815  -8.70664425
  -8.69402853  -8.69124989  -8.66076515  -8.65090717  -8.63797164
  -8.61414944  -8.61275301  -8.57936795  -8.57934762  -8.55272917
  -8.5452769   -8.51333535  -8.50667687  -8.50115887  -8.49891995
  -8.49500087  -8.49266397  -8.47787963  -8.41642821  -8.4118989
  -8.40487986  -8.39796704  -8.38159771  -8.37816283  -8.37174908
  -8.35138026  -8.34346506  -8.330117    -8.32987796  -8.32055374
  -8.29795764  -8.29448914  -8.26011664  -8.25777932  -8.24944124
  -8.23038631  -8.19204998  -8.1879492   -8.18156857  -8.17104396
  -8.14296637  -8.13319584  -8.10819769  -8.06327093  -8.02089414
  -8.01573347  -7.98536286  -7.96936172  -7.94856102  -7.94570681
  -7.92763923  -7.9258916   -7.89196127  -7.88490149  -7.86695292
  -7.86647498  -7.85400235  -7.85250167  -7.81605426  -7.81067418
  -7.77133022  -7.75059405  -7.74872277  -7.70613771  -7.70343103
  -7.6947421   -7.69422519  -7.69300785  -7.69222111  -7.69029852
  -7.68789883  -7.67919406  -7.66407271  -7.64204348  -7.62384202
  -7.60251679  -7.58768585  -7.57539849  -7.55244816  -7.5367211
  -7.52733959  -7.51942891  -7.51537456  -7.5057788   -7.50355076
  -7.48431851  -7.48087993  -7.46138035  -7.39304499  -7.38496157
  -7.36244313  -7.35910942  -7.35497938  -7.31818724  -7.28652427
  -7.2666446   -7.26109967  -7.25591005  -7.2130292   -7.18318261
  -7.10893803  -7.10832736  -7.05002985  -6.9614418   -6.95906356
  -6.90235505  -6.87957358  -6.86965191  -6.86794907  -6.85015128
  -6.84835996  -6.83665358  -6.83342605  -6.83285195  -6.82679776
  -6.78946603  -6.78832811  -6.78384362  -6.77694649  -6.76080576
  -6.75186293  -6.72901939  -6.72649057  -6.72206384  -6.71997062
  -6.70169788  -6.69791783  -6.66285306  -6.55290116  -6.54660316
  -6.53544734  -6.53011624  -6.51820418  -6.51256876  -6.51118511
  -6.49489396  -6.49459235  -6.49403511  -6.49362284  -6.48533749
  -6.47363627  -6.45693355  -6.41149908  -6.35182029  -6.35144061
  -6.34573811  -6.34053654  -6.32578609  -6.16321453  -6.15212877
  -6.13697036  -6.11567384  -6.09120024  -6.07423677  -6.06772557
  -6.06771131  -6.0338868   -6.02557614  -6.0006728   -5.97277828
  -5.89689111  -5.82970117  -5.76102679  -5.74756558  -5.71922698
  -5.69449155  -5.6890279   -5.64333094  -5.61579673  -5.58198552
  -5.51691844  -5.50209693  -5.50091483  -5.47187758  -5.42493771
  -5.4129837   -5.39229224  -5.38013055  -5.3472021   -5.3385794
  -5.33820923  -5.3091106   -5.30662595  -5.2835736   -5.21684579
  -5.12944583  -5.08890325  -5.07848501  -5.05371294  -5.02795798
  -4.86060518  -4.82757292  -4.81156867  -4.77605315  -4.72492103
  -4.63049542  -4.61820224  -4.60294814  -4.48752949  -4.43905112
  -4.41042059  -4.39313445  -4.230832    -4.06630817  -4.05039728
  -4.03104862  -4.03030958  -3.98562123  -3.95434029  -3.85843657
  -3.80279289  -3.58322794  -3.48601822  -3.38446715  -3.3322555
  -3.26743926  -3.2561639   -3.23367749  -3.16219866  -3.15869796
  -3.02106919  -2.9722709   -2.75697993  -2.64166233  -1.91361965]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:1
end of epoch 0: val_loss 1.096426609315415e-05, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.2689e-02,  1.2573e-01,  9.0907e-02, -1.8626e-01,  1.1979e-02,
          1.4948e-05, -1.4014e-02, -4.8641e-02, -2.2440e-01, -1.5901e-01,
         -3.7692e-04, -1.1798e+00, -1.5554e+00]], device='cuda:1'))])
end of epoch 1: val_loss 0.00020110863206355135, val_acc 1.0
trigger times: 1
end of epoch 2: val_loss 2.1471413500862013e-06, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-2.6059e-02, -1.3091e-01,  9.8162e-02, -4.3338e-06,  2.4063e-01,
         -2.2972e-01,  6.2470e-07, -6.5544e-02, -1.5673e-01,  1.3317e-01,
         -3.7710e-04, -1.2938e+00, -1.2089e+00]], device='cuda:1'))])
end of epoch 3: val_loss 5.890598155019688e-05, val_acc 1.0
trigger times: 1
end of epoch 4: val_loss 0.02383832062594589, val_acc 0.995
trigger times: 2
end of epoch 5: val_loss 1.2755356859628364e-07, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 9.2383e-02,  1.3622e-01,  3.0524e-01,  1.0429e-02, -1.5621e-01,
          3.7312e-02, -3.5864e-02, -1.2107e-01,  2.4489e-02, -7.9076e-02,
         -3.7736e-04, -1.9100e+00, -2.8408e+00]], device='cuda:1'))])
end of epoch 6: val_loss 7.277756624425535e-05, val_acc 1.0
trigger times: 1
end of epoch 7: val_loss 3.153004194444975e-07, val_acc 1.0
trigger times: 2
end of epoch 8: val_loss 3.594382621312064e-05, val_acc 1.0
trigger times: 3
end of epoch 9: val_loss 0.0001321963593281339, val_acc 1.0
trigger times: 4
end of epoch 10: val_loss 7.843422887390261e-06, val_acc 1.0
trigger times: 5
end of epoch 11: val_loss 2.2649632050786294e-07, val_acc 1.0
trigger times: 6
end of epoch 12: val_loss 0.00027106173989523087, val_acc 1.0
trigger times: 7
end of epoch 13: val_loss 1.3887800772494075e-07, val_acc 1.0
trigger times: 8
end of epoch 14: val_loss 5.601674811913426e-05, val_acc 1.0
trigger times: 9
end of epoch 15: val_loss 5.364417461350968e-09, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.4249e-01,  2.3237e-02,  3.4071e-01, -3.8215e-02, -1.1012e-04,
         -9.3507e-03,  1.9680e-02, -1.0824e-01,  4.5854e-02, -4.5433e-02,
         -3.7833e-04, -1.9187e+00, -3.0575e+00]], device='cuda:1'))])
end of epoch 16: val_loss 4.716374005333534e-06, val_acc 1.0
trigger times: 1
end of epoch 17: val_loss 0.04440795032710185, val_acc 0.995
trigger times: 2
end of epoch 18: val_loss 7.1525538913874696e-09, val_acc 1.0
trigger times: 3
end of epoch 19: val_loss 0.00024888594036521995, val_acc 1.0
trigger times: 4
end of epoch 20: val_loss 0.005986978141332031, val_acc 0.995
trigger times: 5
end of epoch 21: val_loss 0.00014860185711423668, val_acc 1.0
trigger times: 6
end of epoch 22: val_loss 4.667862895644248e-05, val_acc 1.0
trigger times: 7
end of epoch 23: val_loss 0.4735397180998915, val_acc 0.985
trigger times: 8
end of epoch 24: val_loss 2.4033534043610415e-06, val_acc 1.0
trigger times: 9
end of epoch 25: val_loss 0.00020644091230458627, val_acc 1.0
trigger times: 10
Early stopping.
0 -128.2207145690918 -74.1721178479907
1 -124.65425896644592 -71.31091253188347
2 -122.88957440853119 -70.53269566265587
3 -122.92084527015686 -69.97393648964702
4 -120.31727457046509 -69.31050315164319
5 -119.79033410549164 -68.63219385965232
6 -120.46874642372131 -68.48500695888033
7 -120.0392518043518 -67.89072549190135
8 -117.40522301197052 -67.25386761804988
9 -116.78312134742737 -66.9868806234096
10 -117.17555940151215 -66.39849672036088
11 -115.29271697998047 -65.96752012705973
12 -114.12010109424591 -65.30439263979832
13 -116.24530577659607 -65.0735526580945
14 -115.21081054210663 -64.76596877818709
15 -113.35385382175446 -63.87619083665447
16 -110.71812057495117 -62.862669919490095
17 -328.05646324157715 -61.80421911893565
18 -323.8617115020752 -60.694388703708505
19 -323.4173460006714 -60.044218134909514
20 -324.9539542198181 -59.673772474088956
21 -323.9643359184265 -59.11328062964606
22 -320.6382055282593 -58.78056699141966
23 -316.8626570701599 -58.50468901536585
24 -317.54090547561646 -58.16259957619627
25 -315.44623374938965 -57.79232597100083
26 -322.0600256919861 -57.335851096014636
27 -315.06512784957886 -57.00777649219032
28 -318.69193744659424 -56.74396349407787
29 -319.92600870132446 -56.43035672590278
30 -313.50020456314087 -55.67181192441976
31 -314.74996852874756 -55.19969658860128
32 -313.2604012489319 -54.376108357368935
33 -310.4083261489868 -52.9454820772196
34 -308.0520267486572 -52.00276372402512
35 -169.2956725358963 -45.670579884154705
36 -157.87526720762253 -41.6910044370425
37 -147.39375203847885 -39.31972693233231
38 -136.29098391532898 -37.66475323879293
39 -122.207394272089 -36.20965269874363
40 -129.54311141371727 -35.209705244501436
41 -110.79618439078331 -31.7109134007892
42 -119.03517836332321 -29.106189988903285
43 -98.11362144351006 -25.548365085275513
44 -94.37463027238846 -23.44970807952351
45 -81.1544448286295 -20.13839114930498
46 -30.104596808552742 -18.54530077322492
47 -31.71461582183838 -16.980425898254765
48 -31.55330166220665 -16.333605142059007
49 -36.227692790329456 -15.508532834040299
50 -34.75092642009258 -14.959938614936895
51 -31.88128510862589 -14.603670648072523
52 -30.72436687350273 -14.518057278178569
53 -29.013379491865635 -14.315903078780284
54 -27.281430784612894 -14.011997481099941
55 -63.37488305568695 -13.691844270230611
56 -58.40541449189186 -13.596012850960644
57 -27.434468314051628 -13.39899880277043
58 -25.630945593118668 -13.189273357354436
59 -28.79223570227623 -12.943656232883118
60 -25.03758856654167 -12.762694828821783
61 -33.997535571455956 -12.598055064241702
62 -57.671419724822044 -12.25981586696299
63 -24.26972008496523 -12.122472722957268
64 -27.83322599157691 -11.84952764990956
65 -58.94307051599026 -11.754362495174934
66 -57.16300678253174 -11.565345387673993
67 -22.988795191049576 -11.320831097589815
68 -56.49517711997032 -11.19038698837289
69 -55.143863677978516 -10.941676269692449
70 -58.546291679143906 -10.866047997251195
71 -56.03689533472061 -10.680016434355997
72 -26.391029454767704 -10.531722305997304
73 -26.458315074443817 -10.491363555492372
74 -28.205997437238693 -10.375004869444705
75 -21.22543979436159 -10.335811677130739
76 -23.823984310030937 -10.125804131418743
77 -23.453012622892857 -10.019584945567843
78 -21.098080933094025 -9.881995461906246
79 -54.96059672534466 -9.828047339644366
80 -23.544934391975403 -9.651824897550707
81 -29.129193529486656 -9.580870049493816
82 -19.96259017288685 -9.306495056458639
83 -53.68497049808502 -9.172530919371935
84 -24.857083193957806 -9.079048893736822
85 -52.31966020166874 -8.966157734696775
86 -27.95622146129608 -8.843629267233913
87 -23.975567504763603 -8.727778151027543
88 -52.63065630197525 -8.614149435951592
89 -47.071819595992565 -8.506676869924311
90 -26.61300952732563 -8.404879858630807
91 -38.8330582305789 -8.330116995310416
92 -19.066364459693432 -8.249441236153798
93 -37.76333826780319 -8.133195842510668
94 -46.77725923061371 -7.948561022791138
95 -49.72305470705032 -7.866474981674106
96 -47.470147758722305 -7.748722774635732
97 -25.048866391181946 -7.690298520547252
98 -22.480855494737625 -7.587685853393197
99 -19.755937322974205 -7.505778800914455
100 -36.68012510240078 -7.362443126623615
101 -19.582642287015915 -7.255910049225737
102 -31.59597599506378 -6.959063561385431
103 -50.15828267484903 -6.836653578302678
104 -41.29244325309992 -6.776946485018116
105 -14.95724792778492 -6.701697882810898
106 -31.268138229846954 -6.51820418055673
107 -18.834408953785896 -6.485337492009593
108 -18.211123175919056 -6.340536540052647
109 -20.46083691716194 -6.074236771592862
110 -17.91133262589574 -5.829701167179998
111 -28.494511619210243 -5.615796733870542
112 -15.491000443696976 -5.4129836996448795
113 -16.844511702656746 -5.306625947209992
114 -24.93565857410431 -5.027957977402961
115 -20.174693435430527 -4.61820223804307
116 -17.09973753988743 -4.066308166908517
117 -16.596059191972017 -3.8027928914733375
118 -11.488531325012445 -3.2336774928420455
119 -15.66287924349308 -1.9136196540088464
train accuracy: 0.9994444444444445
validation accuracy: 1.0
[-74.17211785 -73.95782727 -73.26805818 -73.0186223  -72.71649503
 -72.53240426 -72.10762886 -71.31091253 -71.15257801 -71.06127544
 -70.899451   -70.80441266 -70.63515468 -70.62043016 -70.53269566
 -70.39681369 -70.35740546 -70.24539955 -70.17239217 -70.14769102
 -70.1139844  -69.97393649 -69.71058218 -69.68963454 -69.65328467
 -69.46999863 -69.41251292 -69.34855695 -69.31050315 -69.27065534
 -69.1350947  -69.08815837 -68.92907957 -68.89156511 -68.80237261
 -68.63219386 -68.61024866 -68.6068239  -68.60480039 -68.59498466
 -68.59342596 -68.5847388  -68.48500696 -68.46187963 -68.42673896
 -68.40256333 -68.05136636 -67.97875363 -67.96222764 -67.89072549
 -67.83054511 -67.7144862  -67.49051681 -67.47438541 -67.32750834
 -67.26714336 -67.25386762 -67.19962639 -67.14581154 -67.09124055
 -67.06251734 -67.00862004 -67.00637773 -66.98688062 -66.92540899
 -66.90335156 -66.8831681  -66.75857022 -66.67964391 -66.60163304
 -66.49461673 -66.39849672 -66.39360876 -66.29969197 -66.16764842
 -66.16472136 -66.00377018 -65.99300774 -65.96752013 -65.91634725
 -65.91354766 -65.78478981 -65.52872527 -65.50911485 -65.44338807
 -65.30439264 -65.28773769 -65.25277927 -65.25043604 -65.20473009
 -65.17397157 -65.09248013 -65.07355266 -65.04372698 -64.94248071
 -64.92267824 -64.86924824 -64.85665614 -64.79311473 -64.76596878
 -64.63676646 -64.19615668 -64.17049706 -64.02627761 -64.00194249
 -63.94691813 -63.87619084 -63.82346273 -63.41033423 -63.33300159
 -63.08645804 -62.957309   -62.90163285 -62.86266992 -62.76327897
 -62.73402621 -62.7214969  -62.23780065 -62.10576235 -62.08382901
 -61.80421912 -61.77633144 -61.36034637 -61.16005103 -61.13866388
 -61.04998096 -60.84862878 -60.6943887  -60.5875466  -60.51836728
 -60.46065756 -60.38718537 -60.38357794 -60.23840017 -60.04421813
 -60.02638645 -59.83403273 -59.81087215 -59.80758008 -59.79936937
 -59.72978889 -59.67377247 -59.67324583 -59.63573057 -59.479519
 -59.35183559 -59.3331544  -59.15376326 -59.11328063 -59.11108948
 -59.01375074 -59.0017195  -58.91020179 -58.90049235 -58.86177554
 -58.78056699 -58.76791277 -58.75873216 -58.73702192 -58.71874372
 -58.66878745 -58.52511233 -58.50468902 -58.43682135 -58.38369275
 -58.35114862 -58.32056422 -58.31876101 -58.21309823 -58.16259958
 -57.97295989 -57.95252047 -57.95121516 -57.88783722 -57.87472892
 -57.80603645 -57.79232597 -57.76792801 -57.73825517 -57.66311437
 -57.49003961 -57.44614089 -57.43534564 -57.3358511  -57.25402972
 -57.24021776 -57.17404009 -57.10705863 -57.02083028 -57.01031751
 -57.00777649 -56.93392957 -56.88941122 -56.87261742 -56.87019318
 -56.81723664 -56.76272566 -56.74396349 -56.66165036 -56.63445322
 -56.55228584 -56.48413654 -56.45964356 -56.43839989 -56.43035673
 -56.29921443 -56.26727436 -55.9921034  -55.94868324 -55.84721514
 -55.77551486 -55.72514104 -55.67181192 -55.64890947 -55.5140687
 -55.49655349 -55.4349547  -55.41620162 -55.21782741 -55.19969659
 -55.15334161 -54.98547503 -54.95774248 -54.84101147 -54.79798252
 -54.73427941 -54.37610836 -53.97452655 -53.88679139 -53.60251365
 -53.563251   -53.08471312 -53.05236476 -52.94548208 -52.77509559
 -52.75224363 -52.21075633 -52.18252397 -52.160559   -52.06238467
 -52.00276372 -50.4922686  -50.03933802 -49.75347185 -49.72654641
 -46.98011874 -45.73515428 -45.67057988 -44.99030608 -44.14602409
 -43.81326882 -43.18878399 -42.29180715 -42.00401746 -41.69100444
 -41.68588229 -41.2817771  -40.44278203 -40.34838366 -39.59970115
 -39.57586365 -39.31972693 -39.02461056 -38.45534494 -38.4127039
 -38.35634328 -37.79713617 -37.74152899 -37.66475324 -37.51313938
 -37.1809993  -37.10070314 -37.00630589 -36.82191677 -36.48799015
 -36.2096527  -36.19207562 -36.11445903 -35.78149902 -35.39450387
 -35.262825   -35.24303541 -35.20970524 -35.06544085 -34.80241748
 -34.64469045 -33.84284986 -32.70706485 -31.9690994  -31.7109134
 -31.64414356 -31.39238276 -31.22319602 -31.12953085 -29.3915714
 -29.34012561 -29.10618999 -27.4110235  -27.34372236 -27.19668163
 -27.07399029 -26.70472176 -26.2447949  -25.54836509 -25.45878529
 -24.879107   -24.82869536 -24.59274514 -23.97874558 -23.57262108
 -23.44970808 -22.74530916 -22.60679894 -22.19891032 -20.65686376
 -20.44447256 -20.1969901  -20.13839115 -19.63760344 -19.51559872
 -18.95826739 -18.9283881  -18.87905758 -18.7063571  -18.54530077
 -18.13131256 -17.99477406 -17.5574237  -17.40134513 -17.09350147
 -17.01473387 -16.9804259  -16.91589062 -16.82307393 -16.59067732
 -16.49040418 -16.48669442 -16.34426663 -16.33360514 -15.99002393
 -15.92560211 -15.92481331 -15.92378128 -15.73810121 -15.62905519
 -15.58859275 -15.50853283 -15.45216084 -15.3078339  -15.24846554
 -15.19607379 -15.15037833 -15.13097011 -14.96017772 -14.95993861
 -14.90448261 -14.8550828  -14.77725123 -14.74577722 -14.70803207
 -14.65867411 -14.64417174 -14.60367065 -14.58138984 -14.56039097
 -14.55183569 -14.53457164 -14.5314246  -14.52058071 -14.51805728
 -14.46756371 -14.44242009 -14.37936197 -14.37201643 -14.34438737
 -14.32766052 -14.31590308 -14.3132018  -14.28066982 -14.26585911
 -14.19861518 -14.1672544  -14.15554779 -14.10024812 -14.01199748
 -13.95611382 -13.95264064 -13.94274459 -13.92859158 -13.91395112
 -13.87737941 -13.81728443 -13.78494613 -13.77729914 -13.72914188
 -13.69184427 -13.67405283 -13.66567776 -13.65289981 -13.64817052
 -13.64591832 -13.63531017 -13.62102107 -13.59601285 -13.59577016
 -13.56167202 -13.54908178 -13.52842465 -13.52291563 -13.52065533
 -13.41432468 -13.41323139 -13.3989988  -13.39367838 -13.3738228
 -13.35777352 -13.32482296 -13.26277885 -13.25697308 -13.24769836
 -13.19749602 -13.18927336 -13.18685989 -13.17884172 -13.11588637
 -13.11366442 -13.05267593 -13.02745666 -13.01572624 -12.96689133
 -12.94365623 -12.90426226 -12.8745753  -12.87193036 -12.86529864
 -12.84064929 -12.80567857 -12.78986241 -12.76269483 -12.75458949
 -12.68135973 -12.67038963 -12.66418206 -12.63380648 -12.63264281
 -12.63104004 -12.59805506 -12.5917843  -12.57392479 -12.5549764
 -12.52574124 -12.46913248 -12.30017947 -12.27208401 -12.25981587
 -12.2351833  -12.23147123 -12.22332229 -12.19240693 -12.18296302
 -12.15896926 -12.15721294 -12.15190477 -12.13724316 -12.12247272
 -12.1170222  -12.1132243  -12.11081048 -12.106932   -12.10575018
 -12.06837204 -12.01976537 -11.93810862 -11.92156759 -11.86688047
 -11.84952765 -11.83332939 -11.82025112 -11.80121495 -11.78885214
 -11.7636485  -11.76081759 -11.7543625  -11.75089519 -11.74353867
 -11.73682393 -11.6317191  -11.62556278 -11.62395156 -11.59156179
 -11.58343034 -11.56534539 -11.55281202 -11.5270303  -11.45861252
 -11.39414499 -11.37516395 -11.35353684 -11.32823243 -11.3208311
 -11.29899183 -11.29205729 -11.28918302 -11.28697946 -11.26031571
 -11.23719758 -11.19038699 -11.14616918 -11.12139973 -11.11318052
 -11.03324584 -11.00514152 -11.00100398 -10.99547072 -10.97994804
 -10.94167627 -10.93738171 -10.93189112 -10.92726598 -10.91038437
 -10.90474105 -10.8863843  -10.8847678  -10.8699891  -10.86698825
 -10.866048   -10.86572163 -10.8054964  -10.80253887 -10.7891748
 -10.7743224  -10.71111387 -10.6995802  -10.68001643 -10.66960816
 -10.66078229 -10.6282837  -10.62762616 -10.62118709 -10.5874562
 -10.55216091 -10.53172231 -10.52922211 -10.52602619 -10.50969241
 -10.50851478 -10.49500771 -10.49464447 -10.49136356 -10.48068288
 -10.45746496 -10.43670194 -10.41709345 -10.38926265 -10.38796419
 -10.37500487 -10.37029065 -10.36589281 -10.35820774 -10.35155306
 -10.3438193  -10.34355436 -10.33581168 -10.33412559 -10.3276815
 -10.31788619 -10.30149061 -10.293603   -10.24868148 -10.15906067
 -10.12580413 -10.11556218 -10.08428645 -10.07581589 -10.06246895
 -10.03971305 -10.03721915 -10.01958495  -9.99893971  -9.96903965
  -9.96427374  -9.94969155  -9.93883815  -9.90109121  -9.88669646
  -9.88199546  -9.87787986  -9.87386875  -9.86044406  -9.85721598
  -9.85617682  -9.85158091  -9.84130889  -9.82804734  -9.82395819
  -9.78843396  -9.76917041  -9.73483575  -9.68666716  -9.68427725
  -9.66866953  -9.6518249   -9.6415599   -9.63753286  -9.63579851
  -9.63098169  -9.60984242  -9.60601768  -9.60215729  -9.58087005
  -9.47759802  -9.42260606  -9.4019298   -9.38310153  -9.38200198
  -9.36887733  -9.30919238  -9.30649506  -9.28937217  -9.27238242
  -9.27230868  -9.24176854  -9.24174388  -9.23331784  -9.23083416
  -9.20968069  -9.1838749   -9.17253092  -9.15876561  -9.14868716
  -9.12514882  -9.12002976  -9.11900252  -9.11414382  -9.08136258
  -9.07904889  -9.0776691   -9.0744544   -9.04034414  -9.03730767
  -9.03533012  -9.01539794  -8.98517184  -8.98121386  -8.98029062
  -8.96615773  -8.96406066  -8.95953499  -8.93705159  -8.91926507
  -8.90040861  -8.89310364  -8.88126156  -8.84362927  -8.83554155
  -8.83121015  -8.82765866  -8.80771463  -8.78362228  -8.7571979
  -8.72777815  -8.71962399  -8.70664425  -8.69402853  -8.69124989
  -8.66076515  -8.65090717  -8.63797164  -8.61414944  -8.61275301
  -8.57936795  -8.57934762  -8.55272917  -8.5452769   -8.51333535
  -8.50667687  -8.50115887  -8.49891995  -8.49500087  -8.49266397
  -8.47787963  -8.45448279  -8.41642821  -8.4118989   -8.40487986
  -8.39796704  -8.3940636   -8.38159771  -8.37816283  -8.37174908
  -8.35138026  -8.34346506  -8.33446904  -8.330117    -8.32987796
  -8.32055374  -8.29795764  -8.29448914  -8.26011664  -8.25777932
  -8.24944124  -8.23038631  -8.19204998  -8.1879492   -8.18156857
  -8.17104396  -8.14296637  -8.13319584  -8.10819769  -8.10347315
  -8.09174491  -8.06327093  -8.06267269  -8.02286399  -8.02089414
  -8.01573347  -8.0050081   -7.98536286  -7.96936172  -7.94856102
  -7.94570681  -7.92763923  -7.9258916   -7.89196127  -7.88490149
  -7.86695292  -7.86647498  -7.85400235  -7.85250167  -7.81605426
  -7.81067418  -7.77133022  -7.76412316  -7.75059405  -7.74872277
  -7.70613771  -7.70343103  -7.6947421   -7.69422519  -7.69300785
  -7.69222111  -7.69029852  -7.68789883  -7.67919406  -7.67227152
  -7.66407271  -7.65282028  -7.64204348  -7.62384202  -7.60251679
  -7.58768585  -7.57539849  -7.56462659  -7.55244816  -7.54509683
  -7.5367211   -7.52733959  -7.51942891  -7.51537456  -7.5057788
  -7.50355076  -7.48431851  -7.48087993  -7.46138035  -7.39304499
  -7.38496157  -7.36677735  -7.36244313  -7.35910942  -7.35497938
  -7.31818724  -7.28652427  -7.2666446   -7.26109967  -7.25918178
  -7.25591005  -7.2130292   -7.18318261  -7.1561508   -7.15257171
  -7.10893803  -7.10832736  -7.0983844   -7.05002985  -6.98300078
  -6.9614418   -6.95906356  -6.90235505  -6.87957358  -6.86965191
  -6.86794907  -6.85015128  -6.84835996  -6.83665358  -6.83342605
  -6.83285195  -6.82679776  -6.78946603  -6.78832811  -6.78384362
  -6.78332498  -6.77694649  -6.77537776  -6.76080576  -6.75186293
  -6.72901939  -6.72649057  -6.72206384  -6.71997062  -6.70169788
  -6.69791783  -6.66285306  -6.6467127   -6.58577816  -6.55290116
  -6.54660316  -6.53544734  -6.53011624  -6.51820418  -6.51256876
  -6.51118511  -6.49850644  -6.49489396  -6.49459235  -6.49403511
  -6.49362284  -6.48533749  -6.47363627  -6.45693355  -6.41149908
  -6.3537965   -6.35182029  -6.35144061  -6.34573811  -6.34053654
  -6.32578609  -6.16321453  -6.15530064  -6.15212877  -6.13697036
  -6.11567384  -6.09120024  -6.07423677  -6.06772557  -6.06771131
  -6.0338868   -6.02557614  -6.0006728   -5.97277828  -5.89689111
  -5.82970117  -5.80849791  -5.76102679  -5.74756558  -5.71922698
  -5.69449155  -5.6890279   -5.68230406  -5.67663137  -5.66975874
  -5.64333094  -5.61579673  -5.61305267  -5.58828504  -5.58198552
  -5.5757612   -5.56472092  -5.51691844  -5.50209693  -5.50091483
  -5.48138318  -5.47882599  -5.47187758  -5.43711732  -5.42493771
  -5.4129837   -5.39229224  -5.39083745  -5.38714495  -5.38013055
  -5.35769769  -5.35509497  -5.3472021   -5.34062505  -5.3385794
  -5.33820923  -5.33701907  -5.3091106   -5.30662595  -5.2849963
  -5.2835736   -5.24705084  -5.21684579  -5.2082656   -5.19143446
  -5.12944583  -5.08890325  -5.07848501  -5.05371294  -5.03438824
  -5.02795798  -5.00893374  -4.974663    -4.86060518  -4.82757292
  -4.81156867  -4.77605315  -4.72492103  -4.68129121  -4.65703669
  -4.65451139  -4.63049542  -4.61820224  -4.60294814  -4.48752949
  -4.48406017  -4.43905112  -4.41042059  -4.39313445  -4.230832
  -4.13774547  -4.06678939  -4.06630817  -4.05039728  -4.03936929
  -4.03104862  -4.03030958  -4.02312753  -3.98562123  -3.97291131
  -3.95434029  -3.9357421   -3.85843657  -3.84205233  -3.80279289
  -3.63047616  -3.58322794  -3.52492966  -3.48601822  -3.38446715
  -3.35019775  -3.3322555   -3.26743926  -3.2561639   -3.23367749
  -3.21451484  -3.18480139  -3.16219866  -3.15869796  -3.04622804
  -3.02106919  -2.99206201  -2.9722709   -2.95763382  -2.85903238
  -2.85560251  -2.75697993  -2.64166233  -2.50206238  -1.91361965]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:1
end of epoch 0: val_loss 0.00028682771168764276, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.0189e-01,  9.2865e-02,  2.5238e-02, -2.1629e-01,  3.1232e-01,
          7.1229e-06, -6.5005e-03,  3.2266e-02, -3.5486e-01, -1.5190e-05,
         -3.7692e-04, -7.2530e-01, -8.6598e-01]], device='cuda:1'))])
end of epoch 1: val_loss 2.1450674629211424, val_acc 0.965
trigger times: 1
end of epoch 2: val_loss 2.2075122979003936e-06, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.3210e-01,  3.0637e-01, -7.2823e-02, -7.1063e-02,  1.1933e+00,
         -1.0872e-01, -1.3849e-02, -1.4006e-03, -7.9599e-01, -7.4611e-03,
         -3.7710e-04, -2.2781e+00, -2.4815e+00]], device='cuda:1'))])
end of epoch 3: val_loss 3.909988299710676e-07, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.9765e-01,  1.9779e-01,  2.1920e-05,  1.6086e-05,  6.6151e-01,
         -9.8279e-05, -1.1997e-02,  3.6127e-06, -3.5536e-01,  6.3655e-05,
         -3.7719e-04, -1.7434e+00, -2.3476e+00]], device='cuda:1'))])
end of epoch 4: val_loss 0.0025056620554460094, val_acc 1.0
trigger times: 1
end of epoch 5: val_loss 4.7683708714885145e-09, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.2886e-01,  4.7041e-01,  1.7860e-01, -1.6653e-01,  1.5417e+00,
          3.7829e-01, -4.5958e-02, -3.8739e-02, -8.9704e-01, -3.0661e-01,
         -3.7736e-04, -2.2234e+00, -3.7040e+00]], device='cuda:1'))])
end of epoch 6: val_loss 1.2277804488292077e-06, val_acc 1.0
trigger times: 1
end of epoch 7: val_loss 0.00026572970621597137, val_acc 1.0
trigger times: 2
end of epoch 8: val_loss 2.3364747903542593e-07, val_acc 1.0
trigger times: 3
end of epoch 9: val_loss 1.7799404445177913e-05, val_acc 1.0
trigger times: 4
end of epoch 10: val_loss 0.02814815485265143, val_acc 0.995
trigger times: 5
end of epoch 11: val_loss 7.688976090491906e-08, val_acc 1.0
trigger times: 6
end of epoch 12: val_loss 0.09512653215446065, val_acc 0.985
trigger times: 7
end of epoch 13: val_loss 7.083759992383421e-06, val_acc 1.0
trigger times: 8
end of epoch 14: val_loss 3.218623706402468e-07, val_acc 1.0
trigger times: 9
end of epoch 15: val_loss 0.00021411766450885495, val_acc 1.0
trigger times: 10
Early stopping.
0 -174.06665444374084 -74.1721178479907
1 -167.55501914024353 -71.1525780094121
2 -162.95670318603516 -70.35740546141608
3 -165.57057857513428 -69.65328467349545
4 -160.5256805419922 -68.92907956994428
5 -175.68691182136536 -68.5934259629071
6 -163.1925871372223 -67.96222763686896
7 -156.48128128051758 -67.25386761804988
8 -171.35284769535065 -66.9254089942571
9 -163.6462733745575 -66.29969196938822
10 -168.19505727291107 -65.78478981041695
11 -153.9598718881607 -65.20473008643418
12 -170.27331149578094 -64.8566561370319
13 -165.07544016838074 -63.946918129474476
14 -161.06992483139038 -62.862669919490095
15 -243.0747528076172 -61.776331442264365
16 -242.66028761863708 -60.51836727560633
17 -229.87266659736633 -59.8108721498786
18 -239.41360783576965 -59.35183558827016
19 -222.35317862033844 -58.90049234750477
20 -226.05616807937622 -58.525112330336405
21 -221.80380284786224 -58.16259957619627
22 -225.99009835720062 -57.76792801354424
23 -232.3644561767578 -57.24021775550845
24 -222.69933366775513 -56.8726174229368
25 -220.7226300239563 -56.484136535549545
26 -226.37399697303772 -55.77551485623642
27 -224.34941387176514 -55.21782740977726
28 -217.46407675743103 -54.376108357368935
29 -220.77146124839783 -52.775095589593526
30 -205.53431117534637 -50.03933801517046
31 -160.23394644260406 -43.81326882122305
32 -134.60012240707874 -40.34838365523108
33 -173.18185509741306 -37.79713616772368
34 -155.84291779994965 -36.48799015296732
35 -148.50138929486275 -35.209705244501436
36 -109.60031926631927 -31.64414355845032
37 -128.1993167847395 -27.343722362182305
38 -116.45614674687386 -24.828695359328833
39 -82.83646054565907 -20.656863763892378
40 -65.11377453804016 -18.87905758287616
41 -57.820712983608246 -17.014733874139218
42 -57.72708177566528 -16.333605142059007
43 -53.04984560608864 -15.45216083515835
44 -46.95523503422737 -14.904482610357418
45 -41.993040561676025 -14.5813898350114
46 -64.17854219675064 -14.442420089224363
47 -76.5061708688736 -14.265859113982158
48 -39.94109687209129 -13.942744593566932
49 -44.78265878558159 -13.691844270230611
50 -77.09195844829082 -13.596012850960644
51 -74.5390105843544 -13.413231388619275
52 -73.28573197126389 -13.247698357832908
53 -30.082726329565048 -13.027456660672417
54 -47.94336861371994 -12.840649288269582
55 -25.401506766676903 -12.633806480141791
56 -36.73407982289791 -12.469132478750263
57 -67.6021018922329 -12.18296301820615
58 -39.58792996406555 -12.110810484439153
59 -56.114174604415894 -11.84952764990956
60 -41.60190684348345 -11.743538667886787
61 -64.61628964543343 -11.552812021301223
62 -32.3052746579051 -11.298991830252898
63 -30.878746762871742 -11.121399734299642
64 -68.77908837795258 -10.93738170799238
65 -53.161373287439346 -10.866988248627104
66 -49.85587736964226 -10.699580195361252
67 -55.49504208564758 -10.552160914068711
68 -69.59006002545357 -10.491363555492372
69 -47.24879789352417 -10.370290648792462
70 -59.495168298482895 -10.327681503524177
71 -38.235602628439665 -10.084286446825013
72 -19.348878636956215 -9.964273742726046
73 -36.76854819059372 -9.860444062091586
74 -40.65250861644745 -9.769170409973741
75 -58.19757521152496 -9.635798512213555
76 -22.454540759325027 -9.40192979700846
77 -19.287898475304246 -9.241768536707228
78 -41.77449760586023 -9.14868716386642
79 -27.959022402763367 -9.074454396568065
80 -28.110357403755188 -8.966157734696775
81 -27.578990936279297 -8.843629267233913
82 -52.5719962567091 -8.719623989305951
83 -46.29310753941536 -8.612753006795744
84 -18.759640336036682 -8.498919948359026
85 -29.98891943693161 -8.397967037001104
86 -52.015453800559044 -8.330116995310416
87 -25.29244413226843 -8.230386311846033
88 -58.264838725328445 -8.103473150965206
89 -35.76475851982832 -7.985362861808601
90 -16.69077204167843 -7.866952924777113
91 -26.027940154075623 -7.7505940516414515
92 -58.02948635816574 -7.690298520547252
93 -26.048130191862583 -7.602516785576057
94 -19.844719231128693 -7.515374561238876
95 -44.6149725317955 -7.366777351793733
96 -52.253406405448914 -7.2591817824164355
97 -56.37879976630211 -7.098384397277671
98 -57.04082250595093 -6.867949073447351
99 -38.26471143960953 -6.788328111573408
100 -15.578564077615738 -6.726490571697894
101 -14.114999309182167 -6.552901162710296
102 -53.46987025439739 -6.494893955832884
103 -42.708609111607075 -6.353796499624243
104 -10.042922466993332 -6.152128773523117
105 -34.68916706740856 -6.02557613738121
106 -29.4988202303648 -5.719226978965594
107 -52.98785236477852 -5.613052666837154
108 -41.820723190903664 -5.481383183362745
109 -40.35506293177605 -5.387144949896855
110 -37.1327922642231 -5.33701907430182
111 -30.52761870995164 -5.129445826215632
112 -24.105640582740307 -4.860605182736137
113 -39.2534402012825 -4.63049541560991
114 -40.62385433912277 -4.230832004686763
115 -20.74082086980343 -4.023127533562036
116 -36.17192330956459 -3.6304761577478946
117 -24.5640110373497 -3.256163901848479
118 -32.33369426429272 -2.9920620070512687
119 -26.198093734681606 -1.9136196540088464
train accuracy: 0.9955555555555555
validation accuracy: 1.0
[-74.17211785 -73.95782727 -73.26805818 ...  -1.91361965  -1.50369367
  -1.14425067]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:3
end of epoch 0: val_loss 0.0009058994719062951, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.5273e-01,  7.5259e-02,  1.5810e-01, -2.8797e-01,  9.1675e-02,
          3.7173e-02,  3.5076e-03,  3.0001e-02, -1.6815e-01, -6.5412e-02,
         -3.7692e-04, -7.8185e-01, -9.0450e-01]], device='cuda:3'))])
end of epoch 1: val_loss 0.0035925354853880973, val_acc 1.0
trigger times: 1
end of epoch 2: val_loss 0.017824874510988593, val_acc 0.995
trigger times: 2
end of epoch 3: val_loss 2.488186319169472e-06, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 8.1120e-01,  2.4794e-01,  3.7587e-01, -1.4693e-01,  2.2448e-05,
         -1.1524e-05,  2.2871e-02,  1.1033e-01, -6.0078e-02,  2.0050e-06,
         -3.7719e-04, -1.9748e+00, -2.1861e+00]], device='cuda:3'))])
end of epoch 4: val_loss 1.2397272431599049e-05, val_acc 1.0
trigger times: 1
end of epoch 5: val_loss 6.038190123949214, val_acc 0.875
trigger times: 2
end of epoch 6: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 5.8379e-01,  2.3791e-01,  2.7206e-01, -1.6842e-01,  5.4507e-01,
          8.1649e-02, -2.4855e-06,  2.4558e-02, -2.7122e-01, -2.0293e-01,
         -3.7745e-04, -2.3328e+00, -2.6446e+00]], device='cuda:3'))])
end of epoch 7: val_loss 5.161629813699164e-07, val_acc 1.0
trigger times: 1
end of epoch 8: val_loss 0.00011635143629440848, val_acc 1.0
trigger times: 2
end of epoch 9: val_loss 0.0024303185939788465, val_acc 1.0
trigger times: 3
end of epoch 10: val_loss 2.1598390594590457e-06, val_acc 1.0
trigger times: 4
end of epoch 11: val_loss 4.920146012409532e-05, val_acc 1.0
trigger times: 5
end of epoch 12: val_loss 0.093709261715412, val_acc 0.99
trigger times: 6
end of epoch 13: val_loss 3.61191268609673e-07, val_acc 1.0
trigger times: 7
end of epoch 14: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 6.6122e-01,  3.4686e-01,  1.3373e-01, -4.1207e-05, -9.0312e-05,
         -1.7170e-05, -2.3266e-02, -1.9371e-03, -6.1908e-05, -8.6972e-05,
         -3.7823e-04, -2.2308e+00, -3.2011e+00]], device='cuda:3'))])
end of epoch 15: val_loss 1.7857144432298355e-06, val_acc 1.0
trigger times: 1
end of epoch 16: val_loss 4.6608660341007636e-07, val_acc 1.0
trigger times: 2
end of epoch 17: val_loss 2.0861582470388386e-08, val_acc 1.0
trigger times: 3
end of epoch 18: val_loss 5.8501071794410106e-05, val_acc 1.0
trigger times: 4
end of epoch 19: val_loss 0.08071177449048264, val_acc 0.995
trigger times: 5
end of epoch 20: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 7.6066e-01,  4.1010e-01,  4.6839e-01, -2.2751e-01,  6.2641e-01,
         -3.2828e-02,  1.5102e-03,  9.8091e-02, -6.6649e-01, -1.0246e-01,
         -3.7886e-04, -2.1902e+00, -3.6039e+00]], device='cuda:3'))])
end of epoch 21: val_loss 5.386261733065112e-05, val_acc 1.0
trigger times: 1
end of epoch 22: val_loss 7.888974669171488e-05, val_acc 1.0
trigger times: 2
end of epoch 23: val_loss 0.035314764856302645, val_acc 0.995
trigger times: 3
end of epoch 24: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 7.2220e-01,  2.7320e-01,  3.9200e-01, -1.5888e-01,  3.3864e-01,
          9.5991e-02,  6.3224e-03,  1.3370e-01, -4.5539e-01, -3.0371e-01,
         -3.7927e-04, -2.2495e+00, -3.2877e+00]], device='cuda:3'))])
end of epoch 25: val_loss 5.107863017883574e-07, val_acc 1.0
trigger times: 1
end of epoch 26: val_loss 0.5850822218367796, val_acc 0.965
trigger times: 2
end of epoch 27: val_loss 5.6104164104908705e-06, val_acc 1.0
trigger times: 3
end of epoch 28: val_loss 8.821454230201197e-08, val_acc 1.0
trigger times: 4
end of epoch 29: val_loss 1.6936835734426836e-06, val_acc 1.0
trigger times: 5
end of epoch 30: val_loss 0.0006802142513879516, val_acc 1.0
trigger times: 6
end of epoch 31: val_loss 0.013633965253819724, val_acc 0.995
trigger times: 7
end of epoch 32: val_loss 0.0001029337290674448, val_acc 1.0
trigger times: 8
end of epoch 33: val_loss 4.5623318275147536e-05, val_acc 1.0
trigger times: 9
end of epoch 34: val_loss 0.00305741353867802, val_acc 1.0
trigger times: 10
Early stopping.
0 -160.6143982410431 -74.1721178479907
1 -156.793470621109 -71.06127544427346
2 -157.13601660728455 -70.17239217269297
3 -155.78964042663574 -69.34855695105098
4 -154.43389534950256 -68.61024866348654
5 -154.96453142166138 -68.40256332590795
6 -153.73211884498596 -67.3275083366685
7 -153.45310592651367 -66.9868806234096
8 -154.3939185142517 -66.29969196938822
9 -153.70136833190918 -65.52872526670517
10 -150.90670132637024 -65.09248013366215
11 -151.89235401153564 -64.63676646451523
12 -150.13385820388794 -63.33300158711638
13 -130.8792324066162 -62.10576234804211
14 -128.29239130020142 -60.694388703708505
15 -128.0185090303421 -59.83403272829647
16 -127.48760747909546 -59.35183558827016
17 -126.85846626758575 -58.86177554076678
18 -125.95205354690552 -58.43682135095009
19 -125.29856085777283 -57.95121516197284
20 -124.96077358722687 -57.4461408949042
21 -124.37625801563263 -57.00777649219032
22 -125.8604006767273 -56.6344532223106
23 -126.1094720363617 -55.8472151405688
24 -123.39476716518402 -55.21782740977726
25 -122.77743172645569 -53.97452655055861
26 -121.6531378030777 -52.21075632533168
27 -117.19113197922707 -46.98011874490918
28 -109.242188423872 -41.6910044370425
29 -96.87848883867264 -38.45534493538269
30 -93.1178794503212 -37.00630588930485
31 -93.80108991265297 -35.24303541418371
32 -84.84467616677284 -31.64414355845032
33 -77.75969213247299 -27.196681629483837
34 -71.0695244371891 -23.978745577896312
35 -64.22793950140476 -20.13839114930498
36 -24.51526302099228 -18.87905758287616
37 -43.77534708380699 -18.021462363446553
38 -42.72737826406956 -17.191406341729415
39 -39.35531307756901 -16.635301627378418
40 -44.12249514460564 -16.341026632543436
41 -40.22700151801109 -15.876609708092628
42 -24.17656098306179 -15.508532834040299
43 -25.43487621843815 -14.960177716561248
44 -24.23328723013401 -14.708032068741046
45 -25.02685372531414 -14.52058070590298
46 -23.147183775901794 -14.315903078780284
47 -40.16401258111 -14.07014679694041
48 -23.447432309389114 -13.784946125305416
49 -24.73431171476841 -13.635310174325618
50 -23.28821498155594 -13.414324676903227
51 -23.162149965763092 -13.256973076870517
52 -24.732868999242783 -13.027456660672417
53 -23.744455620646477 -12.789862408535097
54 -22.59247861802578 -12.598055064241702
55 -25.498234033584595 -12.25981586696299
56 -19.378942489624023 -12.13724315976819
57 -27.475266590714455 -11.938108617468604
58 -22.325925156474113 -11.76081759070548
59 -21.51515492796898 -11.58343034356252
60 -20.925320506095886 -11.320831097589815
61 -31.526846259832382 -11.121399734299642
62 -23.77547587454319 -10.931891120382838
63 -22.500645145773888 -10.865721625251902
64 -19.301403626799583 -10.660782288857632
65 -29.704960271716118 -10.509692405085175
66 -21.193817496299744 -10.389262650750606
67 -21.606597796082497 -10.334125588660196
68 -19.14791204035282 -10.115562180638529
69 -22.520333915948868 -9.964273742726046
70 -34.740875735878944 -9.8572159761571
71 -27.014480277895927 -9.686667156034257
72 -22.33367645740509 -9.606017684096496
73 -24.45547227561474 -9.368877330089191
74 -26.999455854296684 -9.233317835466233
75 -23.434732884168625 -9.125148824021686
76 -21.909565716981888 -9.040344142090799
77 -21.642480328679085 -8.95953498654925
78 -25.71241457760334 -8.831210153312487
79 -19.332424879074097 -8.70664425465433
80 -18.681857474148273 -8.57934761599037
81 -21.109971523284912 -8.492663967035146
82 -14.55474267154932 -8.390623263584407
83 -18.123483791947365 -8.320553743824137
84 -23.661839574575424 -8.187949197711195
85 -20.401789605617523 -8.062672687413787
86 -23.24152685701847 -7.927639225126769
87 -20.181741409003735 -7.8160542619775635
88 -16.076813027262688 -7.703040937420843
89 -20.6600741147995 -7.664072711774371
90 -19.179340101778507 -7.552448158674197
91 -18.850884180516005 -7.484318505459561
92 -20.37564793974161 -7.318187242990513
93 -19.968646727502346 -7.152571712703033
94 -20.316858932375908 -6.961441796624053
95 -19.70202860981226 -6.8334260471568555
96 -22.140333788469434 -6.760805759962728
97 -20.902692526578903 -6.585778158867617
98 -18.602765560150146 -6.511185112392438
99 -12.614612862467766 -6.427265996078052
100 -16.633604038506746 -6.297345923460855
101 -18.813799910247326 -6.091200240265948
102 -18.230095714330673 -6.000672795245189
103 -18.174311824142933 -5.719226978965594
104 -18.870264016091824 -5.588285041200628
105 -18.286163300275803 -5.481383183362745
106 -17.639609195291996 -5.3908374453295025
107 -17.76305840909481 -5.33701907430182
108 -17.57312709093094 -5.208265603642696
109 -14.858237501233816 -5.033102494558717
110 -18.12988366931677 -4.776053151752164
111 -13.927989296615124 -4.602948144906834
112 -22.23869164660573 -4.230832004686763
113 -22.63287129253149 -4.031048624093466
114 -17.256264865398407 -3.8584365735263226
115 -10.047992121428251 -3.504452131871366
116 -12.503363471478224 -3.2251964534430897
117 -11.496480893343687 -3.0328659246689877
118 -11.584973320364952 -2.776723337306246
119 -10.120976958423853 -1.1442506653112832
train accuracy: 1.0
validation accuracy: 1.0
[-74.17211785 -73.95782727 -73.26805818 ...  -1.75329271  -1.50369367
  -1.14425067]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:1
end of epoch 0: val_loss 0.00041577477130687156, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.4305e-01,  1.5843e-02,  3.9061e-02, -2.0909e-01,  2.4359e-05,
          1.9933e-01,  3.4015e-03,  7.6896e-03, -8.2354e-04, -3.9670e-02,
         -3.7692e-04, -6.3713e-01, -5.8857e-01]], device='cuda:1'))])
end of epoch 1: val_loss 0.02069873124756377, val_acc 0.985
trigger times: 1
end of epoch 2: val_loss 0.0011635936173479422, val_acc 1.0
trigger times: 2
end of epoch 3: val_loss 0.0014220916223712265, val_acc 1.0
trigger times: 3
end of epoch 4: val_loss 7.895361628676767e-05, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 6.6677e-01,  1.8366e-01,  5.1165e-02,  2.4429e-05,  4.0964e-04,
          1.7257e-05,  2.1266e-03, -2.4120e-02, -5.0981e-05,  3.2488e-05,
         -3.7728e-04, -2.5565e+00, -1.7818e+00]], device='cuda:1'))])
end of epoch 5: val_loss 0.0034351339934983118, val_acc 1.0
trigger times: 1
end of epoch 6: val_loss 3.0185792420525105e-05, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 8.0444e-01,  4.1976e-01,  5.6138e-01, -5.2794e-02,  5.9376e-02,
          7.2820e-05,  1.2895e-02, -5.2367e-02, -2.2439e-01,  1.6073e-05,
         -3.7745e-04, -3.6638e+00, -2.8065e+00]], device='cuda:1'))])
end of epoch 7: val_loss 4.2293008737033235e-05, val_acc 1.0
trigger times: 1
end of epoch 8: val_loss 0.36634790003299034, val_acc 0.985
trigger times: 2
end of epoch 9: val_loss 0.0017378765294051846, val_acc 1.0
trigger times: 3
end of epoch 10: val_loss 0.0010731001198288227, val_acc 1.0
trigger times: 4
end of epoch 11: val_loss 2.871447677357253e-06, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 7.9026e-02,  1.1654e-05, -6.1728e-06,  7.4080e-05, -3.7058e-05,
          9.6905e-02,  3.7909e-03, -4.4819e-02,  3.3541e-04,  6.2712e-05,
         -3.7791e-04, -1.4197e+00, -2.3339e+00]], device='cuda:1'))])
end of epoch 12: val_loss 0.04938394129276272, val_acc 0.995
trigger times: 1
end of epoch 13: val_loss 5.9756678454050415e-05, val_acc 1.0
trigger times: 2
end of epoch 14: val_loss 0.0011956838484150011, val_acc 1.0
trigger times: 3
end of epoch 15: val_loss 0.4564920568460357, val_acc 0.98
trigger times: 4
end of epoch 16: val_loss 7.542185002876067e-05, val_acc 1.0
trigger times: 5
end of epoch 17: val_loss 0.0038107645511627195, val_acc 0.995
trigger times: 6
end of epoch 18: val_loss 0.0002454927004873753, val_acc 1.0
trigger times: 7
end of epoch 19: val_loss 3.5602541111003914e-05, val_acc 1.0
trigger times: 8
end of epoch 20: val_loss 0.10453784577722786, val_acc 0.995
trigger times: 9
end of epoch 21: val_loss 0.0240920615196228, val_acc 0.995
trigger times: 10
Early stopping.
0 -398.34152269363403 -74.1721178479907
1 -421.8905692100525 -70.8994510047542
2 -417.0066227912903 -70.11398439797705
3 -392.2236635684967 -69.13509469721924
4 -411.9595637321472 -68.5934259629071
5 -385.9878647327423 -67.83054510718824
6 -378.00313329696655 -67.06251733755995
7 -401.64209175109863 -66.39849672036088
8 -392.7096104621887 -65.78478981041695
9 -392.0971212387085 -65.09248013366215
10 -397.73288345336914 -64.19615667823099
11 -393.1915349960327 -62.957308997795835
12 -176.5828983783722 -61.776331442264365
13 -139.50720286369324 -60.38718536542509
14 -141.73097014427185 -59.673772474088956
15 -167.79577922821045 -59.001719499099124
16 -148.74044013023376 -58.525112330336405
17 -133.1992210149765 -57.95252047370761
18 -159.08139896392822 -57.4461408949042
19 -149.96774899959564 -56.93392956513718
20 -134.85027706623077 -56.459643561793115
21 -153.0851069688797 -55.67181192441976
22 -136.46207690238953 -54.957742477270806
23 -136.53878486156464 -53.052364763466606
24 -152.3994152545929 -50.03933801517046
25 -129.3248409628868 -42.29180714825394
26 -103.54613256454468 -39.024610555047154
27 -78.45043802261353 -37.00630588930485
28 -76.76993751525879 -35.209705244501436
29 -52.68727096915245 -31.223196019713853
30 -80.31457775831223 -26.244794902859052
31 -130.1421930193901 -22.60679894414887
32 -124.02863264083862 -19.069219916538202
33 -113.40092873573303 -18.127041097019113
34 -84.88058799505234 -17.274482717099506
35 -102.43710541725159 -16.79513369053744
36 -95.31406754255295 -16.341026632543436
37 -86.5999273955822 -15.781257051450723
38 -45.68378400802612 -15.307833897061936
39 -4.492355138063431 -14.904482610357418
40 -83.76837629079819 -14.5813898350114
41 -82.34926843643188 -14.396356847233497
42 -83.42692339420319 -14.200458203973822
43 3.778570845723152 -13.92859157811282
44 -23.252802446484566 -13.67405282962576
45 -16.32332941889763 -13.549081776409208
46 -60.90184864401817 -13.353988783180114
47 4.501385100185871 -13.052675933905098
48 -62.59407062828541 -12.865298639028284
49 4.804117053747177 -12.632642813105404
50 18.922242909669876 -12.40769467640963
51 -9.973961919546127 -12.158969262874024
52 11.118139863014221 -12.105750180114182
53 3.993522435426712 -11.84952764990956
54 -5.131117075681686 -11.743538667886787
55 -71.81958276033401 -11.52703030325326
56 12.240356266498566 -11.320831097589815
57 -48.02415881305933 -11.19038698837289
58 -39.210373025387526 -10.941676269692449
59 -63.72748367488384 -10.866047997251195
60 1.3214437812566757 -10.68607454662182
61 12.335370652377605 -10.552160914068711
62 -103.39758688211441 -10.457464959039598
63 -49.08442182838917 -10.351553064761587
64 -39.09755413234234 -10.273250403172675
65 6.080901920795441 -10.067061416087038
66 -4.623874753713608 -9.939959857950758
67 9.086351171135902 -9.851580911421218
68 1.0963854640722275 -9.651824897550707
69 13.717413529753685 -9.580870049493816
70 21.602881848812103 -9.383101526029112
71 -33.6912559568882 -9.241743878159983
72 29.712696224451065 -9.14868716386642
73 -15.10846422612667 -9.074454396568065
74 7.42415389418602 -8.980290623543777
75 39.41775679588318 -8.85323122581894
76 47.23386514186859 -8.722016031144216
77 15.65185084939003 -8.579367950718927
78 -14.380633935332298 -8.495000865396662
79 11.03484320640564 -8.394063598123529
80 10.225513439625502 -8.320553743824137
81 -16.7023533731699 -8.197800349637825
82 13.39038347452879 -8.103473150965206
83 -23.3897602558136 -7.985362861808601
84 -1.3999725356698036 -7.884901491118108
85 -1.2689160257577896 -7.782790769042369
86 6.802107661962509 -7.6942251902277174
87 -37.93547807261348 -7.64204348129513
88 14.40398408472538 -7.545096827352388
89 25.247247219085693 -7.461380354533785
90 46.60248476266861 -7.329561772631171
91 28.83296938240528 -7.18318261420088
92 19.20744900405407 -7.050029845978645
93 32.884251922369 -6.850151278605663
94 19.571097254753113 -6.783324984670566
95 9.66800731420517 -6.701697882810898
96 57.60328334569931 -6.542375476636961
97 29.878231927752495 -6.4940351064209345
98 9.844907477498055 -6.3514406130447
99 32.89229619503021 -6.212574035942411
100 -4.482715494930744 -6.103804288981516
101 29.266794934868813 -6.000672795245189
102 49.21323275566101 -5.832164384512402
103 28.91521556675434 -5.682304058564679
104 22.447678446769714 -5.517198240931295
105 36.75234365463257 -5.437117321905785
106 10.17305339872837 -5.34720210027791
107 24.346049159765244 -5.283573601409269
108 -9.302657157182693 -5.078485007852753
109 59.52744436264038 -4.946479935369378
110 40.5458979010582 -4.657036692347991
111 36.20199564099312 -4.487529493692339
112 24.48072251677513 -4.086351301363474
113 58.964590668678284 -3.9543402921327724
114 63.586210906505585 -3.623509925216658
115 64.88726961612701 -3.442747259427934
116 48.65728622674942 -3.2145148362616784
117 61.460639387369156 -3.0210691850193663
118 69.66748380661011 -2.692415004537417
119 80.5750447511673 -1.1442506653112832
train accuracy: 0.9988888888888889
validation accuracy: 0.995
[-74.17211785 -73.95782727 -73.26805818 ...  -1.75329271  -1.50369367
  -1.14425067]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:3
end of epoch 0: val_loss 4.988958161433743e-06, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.3444e-01,  3.2418e-02,  1.2183e-01, -1.3460e-01,  2.7734e-01,
          1.8571e-01,  4.5644e-03,  3.6100e-02, -3.1898e-01, -2.5383e-01,
         -3.7692e-04, -1.3841e+00, -1.1428e+00]], device='cuda:3'))])
end of epoch 1: val_loss 3.954764618011808e-05, val_acc 1.0
trigger times: 1
end of epoch 2: val_loss 0.993035429897145, val_acc 0.975
trigger times: 2
end of epoch 3: val_loss 4.83295179947163e-06, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 6.4164e-01,  2.0571e-01,  4.2805e-01,  2.9473e-01,  9.4304e-01,
          8.8107e-02,  1.6858e-02, -4.3069e-02, -7.9910e-01, -3.5409e-01,
         -3.7719e-04, -3.2601e+00, -3.0524e+00]], device='cuda:3'))])
end of epoch 4: val_loss 8.982098079215461e-06, val_acc 1.0
trigger times: 1
end of epoch 5: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.4492e-02,  4.8659e-06,  3.5307e-05,  2.8140e-03, -1.7437e-04,
         -6.5383e-05,  1.3102e-02,  7.9318e-06,  2.3958e-04, -2.5589e-05,
         -3.7736e-04, -2.6068e+00, -2.6396e+00]], device='cuda:3'))])
end of epoch 6: val_loss 0.0002060782572965536, val_acc 1.0
trigger times: 1
end of epoch 7: val_loss 0.042248469214246104, val_acc 0.995
trigger times: 2
end of epoch 8: val_loss 2.09348597530834e-05, val_acc 1.0
trigger times: 3
end of epoch 9: val_loss 9.357875796922599e-08, val_acc 1.0
trigger times: 4
end of epoch 10: val_loss 3.425982093513012, val_acc 0.925
trigger times: 5
end of epoch 11: val_loss 1.5391857590962842e-05, val_acc 1.0
trigger times: 6
end of epoch 12: val_loss 8.346696954731669e-05, val_acc 1.0
trigger times: 7
end of epoch 13: val_loss 3.4251887075242846e-05, val_acc 1.0
trigger times: 8
end of epoch 14: val_loss 1.019233851806689e-07, val_acc 1.0
trigger times: 9
end of epoch 15: val_loss 9.28739021400915e-05, val_acc 1.0
trigger times: 10
Early stopping.
0 -363.68990302085876 -74.1721178479907
1 -364.5965976715088 -70.8044126597139
2 -352.6056637763977 -69.71058217802842
3 -357.51297640800476 -68.8915651062313
4 -350.4875521659851 -68.42673895715825
5 -351.23282194137573 -67.26714336425908
6 -345.96050786972046 -66.75857022061828
7 -344.6589651107788 -65.96752012705973
8 -341.254478931427 -65.20473008643418
9 -340.5866553783417 -64.63676646451523
10 -342.0915422439575 -62.957308997795835
11 -331.06745195388794 -61.36034637046674
12 -134.34409475326538 -60.238400168101776
13 -126.72841370105743 -59.4795190019586
14 -127.50717890262604 -58.78056699141966
15 -127.15922951698303 -58.320564222040005
16 -126.03012776374817 -57.76792801354424
17 -127.64719498157501 -57.0208302823768
18 -129.91794741153717 -56.552285837127755
19 -120.0579571723938 -55.72514103936067
20 -118.43350076675415 -54.957742477270806
21 -117.54774105548859 -52.9454820772196
22 -166.91246563196182 -49.72654640753777
23 -168.7441633939743 -41.68588229294918
24 -144.84866979718208 -37.79713616772368
25 -147.16121745109558 -36.114459029559086
26 -140.67903542518616 -31.969099402548657
27 -112.52024856209755 -27.196681629483837
28 -116.56688839197159 -23.44970807952351
29 -125.47182941436768 -19.506005447218197
30 -120.09759211540222 -18.122600478572778
31 -107.08113074302673 -17.247013192707772
32 -98.79016143083572 -16.62260982114398
33 -96.10769373178482 -16.143070183582857
34 -98.46718126535416 -15.63213816750866
35 -43.912834495306015 -15.130970110729379
36 -54.36025992035866 -14.708032068741046
37 -37.01114919781685 -14.4675637058252
38 -34.00321988761425 -14.280669824338958
39 -51.44273364543915 -13.952640642742022
40 -63.464683532714844 -13.691844270230611
41 -53.791008949279785 -13.549081776409208
42 -59.380595207214355 -13.324822962029103
43 -58.35395658761263 -13.113664421126611
44 -54.449532210826874 -12.871930358951412
45 -26.492797143757343 -12.633806480141791
46 -45.70249891281128 -12.513996032277635
47 -44.14925354719162 -12.223322288200382
48 -47.01591029763222 -12.11702219932888
49 -49.90292739868164 -11.949703471602199
50 -50.26591795682907 -11.763648501991785
51 -29.820871740579605 -11.591561793686814
52 -49.377461701631546 -11.381368677597688
53 -43.88063360750675 -11.286979459432317
54 -36.630722373723984 -11.005141518049829
55 -42.773974537849426 -10.886384301991674
56 -25.440011888742447 -10.737323459681452
57 -41.835310094058514 -10.627626155051956
58 -49.448754251003265 -10.491363555492372
59 -44.42199149727821 -10.375004869444705
60 -37.40370336174965 -10.317886185019585
61 -35.76598107814789 -10.108383968042629
62 -75.47265535593033 -9.96903964512557
63 -52.43338602781296 -9.860444062091586
64 -20.48715203255415 -9.684277247412624
65 -41.034741297364235 -9.602157288292089
66 -40.43749558925629 -9.382001976547434
67 -69.4045261144638 -9.233317835466233
68 -6.555939923971891 -9.144064258973524
69 -21.906391486525536 -9.074454396568065
70 -39.773198779672384 -8.966157734696775
71 -22.84737439453602 -8.843629267233913
72 -19.94470550492406 -8.70664425465433
73 -33.97664934396744 -8.552729172085996
74 -19.656079716980457 -8.454482790298536
75 -35.70995923131704 -8.381597705343829
76 -11.85842827707529 -8.300986286589918
77 -33.22151963412762 -8.187949197711195
78 -23.4588810056448 -8.062672687413787
79 -65.2722596526146 -7.948561022791138
80 -11.37311788648367 -7.854002347678565
81 -64.24589735269547 -7.748722774635732
82 -14.800365835428238 -7.679194063330316
83 -35.760763585567474 -7.57539849177145
84 -63.901648223400116 -7.50355076209545
85 -37.600466042757034 -7.359109421674682
86 -32.43108972907066 -7.23966158600652
87 -19.488380406051874 -7.117492960452371
88 -34.689491495490074 -6.959063561385431
89 -30.5323636084795 -6.8334260471568555
90 -35.062935166060925 -6.760805759962728
91 -6.613816291093826 -6.646712695840218
92 -29.901574298739433 -6.5285615052371115
93 -32.683268159627914 -6.473636274838243
94 -24.774739496409893 -6.3302144766947395
95 -7.8131676241755486 -6.171578712362422
96 -33.528903383761644 -6.115673843706155
97 -28.08026994764805 -6.0298048168667115
98 2.05684095621109 -5.935865814862789
99 -29.464649513363838 -5.764207841841876
100 -39.93072673678398 -5.615796733870542
101 -16.250085331499577 -5.502096931280733
102 -4.913002133369446 -5.4249377103205845
103 3.825535975396633 -5.346270199456767
104 -27.08531553670764 -5.283573601409269
105 -6.299024291336536 -5.129445826215632
106 -21.386342599987984 -5.027957977402961
107 -13.634326949715614 -4.846398644655714
108 -3.6071350425481796 -4.657036692347991
109 -0.6970431506633759 -4.511493435451824
110 -24.79405876994133 -4.230832004686763
111 -19.363681122660637 -4.031048624093466
112 -6.323557987809181 -3.928002417125516
113 8.949101626873016 -3.6664589979248827
114 3.0969858318567276 -3.5249296553314746
115 4.518096208572388 -3.267439264821324
116 16.555656880140305 -3.1373284950587914
117 -0.3741665780544281 -2.8556025059129393
118 4.080376446247101 -2.502062380310709
119 19.4870445728302 -1.1442506653112832
train accuracy: 0.9983333333333333
validation accuracy: 1.0
