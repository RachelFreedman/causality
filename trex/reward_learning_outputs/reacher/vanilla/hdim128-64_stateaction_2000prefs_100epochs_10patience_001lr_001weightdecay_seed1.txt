demos: (120, 50, 13)
demo_rewards: (120,)
[-51.11086407 -49.11584688 -48.97455067 -48.8722857  -48.72375071
 -47.2425208  -44.96921644 -44.85812386 -44.46529881 -44.43890163
 -44.14921993 -43.75035245 -43.58405711 -43.39691285 -43.22343613
 -42.9211339  -42.65748859 -42.6023149  -42.32863806 -42.30445768
 -41.12283699 -40.75815407 -40.70441037 -40.03758738 -39.90846007
 -39.57032589 -39.31833047 -39.27893976 -39.11210375 -39.0792282
 -38.7342435  -38.46237505 -37.86129653 -37.30806553 -36.41283474
 -36.30795891 -36.12354063 -36.01221343 -35.76166082 -35.55804095
 -34.8333516  -34.24472332 -33.78094921 -32.94911634 -32.77451865
 -32.11238423 -31.53427075 -30.66780209 -30.40290221 -30.23366087
 -29.87212516 -29.40604135 -29.1352587  -28.84050982 -28.57862903
 -28.43871007 -28.43374877 -28.16728518 -27.92060294 -27.7391148
 -27.29994968 -26.75229479 -25.93903491 -25.92997211 -25.90184838
 -24.37443057 -24.18079375 -24.11517187 -23.99196367 -23.29102321
 -22.59530834 -22.40229356 -22.25673726 -21.7139277  -21.70254077
 -19.72288085 -19.26334551 -18.56975936 -18.11146126 -17.71205165
 -17.6663674  -17.58971226 -16.59087236 -16.36275632 -15.99253949
 -15.33818265 -14.68824709 -14.05563167 -13.91164962 -13.42778136
 -12.61940694 -12.22562907 -11.73504365 -10.78101609 -10.72946334
  -9.78594151  -9.77591752  -9.56682446  -9.19326137  -7.57539849
  -7.36244313  -7.10832736  -7.07294326  -6.95906356  -6.77694649
  -6.72206384  -6.71997062  -6.51820418  -5.61579673  -5.3472021
  -5.07848501  -5.02795798  -4.82757292  -4.63049542  -4.230832
  -4.03104862  -3.38446715  -3.3322555   -2.64166233  -1.91361965]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=128, bias=True)
  (1): Linear(in_features=128, out_features=64, bias=True)
  (2): Linear(in_features=64, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 10112
Number of trainable paramters: 10112
device: cuda:1
end of epoch 0: val_loss 0.26625235599175257, val_acc 0.875
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.4506e-02, -5.5436e-02, -4.0357e-02,  ...,  3.4262e-42,
          1.2145e-02, -4.8984e-03],
        [-3.2213e-02, -1.4735e-02, -4.8297e-02,  ..., -5.5071e-43,
         -2.3315e-02, -5.7089e-04],
        [-2.5606e-03, -5.8719e-03, -2.3858e-03,  ...,  9.8371e-43,
         -7.3127e-03,  2.5941e-03],
        ...,
        [ 3.4685e-02, -8.0651e-02, -2.1083e-02,  ..., -2.3976e-42,
         -1.9410e-02, -1.5574e-02],
        [ 3.0522e-03,  4.3886e-03,  3.2026e-03,  ...,  9.1365e-43,
          3.1483e-03, -1.0289e-03],
        [ 3.2025e-02, -5.4925e-02, -7.9746e-02,  ..., -1.3957e-42,
          2.4479e-01, -3.0608e-02]], device='cuda:1')), ('fcs.0.bias', tensor([-0.1356, -0.0966, -0.1210, -0.0875, -0.1174, -0.0535, -0.2055, -0.1974,
        -0.2318, -0.1445, -0.2203, -0.1260, -0.1423, -0.1401, -0.1504, -0.0684,
        -0.1972, -0.1866, -0.1781, -0.0619, -0.0989, -0.1290, -0.0604, -0.2179,
        -0.0477, -0.1263, -0.0321, -0.1106, -0.2920, -0.0237, -0.1152, -0.1602,
        -0.1184, -0.3013, -0.2377, -0.0274, -0.3501, -0.1209, -0.2362, -0.1562,
        -0.2301, -0.0261, -0.0560, -0.0833, -0.1867, -0.1153, -0.2647, -0.2050,
        -0.0252, -0.1851, -0.1139, -0.0912, -0.0558, -0.0478, -0.1804, -0.1356,
        -0.1777, -0.0883, -0.1596, -0.1620, -0.1814, -0.0412, -0.1374, -0.1276,
        -0.0933, -0.1463, -0.1499, -0.1432, -0.1208, -0.0477, -0.0505, -0.0542,
        -0.1792, -0.1635, -0.1034, -0.1263, -0.0542, -0.1128, -0.0204, -0.2234,
        -0.1301, -0.1407, -0.0550, -0.1496, -0.1155, -0.0802, -0.0519, -0.2577,
        -0.1354, -0.1870, -0.1909, -0.3250, -0.0299, -0.1456, -0.0557, -0.1782,
        -0.1351, -0.0340, -0.1966, -0.1643, -0.1812, -0.1468, -0.1783, -0.0747,
        -0.0298, -0.0952, -0.0010, -0.2930, -0.1672, -0.1380, -0.2707, -0.0997,
        -0.1765, -0.1196, -0.1622, -0.0601, -0.1204, -0.1908, -0.2446, -0.1135,
        -0.0565, -0.0886, -0.1824, -0.0513, -0.3361, -0.1140, -0.1021, -0.1480],
       device='cuda:1')), ('fcs.1.weight', tensor([[-2.4152e-03, -3.2948e-03, -1.4630e-03,  ..., -2.4996e-02,
         -9.1709e-04, -1.0520e-02],
        [-1.0260e-01, -1.6935e-02, -1.0160e-02,  ..., -2.7015e-02,
         -6.1180e-03, -2.0178e-01],
        [-4.0773e-03, -3.4065e-03,  5.3218e-03,  ..., -1.5628e-02,
         -5.1108e-03, -1.5379e-02],
        ...,
        [-6.5238e-02,  2.7332e-03,  1.0086e-03,  ...,  4.3540e-03,
         -1.0921e-04, -4.9201e-02],
        [ 8.6170e-03, -3.5096e-03, -1.0213e-03,  ..., -2.3821e-03,
         -4.9439e-04, -4.6527e-02],
        [-7.1789e-03, -1.4958e-04,  4.7910e-04,  ..., -3.4317e-04,
         -1.5637e-02, -2.3964e-02]], device='cuda:1')), ('fcs.1.bias', tensor([-7.5947e-03, -1.7266e-01, -1.3374e-02, -1.4610e-01, -8.1134e-02,
        -1.4714e-01, -1.8489e-02,  1.4258e-01, -2.8623e-01, -1.1224e-01,
        -2.9943e-02, -6.5593e-03, -1.1982e-01, -2.4810e-01, -4.3344e-02,
        -1.1985e-01, -6.2042e-02, -5.5241e-03, -3.3424e-05, -2.3252e-02,
        -7.2147e-03, -2.0492e-01, -4.7477e-03, -1.0536e-02, -1.8983e-02,
        -1.2287e-01,  2.2846e-01, -5.1051e-02, -8.8511e-03, -1.5491e-02,
        -2.8740e-02, -5.6842e-02, -9.6533e-04, -7.0351e-02, -3.0206e-02,
        -2.2209e-02, -1.7976e-02, -6.3192e-03, -2.3052e-02, -1.9197e-02,
        -4.7681e-03, -4.8637e-02, -1.2663e-01, -2.9238e-02, -1.2590e-02,
         7.1462e-01, -3.5913e-02, -1.7861e-02, -2.3691e-02, -1.8616e-02,
        -1.1678e-02, -2.4119e-03, -5.5985e-03, -1.3553e-02, -2.4539e-02,
        -4.7163e-02, -2.7408e-02,  7.1465e-01, -2.2758e-02, -1.0475e-03,
        -8.9383e-03, -1.0681e-01, -1.6466e-02, -5.9499e-03], device='cuda:1')), ('fcs.2.weight', tensor([[ 2.2771e-02,  2.7078e-01,  2.6651e-02,  8.6088e-03, -1.0696e-02,
          1.4497e-01,  1.6763e-02,  5.2755e-02,  6.8614e-03,  2.7412e-03,
          2.2710e-01,  3.7010e-02,  7.5596e-02,  1.8243e-01,  5.7999e-02,
          2.0733e-01,  8.2401e-02,  2.5256e-02,  2.1881e-03,  2.0523e-02,
          3.0281e-02, -1.3147e-01,  1.9075e-02,  5.4951e-02,  1.3207e-01,
          9.2585e-03,  1.2435e-01, -1.0465e-01,  5.0170e-02,  9.8268e-03,
          3.9574e-02,  3.5631e-02,  3.3548e-05,  5.6442e-02,  3.0767e-03,
          2.6690e-02,  6.9917e-02,  4.2912e-02,  8.3598e-02,  5.7697e-02,
          7.8946e-02,  6.9670e-02,  1.7461e-01,  2.8142e-02,  1.6891e-02,
          2.3527e-01,  1.3528e-02,  3.7309e-02,  5.4865e-02,  1.7570e-02,
          6.1847e-02,  5.6047e-03,  1.6798e-02,  1.1621e-01,  9.7644e-02,
          9.6222e-03,  1.8092e-02,  1.3345e-01,  8.5393e-02,  1.8810e-02,
          1.2575e-02, -2.9936e-02,  8.6115e-03, -5.5361e-04]], device='cuda:1'))])
end of epoch 1: val_loss 2.3488273165322564, val_acc 0.615
trigger times: 1
end of epoch 2: val_loss 2.078039440203216, val_acc 0.68
trigger times: 2
end of epoch 3: val_loss 0.2428540375455168, val_acc 0.88
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.2720e-01, -1.6487e-01,  1.8628e-02,  ...,  1.0888e-17,
          2.0648e-02,  3.9837e-02],
        [-1.2847e-02, -6.9741e-02, -4.1305e-02,  ..., -1.0101e-28,
         -8.5683e-03,  1.9443e-02],
        [ 8.8014e-02,  1.4260e-01,  1.0687e-01,  ...,  3.0688e-42,
          5.3493e-01, -2.0507e-01],
        ...,
        [-7.8757e-03,  7.6380e-03, -9.7483e-02,  ..., -2.0857e-14,
         -7.5718e-03, -4.0397e-02],
        [-1.2992e-03, -3.7993e-04, -6.9110e-03,  ..., -2.9197e-27,
         -1.6185e-03, -2.3907e-04],
        [ 2.4990e-03,  1.4707e-03, -7.3715e-03,  ..., -1.7415e-13,
         -1.0895e-03, -9.9435e-04]], device='cuda:1')), ('fcs.0.bias', tensor([-4.4438e-01, -3.8434e-01, -4.8780e-02, -2.8825e-01, -3.5392e-01,
        -1.4875e-04, -1.9548e-02, -9.2369e-02, -7.5358e-02, -6.8167e-02,
        -1.6480e-01, -1.4197e-02, -2.6309e-01, -6.6992e-02, -2.1525e-01,
         5.7323e-02, -1.6800e-01, -1.7413e-01, -6.3281e-03, -1.2738e-01,
        -3.4260e-01, -2.3307e-01, -1.0789e-02, -4.1584e-02, -1.4667e-01,
        -1.1201e-01, -8.9168e-02, -2.0345e-01, -2.3856e-01, -1.1203e-01,
        -2.1497e-01, -5.2788e-02,  3.3372e-02, -9.6229e-02, -7.4761e-02,
        -8.6057e-03, -1.8631e-01, -2.2365e-02, -6.3195e-02, -2.0121e-01,
        -6.1494e-03, -4.5129e-02, -2.6783e-01, -3.2293e-01, -7.2773e-02,
        -2.5285e-01, -8.6172e-03, -3.1500e-01, -8.0438e-02, -8.0240e-02,
        -3.0168e-02, -7.3974e-03, -4.3986e-02, -1.8947e-01, -2.4826e-01,
        -9.9007e-02, -1.2077e-02, -1.0268e-02, -7.1787e-02, -1.4732e-01,
        -1.8308e-01, -2.8331e-01, -9.5238e-03, -2.0869e-01, -4.2755e-02,
        -3.0695e-01, -5.3209e-02, -3.7959e-02, -2.4016e-01, -6.6937e-02,
        -1.5589e-01, -2.9441e-02, -7.9537e-02, -8.7868e-02, -5.3462e-04,
        -8.6413e-02, -6.5493e-03, -1.1743e-02, -4.0348e-02, -6.7034e-02,
        -1.9938e-01, -1.1982e-01, -2.2462e-02, -1.8033e-02, -4.3272e-02,
        -1.9736e-01, -9.4334e-02, -6.6814e-02, -1.3217e-01, -1.2946e-01,
        -9.3886e-02, -1.3666e-01, -1.9738e-02, -7.8177e-02, -1.7204e-02,
        -4.0308e-02, -1.1452e-01, -1.0450e-02, -1.2326e-02, -1.3554e-01,
        -6.3828e-03,  8.3001e-03, -4.9849e-04, -1.6901e-01, -1.5448e-01,
        -7.0882e-02, -3.5919e-02, -8.4447e-02, -7.6251e-02, -8.2046e-05,
        -1.0628e-01, -1.3935e-01, -1.5685e-01, -4.0734e-01, -2.4567e-03,
        -1.8684e-01, -2.4302e-01, -2.4769e-01, -2.7996e-01, -7.6320e-02,
        -9.0729e-02, -1.3238e-01, -2.6422e-01, -7.6508e-04, -3.4421e-01,
        -2.4964e-01, -1.8782e-02, -2.4632e-02], device='cuda:1')), ('fcs.1.weight', tensor([[-2.8393e-03, -2.0414e-03, -6.0763e-02,  ..., -7.3255e-03,
          3.7530e-03,  1.9843e-03],
        [-8.4834e-02, -4.2287e-03, -1.2465e-01,  ..., -6.8933e-02,
         -3.3875e-03, -1.3754e-03],
        [-7.7173e-02, -3.0182e-02, -5.7411e-02,  ..., -6.9845e-02,
         -6.2202e-04, -1.1619e-03],
        ...,
        [-3.5206e-02, -3.9136e-02,  2.5568e-02,  ..., -6.3122e-02,
          6.0559e-04,  3.8533e-04],
        [-4.0195e-04, -9.8588e-04,  3.5827e-03,  ..., -9.3942e-04,
         -9.0551e-05,  6.3150e-06],
        [-1.1074e-03,  1.6267e-03, -2.0540e-02,  ..., -4.6588e-03,
          3.3177e-04,  3.1867e-04]], device='cuda:1')), ('fcs.1.bias', tensor([-1.8782e-01, -2.5971e-01, -4.0089e-02, -1.3012e-02, -3.0465e-02,
        -9.3098e-02, -2.2509e-01, -1.7129e-03, -1.1239e-01,  2.1933e-02,
        -1.4034e-02, -8.6357e-02, -1.2287e-02, -3.2116e-02, -1.3374e-01,
        -2.7273e-01, -1.3810e-01, -1.7251e-04, -8.0451e-02, -1.1443e-02,
        -2.7252e-01, -1.2078e-01, -3.1400e-03, -6.1813e-02, -1.6540e-01,
        -7.6501e-02, -1.6521e-01, -1.5456e-02, -1.8806e-02, -2.2960e-01,
        -5.5197e-02, -1.3696e-01, -2.0141e-01, -2.0156e-01, -6.6919e-03,
        -1.0144e-02, -1.7145e-01, -1.4894e-01, -1.3508e-01, -1.4884e-03,
        -6.6785e-02, -3.2277e-02, -3.8882e-02, -1.2656e-01, -2.0842e-02,
         9.7422e-01, -1.5239e-02, -2.2488e-01, -1.3837e-02, -5.5435e-02,
        -7.7441e-03, -4.7459e-02, -2.9621e-01, -9.5861e-03, -2.6979e-02,
        -2.0987e-01, -1.1714e-01, -2.0271e-02, -3.3047e-01, -9.8160e-02,
        -7.1345e-02, -5.2618e-02, -3.1241e-02, -4.3172e-03], device='cuda:1')), ('fcs.2.weight', tensor([[ 1.7913e-01, -1.1695e-01, -2.6113e-02,  8.1636e-03,  2.0963e-02,
         -1.2144e-01,  1.8725e-01,  1.0190e-03,  5.3634e-02, -1.0876e-02,
          5.6894e-03, -1.5248e-01, -6.4026e-03,  5.8293e-03,  3.1074e-01,
         -1.0991e-01,  1.1698e-01, -3.2136e-04, -9.9814e-02,  3.2357e-03,
          1.2413e-01, -1.1284e-01, -5.6946e-03, -6.6993e-03,  1.9923e-02,
         -6.6610e-03, -1.1550e-01,  3.9030e-02,  1.1164e-02, -1.8088e-01,
         -2.1331e-02, -4.5364e-02,  1.3474e-01,  1.0399e-01,  3.1358e-03,
         -4.2938e-03,  6.1620e-02,  9.6267e-02,  5.1195e-02,  1.7406e-03,
          2.1203e-02,  5.6705e-02,  4.6209e-02,  1.9367e-01,  1.9190e-02,
          2.8700e-01,  4.0255e-03,  1.4007e-01,  2.0216e-04, -5.3975e-02,
         -6.3123e-03, -4.4375e-02, -4.9063e-02,  9.9658e-03,  9.1496e-03,
          2.2956e-01,  9.9797e-02,  3.0338e-02,  7.7555e-03,  9.9666e-02,
          1.7553e-01,  5.1546e-02, -7.5074e-04,  1.0071e-02]], device='cuda:1'))])
end of epoch 4: val_loss 0.34141735597898615, val_acc 0.84
trigger times: 1
end of epoch 5: val_loss 0.900584716585294, val_acc 0.86
trigger times: 2
end of epoch 6: val_loss 0.9596774351139836, val_acc 0.795
trigger times: 3
end of epoch 7: val_loss 0.3917519720443698, val_acc 0.87
trigger times: 4
end of epoch 8: val_loss 1.3589398322593798, val_acc 0.82
trigger times: 5
end of epoch 9: val_loss 0.3399972888007498, val_acc 0.855
trigger times: 6
end of epoch 10: val_loss 2.446274636782666, val_acc 0.725
trigger times: 7
end of epoch 11: val_loss 0.250245406584961, val_acc 0.885
trigger times: 8
end of epoch 12: val_loss 0.39595110986759335, val_acc 0.865
trigger times: 9
end of epoch 13: val_loss 0.24528806592417873, val_acc 0.87
trigger times: 10
Early stopping.
0 -1.8296668799594045 -51.11086407377863
1 -1.8249866077676415 -49.11584688036212
2 -3.5780844036489725 -48.97455066650668
3 -5.327357517555356 -48.87228569913625
4 -3.237981839105487 -48.723750706751915
5 -1.6650870526209474 -47.242520801549375
6 -3.497145816218108 -44.969216444406115
7 -5.1087963953614235 -44.85812386141036
8 -3.2130606058053672 -44.465298807522004
9 -4.34138052444905 -44.438901626703945
10 -2.4714430645108223 -44.1492199315879
11 -0.9834658317267895 -43.750352447059115
12 -2.8856883123517036 -43.58405711344297
13 -4.566536961123347 -43.39691284921414
14 -1.6635063318535686 -43.22343612991455
15 -1.491536634042859 -42.92113389854083
16 -3.995428360067308 -42.65748859055198
17 -0.58204310759902 -42.60231490040316
18 -1.6434265552088618 -42.3286380570152
19 -1.662136978469789 -42.30445768311566
20 -3.669949217699468 -41.12283699063089
21 -1.3982980904402211 -40.758154070747366
22 -2.0810099383816123 -40.70441036508885
23 -2.2726638168096542 -40.037587376429016
24 -2.4745438508689404 -39.90846007278091
25 -4.037142241373658 -39.57032589487153
26 -1.8322788956575096 -39.31833047231749
27 -2.7909123208373785 -39.27893976130787
28 -2.636796571314335 -39.11210375046212
29 -1.5236859046854079 -39.07922820344388
30 -4.930583704262972 -38.73424350253481
31 -1.0345711736008525 -38.46237505180561
32 -1.3191603643354028 -37.86129653169397
33 -2.816626664251089 -37.308065525311996
34 -0.6554274642840028 -36.41283474392047
35 -2.3510082848370075 -36.307958906842664
36 -2.6387047097086906 -36.12354062747346
37 -1.497400488704443 -36.012213433621724
38 -0.7829846148379147 -35.76166081977253
39 -0.7353820968419313 -35.558040948837615
40 -2.217097779735923 -34.83335159619024
41 -2.6760189197957516 -34.24472332102743
42 -1.0109963584691286 -33.78094921339959
43 -1.330906962044537 -32.949116337767926
44 -0.14187402091920376 -32.774518645207735
45 -1.7238921686075628 -32.11238423004613
46 -0.7000265847891569 -31.534270745249735
47 -3.388385077007115 -30.667802091332018
48 -0.6352629717439413 -30.402902212388465
49 -0.773977329954505 -30.233660870125824
50 -1.5025522075593472 -29.87212515537898
51 -1.387467835098505 -29.40604134962864
52 -1.1764000449329615 -29.13525869956722
53 0.6710166661068797 -28.84050982317397
54 -0.2603122014552355 -28.578629026453186
55 -1.3657423509284854 -28.438710074595054
56 1.4539823643863201 -28.433748774939595
57 -0.900187423452735 -28.16728517571421
58 -1.581896428950131 -27.920602937037046
59 0.9217486293055117 -27.739114797604373
60 -0.4574325751163997 -27.29994968172231
61 0.4512189389206469 -26.752294794786035
62 1.45298339612782 -25.939034905087084
63 -1.255816767748911 -25.929972112830644
64 -0.5049747847951949 -25.901848378876174
65 0.19489265093579888 -24.374430568602165
66 1.8843374010175467 -24.180793753972072
67 -0.07150772586464882 -24.11517186961488
68 -0.7105988268449437 -23.991963674348654
69 -0.80304697714746 -23.291023207711152
70 -1.029345546849072 -22.595308335760205
71 -1.068012185394764 -22.402293560723127
72 0.1853051627986133 -22.256737260461836
73 1.667760749347508 -21.713927702452338
74 0.7621544422581792 -21.702540774014164
75 2.5194978257641196 -19.722880852611173
76 1.2899070288985968 -19.26334550647668
77 0.20307948533445597 -18.569759364071594
78 2.314124904340133 -18.111461264885516
79 0.7326563969254494 -17.712051650475324
80 2.280224327929318 -17.66636739843018
81 2.88240407127887 -17.589712263068826
82 2.9373233979567885 -16.590872364965673
83 1.7978628491982818 -16.362756319978686
84 0.646852558478713 -15.992539490672064
85 7.031882967392448 -15.338182650137867
86 3.5805417145602405 -14.688247089412398
87 1.8279673750512302 -14.055631672914624
88 7.0484512047842145 -13.911649622206243
89 1.7886688187718391 -13.427781363912512
90 1.9016640987247229 -12.619406941033082
91 5.336718061938882 -12.225629065695466
92 4.924962014425546 -11.735043647109059
93 5.5389934801496565 -10.781016093040188
94 8.86846576910466 -10.729463335147118
95 4.783999584615231 -9.785941512083282
96 7.459023206494749 -9.775917521665287
97 2.0127636287361383 -9.56682446099046
98 9.207298561930656 -9.193261368948118
99 8.170810689684004 -7.57539849177145
100 10.559612684883177 -7.362443126623615
101 13.468969013541937 -7.108327355338034
102 9.34309735801071 -7.072943263247867
103 8.6078622629866 -6.959063561385431
104 10.104539964348078 -6.776946485018116
105 11.0541852992028 -6.7220638398623045
106 10.180193299427629 -6.719970621583102
107 11.770825878717005 -6.51820418055673
108 10.190240542404354 -5.615796733870542
109 10.882826473098248 -5.34720210027791
110 10.895342709496617 -5.078485007852753
111 9.004178261384368 -5.027957977402961
112 13.484106423798949 -4.827572916892203
113 13.322877652011812 -4.63049541560991
114 13.463691875338554 -4.230832004686763
115 12.515860584564507 -4.031048624093466
116 13.169467392377555 -3.3844671463622564
117 12.418687843717635 -3.3322555012187633
118 14.025166736915708 -2.6416623314910934
119 14.640940402634442 -1.9136196540088464
train accuracy: 0.8838888888888888
validation accuracy: 0.87
