demos: (120, 50, 13)
demo_rewards: (120,)
[-54.98547503 -50.4922686  -50.03933802 -49.75347185 -49.72654641
 -46.98011874 -45.73515428 -45.67057988 -44.99030608 -44.14602409
 -43.81326882 -43.18878399 -42.29180715 -42.00401746 -41.69100444
 -41.68588229 -41.2817771  -40.44278203 -40.34838366 -39.59970115
 -39.57586365 -39.31972693 -39.02461056 -38.45534494 -38.4127039
 -38.35634328 -37.79713617 -37.74152899 -37.66475324 -37.51313938
 -37.1809993  -37.10070314 -37.00630589 -36.82191677 -36.48799015
 -36.2096527  -36.19207562 -36.11445903 -35.78149902 -35.39450387
 -35.262825   -35.24303541 -35.20970524 -35.06544085 -34.80241748
 -34.64469045 -33.84284986 -32.70706485 -31.9690994  -31.7109134
 -31.64414356 -31.39238276 -31.22319602 -31.12953085 -29.3915714
 -29.34012561 -29.10618999 -27.4110235  -27.34372236 -27.19668163
 -27.07399029 -26.70472176 -26.2447949  -25.54836509 -25.45878529
 -24.879107   -24.82869536 -24.59274514 -23.97874558 -23.57262108
 -23.44970808 -22.74530916 -22.60679894 -22.19891032 -20.65686376
 -20.44447256 -20.1969901  -20.13839115 -19.63760344 -19.51559872
 -18.9283881  -17.99477406 -17.5574237  -16.82307393 -14.8550828
 -14.5314246  -14.44242009 -13.59601285 -12.68135973 -12.66418206
 -12.30017947 -12.15190477 -11.78885214 -10.8699891  -10.3276815
  -9.85721598  -8.330117    -8.13319584  -8.10819769  -7.57539849
  -7.36244313  -7.10832736  -6.95906356  -6.77694649  -6.72206384
  -6.71997062  -6.53544734  -6.51820418  -5.61579673  -5.3472021
  -5.07848501  -5.02795798  -4.82757292  -4.63049542  -4.230832
  -4.03104862  -3.38446715  -3.3322555   -2.64166233  -1.91361965]
maximum traj length 50
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:0
end of epoch 0: val_loss 0.096240079855103, val_acc 0.99
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.0957e-01,  2.4579e-01,  2.1652e-01, -1.6199e-01,  1.4660e-01,
          1.0623e-01, -7.1404e-02,  7.1471e-02,  3.0007e-02, -6.6072e-02,
         -3.7692e-04, -6.6233e-01, -1.1648e+00]], device='cuda:0'))])
end of epoch 1: val_loss 0.0025551388920484895, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 4.4557e-04,  4.7213e-03, -2.8822e-03, -2.3650e-04, -3.4750e-04,
         -2.6194e-04, -1.8834e-03,  3.9040e-04,  9.8174e-04, -6.4484e-04,
         -3.7708e-04,  1.0324e-03, -2.8290e-01]], device='cuda:0'))])
end of epoch 2: val_loss 0.0030773196994960017, val_acc 1.0
trigger times: 1
end of epoch 3: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 1.0347e-04, -2.0164e-06,  7.6881e-05,  3.1395e-05,  4.7162e-04,
         -6.1344e-04, -7.4546e-06,  5.6753e-03,  1.0726e-04,  2.2979e-04,
         -3.7740e-04,  2.7550e-04, -1.3956e+00]], device='cuda:0'))])
end of epoch 4: val_loss 1.858347502068369e-05, val_acc 1.0
trigger times: 1
end of epoch 5: val_loss 2.3841844338789997e-08, val_acc 1.0
trigger times: 2
end of epoch 6: val_loss 0.0, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.1348e-01,  5.9743e-05, -7.8332e-07, -7.2543e-02, -1.3539e-04,
         -2.0011e-01, -2.3248e-02,  4.7862e-02, -2.1839e-04, -5.0755e-04,
         -3.7789e-04, -1.0455e+00, -1.8950e+00]], device='cuda:0'))])
end of epoch 7: val_loss 5.8886398850290785e-05, val_acc 1.0
trigger times: 1
end of epoch 8: val_loss 0.40947289086672045, val_acc 0.94
trigger times: 2
end of epoch 9: val_loss 4.053092465028385e-07, val_acc 1.0
trigger times: 3
end of epoch 10: val_loss 1.8316319253059988e-05, val_acc 1.0
trigger times: 4
end of epoch 11: val_loss 1.1563222521715488e-07, val_acc 1.0
trigger times: 5
end of epoch 12: val_loss 1.5204149468317496e-06, val_acc 1.0
trigger times: 6
end of epoch 13: val_loss 1.7881370339978275e-08, val_acc 1.0
trigger times: 7
end of epoch 14: val_loss 1.329682532851706e-05, val_acc 1.0
trigger times: 8
end of epoch 15: val_loss 0.011447692513290945, val_acc 0.99
trigger times: 9
end of epoch 16: val_loss 2.0265568991817416e-08, val_acc 1.0
trigger times: 10
Early stopping.
0 -45.19703271985054 -54.98547503240923
1 -46.96793995797634 -50.492268601198035
2 -42.07048595696688 -50.03933801517046
3 -43.286250337958336 -49.75347184620696
4 -42.85247267782688 -49.72654640753777
5 -45.50032977759838 -46.98011874490918
6 -43.10262496769428 -45.7351542845057
7 -41.39379017800093 -45.670579884154705
8 -42.625452131032944 -44.99030608142343
9 -40.0601873844862 -44.14602409201361
10 -40.49854677915573 -43.81326882122305
11 -41.033661268651485 -43.18878399086166
12 -41.91154599189758 -42.29180714825394
13 -39.65483867377043 -42.00401746161006
14 -43.797438353300095 -41.6910044370425
15 -40.43140923976898 -41.68588229294918
16 -40.83951959013939 -41.281777102712205
17 -39.1217954903841 -40.44278203413966
18 -40.38611076027155 -40.34838365523108
19 -38.69522161781788 -39.599701153458774
20 -38.73509341478348 -39.57586365327889
21 -36.88056017458439 -39.31972693233231
22 -35.17353730648756 -39.024610555047154
23 -36.95755407214165 -38.45534493538269
24 -36.93366227298975 -38.41270390343083
25 -38.08485172688961 -38.35634328077039
26 -35.74900759384036 -37.79713616772368
27 -33.88130921125412 -37.741528994987384
28 -40.225962936878204 -37.66475323879293
29 -36.46620340645313 -37.513139380385574
30 -40.58649557828903 -37.1809993033689
31 -37.08240670338273 -37.100703136010694
32 -36.28315858542919 -37.00630588930485
33 -37.82548335939646 -36.821916772458344
34 -37.33986760675907 -36.48799015296732
35 -35.01069673895836 -36.20965269874363
36 -36.057428607717156 -36.19207561676116
37 -38.01516507565975 -36.114459029559086
38 -35.56876641511917 -35.78149902167743
39 -33.558008439838886 -35.394503873250635
40 -37.00421068817377 -35.26282499693737
41 -35.867246344685555 -35.24303541418371
42 -37.43491753190756 -35.209705244501436
43 -36.183504834771156 -35.0654408505187
44 -34.839112509042025 -34.80241747531743
45 -34.821483477950096 -34.64469044638467
46 -32.96965931914747 -33.84284985953318
47 -31.283405989408493 -32.70706485357069
48 -30.99421525001526 -31.969099402548657
49 -31.787582516670227 -31.7109134007892
50 -33.282852441072464 -31.64414355845032
51 -32.61710458248854 -31.392382758954444
52 -34.5706005692482 -31.223196019713853
53 -30.781914733350277 -31.12953085092458
54 -32.02594695240259 -29.39157139549552
55 -32.821004539728165 -29.340125609942326
56 -26.69535645470023 -29.106189988903285
57 -29.623294837772846 -27.41102349748205
58 -30.17133366689086 -27.343722362182305
59 -30.59269791096449 -27.196681629483837
60 -29.43798978999257 -27.07399028854534
61 -26.816081881523132 -26.7047217556024
62 -28.73192997276783 -26.244794902859052
63 -29.045637637376785 -25.548365085275513
64 -26.349847055971622 -25.45878528601009
65 -28.022636495530605 -24.879106999799365
66 -27.378861367702484 -24.828695359328833
67 -28.30600495636463 -24.592745144504722
68 -27.290979214012623 -23.978745577896312
69 -26.299182943999767 -23.57262108435893
70 -24.8887418564409 -23.44970807952351
71 -26.185556903481483 -22.745309160183492
72 -25.077392484992743 -22.60679894414887
73 -25.214028619229794 -22.19891031871716
74 -24.919263222720474 -20.656863763892378
75 -22.78260462358594 -20.444472560731253
76 -22.75172777660191 -20.19699010077007
77 -25.154956568032503 -20.13839114930498
78 -23.966000985354185 -19.63760343800059
79 -24.27043828368187 -19.515598718228343
80 -22.897195741534233 -18.92838809611677
81 -22.742372013628483 -17.994774057192853
82 -20.948448233306408 -17.55742370467821
83 -20.144345674663782 -16.823073927842348
84 -19.30384018458426 -14.855082803515382
85 -18.663749208673835 -14.531424598833084
86 -17.737824626266956 -14.442420089224363
87 -19.2120482288301 -13.596012850960644
88 -14.180446343496442 -12.68135972540495
89 -18.369046879932284 -12.66418205637357
90 -17.423927697353065 -12.30017947419658
91 -16.347643211483955 -12.151904772081672
92 -16.207457024604082 -11.788852141676486
93 -15.601896479725838 -10.869989101210326
94 -15.935205765999854 -10.327681503524177
95 -13.325695995241404 -9.8572159761571
96 -12.941312458366156 -8.330116995310416
97 -13.26536257751286 -8.133195842510668
98 -14.116992853581905 -8.108197691178031
99 -9.720804058015347 -7.57539849177145
100 -9.324391547590494 -7.362443126623615
101 -8.999871601350605 -7.108327355338034
102 -9.566145374905318 -6.959063561385431
103 -9.342897260561585 -6.776946485018116
104 -8.648565318668261 -6.7220638398623045
105 -9.577476654201746 -6.719970621583102
106 -13.319308932870626 -6.535447341844848
107 -11.005531668663025 -6.51820418055673
108 -10.712749417871237 -5.615796733870542
109 -9.117066969163716 -5.34720210027791
110 -8.882836697623134 -5.078485007852753
111 -9.155943269841373 -5.027957977402961
112 -8.32128796260804 -4.827572916892203
113 -8.692625860217959 -4.63049541560991
114 -8.411801878362894 -4.230832004686763
115 -8.63701788475737 -4.031048624093466
116 -7.953962415456772 -3.3844671463622564
117 -8.128166631795466 -3.3322555012187633
118 -8.436660783365369 -2.6416623314910934
119 -6.8588943826034665 -1.9136196540088464
train accuracy: 1.0
validation accuracy: 1.0
